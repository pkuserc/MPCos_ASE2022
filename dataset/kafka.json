[
    {
        "id": 1,
        "code": "public static ChannelBuilder createChannelBuilder(AbstractConfig config, Time time, LogContext logContext) {\n    SecurityProtocol securityProtocol = SecurityProtocol.forName(config.getString(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG));\n    String clientSaslMechanism = config.getString(SaslConfigs.SASL_MECHANISM);\n    return ChannelBuilders.clientChannelBuilder(securityProtocol, JaasContext.Type.CLIENT, config, null,\n            clientSaslMechanism, time, true, logContext);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "channel",
            "builder",
            "from",
            "the",
            "provided",
            "configuration"
        ]
    },
    {
        "id": 2,
        "code": "static List<InetAddress> filterPreferredAddresses(InetAddress[] allAddresses) {\n    List<InetAddress> preferredAddresses = new ArrayList<>();\n    Class<? extends InetAddress> clazz = null;\n    for (InetAddress address : allAddresses) {\n        if (clazz == null) {\n            clazz = address.getClass();\n        }\n        if (clazz.isInstance(address)) {\n            preferredAddresses.add(address);\n        }\n    }\n    return preferredAddresses;\n}",
        "summary_tokens": [
            "return",
            "a",
            "list",
            "containing",
            "the",
            "first",
            "address",
            "in",
            "all",
            "addresses",
            "and",
            "subsequent",
            "addresses",
            "that",
            "are",
            "a",
            "subtype",
            "of",
            "the",
            "first",
            "address"
        ]
    },
    {
        "id": 3,
        "code": "public boolean canConnect(String id, long now) {\n    NodeConnectionState state = nodeState.get(id);\n    if (state == null)\n        return true;\n    else\n        return state.state.isDisconnected() &&\n               now - state.lastConnectAttemptMs >= state.reconnectBackoffMs;\n}",
        "summary_tokens": [
            "return",
            "true",
            "iff",
            "we",
            "can",
            "currently",
            "initiate",
            "a",
            "new",
            "connection"
        ]
    },
    {
        "id": 4,
        "code": "public boolean isBlackedOut(String id, long now) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null\n            && state.state.isDisconnected()\n            && now - state.lastConnectAttemptMs < state.reconnectBackoffMs;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "we",
            "are",
            "disconnected",
            "from",
            "the",
            "given",
            "node",
            "and",
            "can",
            "t",
            "re",
            "establish",
            "a",
            "connection",
            "yet"
        ]
    },
    {
        "id": 5,
        "code": "public long connectionDelay(String id, long now) {\n    NodeConnectionState state = nodeState.get(id);\n    if (state == null) return 0;\n\n    if (state.state == ConnectionState.CONNECTING) {\n        return connectionSetupTimeoutMs(id);\n    } else if (state.state.isDisconnected()) {\n        long timeWaited = now - state.lastConnectAttemptMs;\n        return Math.max(state.reconnectBackoffMs - timeWaited, 0);\n    } else {\n            \n            \n        return Long.MAX_VALUE;\n    }\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "milliseconds",
            "to",
            "wait",
            "based",
            "on",
            "the",
            "connection",
            "state",
            "before",
            "attempting",
            "to",
            "send",
            "data"
        ]
    },
    {
        "id": 6,
        "code": "public boolean isConnecting(String id) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null && state.state == ConnectionState.CONNECTING;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "a",
            "specific",
            "connection",
            "establishment",
            "is",
            "currently",
            "underway",
            "id",
            "the",
            "id",
            "of",
            "the",
            "node",
            "to",
            "check"
        ]
    },
    {
        "id": 7,
        "code": "public boolean isPreparingConnection(String id) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null &&\n            (state.state == ConnectionState.CONNECTING || state.state == ConnectionState.CHECKING_API_VERSIONS);\n}",
        "summary_tokens": [
            "check",
            "whether",
            "a",
            "connection",
            "is",
            "either",
            "being",
            "established",
            "or",
            "awaiting",
            "api",
            "version",
            "information"
        ]
    },
    {
        "id": 8,
        "code": "public void connecting(String id, long now, String host) {\n    NodeConnectionState connectionState = nodeState.get(id);\n    if (connectionState != null && connectionState.host().equals(host)) {\n        connectionState.lastConnectAttemptMs = now;\n        connectionState.state = ConnectionState.CONNECTING;\n            \n        connectionState.moveToNextAddress();\n        connectingNodes.add(id);\n        return;\n    } else if (connectionState != null) {\n        log.info(\"Hostname for node {} changed from {} to {}.\", id, connectionState.host(), host);\n    }\n\n        \n        \n    nodeState.put(id, new NodeConnectionState(ConnectionState.CONNECTING, now,\n            reconnectBackoff.backoff(0), connectionSetupTimeout.backoff(0), host, hostResolver));\n    connectingNodes.add(id);\n}",
        "summary_tokens": [
            "enter",
            "the",
            "connecting",
            "state",
            "for",
            "the",
            "given",
            "connection",
            "moving",
            "to",
            "a",
            "new",
            "resolved",
            "address",
            "if",
            "necessary"
        ]
    },
    {
        "id": 9,
        "code": "public InetAddress currentAddress(String id) throws UnknownHostException {\n    return nodeState(id).currentAddress();\n}",
        "summary_tokens": [
            "returns",
            "a",
            "resolved",
            "address",
            "for",
            "the",
            "given",
            "connection",
            "resolving",
            "it",
            "if",
            "necessary"
        ]
    },
    {
        "id": 10,
        "code": "public void disconnected(String id, long now) {\n    NodeConnectionState nodeState = nodeState(id);\n    nodeState.lastConnectAttemptMs = now;\n    updateReconnectBackoff(nodeState);\n    if (nodeState.state == ConnectionState.CONNECTING) {\n        updateConnectionSetupTimeout(nodeState);\n        connectingNodes.remove(id);\n    } else {\n        resetConnectionSetupTimeout(nodeState);\n        if (nodeState.state.isConnected()) {\n                \n                \n            nodeState.clearAddresses();\n        }\n    }\n    nodeState.state = ConnectionState.DISCONNECTED;\n}",
        "summary_tokens": [
            "enter",
            "the",
            "disconnected",
            "state",
            "for",
            "the",
            "given",
            "node"
        ]
    },
    {
        "id": 11,
        "code": "public void throttle(String id, long throttleUntilTimeMs) {\n    NodeConnectionState state = nodeState.get(id);\n        \n    if (state != null && state.throttleUntilTimeMs < throttleUntilTimeMs) {\n        state.throttleUntilTimeMs = throttleUntilTimeMs;\n    }\n}",
        "summary_tokens": [
            "indicate",
            "that",
            "the",
            "connection",
            "is",
            "throttled",
            "until",
            "the",
            "specified",
            "deadline"
        ]
    },
    {
        "id": 12,
        "code": "public long throttleDelayMs(String id, long now) {\n    NodeConnectionState state = nodeState.get(id);\n    if (state != null && state.throttleUntilTimeMs > now) {\n        return state.throttleUntilTimeMs - now;\n    } else {\n        return 0;\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "remaining",
            "throttling",
            "delay",
            "in",
            "milliseconds",
            "if",
            "throttling",
            "is",
            "in",
            "progress"
        ]
    },
    {
        "id": 13,
        "code": "public long pollDelayMs(String id, long now) {\n    long throttleDelayMs = throttleDelayMs(id, now);\n    if (isConnected(id) && throttleDelayMs > 0) {\n        return throttleDelayMs;\n    } else {\n        return connectionDelay(id, now);\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "number",
            "of",
            "milliseconds",
            "to",
            "wait",
            "based",
            "on",
            "the",
            "connection",
            "state",
            "and",
            "the",
            "throttle",
            "time",
            "before",
            "attempting",
            "to",
            "send",
            "data"
        ]
    },
    {
        "id": 14,
        "code": "public void checkingApiVersions(String id) {\n    NodeConnectionState nodeState = nodeState(id);\n    nodeState.state = ConnectionState.CHECKING_API_VERSIONS;\n    resetConnectionSetupTimeout(nodeState);\n    connectingNodes.remove(id);\n}",
        "summary_tokens": [
            "enter",
            "the",
            "checking",
            "api",
            "versions",
            "state",
            "for",
            "the",
            "given",
            "node"
        ]
    },
    {
        "id": 15,
        "code": "public void ready(String id) {\n    NodeConnectionState nodeState = nodeState(id);\n    nodeState.state = ConnectionState.READY;\n    nodeState.authenticationException = null;\n    resetReconnectBackoff(nodeState);\n    resetConnectionSetupTimeout(nodeState);\n    connectingNodes.remove(id);\n}",
        "summary_tokens": [
            "enter",
            "the",
            "ready",
            "state",
            "for",
            "the",
            "given",
            "node"
        ]
    },
    {
        "id": 16,
        "code": "public void authenticationFailed(String id, long now, AuthenticationException exception) {\n    NodeConnectionState nodeState = nodeState(id);\n    nodeState.authenticationException = exception;\n    nodeState.state = ConnectionState.AUTHENTICATION_FAILED;\n    nodeState.lastConnectAttemptMs = now;\n    updateReconnectBackoff(nodeState);\n}",
        "summary_tokens": [
            "enter",
            "the",
            "authentication",
            "failed",
            "state",
            "for",
            "the",
            "given",
            "node"
        ]
    },
    {
        "id": 17,
        "code": "public boolean isReady(String id, long now) {\n    return isReady(nodeState.get(id), now);\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "connection",
            "is",
            "in",
            "the",
            "ready",
            "state",
            "and",
            "currently",
            "not",
            "throttled"
        ]
    },
    {
        "id": 18,
        "code": "public boolean hasReadyNodes(long now) {\n    for (Map.Entry<String, NodeConnectionState> entry : nodeState.entrySet()) {\n        if (isReady(entry.getValue(), now)) {\n            return true;\n        }\n    }\n    return false;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "there",
            "is",
            "at",
            "least",
            "one",
            "node",
            "with",
            "connection",
            "in",
            "the",
            "ready",
            "state",
            "and",
            "not",
            "throttled"
        ]
    },
    {
        "id": 19,
        "code": "public boolean isConnected(String id) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null && state.state.isConnected();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "connection",
            "has",
            "been",
            "established",
            "id",
            "the",
            "id",
            "of",
            "the",
            "node",
            "to",
            "check"
        ]
    },
    {
        "id": 20,
        "code": "public boolean isDisconnected(String id) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null && state.state.isDisconnected();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "connection",
            "has",
            "been",
            "disconnected",
            "id",
            "the",
            "id",
            "of",
            "the",
            "node",
            "to",
            "check"
        ]
    },
    {
        "id": 21,
        "code": "public AuthenticationException authenticationException(String id) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null ? state.authenticationException : null;\n}",
        "summary_tokens": [
            "return",
            "authentication",
            "exception",
            "if",
            "an",
            "authentication",
            "error",
            "occurred",
            "id",
            "the",
            "id",
            "of",
            "the",
            "node",
            "to",
            "check"
        ]
    },
    {
        "id": 22,
        "code": "private void resetReconnectBackoff(NodeConnectionState nodeState) {\n    nodeState.failedAttempts = 0;\n    nodeState.reconnectBackoffMs = reconnectBackoff.backoff(0);\n}",
        "summary_tokens": [
            "resets",
            "the",
            "failure",
            "count",
            "for",
            "a",
            "node",
            "and",
            "sets",
            "the",
            "reconnect",
            "backoff",
            "to",
            "the",
            "base",
            "value",
            "configured",
            "via",
            "reconnect"
        ]
    },
    {
        "id": 23,
        "code": "private void resetConnectionSetupTimeout(NodeConnectionState nodeState) {\n    nodeState.failedConnectAttempts = 0;\n    nodeState.connectionSetupTimeoutMs = connectionSetupTimeout.backoff(0);\n}",
        "summary_tokens": [
            "resets",
            "the",
            "failure",
            "count",
            "for",
            "a",
            "node",
            "and",
            "sets",
            "the",
            "connection",
            "setup",
            "timeout",
            "to",
            "the",
            "base",
            "value",
            "configured",
            "via",
            "socket"
        ]
    },
    {
        "id": 24,
        "code": "private void updateReconnectBackoff(NodeConnectionState nodeState) {\n    nodeState.reconnectBackoffMs = reconnectBackoff.backoff(nodeState.failedAttempts);\n    nodeState.failedAttempts++;\n}",
        "summary_tokens": [
            "increment",
            "the",
            "failure",
            "counter",
            "update",
            "the",
            "node",
            "reconnect",
            "backoff",
            "exponentially",
            "and",
            "record",
            "the",
            "current",
            "timestamp"
        ]
    },
    {
        "id": 25,
        "code": "private void updateConnectionSetupTimeout(NodeConnectionState nodeState) {\n    nodeState.failedConnectAttempts++;\n    nodeState.connectionSetupTimeoutMs = connectionSetupTimeout.backoff(nodeState.failedConnectAttempts);\n}",
        "summary_tokens": [
            "increment",
            "the",
            "failure",
            "counter",
            "and",
            "update",
            "the",
            "node",
            "connection",
            "setup",
            "timeout",
            "exponentially"
        ]
    },
    {
        "id": 26,
        "code": "public void remove(String id) {\n    nodeState.remove(id);\n    connectingNodes.remove(id);\n}",
        "summary_tokens": [
            "remove",
            "the",
            "given",
            "node",
            "from",
            "the",
            "tracked",
            "connection",
            "states"
        ]
    },
    {
        "id": 27,
        "code": "public ConnectionState connectionState(String id) {\n    return nodeState(id).state;\n}",
        "summary_tokens": [
            "get",
            "the",
            "state",
            "of",
            "a",
            "given",
            "connection"
        ]
    },
    {
        "id": 28,
        "code": "private NodeConnectionState nodeState(String id) {\n    NodeConnectionState state = this.nodeState.get(id);\n    if (state == null)\n        throw new IllegalStateException(\"No entry found for connection \" + id);\n    return state;\n}",
        "summary_tokens": [
            "get",
            "the",
            "state",
            "of",
            "a",
            "given",
            "node"
        ]
    },
    {
        "id": 29,
        "code": "Set<String> connectingNodes() {\n    return this.connectingNodes;\n}",
        "summary_tokens": [
            "get",
            "the",
            "id",
            "set",
            "of",
            "nodes",
            "which",
            "are",
            "in",
            "connecting",
            "state"
        ]
    },
    {
        "id": 30,
        "code": "public long lastConnectAttemptMs(String id) {\n    NodeConnectionState nodeState = this.nodeState.get(id);\n    return nodeState == null ? 0 : nodeState.lastConnectAttemptMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "timestamp",
            "of",
            "the",
            "latest",
            "connection",
            "attempt",
            "of",
            "a",
            "given",
            "node",
            "id",
            "the",
            "connection",
            "to",
            "fetch",
            "the",
            "state",
            "for"
        ]
    },
    {
        "id": 31,
        "code": "public long connectionSetupTimeoutMs(String id) {\n    NodeConnectionState nodeState = this.nodeState(id);\n    return nodeState.connectionSetupTimeoutMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "socket",
            "connection",
            "setup",
            "timeout",
            "of",
            "the",
            "given",
            "node"
        ]
    },
    {
        "id": 32,
        "code": "public boolean isConnectionSetupTimeout(String id, long now) {\n    NodeConnectionState nodeState = this.nodeState(id);\n    if (nodeState.state != ConnectionState.CONNECTING)\n        throw new IllegalStateException(\"Node \" + id + \" is not in connecting state\");\n    return now - lastConnectAttemptMs(id) > connectionSetupTimeoutMs(id);\n}",
        "summary_tokens": [
            "test",
            "if",
            "the",
            "connection",
            "to",
            "the",
            "given",
            "node",
            "has",
            "reached",
            "its",
            "timeout",
            "id",
            "the",
            "connection",
            "to",
            "fetch",
            "the",
            "state",
            "for",
            "now",
            "the",
            "current",
            "time",
            "in",
            "ms"
        ]
    },
    {
        "id": 33,
        "code": "public List<String> nodesWithConnectionSetupTimeout(long now) {\n    return connectingNodes.stream()\n        .filter(id -> isConnectionSetupTimeout(id, now))\n        .collect(Collectors.toList());\n}",
        "summary_tokens": [
            "return",
            "the",
            "list",
            "of",
            "nodes",
            "whose",
            "connection",
            "setup",
            "has",
            "timed",
            "out"
        ]
    },
    {
        "id": 34,
        "code": "public static Map<String, Object> postProcessReconnectBackoffConfigs(AbstractConfig config,\n                                                Map<String, Object> parsedValues) {\n    HashMap<String, Object> rval = new HashMap<>();\n    Map<String, Object> originalConfig = config.originals();\n    if ((!originalConfig.containsKey(RECONNECT_BACKOFF_MAX_MS_CONFIG)) &&\n        originalConfig.containsKey(RECONNECT_BACKOFF_MS_CONFIG)) {\n        log.debug(\"Disabling exponential reconnect backoff because {} is set, but {} is not.\",\n                RECONNECT_BACKOFF_MS_CONFIG, RECONNECT_BACKOFF_MAX_MS_CONFIG);\n        rval.put(RECONNECT_BACKOFF_MAX_MS_CONFIG, parsedValues.get(RECONNECT_BACKOFF_MS_CONFIG));\n    }\n    return rval;\n}",
        "summary_tokens": [
            "postprocess",
            "the",
            "configuration",
            "so",
            "that",
            "exponential",
            "backoff",
            "is",
            "disabled",
            "when",
            "reconnect",
            "backoff",
            "is",
            "explicitly",
            "configured",
            "but",
            "the",
            "maximum",
            "reconnect",
            "backoff",
            "is",
            "not",
            "explicitly",
            "configured"
        ]
    },
    {
        "id": 35,
        "code": "public Builder newBuilder(int size, boolean copySessionPartitions) {\n    return new Builder(size, copySessionPartitions);\n}",
        "summary_tokens": [
            "a",
            "builder",
            "that",
            "allows",
            "for",
            "presizing",
            "the",
            "partition",
            "data",
            "hashmap",
            "and",
            "avoiding",
            "making",
            "a",
            "secondary",
            "copy",
            "of",
            "the",
            "session",
            "partitions",
            "in",
            "cases",
            "where",
            "this",
            "is",
            "not",
            "necessarily"
        ]
    },
    {
        "id": 36,
        "code": "static <T> Set<T> findMissing(Set<T> toFind, Set<T> toSearch) {\n    Set<T> ret = new LinkedHashSet<>();\n    for (T toFindItem: toFind) {\n        if (!toSearch.contains(toFindItem)) {\n            ret.add(toFindItem);\n        }\n    }\n    return ret;\n}",
        "summary_tokens": [
            "return",
            "missing",
            "items",
            "which",
            "are",
            "expected",
            "to",
            "be",
            "in",
            "a",
            "particular",
            "set",
            "but",
            "which",
            "are",
            "not"
        ]
    },
    {
        "id": 37,
        "code": "String verifyFullFetchResponsePartitions(Set<TopicPartition> topicPartitions, Set<Uuid> ids, short version) {\n    StringBuilder bld = new StringBuilder();\n    Set<TopicPartition> extra =\n        findMissing(topicPartitions, sessionPartitions.keySet());\n    Set<TopicPartition> omitted =\n        findMissing(sessionPartitions.keySet(), topicPartitions);\n    Set<Uuid> extraIds = new HashSet<>();\n    if (version >= 13) {\n        extraIds = findMissing(ids, sessionTopicNames.keySet());\n    }\n    if (!omitted.isEmpty()) {\n        bld.append(\"omittedPartitions=(\").append(Utils.join(omitted, \", \")).append(\", \");\n    }\n    if (!extra.isEmpty()) {\n        bld.append(\"extraPartitions=(\").append(Utils.join(extra, \", \")).append(\", \");\n    }\n    if (!extraIds.isEmpty()) {\n        bld.append(\"extraIds=(\").append(Utils.join(extraIds, \", \")).append(\", \");\n    }\n    if ((!omitted.isEmpty()) || (!extra.isEmpty()) || (!extraIds.isEmpty())) {\n        bld.append(\"response=(\").append(Utils.join(topicPartitions, \", \")).append(\")\");\n        return bld.toString();\n    }\n    return null;\n}",
        "summary_tokens": [
            "verify",
            "that",
            "a",
            "full",
            "fetch",
            "response",
            "contains",
            "all",
            "the",
            "partitions",
            "in",
            "the",
            "fetch",
            "session"
        ]
    },
    {
        "id": 38,
        "code": "String verifyIncrementalFetchResponsePartitions(Set<TopicPartition> topicPartitions, Set<Uuid> ids, short version) {\n    Set<Uuid> extraIds = new HashSet<>();\n    if (version >= 13) {\n        extraIds = findMissing(ids, sessionTopicNames.keySet());\n    }\n    Set<TopicPartition> extra =\n        findMissing(topicPartitions, sessionPartitions.keySet());\n    StringBuilder bld = new StringBuilder();\n    if (!extra.isEmpty())\n        bld.append(\"extraPartitions=(\").append(Utils.join(extra, \", \")).append(\"), \");\n    if (!extraIds.isEmpty())\n        bld.append(\"extraIds=(\").append(Utils.join(extraIds, \", \")).append(\"), \");\n    if ((!extra.isEmpty()) || (!extraIds.isEmpty())) {\n        bld.append(\"response=(\").append(Utils.join(topicPartitions, \", \")).append(\")\");\n        return bld.toString();\n    }\n    return null;\n}",
        "summary_tokens": [
            "verify",
            "that",
            "the",
            "partitions",
            "in",
            "an",
            "incremental",
            "fetch",
            "response",
            "are",
            "contained",
            "in",
            "the",
            "session"
        ]
    },
    {
        "id": 39,
        "code": "private String responseDataToLogString(Set<TopicPartition> topicPartitions) {\n    if (!log.isTraceEnabled()) {\n        int implied = sessionPartitions.size() - topicPartitions.size();\n        if (implied > 0) {\n            return String.format(\" with %d response partition(s), %d implied partition(s)\",\n                topicPartitions.size(), implied);\n        } else {\n            return String.format(\" with %d response partition(s)\",\n                topicPartitions.size());\n        }\n    }\n    StringBuilder bld = new StringBuilder();\n    bld.append(\" with response=(\").\n        append(Utils.join(topicPartitions, \", \")).\n        append(\")\");\n    String prefix = \", implied=(\";\n    String suffix = \"\";\n    for (TopicPartition partition : sessionPartitions.keySet()) {\n        if (!topicPartitions.contains(partition)) {\n            bld.append(prefix);\n            bld.append(partition);\n            prefix = \", \";\n            suffix = \")\";\n        }\n    }\n    bld.append(suffix);\n    return bld.toString();\n}",
        "summary_tokens": [
            "create",
            "a",
            "string",
            "describing",
            "the",
            "partitions",
            "in",
            "a",
            "fetch",
            "response"
        ]
    },
    {
        "id": 40,
        "code": "public boolean handleResponse(FetchResponse response, short version) {\n    if (response.error() != Errors.NONE) {\n        log.info(\"Node {} was unable to process the fetch request with {}: {}.\",\n            node, nextMetadata, response.error());\n        if (response.error() == Errors.FETCH_SESSION_ID_NOT_FOUND) {\n            nextMetadata = FetchMetadata.INITIAL;\n        } else {\n            nextMetadata = nextMetadata.nextCloseExisting();\n        }\n        return false;\n    }\n    Set<TopicPartition> topicPartitions = response.responseData(sessionTopicNames, version).keySet();\n    if (nextMetadata.isFull()) {\n        if (topicPartitions.isEmpty() && response.throttleTimeMs() > 0) {\n                \n                \n                \n                \n                \n                \n            if (log.isDebugEnabled()) {\n                log.debug(\"Node {} sent a empty full fetch response to indicate that this \" +\n                    \"client should be throttled for {} ms.\", node, response.throttleTimeMs());\n            }\n            nextMetadata = FetchMetadata.INITIAL;\n            return false;\n        }\n        String problem = verifyFullFetchResponsePartitions(topicPartitions, response.topicIds(), version);\n        if (problem != null) {\n            log.info(\"Node {} sent an invalid full fetch response with {}\", node, problem);\n            nextMetadata = FetchMetadata.INITIAL;\n            return false;\n        } else if (response.sessionId() == INVALID_SESSION_ID) {\n            if (log.isDebugEnabled())\n                log.debug(\"Node {} sent a full fetch response{}\", node, responseDataToLogString(topicPartitions));\n            nextMetadata = FetchMetadata.INITIAL;\n            return true;\n        } else {\n                \n            if (log.isDebugEnabled())\n                log.debug(\"Node {} sent a full fetch response that created a new incremental \" +\n                        \"fetch session {}{}\", node, response.sessionId(), responseDataToLogString(topicPartitions));\n            nextMetadata = FetchMetadata.newIncremental(response.sessionId());\n            return true;\n        }\n    } else {\n        String problem = verifyIncrementalFetchResponsePartitions(topicPartitions, response.topicIds(), version);\n        if (problem != null) {\n            log.info(\"Node {} sent an invalid incremental fetch response with {}\", node, problem);\n            nextMetadata = nextMetadata.nextCloseExisting();\n            return false;\n        } else if (response.sessionId() == INVALID_SESSION_ID) {\n                \n            if (log.isDebugEnabled())\n                log.debug(\"Node {} sent an incremental fetch response closing session {}{}\",\n                        node, nextMetadata.sessionId(), responseDataToLogString(topicPartitions));\n            nextMetadata = FetchMetadata.INITIAL;\n            return true;\n        } else {\n                \n                \n                \n            if (log.isDebugEnabled())\n                log.debug(\"Node {} sent an incremental fetch response with throttleTimeMs = {} \" +\n                    \"for session {}{}\", node, response.throttleTimeMs(), response.sessionId(),\n                    responseDataToLogString(topicPartitions));\n            nextMetadata = nextMetadata.nextIncremental();\n            return true;\n        }\n    }\n}",
        "summary_tokens": [
            "handle",
            "the",
            "fetch",
            "response"
        ]
    },
    {
        "id": 41,
        "code": "public void handleError(Throwable t) {\n    log.info(\"Error sending fetch request {} to node {}:\", nextMetadata, node, t);\n    nextMetadata = nextMetadata.nextCloseExisting();\n}",
        "summary_tokens": [
            "handle",
            "an",
            "error",
            "sending",
            "the",
            "prepared",
            "request"
        ]
    },
    {
        "id": 42,
        "code": "public void add(NetworkClient.InFlightRequest request) {\n    String destination = request.destination;\n    Deque<NetworkClient.InFlightRequest> reqs = this.requests.get(destination);\n    if (reqs == null) {\n        reqs = new ArrayDeque<>();\n        this.requests.put(destination, reqs);\n    }\n    reqs.addFirst(request);\n    inFlightRequestCount.incrementAndGet();\n}",
        "summary_tokens": [
            "add",
            "the",
            "given",
            "request",
            "to",
            "the",
            "queue",
            "for",
            "the",
            "connection",
            "it",
            "was",
            "directed",
            "to"
        ]
    },
    {
        "id": 43,
        "code": "private Deque<NetworkClient.InFlightRequest> requestQueue(String node) {\n    Deque<NetworkClient.InFlightRequest> reqs = requests.get(node);\n    if (reqs == null || reqs.isEmpty())\n        throw new IllegalStateException(\"There are no in-flight requests for node \" + node);\n    return reqs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "request",
            "queue",
            "for",
            "the",
            "given",
            "node"
        ]
    },
    {
        "id": 44,
        "code": "public NetworkClient.InFlightRequest completeNext(String node) {\n    NetworkClient.InFlightRequest inFlightRequest = requestQueue(node).pollLast();\n    inFlightRequestCount.decrementAndGet();\n    return inFlightRequest;\n}",
        "summary_tokens": [
            "get",
            "the",
            "oldest",
            "request",
            "the",
            "one",
            "that",
            "will",
            "be",
            "completed",
            "next",
            "for",
            "the",
            "given",
            "node"
        ]
    },
    {
        "id": 45,
        "code": "public NetworkClient.InFlightRequest lastSent(String node) {\n    return requestQueue(node).peekFirst();\n}",
        "summary_tokens": [
            "get",
            "the",
            "last",
            "request",
            "we",
            "sent",
            "to",
            "the",
            "given",
            "node",
            "but",
            "don",
            "t",
            "remove",
            "it",
            "from",
            "the",
            "queue",
            "node",
            "the",
            "node",
            "id"
        ]
    },
    {
        "id": 46,
        "code": "public NetworkClient.InFlightRequest completeLastSent(String node) {\n    NetworkClient.InFlightRequest inFlightRequest = requestQueue(node).pollFirst();\n    inFlightRequestCount.decrementAndGet();\n    return inFlightRequest;\n}",
        "summary_tokens": [
            "complete",
            "the",
            "last",
            "request",
            "that",
            "was",
            "sent",
            "to",
            "a",
            "particular",
            "node"
        ]
    },
    {
        "id": 47,
        "code": "public boolean canSendMore(String node) {\n    Deque<NetworkClient.InFlightRequest> queue = requests.get(node);\n    return queue == null || queue.isEmpty() ||\n           (queue.peekFirst().send.completed() && queue.size() < this.maxInFlightRequestsPerConnection);\n}",
        "summary_tokens": [
            "can",
            "we",
            "send",
            "more",
            "requests",
            "to",
            "this",
            "node"
        ]
    },
    {
        "id": 48,
        "code": "public int count() {\n    return inFlightRequestCount.get();\n}",
        "summary_tokens": [
            "count",
            "all",
            "in",
            "flight",
            "requests",
            "for",
            "all",
            "nodes"
        ]
    },
    {
        "id": 49,
        "code": "public boolean isEmpty() {\n    for (Deque<NetworkClient.InFlightRequest> deque : this.requests.values()) {\n        if (!deque.isEmpty())\n            return false;\n    }\n    return true;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "there",
            "is",
            "no",
            "in",
            "flight",
            "request",
            "and",
            "false",
            "otherwise"
        ]
    },
    {
        "id": 50,
        "code": "public Iterable<NetworkClient.InFlightRequest> clearAll(String node) {\n    Deque<NetworkClient.InFlightRequest> reqs = requests.get(node);\n    if (reqs == null) {\n        return Collections.emptyList();\n    } else {\n        final Deque<NetworkClient.InFlightRequest> clearedRequests = requests.remove(node);\n        inFlightRequestCount.getAndAdd(-clearedRequests.size());\n        return () -> clearedRequests.descendingIterator();\n    }\n}",
        "summary_tokens": [
            "clear",
            "out",
            "all",
            "the",
            "in",
            "flight",
            "requests",
            "for",
            "the",
            "given",
            "node",
            "and",
            "return",
            "them"
        ]
    },
    {
        "id": 51,
        "code": "public List<String> nodesWithTimedOutRequests(long now) {\n    List<String> nodeIds = new ArrayList<>();\n    for (Map.Entry<String, Deque<NetworkClient.InFlightRequest>> requestEntry : requests.entrySet()) {\n        String nodeId = requestEntry.getKey();\n        Deque<NetworkClient.InFlightRequest> deque = requestEntry.getValue();\n        if (hasExpiredRequest(now, deque))\n            nodeIds.add(nodeId);\n    }\n    return nodeIds;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "list",
            "of",
            "nodes",
            "with",
            "pending",
            "in",
            "flight",
            "request",
            "that",
            "need",
            "to",
            "be",
            "timed",
            "out"
        ]
    },
    {
        "id": 52,
        "code": "public synchronized Cluster fetch() {\n    return cache.cluster();\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "cluster",
            "info",
            "without",
            "blocking"
        ]
    },
    {
        "id": 53,
        "code": "public synchronized long timeToAllowUpdate(long nowMs) {\n    return Math.max(this.lastRefreshMs + this.refreshBackoffMs - nowMs, 0);\n}",
        "summary_tokens": [
            "return",
            "the",
            "next",
            "time",
            "when",
            "the",
            "current",
            "cluster",
            "info",
            "can",
            "be",
            "updated",
            "i"
        ]
    },
    {
        "id": 54,
        "code": "public synchronized long timeToNextUpdate(long nowMs) {\n    long timeToExpire = updateRequested() ? 0 : Math.max(this.lastSuccessfulRefreshMs + this.metadataExpireMs - nowMs, 0);\n    return Math.max(timeToExpire, timeToAllowUpdate(nowMs));\n}",
        "summary_tokens": [
            "the",
            "next",
            "time",
            "to",
            "update",
            "the",
            "cluster",
            "info",
            "is",
            "the",
            "maximum",
            "of",
            "the",
            "time",
            "the",
            "current",
            "info",
            "will",
            "expire",
            "and",
            "the",
            "time",
            "the",
            "current",
            "info",
            "can",
            "be",
            "updated",
            "i"
        ]
    },
    {
        "id": 55,
        "code": "public synchronized int requestUpdate() {\n    this.needFullUpdate = true;\n    return this.updateVersion;\n}",
        "summary_tokens": [
            "request",
            "an",
            "update",
            "of",
            "the",
            "current",
            "cluster",
            "metadata",
            "info",
            "return",
            "the",
            "current",
            "update",
            "version",
            "before",
            "the",
            "update"
        ]
    },
    {
        "id": 56,
        "code": "public synchronized boolean updateLastSeenEpochIfNewer(TopicPartition topicPartition, int leaderEpoch) {\n    Objects.requireNonNull(topicPartition, \"TopicPartition cannot be null\");\n    if (leaderEpoch < 0)\n        throw new IllegalArgumentException(\"Invalid leader epoch \" + leaderEpoch + \" (must be non-negative)\");\n\n    Integer oldEpoch = lastSeenLeaderEpochs.get(topicPartition);\n    log.trace(\"Determining if we should replace existing epoch {} with new epoch {} for partition {}\", oldEpoch, leaderEpoch, topicPartition);\n\n    final boolean updated;\n    if (oldEpoch == null) {\n        log.debug(\"Not replacing null epoch with new epoch {} for partition {}\", leaderEpoch, topicPartition);\n        updated = false;\n    } else if (leaderEpoch > oldEpoch) {\n        log.debug(\"Updating last seen epoch from {} to {} for partition {}\", oldEpoch, leaderEpoch, topicPartition);\n        lastSeenLeaderEpochs.put(topicPartition, leaderEpoch);\n        updated = true;\n    } else {\n        log.debug(\"Not replacing existing epoch {} with new epoch {} for partition {}\", oldEpoch, leaderEpoch, topicPartition);\n        updated = false;\n    }\n\n    this.needFullUpdate = this.needFullUpdate || updated;\n    return updated;\n}",
        "summary_tokens": [
            "request",
            "an",
            "update",
            "for",
            "the",
            "partition",
            "metadata",
            "iff",
            "we",
            "have",
            "seen",
            "a",
            "newer",
            "leader",
            "epoch"
        ]
    },
    {
        "id": 57,
        "code": "public synchronized boolean updateRequested() {\n    return this.needFullUpdate || this.needPartialUpdate;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "an",
            "update",
            "has",
            "been",
            "explicitly",
            "requested"
        ]
    },
    {
        "id": 58,
        "code": "synchronized Optional<MetadataResponse.PartitionMetadata> partitionMetadataIfCurrent(TopicPartition topicPartition) {\n    Integer epoch = lastSeenLeaderEpochs.get(topicPartition);\n    Optional<MetadataResponse.PartitionMetadata> partitionMetadata = cache.partitionMetadata(topicPartition);\n    if (epoch == null) {\n            \n        return partitionMetadata;\n    } else {\n        return partitionMetadata.filter(metadata ->\n                metadata.leaderEpoch.orElse(NO_PARTITION_LEADER_EPOCH).equals(epoch));\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "cached",
            "partition",
            "info",
            "if",
            "it",
            "exists",
            "and",
            "a",
            "newer",
            "leader",
            "epoch",
            "isn",
            "t",
            "known",
            "about"
        ]
    },
    {
        "id": 59,
        "code": "public synchronized Map<String, Uuid> topicIds() {\n    return cache.topicIds();\n}",
        "summary_tokens": [
            "a",
            "mapping",
            "from",
            "topic",
            "names",
            "to",
            "topic",
            "ids",
            "for",
            "all",
            "topics",
            "with",
            "valid",
            "ids",
            "in",
            "the",
            "cache"
        ]
    },
    {
        "id": 60,
        "code": "public synchronized void updateWithCurrentRequestVersion(MetadataResponse response, boolean isPartialUpdate, long nowMs) {\n    this.update(this.requestVersion, response, isPartialUpdate, nowMs);\n}",
        "summary_tokens": [
            "update",
            "metadata",
            "assuming",
            "the",
            "current",
            "request",
            "version"
        ]
    },
    {
        "id": 61,
        "code": "public synchronized void update(int requestVersion, MetadataResponse response, boolean isPartialUpdate, long nowMs) {\n    Objects.requireNonNull(response, \"Metadata response cannot be null\");\n    if (isClosed())\n        throw new IllegalStateException(\"Update requested after metadata close\");\n\n    this.needPartialUpdate = requestVersion < this.requestVersion;\n    this.lastRefreshMs = nowMs;\n    this.updateVersion += 1;\n    if (!isPartialUpdate) {\n        this.needFullUpdate = false;\n        this.lastSuccessfulRefreshMs = nowMs;\n    }\n\n    String previousClusterId = cache.clusterResource().clusterId();\n\n    this.cache = handleMetadataResponse(response, isPartialUpdate, nowMs);\n\n    Cluster cluster = cache.cluster();\n    maybeSetMetadataError(cluster);\n\n    this.lastSeenLeaderEpochs.keySet().removeIf(tp -> !retainTopic(tp.topic(), false, nowMs));\n\n    String newClusterId = cache.clusterResource().clusterId();\n    if (!Objects.equals(previousClusterId, newClusterId)) {\n        log.info(\"Cluster ID: {}\", newClusterId);\n    }\n    clusterResourceListeners.onUpdate(cache.clusterResource());\n\n    log.debug(\"Updated cluster metadata updateVersion {} to {}\", this.updateVersion, this.cache);\n}",
        "summary_tokens": [
            "updates",
            "the",
            "cluster",
            "metadata"
        ]
    },
    {
        "id": 62,
        "code": "private MetadataCache handleMetadataResponse(MetadataResponse metadataResponse, boolean isPartialUpdate, long nowMs) {\n        \n    Set<String> topics = new HashSet<>();\n\n        \n    Set<String> internalTopics = new HashSet<>();\n    Set<String> unauthorizedTopics = new HashSet<>();\n    Set<String> invalidTopics = new HashSet<>();\n\n    List<MetadataResponse.PartitionMetadata> partitions = new ArrayList<>();\n    Map<String, Uuid> topicIds = new HashMap<>();\n    Map<String, Uuid> oldTopicIds = cache.topicIds();\n    for (MetadataResponse.TopicMetadata metadata : metadataResponse.topicMetadata()) {\n        String topicName = metadata.topic();\n        Uuid topicId = metadata.topicId();\n        topics.add(topicName);\n            \n        Uuid oldTopicId = null;\n        if (!Uuid.ZERO_UUID.equals(topicId)) {\n            topicIds.put(topicName, topicId);\n            oldTopicId = oldTopicIds.get(topicName);\n        } else {\n            topicId = null;\n        }\n\n        if (!retainTopic(topicName, metadata.isInternal(), nowMs))\n            continue;\n\n        if (metadata.isInternal())\n            internalTopics.add(topicName);\n\n        if (metadata.error() == Errors.NONE) {\n            for (MetadataResponse.PartitionMetadata partitionMetadata : metadata.partitionMetadata()) {\n                    \n                    \n                updateLatestMetadata(partitionMetadata, metadataResponse.hasReliableLeaderEpochs(), topicId, oldTopicId)\n                    .ifPresent(partitions::add);\n\n                if (partitionMetadata.error.exception() instanceof InvalidMetadataException) {\n                    log.debug(\"Requesting metadata update for partition {} due to error {}\",\n                            partitionMetadata.topicPartition, partitionMetadata.error);\n                    requestUpdate();\n                }\n            }\n        } else {\n            if (metadata.error().exception() instanceof InvalidMetadataException) {\n                log.debug(\"Requesting metadata update for topic {} due to error {}\", topicName, metadata.error());\n                requestUpdate();\n            }\n\n            if (metadata.error() == Errors.INVALID_TOPIC_EXCEPTION)\n                invalidTopics.add(topicName);\n            else if (metadata.error() == Errors.TOPIC_AUTHORIZATION_FAILED)\n                unauthorizedTopics.add(topicName);\n        }\n    }\n\n    Map<Integer, Node> nodes = metadataResponse.brokersById();\n    if (isPartialUpdate)\n        return this.cache.mergeWith(metadataResponse.clusterId(), nodes, partitions,\n            unauthorizedTopics, invalidTopics, internalTopics, metadataResponse.controller(), topicIds,\n            (topic, isInternal) -> !topics.contains(topic) && retainTopic(topic, isInternal, nowMs));\n    else\n        return new MetadataCache(metadataResponse.clusterId(), nodes, partitions,\n            unauthorizedTopics, invalidTopics, internalTopics, metadataResponse.controller(), topicIds);\n}",
        "summary_tokens": [
            "transform",
            "a",
            "metadata",
            "response",
            "into",
            "a",
            "new",
            "metadata",
            "cache",
            "instance"
        ]
    },
    {
        "id": 63,
        "code": "private Optional<MetadataResponse.PartitionMetadata> updateLatestMetadata(\n        MetadataResponse.PartitionMetadata partitionMetadata,\n        boolean hasReliableLeaderEpoch,\n        Uuid topicId,\n        Uuid oldTopicId) {\n    TopicPartition tp = partitionMetadata.topicPartition;\n    if (hasReliableLeaderEpoch && partitionMetadata.leaderEpoch.isPresent()) {\n        int newEpoch = partitionMetadata.leaderEpoch.get();\n        Integer currentEpoch = lastSeenLeaderEpochs.get(tp);\n        if (topicId != null && !topicId.equals(oldTopicId)) {\n                \n                \n                \n                \n            log.info(\"Resetting the last seen epoch of partition {} to {} since the associated topicId changed from {} to {}\",\n                     tp, newEpoch, oldTopicId, topicId);\n            lastSeenLeaderEpochs.put(tp, newEpoch);\n            return Optional.of(partitionMetadata);\n        } else if (currentEpoch == null || newEpoch >= currentEpoch) {\n                \n            log.debug(\"Updating last seen epoch for partition {} from {} to epoch {} from new metadata\", tp, currentEpoch, newEpoch);\n            lastSeenLeaderEpochs.put(tp, newEpoch);\n            return Optional.of(partitionMetadata);\n        } else {\n                \n            log.debug(\"Got metadata for an older epoch {} (current is {}) for partition {}, not updating\", newEpoch, currentEpoch, tp);\n            return cache.partitionMetadata(tp);\n        }\n    } else {\n            \n        lastSeenLeaderEpochs.remove(tp);\n        return Optional.of(partitionMetadata.withoutLeaderEpoch());\n    }\n}",
        "summary_tokens": [
            "compute",
            "the",
            "latest",
            "partition",
            "metadata",
            "to",
            "cache",
            "given",
            "ordering",
            "by",
            "leader",
            "epochs",
            "if",
            "both",
            "available",
            "and",
            "reliable",
            "and",
            "whether",
            "the",
            "topic",
            "id",
            "changed"
        ]
    },
    {
        "id": 64,
        "code": "public synchronized void maybeThrowAnyException() {\n    clearErrorsAndMaybeThrowException(this::recoverableException);\n}",
        "summary_tokens": [
            "if",
            "any",
            "non",
            "retriable",
            "exceptions",
            "were",
            "encountered",
            "during",
            "metadata",
            "update",
            "clear",
            "and",
            "throw",
            "the",
            "exception"
        ]
    },
    {
        "id": 65,
        "code": "protected synchronized void maybeThrowFatalException() {\n    KafkaException metadataException = this.fatalException;\n    if (metadataException != null) {\n        fatalException = null;\n        throw metadataException;\n    }\n}",
        "summary_tokens": [
            "if",
            "any",
            "fatal",
            "exceptions",
            "were",
            "encountered",
            "during",
            "metadata",
            "update",
            "throw",
            "the",
            "exception"
        ]
    },
    {
        "id": 66,
        "code": "public synchronized void maybeThrowExceptionForTopic(String topic) {\n    clearErrorsAndMaybeThrowException(() -> recoverableExceptionForTopic(topic));\n}",
        "summary_tokens": [
            "if",
            "any",
            "non",
            "retriable",
            "exceptions",
            "were",
            "encountered",
            "during",
            "metadata",
            "update",
            "throw",
            "exception",
            "if",
            "the",
            "exception",
            "is",
            "fatal",
            "or",
            "related",
            "to",
            "the",
            "specified",
            "topic"
        ]
    },
    {
        "id": 67,
        "code": "public synchronized void failedUpdate(long now) {\n    this.lastRefreshMs = now;\n}",
        "summary_tokens": [
            "record",
            "an",
            "attempt",
            "to",
            "update",
            "the",
            "metadata",
            "that",
            "failed"
        ]
    },
    {
        "id": 68,
        "code": "public synchronized void fatalError(KafkaException exception) {\n    this.fatalException = exception;\n}",
        "summary_tokens": [
            "propagate",
            "a",
            "fatal",
            "error",
            "which",
            "affects",
            "the",
            "ability",
            "to",
            "fetch",
            "metadata",
            "for",
            "the",
            "cluster"
        ]
    },
    {
        "id": 69,
        "code": "public synchronized int updateVersion() {\n    return this.updateVersion;\n}",
        "summary_tokens": [
            "the",
            "current",
            "metadata",
            "update",
            "version"
        ]
    },
    {
        "id": 70,
        "code": "public synchronized long lastSuccessfulUpdate() {\n    return this.lastSuccessfulRefreshMs;\n}",
        "summary_tokens": [
            "the",
            "last",
            "time",
            "metadata",
            "was",
            "successfully",
            "updated"
        ]
    },
    {
        "id": 71,
        "code": "public synchronized void close() {\n    this.isClosed = true;\n}",
        "summary_tokens": [
            "close",
            "this",
            "metadata",
            "instance",
            "to",
            "indicate",
            "that",
            "metadata",
            "updates",
            "are",
            "no",
            "longer",
            "possible"
        ]
    },
    {
        "id": 72,
        "code": "public synchronized boolean isClosed() {\n    return this.isClosed;\n}",
        "summary_tokens": [
            "check",
            "if",
            "this",
            "metadata",
            "instance",
            "has",
            "been",
            "closed"
        ]
    },
    {
        "id": 73,
        "code": "protected MetadataRequest.Builder newMetadataRequestBuilder() {\n    return MetadataRequest.Builder.allTopics();\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "metadata",
            "request",
            "builder",
            "for",
            "fetching",
            "cluster",
            "data",
            "and",
            "all",
            "active",
            "topics"
        ]
    },
    {
        "id": 74,
        "code": "protected MetadataRequest.Builder newMetadataRequestBuilderForNewTopics() {\n    return null;\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "metadata",
            "request",
            "builder",
            "for",
            "fetching",
            "cluster",
            "data",
            "and",
            "any",
            "uncached",
            "topics",
            "otherwise",
            "null",
            "if",
            "the",
            "functionality",
            "is",
            "not",
            "supported"
        ]
    },
    {
        "id": 75,
        "code": "MetadataCache mergeWith(String newClusterId,\n                        Map<Integer, Node> newNodes,\n                        Collection<PartitionMetadata> addPartitions,\n                        Set<String> addUnauthorizedTopics,\n                        Set<String> addInvalidTopics,\n                        Set<String> addInternalTopics,\n                        Node newController,\n                        Map<String, Uuid> topicIds,\n                        BiPredicate<String, Boolean> retainTopic) {\n\n    Predicate<String> shouldRetainTopic = topic -> retainTopic.test(topic, internalTopics.contains(topic));\n\n    Map<TopicPartition, PartitionMetadata> newMetadataByPartition = new HashMap<>(addPartitions.size());\n\n        \n        \n        \n    Map<String, Uuid> newTopicIds = topicIds.entrySet().stream()\n            .filter(entry -> shouldRetainTopic.test(entry.getKey()))\n            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    for (PartitionMetadata partition : addPartitions) {\n        newMetadataByPartition.put(partition.topicPartition, partition);\n        Uuid id = topicIds.get(partition.topic());\n        if (id != null)\n            newTopicIds.put(partition.topic(), id);\n        else\n                \n            newTopicIds.remove(partition.topic());\n    }\n    for (Map.Entry<TopicPartition, PartitionMetadata> entry : metadataByPartition.entrySet()) {\n        if (shouldRetainTopic.test(entry.getKey().topic())) {\n            newMetadataByPartition.putIfAbsent(entry.getKey(), entry.getValue());\n        }\n    }\n\n    Set<String> newUnauthorizedTopics = fillSet(addUnauthorizedTopics, unauthorizedTopics, shouldRetainTopic);\n    Set<String> newInvalidTopics = fillSet(addInvalidTopics, invalidTopics, shouldRetainTopic);\n    Set<String> newInternalTopics = fillSet(addInternalTopics, internalTopics, shouldRetainTopic);\n\n    return new MetadataCache(newClusterId, newNodes, newMetadataByPartition.values(), newUnauthorizedTopics,\n            newInvalidTopics, newInternalTopics, newController, newTopicIds);\n}",
        "summary_tokens": [
            "merges",
            "the",
            "metadata",
            "cache",
            "s",
            "contents",
            "with",
            "the",
            "provided",
            "metadata",
            "returning",
            "a",
            "new",
            "metadata",
            "cache"
        ]
    },
    {
        "id": 76,
        "code": "private static <T> Set<T> fillSet(Set<T> baseSet, Set<T> fillSet, Predicate<T> predicate) {\n    Set<T> result = new HashSet<>(baseSet);\n    for (T element : fillSet) {\n        if (predicate.test(element)) {\n            result.add(element);\n        }\n    }\n    return result;\n}",
        "summary_tokens": [
            "copies",
            "base",
            "set",
            "and",
            "adds",
            "all",
            "non",
            "existent",
            "elements",
            "in",
            "fill",
            "set",
            "such",
            "that",
            "predicate",
            "is",
            "true"
        ]
    },
    {
        "id": 77,
        "code": "public boolean ready(Node node, long now) {\n    if (node.isEmpty())\n        throw new IllegalArgumentException(\"Cannot connect to empty node \" + node);\n\n    if (isReady(node, now))\n        return true;\n\n    if (connectionStates.canConnect(node.idString(), now))\n            \n        initiateConnect(node, now);\n\n    return false;\n}",
        "summary_tokens": [
            "begin",
            "connecting",
            "to",
            "the",
            "given",
            "node",
            "return",
            "true",
            "if",
            "we",
            "are",
            "already",
            "connected",
            "and",
            "ready",
            "to",
            "send",
            "to",
            "that",
            "node"
        ]
    },
    {
        "id": 78,
        "code": "public void disconnect(String nodeId) {\n    if (connectionStates.isDisconnected(nodeId)) {\n        log.debug(\"Client requested disconnect from node {}, which is already disconnected\", nodeId);\n        return;\n    }\n\n    log.info(\"Client requested disconnect from node {}\", nodeId);\n    selector.close(nodeId);\n    long now = time.milliseconds();\n    cancelInFlightRequests(nodeId, now, abortedSends);\n    connectionStates.disconnected(nodeId, now);\n}",
        "summary_tokens": [
            "disconnects",
            "the",
            "connection",
            "to",
            "a",
            "particular",
            "node",
            "if",
            "there",
            "is",
            "one"
        ]
    },
    {
        "id": 79,
        "code": "public void close() {\n    state.compareAndSet(State.ACTIVE, State.CLOSING);\n    if (state.compareAndSet(State.CLOSING, State.CLOSED)) {\n        this.selector.close();\n        this.metadataUpdater.close();\n    } else {\n        log.warn(\"Attempting to close NetworkClient that has already been closed.\");\n    }\n}",
        "summary_tokens": [
            "close",
            "the",
            "network",
            "client"
        ]
    },
    {
        "id": 80,
        "code": "public long connectionDelay(Node node, long now) {\n    return connectionStates.connectionDelay(node.idString(), now);\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "milliseconds",
            "to",
            "wait",
            "based",
            "on",
            "the",
            "connection",
            "state",
            "before",
            "attempting",
            "to",
            "send",
            "data"
        ]
    },
    {
        "id": 81,
        "code": "public long pollDelayMs(Node node, long now) {\n    return connectionStates.pollDelayMs(node.idString(), now);\n}",
        "summary_tokens": [
            "return",
            "the",
            "poll",
            "delay",
            "in",
            "milliseconds",
            "based",
            "on",
            "both",
            "connection",
            "and",
            "throttle",
            "delay"
        ]
    },
    {
        "id": 82,
        "code": "public boolean connectionFailed(Node node) {\n    return connectionStates.isDisconnected(node.idString());\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "connection",
            "of",
            "the",
            "node",
            "has",
            "failed",
            "based",
            "on",
            "the",
            "connection",
            "state"
        ]
    },
    {
        "id": 83,
        "code": "public AuthenticationException authenticationException(Node node) {\n    return connectionStates.authenticationException(node.idString());\n}",
        "summary_tokens": [
            "check",
            "if",
            "authentication",
            "to",
            "this",
            "node",
            "has",
            "failed",
            "based",
            "on",
            "the",
            "connection",
            "state"
        ]
    },
    {
        "id": 84,
        "code": "public boolean isReady(Node node, long now) {\n        \n        \n    return !metadataUpdater.isUpdateDue(now) && canSendRequest(node.idString(), now);\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "node",
            "with",
            "the",
            "given",
            "id",
            "is",
            "ready",
            "to",
            "send",
            "more",
            "requests"
        ]
    },
    {
        "id": 85,
        "code": "private boolean canSendRequest(String node, long now) {\n    return connectionStates.isReady(node, now) && selector.isChannelReady(node) &&\n        inFlightRequests.canSendMore(node);\n}",
        "summary_tokens": [
            "are",
            "we",
            "connected",
            "and",
            "ready",
            "and",
            "able",
            "to",
            "send",
            "more",
            "requests",
            "to",
            "the",
            "given",
            "connection"
        ]
    },
    {
        "id": 86,
        "code": "public void send(ClientRequest request, long now) {\n    doSend(request, false, now);\n}",
        "summary_tokens": [
            "queue",
            "up",
            "the",
            "given",
            "request",
            "for",
            "sending"
        ]
    },
    {
        "id": 87,
        "code": "public List<ClientResponse> poll(long timeout, long now) {\n    ensureActive();\n\n    if (!abortedSends.isEmpty()) {\n            \n            \n        List<ClientResponse> responses = new ArrayList<>();\n        handleAbortedSends(responses);\n        completeResponses(responses);\n        return responses;\n    }\n\n    long metadataTimeout = metadataUpdater.maybeUpdate(now);\n    try {\n        this.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));\n    } catch (IOException e) {\n        log.error(\"Unexpected error during I/O\", e);\n    }\n\n        \n    long updatedNow = this.time.milliseconds();\n    List<ClientResponse> responses = new ArrayList<>();\n    handleCompletedSends(responses, updatedNow);\n    handleCompletedReceives(responses, updatedNow);\n    handleDisconnections(responses, updatedNow);\n    handleConnections();\n    handleInitiateApiVersionRequests(updatedNow);\n    handleTimedOutConnections(responses, updatedNow);\n    handleTimedOutRequests(responses, updatedNow);\n    completeResponses(responses);\n\n    return responses;\n}",
        "summary_tokens": [
            "do",
            "actual",
            "reads",
            "and",
            "writes",
            "to",
            "sockets"
        ]
    },
    {
        "id": 88,
        "code": "public int inFlightRequestCount(String node) {\n    return this.inFlightRequests.count(node);\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "in",
            "flight",
            "requests",
            "for",
            "a",
            "given",
            "node"
        ]
    },
    {
        "id": 89,
        "code": "public void wakeup() {\n    this.selector.wakeup();\n}",
        "summary_tokens": [
            "interrupt",
            "the",
            "client",
            "if",
            "it",
            "is",
            "blocked",
            "waiting",
            "on",
            "i",
            "o"
        ]
    },
    {
        "id": 90,
        "code": "public Node leastLoadedNode(long now) {\n    List<Node> nodes = this.metadataUpdater.fetchNodes();\n    if (nodes.isEmpty())\n        throw new IllegalStateException(\"There are no nodes in the Kafka cluster\");\n    int inflight = Integer.MAX_VALUE;\n\n    Node foundConnecting = null;\n    Node foundCanConnect = null;\n    Node foundReady = null;\n\n    int offset = this.randOffset.nextInt(nodes.size());\n    for (int i = 0; i < nodes.size(); i++) {\n        int idx = (offset + i) % nodes.size();\n        Node node = nodes.get(idx);\n        if (canSendRequest(node.idString(), now)) {\n            int currInflight = this.inFlightRequests.count(node.idString());\n            if (currInflight == 0) {\n                    \n                log.trace(\"Found least loaded node {} connected with no in-flight requests\", node);\n                return node;\n            } else if (currInflight < inflight) {\n                    \n                inflight = currInflight;\n                foundReady = node;\n            }\n        } else if (connectionStates.isPreparingConnection(node.idString())) {\n            foundConnecting = node;\n        } else if (canConnect(node, now)) {\n            if (foundCanConnect == null ||\n                    this.connectionStates.lastConnectAttemptMs(foundCanConnect.idString()) >\n                            this.connectionStates.lastConnectAttemptMs(node.idString())) {\n                foundCanConnect = node;\n            }\n        } else {\n            log.trace(\"Removing node {} from least loaded node selection since it is neither ready \" +\n                    \"for sending or connecting\", node);\n        }\n    }\n\n        \n        \n    if (foundReady != null) {\n        log.trace(\"Found least loaded node {} with {} inflight requests\", foundReady, inflight);\n        return foundReady;\n    } else if (foundConnecting != null) {\n        log.trace(\"Found least loaded connecting node {}\", foundConnecting);\n        return foundConnecting;\n    } else if (foundCanConnect != null) {\n        log.trace(\"Found least loaded node {} with no active connection\", foundCanConnect);\n        return foundCanConnect;\n    } else {\n        log.trace(\"Least loaded node selection failed to find an available node\");\n        return null;\n    }\n}",
        "summary_tokens": [
            "choose",
            "the",
            "node",
            "with",
            "the",
            "fewest",
            "outstanding",
            "requests",
            "which",
            "is",
            "at",
            "least",
            "eligible",
            "for",
            "connection"
        ]
    },
    {
        "id": 91,
        "code": "private void processDisconnection(List<ClientResponse> responses,\n                                  String nodeId,\n                                  long now,\n                                  ChannelState disconnectState) {\n    connectionStates.disconnected(nodeId, now);\n    apiVersions.remove(nodeId);\n    nodesNeedingApiVersionsFetch.remove(nodeId);\n    switch (disconnectState.state()) {\n        case AUTHENTICATION_FAILED:\n            AuthenticationException exception = disconnectState.exception();\n            connectionStates.authenticationFailed(nodeId, now, exception);\n            log.error(\"Connection to node {} ({}) failed authentication due to: {}\", nodeId,\n                disconnectState.remoteAddress(), exception.getMessage());\n            break;\n        case AUTHENTICATE:\n            log.warn(\"Connection to node {} ({}) terminated during authentication. This may happen \" +\n                \"due to any of the following reasons: (1) Authentication failed due to invalid \" +\n                \"credentials with brokers older than 1.0.0, (2) Firewall blocking Kafka TLS \" +\n                \"traffic (eg it may only allow HTTPS traffic), (3) Transient network issue.\",\n                nodeId, disconnectState.remoteAddress());\n            break;\n        case NOT_CONNECTED:\n            log.warn(\"Connection to node {} ({}) could not be established. Broker may not be available.\", nodeId, disconnectState.remoteAddress());\n            break;\n        default:\n            break; \n    }\n\n    cancelInFlightRequests(nodeId, now, responses);\n    metadataUpdater.handleServerDisconnect(now, nodeId, Optional.ofNullable(disconnectState.exception()));\n}",
        "summary_tokens": [
            "post",
            "process",
            "disconnection",
            "of",
            "a",
            "node"
        ]
    },
    {
        "id": 92,
        "code": "private void handleTimedOutRequests(List<ClientResponse> responses, long now) {\n    List<String> nodeIds = this.inFlightRequests.nodesWithTimedOutRequests(now);\n    for (String nodeId : nodeIds) {\n            \n        this.selector.close(nodeId);\n        log.info(\"Disconnecting from node {} due to request timeout.\", nodeId);\n        processDisconnection(responses, nodeId, now, ChannelState.LOCAL_CLOSE);\n    }\n}",
        "summary_tokens": [
            "iterate",
            "over",
            "all",
            "the",
            "inflight",
            "requests",
            "and",
            "expire",
            "any",
            "requests",
            "that",
            "have",
            "exceeded",
            "the",
            "configured",
            "request",
            "timeout"
        ]
    },
    {
        "id": 93,
        "code": "private void handleTimedOutConnections(List<ClientResponse> responses, long now) {\n    List<String> nodes = connectionStates.nodesWithConnectionSetupTimeout(now);\n    for (String nodeId : nodes) {\n        this.selector.close(nodeId);\n        log.info(\n            \"Disconnecting from node {} due to socket connection setup timeout. \" +\n            \"The timeout value is {} ms.\",\n            nodeId,\n            connectionStates.connectionSetupTimeoutMs(nodeId));\n        processDisconnection(responses, nodeId, now, ChannelState.LOCAL_CLOSE);\n    }\n}",
        "summary_tokens": [
            "handle",
            "socket",
            "channel",
            "connection",
            "timeout"
        ]
    },
    {
        "id": 94,
        "code": "private void handleCompletedSends(List<ClientResponse> responses, long now) {\n        \n    for (NetworkSend send : this.selector.completedSends()) {\n        InFlightRequest request = this.inFlightRequests.lastSent(send.destinationId());\n        if (!request.expectResponse) {\n            this.inFlightRequests.completeLastSent(send.destinationId());\n            responses.add(request.completed(null, now));\n        }\n    }\n}",
        "summary_tokens": [
            "handle",
            "any",
            "completed",
            "request",
            "send"
        ]
    },
    {
        "id": 95,
        "code": "private void maybeThrottle(AbstractResponse response, short apiVersion, String nodeId, long now) {\n    int throttleTimeMs = response.throttleTimeMs();\n    if (throttleTimeMs > 0 && response.shouldClientThrottle(apiVersion)) {\n        connectionStates.throttle(nodeId, now + throttleTimeMs);\n        log.trace(\"Connection to node {} is throttled for {} ms until timestamp {}\", nodeId, throttleTimeMs,\n                  now + throttleTimeMs);\n    }\n}",
        "summary_tokens": [
            "if",
            "a",
            "response",
            "from",
            "a",
            "node",
            "includes",
            "a",
            "non",
            "zero",
            "throttle",
            "delay",
            "and",
            "client",
            "side",
            "throttling",
            "has",
            "been",
            "enabled",
            "for",
            "the",
            "connection",
            "to",
            "the",
            "node",
            "throttle",
            "the",
            "connection",
            "for",
            "the",
            "specified",
            "delay"
        ]
    },
    {
        "id": 96,
        "code": "private void handleCompletedReceives(List<ClientResponse> responses, long now) {\n    for (NetworkReceive receive : this.selector.completedReceives()) {\n        String source = receive.source();\n        InFlightRequest req = inFlightRequests.completeNext(source);\n\n        AbstractResponse response = parseResponse(receive.payload(), req.header);\n        if (throttleTimeSensor != null)\n            throttleTimeSensor.record(response.throttleTimeMs(), now);\n\n        if (log.isDebugEnabled()) {\n            log.debug(\"Received {} response from node {} for request with header {}: {}\",\n                req.header.apiKey(), req.destination, req.header, response);\n        }\n\n            \n        maybeThrottle(response, req.header.apiVersion(), req.destination, now);\n        if (req.isInternalRequest && response instanceof MetadataResponse)\n            metadataUpdater.handleSuccessfulResponse(req.header, now, (MetadataResponse) response);\n        else if (req.isInternalRequest && response instanceof ApiVersionsResponse)\n            handleApiVersionsResponse(responses, req, now, (ApiVersionsResponse) response);\n        else\n            responses.add(req.completed(response, now));\n    }\n}",
        "summary_tokens": [
            "handle",
            "any",
            "completed",
            "receives",
            "and",
            "update",
            "the",
            "response",
            "list",
            "with",
            "the",
            "responses",
            "received"
        ]
    },
    {
        "id": 97,
        "code": "private void handleDisconnections(List<ClientResponse> responses, long now) {\n    for (Map.Entry<String, ChannelState> entry : this.selector.disconnected().entrySet()) {\n        String node = entry.getKey();\n        log.info(\"Node {} disconnected.\", node);\n        processDisconnection(responses, node, now, entry.getValue());\n    }\n}",
        "summary_tokens": [
            "handle",
            "any",
            "disconnected",
            "connections"
        ]
    },
    {
        "id": 98,
        "code": "private void handleConnections() {\n    for (String node : this.selector.connected()) {\n            \n            \n            \n            \n        if (discoverBrokerVersions) {\n            nodesNeedingApiVersionsFetch.put(node, new ApiVersionsRequest.Builder());\n            log.debug(\"Completed connection to node {}. Fetching API versions.\", node);\n        } else {\n            this.connectionStates.ready(node);\n            log.debug(\"Completed connection to node {}. Ready.\", node);\n        }\n    }\n}",
        "summary_tokens": [
            "record",
            "any",
            "newly",
            "completed",
            "connections"
        ]
    },
    {
        "id": 99,
        "code": "private void initiateConnect(Node node, long now) {\n    String nodeConnectionId = node.idString();\n    try {\n        connectionStates.connecting(nodeConnectionId, now, node.host());\n        InetAddress address = connectionStates.currentAddress(nodeConnectionId);\n        log.debug(\"Initiating connection to node {} using address {}\", node, address);\n        selector.connect(nodeConnectionId,\n                new InetSocketAddress(address, node.port()),\n                this.socketSendBuffer,\n                this.socketReceiveBuffer);\n    } catch (IOException e) {\n        log.warn(\"Error connecting to node {}\", node, e);\n            \n        connectionStates.disconnected(nodeConnectionId, now);\n            \n        metadataUpdater.handleServerDisconnect(now, nodeConnectionId, Optional.empty());\n    }\n}",
        "summary_tokens": [
            "initiate",
            "a",
            "connection",
            "to",
            "the",
            "given",
            "node",
            "node",
            "the",
            "node",
            "to",
            "connect",
            "to",
            "now",
            "current",
            "time",
            "in",
            "epoch",
            "milliseconds"
        ]
    },
    {
        "id": 100,
        "code": "public static boolean isReady(KafkaClient client, Node node, long currentTime) {\n    client.poll(0, currentTime);\n    return client.isReady(node, currentTime);\n}",
        "summary_tokens": [
            "checks",
            "whether",
            "the",
            "node",
            "is",
            "currently",
            "connected",
            "first",
            "calling",
            "client"
        ]
    },
    {
        "id": 101,
        "code": "public static NodeApiVersions create(short apiKey, short minVersion, short maxVersion) {\n    return create(Collections.singleton(new ApiVersion()\n            .setApiKey(apiKey)\n            .setMinVersion(minVersion)\n            .setMaxVersion(maxVersion)));\n}",
        "summary_tokens": [
            "create",
            "a",
            "node",
            "api",
            "versions",
            "object",
            "with",
            "a",
            "single",
            "api",
            "key"
        ]
    },
    {
        "id": 102,
        "code": "public short latestUsableVersion(ApiKeys apiKey, short oldestAllowedVersion, short latestAllowedVersion) {\n    if (!supportedVersions.containsKey(apiKey))\n        throw new UnsupportedVersionException(\"The broker does not support \" + apiKey);\n    ApiVersion supportedVersion = supportedVersions.get(apiKey);\n    Optional<ApiVersion> intersectVersion = ApiVersionsResponse.intersect(supportedVersion,\n        new ApiVersion()\n            .setApiKey(apiKey.id)\n            .setMinVersion(oldestAllowedVersion)\n            .setMaxVersion(latestAllowedVersion));\n\n    if (intersectVersion.isPresent())\n        return intersectVersion.get().maxVersion();\n    else\n        throw new UnsupportedVersionException(\"The broker does not support \" + apiKey +\n            \" with version in range [\" + oldestAllowedVersion + \",\" + latestAllowedVersion + \"]. The supported\" +\n            \" range is [\" + supportedVersion.minVersion() + \",\" + supportedVersion.maxVersion() + \"].\");\n}",
        "summary_tokens": [
            "get",
            "the",
            "latest",
            "version",
            "supported",
            "by",
            "the",
            "broker",
            "within",
            "an",
            "allowed",
            "range",
            "of",
            "versions"
        ]
    },
    {
        "id": 103,
        "code": "public String toString(boolean lineBreaks) {\n        \n        \n        \n    TreeMap<Short, String> apiKeysText = new TreeMap<>();\n    for (ApiVersion supportedVersion : this.supportedVersions.values())\n        apiKeysText.put(supportedVersion.apiKey(), apiVersionToText(supportedVersion));\n    for (ApiVersion apiVersion : unknownApis)\n        apiKeysText.put(apiVersion.apiKey(), apiVersionToText(apiVersion));\n\n        \n        \n    for (ApiKeys apiKey : ApiKeys.zkBrokerApis()) {\n        if (!apiKeysText.containsKey(apiKey.id)) {\n            StringBuilder bld = new StringBuilder();\n            bld.append(apiKey.name).append(\"(\").\n                    append(apiKey.id).append(\"): \").append(\"UNSUPPORTED\");\n            apiKeysText.put(apiKey.id, bld.toString());\n        }\n    }\n    String separator = lineBreaks ? \",\\n\\t\" : \", \";\n    StringBuilder bld = new StringBuilder();\n    bld.append(\"(\");\n    if (lineBreaks)\n        bld.append(\"\\n\\t\");\n    bld.append(Utils.join(apiKeysText.values(), separator));\n    if (lineBreaks)\n        bld.append(\"\\n\");\n    bld.append(\")\");\n    return bld.toString();\n}",
        "summary_tokens": [
            "convert",
            "the",
            "object",
            "to",
            "a",
            "string"
        ]
    },
    {
        "id": 104,
        "code": "public ApiVersion apiVersion(ApiKeys apiKey) {\n    return supportedVersions.get(apiKey);\n}",
        "summary_tokens": [
            "get",
            "the",
            "version",
            "information",
            "for",
            "a",
            "given",
            "api"
        ]
    },
    {
        "id": 105,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "get",
            "a",
            "future",
            "which",
            "completes",
            "when",
            "the",
            "transaction",
            "specified",
            "by",
            "abort",
            "transaction",
            "spec",
            "in",
            "the",
            "respective",
            "call",
            "to",
            "admin",
            "abort",
            "transaction",
            "abort",
            "transaction",
            "spec",
            "abort",
            "transaction",
            "options",
            "returns",
            "successfully",
            "or",
            "fails",
            "due",
            "to",
            "an",
            "error",
            "or",
            "timeout"
        ]
    },
    {
        "id": 106,
        "code": "public Integer timeoutMs() {\n    return timeoutMs;\n}",
        "summary_tokens": [
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 107,
        "code": "static Admin create(Map<String, Object> conf) {\n    return KafkaAdminClient.createInternal(new AdminClientConfig(conf, true), null, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "admin",
            "with",
            "the",
            "given",
            "configuration"
        ]
    },
    {
        "id": 108,
        "code": "default void close() {\n    close(Duration.ofMillis(Long.MAX_VALUE));\n}",
        "summary_tokens": [
            "close",
            "the",
            "admin",
            "and",
            "release",
            "all",
            "associated",
            "resources"
        ]
    },
    {
        "id": 109,
        "code": "default CreateTopicsResult createTopics(Collection<NewTopic> newTopics) {\n    return createTopics(newTopics, new CreateTopicsOptions());\n}",
        "summary_tokens": [
            "create",
            "a",
            "batch",
            "of",
            "new",
            "topics",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 110,
        "code": "default DeleteTopicsResult deleteTopics(TopicCollection topics) {\n    return deleteTopics(topics, new DeleteTopicsOptions());\n}",
        "summary_tokens": [
            "this",
            "is",
            "a",
            "convenience",
            "method",
            "for",
            "delete",
            "topics",
            "topic",
            "collection",
            "delete",
            "topics",
            "options",
            "with",
            "default",
            "options"
        ]
    },
    {
        "id": 111,
        "code": "default ListTopicsResult listTopics() {\n    return listTopics(new ListTopicsOptions());\n}",
        "summary_tokens": [
            "list",
            "the",
            "topics",
            "available",
            "in",
            "the",
            "cluster",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 112,
        "code": "default DescribeTopicsResult describeTopics(TopicCollection topics) {\n    return describeTopics(topics, new DescribeTopicsOptions());\n}",
        "summary_tokens": [
            "this",
            "is",
            "a",
            "convenience",
            "method",
            "for",
            "describe",
            "topics",
            "topic",
            "collection",
            "describe",
            "topics",
            "options",
            "with",
            "default",
            "options"
        ]
    },
    {
        "id": 113,
        "code": "default DescribeClusterResult describeCluster() {\n    return describeCluster(new DescribeClusterOptions());\n}",
        "summary_tokens": [
            "get",
            "information",
            "about",
            "the",
            "nodes",
            "in",
            "the",
            "cluster",
            "using",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 114,
        "code": "default DescribeAclsResult describeAcls(AclBindingFilter filter) {\n    return describeAcls(filter, new DescribeAclsOptions());\n}",
        "summary_tokens": [
            "this",
            "is",
            "a",
            "convenience",
            "method",
            "for",
            "describe",
            "acls",
            "acl",
            "binding",
            "filter",
            "describe",
            "acls",
            "options",
            "with",
            "default",
            "options"
        ]
    },
    {
        "id": 115,
        "code": "default CreateAclsResult createAcls(Collection<AclBinding> acls) {\n    return createAcls(acls, new CreateAclsOptions());\n}",
        "summary_tokens": [
            "this",
            "is",
            "a",
            "convenience",
            "method",
            "for",
            "create",
            "acls",
            "collection",
            "create",
            "acls",
            "options",
            "with",
            "default",
            "options"
        ]
    },
    {
        "id": 116,
        "code": "default DeleteAclsResult deleteAcls(Collection<AclBindingFilter> filters) {\n    return deleteAcls(filters, new DeleteAclsOptions());\n}",
        "summary_tokens": [
            "this",
            "is",
            "a",
            "convenience",
            "method",
            "for",
            "delete",
            "acls",
            "collection",
            "delete",
            "acls",
            "options",
            "with",
            "default",
            "options"
        ]
    },
    {
        "id": 117,
        "code": "default DescribeConfigsResult describeConfigs(Collection<ConfigResource> resources) {\n    return describeConfigs(resources, new DescribeConfigsOptions());\n}",
        "summary_tokens": [
            "get",
            "the",
            "configuration",
            "for",
            "the",
            "specified",
            "resources",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 118,
        "code": "default AlterConfigsResult alterConfigs(Map<ConfigResource, Config> configs) {\n    return alterConfigs(configs, new AlterConfigsOptions());\n}",
        "summary_tokens": [
            "update",
            "the",
            "configuration",
            "for",
            "the",
            "specified",
            "resources",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 119,
        "code": "default AlterConfigsResult incrementalAlterConfigs(Map<ConfigResource, Collection<AlterConfigOp>> configs) {\n    return incrementalAlterConfigs(configs, new AlterConfigsOptions());\n}",
        "summary_tokens": [
            "incrementally",
            "updates",
            "the",
            "configuration",
            "for",
            "the",
            "specified",
            "resources",
            "with",
            "default",
            "options"
        ]
    },
    {
        "id": 120,
        "code": "default AlterReplicaLogDirsResult alterReplicaLogDirs(Map<TopicPartitionReplica, String> replicaAssignment) {\n    return alterReplicaLogDirs(replicaAssignment, new AlterReplicaLogDirsOptions());\n}",
        "summary_tokens": [
            "change",
            "the",
            "log",
            "directory",
            "for",
            "the",
            "specified",
            "replicas"
        ]
    },
    {
        "id": 121,
        "code": "default DescribeLogDirsResult describeLogDirs(Collection<Integer> brokers) {\n    return describeLogDirs(brokers, new DescribeLogDirsOptions());\n}",
        "summary_tokens": [
            "query",
            "the",
            "information",
            "of",
            "all",
            "log",
            "directories",
            "on",
            "the",
            "given",
            "set",
            "of",
            "brokers",
            "p",
            "this",
            "is",
            "a",
            "convenience",
            "method",
            "for",
            "describe",
            "log",
            "dirs",
            "collection",
            "describe",
            "log",
            "dirs",
            "options",
            "with",
            "default",
            "options"
        ]
    },
    {
        "id": 122,
        "code": "default DescribeReplicaLogDirsResult describeReplicaLogDirs(Collection<TopicPartitionReplica> replicas) {\n    return describeReplicaLogDirs(replicas, new DescribeReplicaLogDirsOptions());\n}",
        "summary_tokens": [
            "query",
            "the",
            "replica",
            "log",
            "directory",
            "information",
            "for",
            "the",
            "specified",
            "replicas"
        ]
    },
    {
        "id": 123,
        "code": "default CreatePartitionsResult createPartitions(Map<String, NewPartitions> newPartitions) {\n    return createPartitions(newPartitions, new CreatePartitionsOptions());\n}",
        "summary_tokens": [
            "increase",
            "the",
            "number",
            "of",
            "partitions",
            "of",
            "the",
            "topics",
            "given",
            "as",
            "the",
            "keys",
            "of",
            "new",
            "partitions",
            "according",
            "to",
            "the",
            "corresponding",
            "values"
        ]
    },
    {
        "id": 124,
        "code": "default DeleteRecordsResult deleteRecords(Map<TopicPartition, RecordsToDelete> recordsToDelete) {\n    return deleteRecords(recordsToDelete, new DeleteRecordsOptions());\n}",
        "summary_tokens": [
            "delete",
            "records",
            "whose",
            "offset",
            "is",
            "smaller",
            "than",
            "the",
            "given",
            "offset",
            "of",
            "the",
            "corresponding",
            "partition"
        ]
    },
    {
        "id": 125,
        "code": "default CreateDelegationTokenResult createDelegationToken() {\n    return createDelegationToken(new CreateDelegationTokenOptions());\n}",
        "summary_tokens": [
            "create",
            "a",
            "delegation",
            "token"
        ]
    },
    {
        "id": 126,
        "code": "default RenewDelegationTokenResult renewDelegationToken(byte[] hmac) {\n    return renewDelegationToken(hmac, new RenewDelegationTokenOptions());\n}",
        "summary_tokens": [
            "renew",
            "a",
            "delegation",
            "token"
        ]
    },
    {
        "id": 127,
        "code": "default ExpireDelegationTokenResult expireDelegationToken(byte[] hmac) {\n    return expireDelegationToken(hmac, new ExpireDelegationTokenOptions());\n}",
        "summary_tokens": [
            "expire",
            "a",
            "delegation",
            "token"
        ]
    },
    {
        "id": 128,
        "code": "default DescribeDelegationTokenResult describeDelegationToken() {\n    return describeDelegationToken(new DescribeDelegationTokenOptions());\n}",
        "summary_tokens": [
            "describe",
            "the",
            "delegation",
            "tokens"
        ]
    },
    {
        "id": 129,
        "code": "default DescribeConsumerGroupsResult describeConsumerGroups(Collection<String> groupIds) {\n    return describeConsumerGroups(groupIds, new DescribeConsumerGroupsOptions());\n}",
        "summary_tokens": [
            "describe",
            "some",
            "group",
            "ids",
            "in",
            "the",
            "cluster",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 130,
        "code": "default ListConsumerGroupsResult listConsumerGroups() {\n    return listConsumerGroups(new ListConsumerGroupsOptions());\n}",
        "summary_tokens": [
            "list",
            "the",
            "consumer",
            "groups",
            "available",
            "in",
            "the",
            "cluster",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 131,
        "code": "default ListConsumerGroupOffsetsResult listConsumerGroupOffsets(Map<String, ListConsumerGroupOffsetsSpec> groupSpecs) {\n    return listConsumerGroupOffsets(groupSpecs, new ListConsumerGroupOffsetsOptions());\n}",
        "summary_tokens": [
            "list",
            "the",
            "consumer",
            "group",
            "offsets",
            "available",
            "in",
            "the",
            "cluster",
            "for",
            "the",
            "specified",
            "groups",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 132,
        "code": "default DeleteConsumerGroupsResult deleteConsumerGroups(Collection<String> groupIds) {\n    return deleteConsumerGroups(groupIds, new DeleteConsumerGroupsOptions());\n}",
        "summary_tokens": [
            "delete",
            "consumer",
            "groups",
            "from",
            "the",
            "cluster",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 133,
        "code": "default DeleteConsumerGroupOffsetsResult deleteConsumerGroupOffsets(String groupId, Set<TopicPartition> partitions) {\n    return deleteConsumerGroupOffsets(groupId, partitions, new DeleteConsumerGroupOffsetsOptions());\n}",
        "summary_tokens": [
            "delete",
            "committed",
            "offsets",
            "for",
            "a",
            "set",
            "of",
            "partitions",
            "in",
            "a",
            "consumer",
            "group",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 134,
        "code": "default ElectLeadersResult electLeaders(ElectionType electionType, Set<TopicPartition> partitions) {\n    return electLeaders(electionType, partitions, new ElectLeadersOptions());\n}",
        "summary_tokens": [
            "elect",
            "a",
            "replica",
            "as",
            "leader",
            "for",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 135,
        "code": "default AlterPartitionReassignmentsResult alterPartitionReassignments(\n    Map<TopicPartition, Optional<NewPartitionReassignment>> reassignments) {\n    return alterPartitionReassignments(reassignments, new AlterPartitionReassignmentsOptions());\n}",
        "summary_tokens": [
            "change",
            "the",
            "reassignments",
            "for",
            "one",
            "or",
            "more",
            "partitions"
        ]
    },
    {
        "id": 136,
        "code": "default ListPartitionReassignmentsResult listPartitionReassignments(ListPartitionReassignmentsOptions options) {\n    return listPartitionReassignments(Optional.empty(), options);\n}",
        "summary_tokens": [
            "list",
            "all",
            "of",
            "the",
            "current",
            "partition",
            "reassignments"
        ]
    },
    {
        "id": 137,
        "code": "default AlterConsumerGroupOffsetsResult alterConsumerGroupOffsets(String groupId, Map<TopicPartition, OffsetAndMetadata> offsets) {\n    return alterConsumerGroupOffsets(groupId, offsets, new AlterConsumerGroupOffsetsOptions());\n}",
        "summary_tokens": [
            "p",
            "alters",
            "offsets",
            "for",
            "the",
            "specified",
            "group"
        ]
    },
    {
        "id": 138,
        "code": "default ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartitionOffsets) {\n    return listOffsets(topicPartitionOffsets, new ListOffsetsOptions());\n}",
        "summary_tokens": [
            "p",
            "list",
            "offset",
            "for",
            "the",
            "specified",
            "partitions",
            "and",
            "offset",
            "spec"
        ]
    },
    {
        "id": 139,
        "code": "default DescribeClientQuotasResult describeClientQuotas(ClientQuotaFilter filter) {\n    return describeClientQuotas(filter, new DescribeClientQuotasOptions());\n}",
        "summary_tokens": [
            "describes",
            "all",
            "entities",
            "matching",
            "the",
            "provided",
            "filter",
            "that",
            "have",
            "at",
            "least",
            "one",
            "client",
            "quota",
            "configuration",
            "value",
            "defined"
        ]
    },
    {
        "id": 140,
        "code": "default AlterClientQuotasResult alterClientQuotas(Collection<ClientQuotaAlteration> entries) {\n    return alterClientQuotas(entries, new AlterClientQuotasOptions());\n}",
        "summary_tokens": [
            "alters",
            "client",
            "quota",
            "configurations",
            "with",
            "the",
            "specified",
            "alterations"
        ]
    },
    {
        "id": 141,
        "code": "default DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users) {\n    return describeUserScramCredentials(users, new DescribeUserScramCredentialsOptions());\n}",
        "summary_tokens": [
            "describe",
            "sasl",
            "scram",
            "credentials",
            "for",
            "the",
            "given",
            "users"
        ]
    },
    {
        "id": 142,
        "code": "default AlterUserScramCredentialsResult alterUserScramCredentials(List<UserScramCredentialAlteration> alterations) {\n    return alterUserScramCredentials(alterations, new AlterUserScramCredentialsOptions());\n}",
        "summary_tokens": [
            "alter",
            "sasl",
            "scram",
            "credentials",
            "for",
            "the",
            "given",
            "users"
        ]
    },
    {
        "id": 143,
        "code": "default DescribeFeaturesResult describeFeatures() {\n    return describeFeatures(new DescribeFeaturesOptions());\n}",
        "summary_tokens": [
            "describes",
            "finalized",
            "as",
            "well",
            "as",
            "supported",
            "features"
        ]
    },
    {
        "id": 144,
        "code": "default DescribeMetadataQuorumResult describeMetadataQuorum() {\n    return describeMetadataQuorum(new DescribeMetadataQuorumOptions());\n}",
        "summary_tokens": [
            "describes",
            "the",
            "state",
            "of",
            "the",
            "metadata",
            "quorum"
        ]
    },
    {
        "id": 145,
        "code": "default DescribeProducersResult describeProducers(Collection<TopicPartition> partitions) {\n    return describeProducers(partitions, new DescribeProducersOptions());\n}",
        "summary_tokens": [
            "describe",
            "producer",
            "state",
            "on",
            "a",
            "set",
            "of",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 146,
        "code": "default DescribeTransactionsResult describeTransactions(Collection<String> transactionalIds) {\n    return describeTransactions(transactionalIds, new DescribeTransactionsOptions());\n}",
        "summary_tokens": [
            "describe",
            "the",
            "state",
            "of",
            "a",
            "set",
            "of",
            "transactional",
            "ids"
        ]
    },
    {
        "id": 147,
        "code": "default AbortTransactionResult abortTransaction(AbortTransactionSpec spec) {\n    return abortTransaction(spec, new AbortTransactionOptions());\n}",
        "summary_tokens": [
            "forcefully",
            "abort",
            "a",
            "transaction",
            "which",
            "is",
            "open",
            "on",
            "a",
            "topic",
            "partition"
        ]
    },
    {
        "id": 148,
        "code": "default ListTransactionsResult listTransactions() {\n    return listTransactions(new ListTransactionsOptions());\n}",
        "summary_tokens": [
            "list",
            "active",
            "transactions",
            "in",
            "the",
            "cluster"
        ]
    },
    {
        "id": 149,
        "code": "default FenceProducersResult fenceProducers(Collection<String> transactionalIds) {\n    return fenceProducers(transactionalIds, new FenceProducersOptions());\n}",
        "summary_tokens": [
            "fence",
            "out",
            "all",
            "active",
            "producers",
            "that",
            "use",
            "any",
            "of",
            "the",
            "provided",
            "transactional",
            "ids",
            "with",
            "the",
            "default",
            "options"
        ]
    },
    {
        "id": 150,
        "code": "public static AdminClient create(Map<String, Object> conf) {\n    return (AdminClient) Admin.create(conf);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "admin",
            "with",
            "the",
            "given",
            "configuration"
        ]
    },
    {
        "id": 151,
        "code": "public AlterClientQuotasOptions validateOnly(boolean validateOnly) {\n    this.validateOnly = validateOnly;\n    return this;\n}",
        "summary_tokens": [
            "sets",
            "whether",
            "the",
            "request",
            "should",
            "be",
            "validated",
            "without",
            "altering",
            "the",
            "configs"
        ]
    },
    {
        "id": 152,
        "code": "public Map<ClientQuotaEntity, KafkaFuture<Void>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "map",
            "from",
            "quota",
            "entity",
            "to",
            "a",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "operation"
        ]
    },
    {
        "id": 153,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "quota",
            "alterations",
            "succeed"
        ]
    },
    {
        "id": 154,
        "code": "public AlterConfigsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 155,
        "code": "public boolean shouldValidateOnly() {\n    return validateOnly;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "request",
            "should",
            "be",
            "validated",
            "without",
            "altering",
            "the",
            "configs"
        ]
    },
    {
        "id": 156,
        "code": "public AlterConfigsOptions validateOnly(boolean validateOnly) {\n    this.validateOnly = validateOnly;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "the",
            "request",
            "should",
            "be",
            "validated",
            "without",
            "altering",
            "the",
            "configs"
        ]
    },
    {
        "id": 157,
        "code": "public Map<ConfigResource, KafkaFuture<Void>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "resources",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "operation",
            "on",
            "each",
            "resource"
        ]
    },
    {
        "id": 158,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "alter",
            "configs",
            "operations",
            "succeed"
        ]
    },
    {
        "id": 159,
        "code": "public KafkaFuture<Void> partitionResult(final TopicPartition partition) {\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n\n    this.future.whenComplete((topicPartitions, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else if (!topicPartitions.containsKey(partition)) {\n            result.completeExceptionally(new IllegalArgumentException(\n                \"Alter offset for partition \\\"\" + partition + \"\\\" was not attempted\"));\n        } else {\n            final Errors error = topicPartitions.get(partition);\n            if (error == Errors.NONE) {\n                result.complete(null);\n            } else {\n                result.completeExceptionally(error.exception());\n            }\n        }\n    });\n\n    return result;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "result",
            "for",
            "a",
            "given",
            "partition"
        ]
    },
    {
        "id": 160,
        "code": "public KafkaFuture<Void> all() {\n    return this.future.thenApply(topicPartitionErrorsMap ->  {\n        List<TopicPartition> partitionsFailed = topicPartitionErrorsMap.entrySet()\n            .stream()\n            .filter(e -> e.getValue() != Errors.NONE)\n            .map(Map.Entry::getKey)\n            .collect(Collectors.toList());\n        for (Errors error : topicPartitionErrorsMap.values()) {\n            if (error != Errors.NONE) {\n                throw error.exception(\n                    \"Failed altering consumer group offsets for the following partitions: \" + partitionsFailed);\n            }\n        }\n        return null;\n    });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "if",
            "all",
            "the",
            "alter",
            "offsets",
            "succeed"
        ]
    },
    {
        "id": 161,
        "code": "public Map<TopicPartition, KafkaFuture<Void>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "partitions",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "reassignment"
        ]
    },
    {
        "id": 162,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "reassignments",
            "were",
            "successfully",
            "initiated"
        ]
    },
    {
        "id": 163,
        "code": "public Map<TopicPartitionReplica, KafkaFuture<Void>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "topic",
            "partition",
            "replica",
            "to",
            "kafka",
            "future",
            "which",
            "holds",
            "the",
            "status",
            "of",
            "individual",
            "replica",
            "movement"
        ]
    },
    {
        "id": 164,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "kafka",
            "future",
            "which",
            "succeeds",
            "on",
            "kafka",
            "future",
            "get",
            "if",
            "all",
            "the",
            "replica",
            "movement",
            "have",
            "succeeded"
        ]
    },
    {
        "id": 165,
        "code": "public Map<String, KafkaFuture<Void>> values() {\n    return this.futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "user",
            "names",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "alteration",
            "s",
            "for",
            "each",
            "user"
        ]
    },
    {
        "id": 166,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "user",
            "scram",
            "credential",
            "alterations",
            "succeed"
        ]
    },
    {
        "id": 167,
        "code": "public Collection<ConfigEntry> entries() {\n    return Collections.unmodifiableCollection(entries.values());\n}",
        "summary_tokens": [
            "configuration",
            "entries",
            "for",
            "a",
            "resource"
        ]
    },
    {
        "id": 168,
        "code": "public ConfigEntry get(String name) {\n    return entries.get(name);\n}",
        "summary_tokens": [
            "get",
            "the",
            "configuration",
            "entry",
            "with",
            "the",
            "provided",
            "name",
            "or",
            "null",
            "if",
            "there",
            "isn",
            "t",
            "one"
        ]
    },
    {
        "id": 169,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "return",
            "the",
            "config",
            "name"
        ]
    },
    {
        "id": 170,
        "code": "public String value() {\n    return value;\n}",
        "summary_tokens": [
            "return",
            "the",
            "value",
            "or",
            "null"
        ]
    },
    {
        "id": 171,
        "code": "public ConfigSource source() {\n    return source;\n}",
        "summary_tokens": [
            "return",
            "the",
            "source",
            "of",
            "this",
            "configuration",
            "entry"
        ]
    },
    {
        "id": 172,
        "code": "public boolean isDefault() {\n    return source == ConfigSource.DEFAULT_CONFIG;\n}",
        "summary_tokens": [
            "return",
            "whether",
            "the",
            "config",
            "value",
            "is",
            "the",
            "default",
            "or",
            "if",
            "it",
            "s",
            "been",
            "explicitly",
            "set"
        ]
    },
    {
        "id": 173,
        "code": "public boolean isSensitive() {\n    return isSensitive;\n}",
        "summary_tokens": [
            "return",
            "whether",
            "the",
            "config",
            "value",
            "is",
            "sensitive"
        ]
    },
    {
        "id": 174,
        "code": "public boolean isReadOnly() {\n    return isReadOnly;\n}",
        "summary_tokens": [
            "return",
            "whether",
            "the",
            "config",
            "is",
            "read",
            "only",
            "and",
            "cannot",
            "be",
            "updated"
        ]
    },
    {
        "id": 175,
        "code": "public List<ConfigSynonym> synonyms() {\n    return  synonyms;\n}",
        "summary_tokens": [
            "returns",
            "all",
            "config",
            "values",
            "that",
            "may",
            "be",
            "used",
            "as",
            "the",
            "value",
            "of",
            "this",
            "config",
            "along",
            "with",
            "their",
            "source",
            "in",
            "the",
            "order",
            "of",
            "precedence"
        ]
    },
    {
        "id": 176,
        "code": "public ConfigType type() {\n    return type;\n}",
        "summary_tokens": [
            "return",
            "the",
            "config",
            "data",
            "type"
        ]
    },
    {
        "id": 177,
        "code": "public String documentation() {\n    return documentation;\n}",
        "summary_tokens": [
            "return",
            "the",
            "config",
            "documentation"
        ]
    },
    {
        "id": 178,
        "code": "public String toString() {\n    return \"ConfigEntry(\" +\n            \"name=\" + name +\n            \", value=\" + (isSensitive ? \"Redacted\" : value) +\n            \", source=\" + source +\n            \", isSensitive=\" + isSensitive +\n            \", isReadOnly=\" + isReadOnly +\n            \", synonyms=\" + synonyms +\n            \", type=\" + type +\n            \", documentation=\" + documentation +\n            \")\";\n}",
        "summary_tokens": [
            "override",
            "to",
            "string",
            "to",
            "redact",
            "sensitive",
            "value"
        ]
    },
    {
        "id": 179,
        "code": "public String groupId() {\n    return groupId;\n}",
        "summary_tokens": [
            "the",
            "id",
            "of",
            "the",
            "consumer",
            "group"
        ]
    },
    {
        "id": 180,
        "code": "public boolean isSimpleConsumerGroup() {\n    return isSimpleConsumerGroup;\n}",
        "summary_tokens": [
            "if",
            "consumer",
            "group",
            "is",
            "simple",
            "or",
            "not"
        ]
    },
    {
        "id": 181,
        "code": "public Collection<MemberDescription> members() {\n    return members;\n}",
        "summary_tokens": [
            "a",
            "list",
            "of",
            "the",
            "members",
            "of",
            "the",
            "consumer",
            "group"
        ]
    },
    {
        "id": 182,
        "code": "public String partitionAssignor() {\n    return partitionAssignor;\n}",
        "summary_tokens": [
            "the",
            "consumer",
            "group",
            "partition",
            "assignor"
        ]
    },
    {
        "id": 183,
        "code": "public ConsumerGroupState state() {\n    return state;\n}",
        "summary_tokens": [
            "the",
            "consumer",
            "group",
            "state",
            "or",
            "unknown",
            "if",
            "the",
            "state",
            "is",
            "too",
            "new",
            "for",
            "us",
            "to",
            "parse"
        ]
    },
    {
        "id": 184,
        "code": "public Node coordinator() {\n    return coordinator;\n}",
        "summary_tokens": [
            "the",
            "consumer",
            "group",
            "coordinator",
            "or",
            "null",
            "if",
            "the",
            "coordinator",
            "is",
            "not",
            "known"
        ]
    },
    {
        "id": 185,
        "code": "public  Set<AclOperation> authorizedOperations() {\n    return authorizedOperations;\n}",
        "summary_tokens": [
            "authorized",
            "operations",
            "for",
            "this",
            "group",
            "or",
            "null",
            "if",
            "that",
            "information",
            "is",
            "not",
            "known"
        ]
    },
    {
        "id": 186,
        "code": "public boolean isSimpleConsumerGroup() {\n    return isSimpleConsumerGroup;\n}",
        "summary_tokens": [
            "if",
            "consumer",
            "group",
            "is",
            "simple",
            "or",
            "not"
        ]
    },
    {
        "id": 187,
        "code": "public CreateAclsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 188,
        "code": "public Map<AclBinding, KafkaFuture<Void>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "acl",
            "bindings",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "creation",
            "of",
            "each",
            "acl",
            "binding"
        ]
    },
    {
        "id": 189,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "acl",
            "creations",
            "succeed"
        ]
    },
    {
        "id": 190,
        "code": "public KafkaFuture<DelegationToken> delegationToken() {\n    return delegationToken;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "a",
            "delegation",
            "token"
        ]
    },
    {
        "id": 191,
        "code": "public CreatePartitionsOptions validateOnly(boolean validateOnly) {\n    this.validateOnly = validateOnly;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "the",
            "request",
            "should",
            "be",
            "validated",
            "without",
            "creating",
            "new",
            "partitions"
        ]
    },
    {
        "id": 192,
        "code": "public CreatePartitionsOptions retryOnQuotaViolation(boolean retryOnQuotaViolation) {\n    this.retryOnQuotaViolation = retryOnQuotaViolation;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "quota",
            "violation",
            "should",
            "be",
            "automatically",
            "retried"
        ]
    },
    {
        "id": 193,
        "code": "public boolean shouldRetryOnQuotaViolation() {\n    return retryOnQuotaViolation;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "quota",
            "violation",
            "should",
            "be",
            "automatically",
            "retried"
        ]
    },
    {
        "id": 194,
        "code": "public Map<String, KafkaFuture<Void>> values() {\n    return values;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "topic",
            "names",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "partition",
            "creations"
        ]
    },
    {
        "id": 195,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(values.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "if",
            "all",
            "the",
            "partition",
            "creations",
            "succeed"
        ]
    },
    {
        "id": 196,
        "code": "public CreateTopicsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 197,
        "code": "public CreateTopicsOptions validateOnly(boolean validateOnly) {\n    this.validateOnly = validateOnly;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "the",
            "request",
            "should",
            "be",
            "validated",
            "without",
            "creating",
            "the",
            "topic"
        ]
    },
    {
        "id": 198,
        "code": "public boolean shouldValidateOnly() {\n    return validateOnly;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "request",
            "should",
            "be",
            "validated",
            "without",
            "creating",
            "the",
            "topic"
        ]
    },
    {
        "id": 199,
        "code": "public CreateTopicsOptions retryOnQuotaViolation(boolean retryOnQuotaViolation) {\n    this.retryOnQuotaViolation = retryOnQuotaViolation;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "quota",
            "violation",
            "should",
            "be",
            "automatically",
            "retried"
        ]
    },
    {
        "id": 200,
        "code": "public boolean shouldRetryOnQuotaViolation() {\n    return retryOnQuotaViolation;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "quota",
            "violation",
            "should",
            "be",
            "automatically",
            "retried"
        ]
    },
    {
        "id": 201,
        "code": "public Map<String, KafkaFuture<Void>> values() {\n    return futures.entrySet().stream()\n            .collect(Collectors.toMap(Map.Entry::getKey, e -> e.getValue().thenApply(v -> (Void) null)));\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "topic",
            "names",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "topic",
            "creations"
        ]
    },
    {
        "id": 202,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "if",
            "all",
            "the",
            "topic",
            "creations",
            "succeed"
        ]
    },
    {
        "id": 203,
        "code": "public KafkaFuture<Config> config(String topic) {\n    return futures.get(topic).thenApply(TopicMetadataAndConfig::config);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "that",
            "provides",
            "topic",
            "configs",
            "for",
            "the",
            "topic",
            "when",
            "the",
            "request",
            "completes"
        ]
    },
    {
        "id": 204,
        "code": "public KafkaFuture<Uuid> topicId(String topic) {\n    return futures.get(topic).thenApply(TopicMetadataAndConfig::topicId);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "that",
            "provides",
            "topic",
            "id",
            "for",
            "the",
            "topic",
            "when",
            "the",
            "request",
            "completes"
        ]
    },
    {
        "id": 205,
        "code": "public KafkaFuture<Integer> numPartitions(String topic) {\n    return futures.get(topic).thenApply(TopicMetadataAndConfig::numPartitions);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "that",
            "provides",
            "number",
            "of",
            "partitions",
            "in",
            "the",
            "topic",
            "when",
            "the",
            "request",
            "completes"
        ]
    },
    {
        "id": 206,
        "code": "public KafkaFuture<Integer> replicationFactor(String topic) {\n    return futures.get(topic).thenApply(TopicMetadataAndConfig::replicationFactor);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "that",
            "provides",
            "replication",
            "factor",
            "for",
            "the",
            "topic",
            "when",
            "the",
            "request",
            "completes"
        ]
    },
    {
        "id": 207,
        "code": "public DeleteAclsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 208,
        "code": "public Map<AclBindingFilter, KafkaFuture<FilterResults>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "acl",
            "filters",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "deletions",
            "by",
            "each",
            "filter"
        ]
    },
    {
        "id": 209,
        "code": "public KafkaFuture<Collection<AclBinding>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).thenApply(v -> getAclBindings(futures));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "acls",
            "deletions",
            "succeed",
            "and",
            "which",
            "contains",
            "all",
            "the",
            "deleted",
            "acls"
        ]
    },
    {
        "id": 210,
        "code": "public KafkaFuture<Void> partitionResult(final TopicPartition partition) {\n    if (!partitions.contains(partition)) {\n        throw new IllegalArgumentException(\"Partition \" + partition + \" was not included in the original request\");\n    }\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n\n    this.future.whenComplete((topicPartitions, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else if (!maybeCompleteExceptionally(topicPartitions, partition, result)) {\n            result.complete(null);\n        }\n    });\n    return result;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "result",
            "for",
            "a",
            "given",
            "partition"
        ]
    },
    {
        "id": 211,
        "code": "public KafkaFuture<Void> all() {\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n\n    this.future.whenComplete((topicPartitions, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else {\n            for (TopicPartition partition : partitions) {\n                if (maybeCompleteExceptionally(topicPartitions, partition, result)) {\n                    return;\n                }\n            }\n            result.complete(null);\n        }\n    });\n    return result;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "deletions",
            "succeed"
        ]
    },
    {
        "id": 212,
        "code": "public Map<String, KafkaFuture<Void>> deletedGroups() {\n    Map<String, KafkaFuture<Void>> deletedGroups = new HashMap<>(futures.size());\n    futures.forEach((key, future) -> deletedGroups.put(key, future));\n    return deletedGroups;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "group",
            "id",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "deletions"
        ]
    },
    {
        "id": 213,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "consumer",
            "group",
            "deletions",
            "succeed"
        ]
    },
    {
        "id": 214,
        "code": "public Map<TopicPartition, KafkaFuture<DeletedRecords>> lowWatermarks() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "topic",
            "partition",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "deletions"
        ]
    },
    {
        "id": 215,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "records",
            "deletions",
            "succeed"
        ]
    },
    {
        "id": 216,
        "code": "public DeleteTopicsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 217,
        "code": "public DeleteTopicsOptions retryOnQuotaViolation(boolean retryOnQuotaViolation) {\n    this.retryOnQuotaViolation = retryOnQuotaViolation;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "quota",
            "violation",
            "should",
            "be",
            "automatically",
            "retried"
        ]
    },
    {
        "id": 218,
        "code": "public boolean shouldRetryOnQuotaViolation() {\n    return retryOnQuotaViolation;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "quota",
            "violation",
            "should",
            "be",
            "automatically",
            "retried"
        ]
    },
    {
        "id": 219,
        "code": "public Map<Uuid, KafkaFuture<Void>> topicIdValues() {\n    return topicIdFutures;\n}",
        "summary_tokens": [
            "use",
            "when",
            "admin",
            "delete",
            "topics",
            "topic",
            "collection",
            "delete",
            "topics",
            "options",
            "used",
            "a",
            "topic",
            "id",
            "collection",
            "a",
            "map",
            "from",
            "topic",
            "ids",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "deletions",
            "if",
            "the",
            "delete",
            "topics",
            "request",
            "used",
            "topic",
            "ids"
        ]
    },
    {
        "id": 220,
        "code": "public Map<String, KafkaFuture<Void>> topicNameValues() {\n    return nameFutures;\n}",
        "summary_tokens": [
            "use",
            "when",
            "admin",
            "delete",
            "topics",
            "topic",
            "collection",
            "delete",
            "topics",
            "options",
            "used",
            "a",
            "topic",
            "name",
            "collection",
            "a",
            "map",
            "from",
            "topic",
            "names",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "deletions",
            "if",
            "the",
            "delete",
            "topics",
            "request",
            "used",
            "topic",
            "names"
        ]
    },
    {
        "id": 221,
        "code": "public Map<String, KafkaFuture<Void>> values() {\n    return nameFutures;\n}",
        "summary_tokens": [
            "a",
            "map",
            "from",
            "topic",
            "names",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "deletions",
            "if",
            "the",
            "delete",
            "topics",
            "request",
            "used",
            "topic",
            "names"
        ]
    },
    {
        "id": 222,
        "code": "public KafkaFuture<Void> all() {\n    return (topicIdFutures == null) ? KafkaFuture.allOf(nameFutures.values().toArray(new KafkaFuture[0])) :\n        KafkaFuture.allOf(topicIdFutures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "topic",
            "deletions",
            "succeed"
        ]
    },
    {
        "id": 223,
        "code": "public long lowWatermark() {\n    return lowWatermark;\n}",
        "summary_tokens": [
            "return",
            "the",
            "low",
            "watermark",
            "for",
            "the",
            "topic",
            "partition",
            "on",
            "which",
            "the",
            "deletion",
            "was",
            "executed"
        ]
    },
    {
        "id": 224,
        "code": "public DescribeAclsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 225,
        "code": "public KafkaFuture<Collection<AclBinding>> values() {\n    return future;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "containing",
            "the",
            "acls",
            "requested"
        ]
    },
    {
        "id": 226,
        "code": "public KafkaFuture<Map<ClientQuotaEntity, Map<String, Double>>> entities() {\n    return entities;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "map",
            "from",
            "quota",
            "entity",
            "to",
            "a",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "operation"
        ]
    },
    {
        "id": 227,
        "code": "public DescribeClusterOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 228,
        "code": "public boolean includeAuthorizedOperations() {\n    return includeAuthorizedOperations;\n}",
        "summary_tokens": [
            "specify",
            "if",
            "authorized",
            "operations",
            "should",
            "be",
            "included",
            "in",
            "the",
            "response"
        ]
    },
    {
        "id": 229,
        "code": "public KafkaFuture<Collection<Node>> nodes() {\n    return nodes;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "a",
            "collection",
            "of",
            "nodes"
        ]
    },
    {
        "id": 230,
        "code": "public KafkaFuture<Node> controller() {\n    return controller;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "the",
            "current",
            "controller",
            "id"
        ]
    },
    {
        "id": 231,
        "code": "public KafkaFuture<String> clusterId() {\n    return clusterId;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "the",
            "current",
            "cluster",
            "id"
        ]
    },
    {
        "id": 232,
        "code": "public KafkaFuture<Set<AclOperation>> authorizedOperations() {\n    return authorizedOperations;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "authorized",
            "operations"
        ]
    },
    {
        "id": 233,
        "code": "public DescribeConfigsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 234,
        "code": "public DescribeConfigsOptions includeSynonyms(boolean includeSynonyms) {\n    this.includeSynonyms = includeSynonyms;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "synonym",
            "configs",
            "should",
            "be",
            "returned",
            "in",
            "the",
            "response"
        ]
    },
    {
        "id": 235,
        "code": "public DescribeConfigsOptions includeDocumentation(boolean includeDocumentation) {\n    this.includeDocumentation = includeDocumentation;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "to",
            "true",
            "if",
            "config",
            "documentation",
            "should",
            "be",
            "returned",
            "in",
            "the",
            "response"
        ]
    },
    {
        "id": 236,
        "code": "public Map<ConfigResource, KafkaFuture<Config>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "resources",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "the",
            "configuration",
            "for",
            "each",
            "resource"
        ]
    },
    {
        "id": 237,
        "code": "public KafkaFuture<Map<ConfigResource, Config>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n            thenApply(new KafkaFuture.BaseFunction<Void, Map<ConfigResource, Config>>() {\n                @Override\n                public Map<ConfigResource, Config> apply(Void v) {\n                    Map<ConfigResource, Config> configs = new HashMap<>(futures.size());\n                    for (Map.Entry<ConfigResource, KafkaFuture<Config>> entry : futures.entrySet()) {\n                        try {\n                            configs.put(entry.getKey(), entry.getValue().get());\n                        } catch (InterruptedException | ExecutionException e) {\n                                \n                                \n                            throw new RuntimeException(e);\n                        }\n                    }\n                    return configs;\n                }\n            });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "config",
            "descriptions",
            "succeed"
        ]
    },
    {
        "id": 238,
        "code": "public Map<String, KafkaFuture<ConsumerGroupDescription>> describedGroups() {\n    Map<String, KafkaFuture<ConsumerGroupDescription>> describedGroups = new HashMap<>();\n    futures.forEach((key, future) -> describedGroups.put(key, future));\n    return describedGroups;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "group",
            "id",
            "to",
            "futures",
            "which",
            "yield",
            "group",
            "descriptions"
        ]
    },
    {
        "id": 239,
        "code": "public KafkaFuture<Map<String, ConsumerGroupDescription>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).thenApply(\n        nil -> {\n            Map<String, ConsumerGroupDescription> descriptions = new HashMap<>(futures.size());\n            futures.forEach((key, future) -> {\n                try {\n                    descriptions.put(key, future.get());\n                } catch (InterruptedException | ExecutionException e) {\n                        \n                        \n                    throw new RuntimeException(e);\n                }\n            });\n            return descriptions;\n        });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "yields",
            "all",
            "consumer",
            "group",
            "description",
            "objects",
            "if",
            "all",
            "the",
            "describes",
            "succeed"
        ]
    },
    {
        "id": 240,
        "code": "public DescribeDelegationTokenOptions owners(List<KafkaPrincipal> owners) {\n    this.owners = owners;\n    return this;\n}",
        "summary_tokens": [
            "if",
            "owners",
            "is",
            "null",
            "all",
            "the",
            "user",
            "owned",
            "tokens",
            "and",
            "tokens",
            "where",
            "user",
            "have",
            "describe",
            "permission",
            "will",
            "be",
            "returned"
        ]
    },
    {
        "id": 241,
        "code": "public KafkaFuture<List<DelegationToken>> delegationTokens() {\n    return delegationTokens;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "list",
            "of",
            "delegation",
            "tokens"
        ]
    },
    {
        "id": 242,
        "code": "public Map<Integer, KafkaFuture<Map<String, DescribeLogDirsResponse.LogDirInfo>>> values() {\n    return descriptions().entrySet().stream()\n        .collect(Collectors.toMap(\n            Map.Entry::getKey,\n            entry -> entry.getValue().thenApply(map -> convertMapValues(map))));\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "broker",
            "id",
            "to",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "information",
            "of",
            "partitions",
            "on",
            "each",
            "individual",
            "broker"
        ]
    },
    {
        "id": 243,
        "code": "public Map<Integer, KafkaFuture<Map<String, LogDirDescription>>> descriptions() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "broker",
            "id",
            "to",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "information",
            "of",
            "partitions",
            "on",
            "each",
            "individual",
            "broker"
        ]
    },
    {
        "id": 244,
        "code": "public KafkaFuture<Map<Integer, Map<String, DescribeLogDirsResponse.LogDirInfo>>> all() {\n    return allDescriptions().thenApply(map -> map.entrySet().stream().collect(Collectors.toMap(\n        entry -> entry.getKey(),\n        entry -> convertMapValues(entry.getValue())\n    )));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "brokers",
            "have",
            "responded",
            "without",
            "error",
            "deprecated",
            "since",
            "kafka",
            "0"
        ]
    },
    {
        "id": 245,
        "code": "public KafkaFuture<Map<Integer, Map<String, LogDirDescription>>> allDescriptions() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n        thenApply(v -> {\n            Map<Integer, Map<String, LogDirDescription>> descriptions = new HashMap<>(futures.size());\n            for (Map.Entry<Integer, KafkaFuture<Map<String, LogDirDescription>>> entry : futures.entrySet()) {\n                try {\n                    descriptions.put(entry.getKey(), entry.getValue().get());\n                } catch (InterruptedException | ExecutionException e) {\n                        \n                    throw new RuntimeException(e);\n                }\n            }\n            return descriptions;\n        });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "brokers",
            "have",
            "responded",
            "without",
            "error"
        ]
    },
    {
        "id": 246,
        "code": "public KafkaFuture<QuorumInfo> quorumInfo() {\n    return quorumInfo;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "containing",
            "the",
            "quorum",
            "info"
        ]
    },
    {
        "id": 247,
        "code": "public Map<TopicPartitionReplica, KafkaFuture<ReplicaLogDirInfo>> values() {\n    return futures;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "replica",
            "to",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "log",
            "directory",
            "information",
            "of",
            "individual",
            "replicas"
        ]
    },
    {
        "id": 248,
        "code": "public KafkaFuture<Map<TopicPartitionReplica, ReplicaLogDirInfo>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).\n        thenApply(new KafkaFuture.BaseFunction<Void, Map<TopicPartitionReplica, ReplicaLogDirInfo>>() {\n            @Override\n            public Map<TopicPartitionReplica, ReplicaLogDirInfo> apply(Void v) {\n                Map<TopicPartitionReplica, ReplicaLogDirInfo> replicaLogDirInfos = new HashMap<>();\n                for (Map.Entry<TopicPartitionReplica, KafkaFuture<ReplicaLogDirInfo>> entry : futures.entrySet()) {\n                    try {\n                        replicaLogDirInfos.put(entry.getKey(), entry.getValue().get());\n                    } catch (InterruptedException | ExecutionException e) {\n                            \n                        throw new RuntimeException(e);\n                    }\n                }\n                return replicaLogDirInfos;\n            }\n        });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "if",
            "log",
            "directory",
            "information",
            "of",
            "all",
            "replicas",
            "are",
            "available"
        ]
    },
    {
        "id": 249,
        "code": "public DescribeTopicsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 250,
        "code": "public Map<Uuid, KafkaFuture<TopicDescription>> topicIdValues() {\n    return topicIdFutures;\n}",
        "summary_tokens": [
            "use",
            "when",
            "admin",
            "describe",
            "topics",
            "topic",
            "collection",
            "describe",
            "topics",
            "options",
            "used",
            "a",
            "topic",
            "id",
            "collection"
        ]
    },
    {
        "id": 251,
        "code": "public Map<String, KafkaFuture<TopicDescription>> topicNameValues() {\n    return nameFutures;\n}",
        "summary_tokens": [
            "use",
            "when",
            "admin",
            "describe",
            "topics",
            "topic",
            "collection",
            "describe",
            "topics",
            "options",
            "used",
            "a",
            "topic",
            "name",
            "collection"
        ]
    },
    {
        "id": 252,
        "code": "public Map<String, KafkaFuture<TopicDescription>> values() {\n    return nameFutures;\n}",
        "summary_tokens": [
            "a",
            "map",
            "from",
            "topic",
            "names",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "topics",
            "if",
            "the",
            "request",
            "used",
            "topic",
            "names",
            "otherwise",
            "return",
            "null"
        ]
    },
    {
        "id": 253,
        "code": "private static <T> KafkaFuture<Map<T, TopicDescription>> all(Map<T, KafkaFuture<TopicDescription>> futures) {\n    KafkaFuture<Void> future = KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n    return future.\n        thenApply(v -> {\n            Map<T, TopicDescription> descriptions = new HashMap<>(futures.size());\n            for (Map.Entry<T, KafkaFuture<TopicDescription>> entry : futures.entrySet()) {\n                try {\n                    descriptions.put(entry.getKey(), entry.getValue().get());\n                } catch (InterruptedException | ExecutionException e) {\n                        \n                        \n                    throw new RuntimeException(e);\n                }\n            }\n            return descriptions;\n        });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "topic",
            "descriptions",
            "succeed"
        ]
    },
    {
        "id": 254,
        "code": "public KafkaFuture<Map<String, TopicDescription>> allTopicNames() {\n    return all(nameFutures);\n}",
        "summary_tokens": [
            "a",
            "future",
            "map",
            "from",
            "topic",
            "names",
            "to",
            "descriptions",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "description",
            "if",
            "the",
            "describe",
            "topic",
            "request",
            "used",
            "topic",
            "names",
            "otherwise",
            "return",
            "null",
            "this",
            "request",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "topic",
            "descriptions",
            "succeed"
        ]
    },
    {
        "id": 255,
        "code": "public KafkaFuture<Map<Uuid, TopicDescription>> allTopicIds() {\n    return all(topicIdFutures);\n}",
        "summary_tokens": [
            "a",
            "future",
            "map",
            "from",
            "topic",
            "ids",
            "to",
            "descriptions",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "description",
            "if",
            "the",
            "describe",
            "topic",
            "request",
            "used",
            "topic",
            "ids",
            "otherwise",
            "return",
            "null",
            "this",
            "request",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "topic",
            "descriptions",
            "succeed"
        ]
    },
    {
        "id": 256,
        "code": "public KafkaFuture<TransactionDescription> description(String transactionalId) {\n    CoordinatorKey key = CoordinatorKey.byTransactionalId(transactionalId);\n    KafkaFuture<TransactionDescription> future = futures.get(key);\n    if (future == null) {\n        throw new IllegalArgumentException(\"TransactionalId \" +\n            \"`\" + transactionalId + \"` was not included in the request\");\n    }\n    return future;\n}",
        "summary_tokens": [
            "get",
            "the",
            "description",
            "of",
            "a",
            "specific",
            "transactional",
            "id"
        ]
    },
    {
        "id": 257,
        "code": "public KafkaFuture<Map<String, TransactionDescription>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]))\n        .thenApply(nil -> {\n            Map<String, TransactionDescription> results = new HashMap<>(futures.size());\n            for (Map.Entry<CoordinatorKey, KafkaFuture<TransactionDescription>> entry : futures.entrySet()) {\n                try {\n                    results.put(entry.getKey().idValue, entry.getValue().get());\n                } catch (InterruptedException | ExecutionException e) {\n                        \n                    throw new RuntimeException(e);\n                }\n            }\n            return results;\n        });\n}",
        "summary_tokens": [
            "get",
            "a",
            "future",
            "which",
            "returns",
            "a",
            "map",
            "of",
            "the",
            "transaction",
            "descriptions",
            "requested",
            "in",
            "the",
            "respective",
            "call",
            "to",
            "admin",
            "describe",
            "transactions",
            "collection",
            "describe",
            "transactions",
            "options"
        ]
    },
    {
        "id": 258,
        "code": "public KafkaFuture<Map<String, UserScramCredentialsDescription>> all() {\n    final KafkaFutureImpl<Map<String, UserScramCredentialsDescription>> retval = new KafkaFutureImpl<>();\n    dataFuture.whenComplete((data, throwable) -> {\n        if (throwable != null) {\n            retval.completeExceptionally(throwable);\n        } else {\n                \n            Optional<DescribeUserScramCredentialsResponseData.DescribeUserScramCredentialsResult> optionalFirstFailedDescribe =\n                    data.results().stream().filter(result ->\n                            result.errorCode() != Errors.NONE.code() && result.errorCode() != Errors.RESOURCE_NOT_FOUND.code()).findFirst();\n            if (optionalFirstFailedDescribe.isPresent()) {\n                retval.completeExceptionally(Errors.forCode(optionalFirstFailedDescribe.get().errorCode()).exception(optionalFirstFailedDescribe.get().errorMessage()));\n            } else {\n                Map<String, UserScramCredentialsDescription> retvalMap = new HashMap<>();\n                data.results().stream().forEach(userResult ->\n                        retvalMap.put(userResult.user(), new UserScramCredentialsDescription(userResult.user(),\n                                getScramCredentialInfosFor(userResult))));\n                retval.complete(retvalMap);\n            }\n        }\n    });\n    return retval;\n}",
        "summary_tokens": [
            "a",
            "future",
            "for",
            "the",
            "results",
            "of",
            "all",
            "described",
            "users",
            "with",
            "map",
            "keys",
            "one",
            "per",
            "user",
            "being",
            "consistent",
            "with",
            "the",
            "contents",
            "of",
            "the",
            "list",
            "returned",
            "by",
            "users"
        ]
    },
    {
        "id": 259,
        "code": "public KafkaFuture<List<String>> users() {\n    final KafkaFutureImpl<List<String>> retval = new KafkaFutureImpl<>();\n    dataFuture.whenComplete((data, throwable) -> {\n        if (throwable != null) {\n            retval.completeExceptionally(throwable);\n        } else {\n            retval.complete(data.results().stream()\n                    .filter(result -> result.errorCode() != Errors.RESOURCE_NOT_FOUND.code())\n                    .map(result -> result.user()).collect(Collectors.toList()));\n        }\n    });\n    return retval;\n}",
        "summary_tokens": [
            "a",
            "future",
            "indicating",
            "the",
            "distinct",
            "users",
            "that",
            "meet",
            "the",
            "request",
            "criteria",
            "and",
            "that",
            "have",
            "at",
            "least",
            "one",
            "credential"
        ]
    },
    {
        "id": 260,
        "code": "public KafkaFuture<UserScramCredentialsDescription> description(String userName) {\n    final KafkaFutureImpl<UserScramCredentialsDescription> retval = new KafkaFutureImpl<>();\n    dataFuture.whenComplete((data, throwable) -> {\n        if (throwable != null) {\n            retval.completeExceptionally(throwable);\n        } else {\n                \n                \n            Optional<DescribeUserScramCredentialsResponseData.DescribeUserScramCredentialsResult> optionalUserResult =\n                    data.results().stream().filter(result -> result.user().equals(userName)).findFirst();\n            if (!optionalUserResult.isPresent()) {\n                retval.completeExceptionally(new ResourceNotFoundException(\"No such user: \" + userName));\n            } else {\n                DescribeUserScramCredentialsResponseData.DescribeUserScramCredentialsResult userResult = optionalUserResult.get();\n                if (userResult.errorCode() != Errors.NONE.code()) {\n                        \n                    retval.completeExceptionally(Errors.forCode(userResult.errorCode()).exception(userResult.errorMessage()));\n                } else {\n                    retval.complete(new UserScramCredentialsDescription(userResult.user(), getScramCredentialInfosFor(userResult)));\n                }\n            }\n        }\n    });\n    return retval;\n}",
        "summary_tokens": [
            "user",
            "name",
            "the",
            "name",
            "of",
            "the",
            "user",
            "description",
            "being",
            "requested",
            "a",
            "future",
            "indicating",
            "the",
            "description",
            "results",
            "for",
            "the",
            "given",
            "user"
        ]
    },
    {
        "id": 261,
        "code": "public KafkaFuture<Map<TopicPartition, Optional<Throwable>>> partitions() {\n    return electionFuture;\n}",
        "summary_tokens": [
            "p",
            "get",
            "a",
            "future",
            "for",
            "the",
            "topic",
            "partitions",
            "for",
            "which",
            "a",
            "leader",
            "election",
            "was",
            "attempted"
        ]
    },
    {
        "id": 262,
        "code": "public KafkaFuture<Void> all() {\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n\n    partitions().whenComplete(\n            new KafkaFuture.BiConsumer<Map<TopicPartition, Optional<Throwable>>, Throwable>() {\n                @Override\n                public void accept(Map<TopicPartition, Optional<Throwable>> topicPartitions, Throwable throwable) {\n                    if (throwable != null) {\n                        result.completeExceptionally(throwable);\n                    } else {\n                        for (Optional<Throwable> exception : topicPartitions.values()) {\n                            if (exception.isPresent()) {\n                                result.completeExceptionally(exception.get());\n                                return;\n                            }\n                        }\n                        result.complete(null);\n                    }\n                }\n            });\n\n    return result;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "if",
            "all",
            "the",
            "topic",
            "elections",
            "succeed"
        ]
    },
    {
        "id": 263,
        "code": "public KafkaFuture<Long> expiryTimestamp() {\n    return expiryTimestamp;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "expiry",
            "timestamp"
        ]
    },
    {
        "id": 264,
        "code": "public Map<String, FinalizedVersionRange> finalizedFeatures() {\n    return new HashMap<>(finalizedFeatures);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "map",
            "of",
            "finalized",
            "feature",
            "versions"
        ]
    },
    {
        "id": 265,
        "code": "public Optional<Long> finalizedFeaturesEpoch() {\n    return finalizedFeaturesEpoch;\n}",
        "summary_tokens": [
            "the",
            "epoch",
            "for",
            "the",
            "finalized",
            "features"
        ]
    },
    {
        "id": 266,
        "code": "public Map<String, SupportedVersionRange> supportedFeatures() {\n    return new HashMap<>(supportedFeatures);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "map",
            "of",
            "supported",
            "feature",
            "versions"
        ]
    },
    {
        "id": 267,
        "code": "public Map<String, KafkaFuture<Void>> fencedProducers() {\n    return futures.entrySet().stream().collect(Collectors.toMap(\n        e -> e.getKey().idValue,\n        e -> e.getValue().thenApply(p -> null)\n    ));\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "transactional",
            "id",
            "to",
            "futures",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "status",
            "of",
            "individual",
            "fencings"
        ]
    },
    {
        "id": 268,
        "code": "public KafkaFuture<Long> producerId(String transactionalId) {\n    return findAndApply(transactionalId, p -> p.producerId);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "that",
            "provides",
            "the",
            "producer",
            "id",
            "generated",
            "while",
            "initializing",
            "the",
            "given",
            "transaction",
            "when",
            "the",
            "request",
            "completes"
        ]
    },
    {
        "id": 269,
        "code": "public KafkaFuture<Short> epochId(String transactionalId) {\n    return findAndApply(transactionalId, p -> p.epoch);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "that",
            "provides",
            "the",
            "epoch",
            "id",
            "generated",
            "while",
            "initializing",
            "the",
            "given",
            "transaction",
            "when",
            "the",
            "request",
            "completes"
        ]
    },
    {
        "id": 270,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "all",
            "the",
            "producer",
            "fencings",
            "succeed"
        ]
    },
    {
        "id": 271,
        "code": "static <K, V> List<V> getOrCreateListValue(Map<K, List<V>> map, K key) {\n    return map.computeIfAbsent(key, k -> new LinkedList<>());\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "a",
            "list",
            "value",
            "from",
            "a",
            "map"
        ]
    },
    {
        "id": 272,
        "code": "private static <T> void completeAllExceptionally(Stream<KafkaFutureImpl<T>> futures, Throwable exc) {\n    futures.forEach(future -> future.completeExceptionally(exc));\n}",
        "summary_tokens": [
            "send",
            "an",
            "exception",
            "to",
            "all",
            "futures",
            "in",
            "the",
            "provided",
            "stream"
        ]
    },
    {
        "id": 273,
        "code": "static int calcTimeoutMsRemainingAsInt(long now, long deadlineMs) {\n    long deltaMs = deadlineMs - now;\n    if (deltaMs > Integer.MAX_VALUE)\n        deltaMs = Integer.MAX_VALUE;\n    else if (deltaMs < Integer.MIN_VALUE)\n        deltaMs = Integer.MIN_VALUE;\n    return (int) deltaMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "time",
            "remaining",
            "before",
            "a",
            "deadline",
            "as",
            "an",
            "integer"
        ]
    },
    {
        "id": 274,
        "code": "static String generateClientId(AdminClientConfig config) {\n    String clientId = config.getString(AdminClientConfig.CLIENT_ID_CONFIG);\n    if (!clientId.isEmpty())\n        return clientId;\n    return \"adminclient-\" + ADMIN_CLIENT_ID_SEQUENCE.getAndIncrement();\n}",
        "summary_tokens": [
            "generate",
            "the",
            "client",
            "id",
            "based",
            "on",
            "the",
            "configuration"
        ]
    },
    {
        "id": 275,
        "code": "private long calcDeadlineMs(long now, Integer optionTimeoutMs) {\n    if (optionTimeoutMs != null)\n        return now + Math.max(0, optionTimeoutMs);\n    return now + defaultApiTimeoutMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "deadline",
            "for",
            "a",
            "particular",
            "call"
        ]
    },
    {
        "id": 276,
        "code": "static String prettyPrintException(Throwable throwable) {\n    if (throwable == null)\n        return \"Null exception.\";\n    if (throwable.getMessage() != null) {\n        return throwable.getClass().getSimpleName() + \": \" + throwable.getMessage();\n    }\n    return throwable.getClass().getSimpleName();\n}",
        "summary_tokens": [
            "pretty",
            "print",
            "an",
            "exception"
        ]
    },
    {
        "id": 277,
        "code": "private static boolean topicNameIsUnrepresentable(String topicName) {\n    return topicName == null || topicName.isEmpty();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "a",
            "topic",
            "name",
            "cannot",
            "be",
            "represented",
            "in",
            "an",
            "rpc"
        ]
    },
    {
        "id": 278,
        "code": "private static <K, V> void completeUnrealizedFutures(\n        Stream<Map.Entry<K, KafkaFutureImpl<V>>> futures,\n        Function<K, String> messageFormatter) {\n    futures.filter(entry -> !entry.getValue().isDone()).forEach(entry ->\n            entry.getValue().completeExceptionally(new ApiException(messageFormatter.apply(entry.getKey()))));\n}",
        "summary_tokens": [
            "fail",
            "futures",
            "in",
            "the",
            "given",
            "stream",
            "which",
            "are",
            "not",
            "done"
        ]
    },
    {
        "id": 279,
        "code": "private static <K, V> void maybeCompleteQuotaExceededException(\n        boolean shouldRetryOnQuotaViolation,\n        Throwable throwable,\n        Map<K, KafkaFutureImpl<V>> futures,\n        Map<K, ThrottlingQuotaExceededException> quotaExceededExceptions,\n        int throttleTimeDelta) {\n    if (shouldRetryOnQuotaViolation && throwable instanceof TimeoutException) {\n        quotaExceededExceptions.forEach((key, value) -> futures.get(key).completeExceptionally(\n            new ThrottlingQuotaExceededException(\n                Math.max(0, value.throttleTimeMs() - throttleTimeDelta),\n                value.getMessage())));\n    }\n}",
        "summary_tokens": [
            "fail",
            "futures",
            "in",
            "the",
            "given",
            "map",
            "which",
            "were",
            "retried",
            "due",
            "to",
            "exceeding",
            "quota"
        ]
    },
    {
        "id": 280,
        "code": "private <T, O extends AbstractOptions<O>> Call getMetadataCall(MetadataOperationContext<T, O> context,\n                                                               Supplier<List<Call>> nextCalls) {\n    return new Call(\"metadata\", context.deadline(), new LeastLoadedNodeProvider()) {\n        @Override\n        MetadataRequest.Builder createRequest(int timeoutMs) {\n            return new MetadataRequest.Builder(new MetadataRequestData()\n                .setTopics(convertToMetadataRequestTopic(context.topics()))\n                .setAllowAutoTopicCreation(false));\n        }\n\n        @Override\n        void handleResponse(AbstractResponse abstractResponse) {\n            MetadataResponse response = (MetadataResponse) abstractResponse;\n            MetadataOperationContext.handleMetadataErrors(response);\n\n            context.setResponse(Optional.of(response));\n\n            for (Call call : nextCalls.get()) {\n                runnable.call(call, time.milliseconds());\n            }\n        }\n\n        @Override\n        void handleFailure(Throwable throwable) {\n            for (KafkaFutureImpl<T> future : context.futures().values()) {\n                future.completeExceptionally(throwable);\n            }\n        }\n    };\n}",
        "summary_tokens": [
            "returns",
            "a",
            "call",
            "object",
            "to",
            "fetch",
            "the",
            "cluster",
            "metadata"
        ]
    },
    {
        "id": 281,
        "code": "private Integer nodeFor(ConfigResource resource) {\n    if ((resource.type() == ConfigResource.Type.BROKER && !resource.isDefault())\n            || resource.type() == ConfigResource.Type.BROKER_LOGGER) {\n        return Integer.valueOf(resource.name());\n    } else {\n        return null;\n    }\n}",
        "summary_tokens": [
            "returns",
            "the",
            "broker",
            "id",
            "pertaining",
            "to",
            "the",
            "given",
            "resource",
            "or",
            "null",
            "if",
            "the",
            "resource",
            "is",
            "not",
            "associated",
            "with",
            "a",
            "particular",
            "broker"
        ]
    },
    {
        "id": 282,
        "code": "static <K> Throwable getSubLevelError(Map<K, Errors> subLevelErrors, K subKey, String keyNotFoundMsg) {\n    if (!subLevelErrors.containsKey(subKey)) {\n        return new IllegalArgumentException(keyNotFoundMsg);\n    } else {\n        return subLevelErrors.get(subKey).exception();\n    }\n}",
        "summary_tokens": [
            "get",
            "a",
            "sub",
            "level",
            "error",
            "when",
            "the",
            "request",
            "is",
            "in",
            "batch"
        ]
    },
    {
        "id": 283,
        "code": "public List<TopicPartition> topicPartitions() {\n    return topicPartitions;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "list",
            "of",
            "topic",
            "partitions",
            "to",
            "add",
            "as",
            "part",
            "of",
            "the",
            "result"
        ]
    },
    {
        "id": 284,
        "code": "public ListConsumerGroupOffsetsOptions requireStable(final boolean requireStable) {\n    this.requireStable = requireStable;\n    return this;\n}",
        "summary_tokens": [
            "sets",
            "an",
            "optional",
            "require",
            "stable",
            "flag"
        ]
    },
    {
        "id": 285,
        "code": "public KafkaFuture<Map<TopicPartition, OffsetAndMetadata>> partitionsToOffsetAndMetadata(String groupId) {\n    if (!futures.containsKey(groupId))\n        throw new IllegalArgumentException(\"Offsets for consumer group '\" + groupId + \"' were not requested.\");\n    return futures.get(groupId);\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "yields",
            "a",
            "map",
            "of",
            "topic",
            "partitions",
            "to",
            "offset",
            "and",
            "metadata",
            "objects",
            "for",
            "the",
            "specified",
            "group"
        ]
    },
    {
        "id": 286,
        "code": "public KafkaFuture<Map<String, Map<TopicPartition, OffsetAndMetadata>>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).thenApply(\n        nil -> {\n            Map<String, Map<TopicPartition, OffsetAndMetadata>> listedConsumerGroupOffsets = new HashMap<>(futures.size());\n            futures.forEach((key, future) -> {\n                try {\n                    listedConsumerGroupOffsets.put(key, future.get());\n                } catch (InterruptedException | ExecutionException e) {\n                        \n                        \n                    throw new RuntimeException(e);\n                }\n            });\n            return listedConsumerGroupOffsets;\n        });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "yields",
            "all",
            "map",
            "string",
            "map",
            "topic",
            "partition",
            "offset",
            "and",
            "metadata",
            "objects",
            "if",
            "requests",
            "for",
            "all",
            "the",
            "groups",
            "succeed"
        ]
    },
    {
        "id": 287,
        "code": "public Collection<TopicPartition> topicPartitions() {\n    return topicPartitions;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "topic",
            "partitions",
            "whose",
            "offsets",
            "are",
            "to",
            "be",
            "listed",
            "for",
            "a",
            "consumer",
            "group"
        ]
    },
    {
        "id": 288,
        "code": "public ListConsumerGroupsOptions inStates(Set<ConsumerGroupState> states) {\n    this.states = (states == null) ? Collections.emptySet() : new HashSet<>(states);\n    return this;\n}",
        "summary_tokens": [
            "if",
            "states",
            "is",
            "set",
            "only",
            "groups",
            "in",
            "these",
            "states",
            "will",
            "be",
            "returned",
            "by",
            "list",
            "consumer",
            "groups",
            "otherwise",
            "all",
            "groups",
            "are",
            "returned"
        ]
    },
    {
        "id": 289,
        "code": "public Set<ConsumerGroupState> states() {\n    return states;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "list",
            "of",
            "states",
            "that",
            "are",
            "requested",
            "or",
            "empty",
            "if",
            "no",
            "states",
            "have",
            "been",
            "specified"
        ]
    },
    {
        "id": 290,
        "code": "public KafkaFuture<Collection<ConsumerGroupListing>> all() {\n    return all;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "that",
            "yields",
            "either",
            "an",
            "exception",
            "or",
            "the",
            "full",
            "set",
            "of",
            "consumer",
            "group",
            "listings"
        ]
    },
    {
        "id": 291,
        "code": "public KafkaFuture<Collection<ConsumerGroupListing>> valid() {\n    return valid;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "just",
            "the",
            "valid",
            "listings"
        ]
    },
    {
        "id": 292,
        "code": "public KafkaFuture<Collection<Throwable>> errors() {\n    return errors;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "just",
            "the",
            "errors",
            "which",
            "occurred"
        ]
    },
    {
        "id": 293,
        "code": "public KafkaFuture<ListOffsetsResultInfo> partitionResult(final TopicPartition partition) {\n    KafkaFuture<ListOffsetsResultInfo> future = futures.get(partition);\n    if (future == null) {\n        throw new IllegalArgumentException(\n                \"List Offsets for partition \\\"\" + partition + \"\\\" was not attempted\");\n    }\n    return future;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "can",
            "be",
            "used",
            "to",
            "check",
            "the",
            "result",
            "for",
            "a",
            "given",
            "partition"
        ]
    },
    {
        "id": 294,
        "code": "public KafkaFuture<Map<TopicPartition, ListOffsetsResultInfo>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]))\n            .thenApply(new KafkaFuture.BaseFunction<Void, Map<TopicPartition, ListOffsetsResultInfo>>() {\n                @Override\n                public Map<TopicPartition, ListOffsetsResultInfo> apply(Void v) {\n                    Map<TopicPartition, ListOffsetsResultInfo> offsets = new HashMap<>(futures.size());\n                    for (Map.Entry<TopicPartition, KafkaFuture<ListOffsetsResultInfo>> entry : futures.entrySet()) {\n                        try {\n                            offsets.put(entry.getKey(), entry.getValue().get());\n                        } catch (InterruptedException | ExecutionException e) {\n                                \n                            throw new RuntimeException(e);\n                        }\n                    }\n                    return offsets;\n                }\n            });\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "only",
            "if",
            "offsets",
            "for",
            "all",
            "specified",
            "partitions",
            "have",
            "been",
            "successfully",
            "retrieved"
        ]
    },
    {
        "id": 295,
        "code": "public KafkaFuture<Map<TopicPartition, PartitionReassignment>> reassignments() {\n    return future;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "yields",
            "a",
            "map",
            "containing",
            "each",
            "partition",
            "s",
            "reassignments"
        ]
    },
    {
        "id": 296,
        "code": "public ListTopicsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "for",
            "this",
            "operation",
            "or",
            "null",
            "if",
            "the",
            "default",
            "api",
            "timeout",
            "for",
            "the",
            "admin",
            "client",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 297,
        "code": "public ListTopicsOptions listInternal(boolean listInternal) {\n    this.listInternal = listInternal;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "whether",
            "we",
            "should",
            "list",
            "internal",
            "topics"
        ]
    },
    {
        "id": 298,
        "code": "public boolean shouldListInternal() {\n    return listInternal;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "we",
            "should",
            "list",
            "internal",
            "topics"
        ]
    },
    {
        "id": 299,
        "code": "public KafkaFuture<Map<String, TopicListing>> namesToListings() {\n    return future;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "yields",
            "a",
            "map",
            "of",
            "topic",
            "names",
            "to",
            "topic",
            "listing",
            "objects"
        ]
    },
    {
        "id": 300,
        "code": "public KafkaFuture<Collection<TopicListing>> listings() {\n    return future.thenApply(namesToDescriptions -> namesToDescriptions.values());\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "yields",
            "a",
            "collection",
            "of",
            "topic",
            "listing",
            "objects"
        ]
    },
    {
        "id": 301,
        "code": "public KafkaFuture<Set<String>> names() {\n    return future.thenApply(namesToListings -> namesToListings.keySet());\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "yields",
            "a",
            "collection",
            "of",
            "topic",
            "names"
        ]
    },
    {
        "id": 302,
        "code": "public ListTransactionsOptions filterStates(Collection<TransactionState> states) {\n    this.filteredStates = new HashSet<>(states);\n    return this;\n}",
        "summary_tokens": [
            "filter",
            "only",
            "the",
            "transactions",
            "that",
            "are",
            "in",
            "a",
            "specific",
            "set",
            "of",
            "states"
        ]
    },
    {
        "id": 303,
        "code": "public ListTransactionsOptions filterProducerIds(Collection<Long> producerIdFilters) {\n    this.filteredProducerIds = new HashSet<>(producerIdFilters);\n    return this;\n}",
        "summary_tokens": [
            "filter",
            "only",
            "the",
            "transactions",
            "from",
            "producers",
            "in",
            "a",
            "specific",
            "set",
            "of",
            "producer",
            "ids"
        ]
    },
    {
        "id": 304,
        "code": "public Set<TransactionState> filteredStates() {\n    return filteredStates;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "set",
            "of",
            "states",
            "to",
            "be",
            "filtered",
            "or",
            "empty",
            "if",
            "no",
            "states",
            "have",
            "been",
            "specified"
        ]
    },
    {
        "id": 305,
        "code": "public Set<Long> filteredProducerIds() {\n    return filteredProducerIds;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "set",
            "of",
            "producer",
            "ids",
            "that",
            "are",
            "being",
            "filtered",
            "or",
            "empty",
            "if",
            "none",
            "have",
            "been",
            "specified"
        ]
    },
    {
        "id": 306,
        "code": "public KafkaFuture<Collection<TransactionListing>> all() {\n    return allByBrokerId().thenApply(map -> {\n        List<TransactionListing> allListings = new ArrayList<>();\n        for (Collection<TransactionListing> listings : map.values()) {\n            allListings.addAll(listings);\n        }\n        return allListings;\n    });\n}",
        "summary_tokens": [
            "get",
            "all",
            "transaction",
            "listings"
        ]
    },
    {
        "id": 307,
        "code": "public KafkaFuture<Map<Integer, KafkaFuture<Collection<TransactionListing>>>> byBrokerId() {\n    KafkaFutureImpl<Map<Integer, KafkaFuture<Collection<TransactionListing>>>> result = new KafkaFutureImpl<>();\n    future.whenComplete((brokerFutures, exception) -> {\n        if (brokerFutures != null) {\n            Map<Integer, KafkaFuture<Collection<TransactionListing>>> brokerFuturesCopy =\n                new HashMap<>(brokerFutures.size());\n            brokerFuturesCopy.putAll(brokerFutures);\n            result.complete(brokerFuturesCopy);\n        } else {\n            result.completeExceptionally(exception);\n        }\n    });\n    return result;\n}",
        "summary_tokens": [
            "get",
            "a",
            "future",
            "which",
            "returns",
            "a",
            "map",
            "containing",
            "the",
            "underlying",
            "listing",
            "future",
            "for",
            "each",
            "broker",
            "in",
            "the",
            "cluster"
        ]
    },
    {
        "id": 308,
        "code": "public KafkaFuture<Map<Integer, Collection<TransactionListing>>> allByBrokerId() {\n    KafkaFutureImpl<Map<Integer, Collection<TransactionListing>>> allFuture = new KafkaFutureImpl<>();\n    Map<Integer, Collection<TransactionListing>> allListingsMap = new HashMap<>();\n\n    future.whenComplete((map, topLevelException) -> {\n        if (topLevelException != null) {\n            allFuture.completeExceptionally(topLevelException);\n            return;\n        }\n\n        Set<Integer> remainingResponses = new HashSet<>(map.keySet());\n        map.forEach((brokerId, future) -> {\n            future.whenComplete((listings, brokerException) -> {\n                if (brokerException != null) {\n                    allFuture.completeExceptionally(brokerException);\n                } else if (!allFuture.isDone()) {\n                    allListingsMap.put(brokerId, listings);\n                    remainingResponses.remove(brokerId);\n\n                    if (remainingResponses.isEmpty()) {\n                        allFuture.complete(allListingsMap);\n                    }\n                }\n            });\n        });\n    });\n\n    return allFuture;\n}",
        "summary_tokens": [
            "get",
            "all",
            "transaction",
            "listings",
            "in",
            "a",
            "map",
            "which",
            "is",
            "keyed",
            "by",
            "the",
            "id",
            "of",
            "respective",
            "broker",
            "that",
            "is",
            "currently",
            "managing",
            "them"
        ]
    },
    {
        "id": 309,
        "code": "public ApiException error() {\n    return error;\n}",
        "summary_tokens": [
            "returns",
            "api",
            "exception",
            "if",
            "the",
            "log",
            "directory",
            "is",
            "offline",
            "or",
            "an",
            "error",
            "occurred",
            "otherwise",
            "returns",
            "null"
        ]
    },
    {
        "id": 310,
        "code": "public Map<TopicPartition, ReplicaInfo> replicaInfos() {\n    return unmodifiableMap(replicaInfos);\n}",
        "summary_tokens": [
            "a",
            "map",
            "from",
            "topic",
            "partition",
            "to",
            "replica",
            "information",
            "for",
            "that",
            "partition",
            "in",
            "this",
            "log",
            "directory"
        ]
    },
    {
        "id": 311,
        "code": "public OptionalLong totalBytes() {\n    return totalBytes;\n}",
        "summary_tokens": [
            "the",
            "total",
            "size",
            "of",
            "the",
            "volume",
            "this",
            "log",
            "directory",
            "is",
            "on",
            "or",
            "empty",
            "if",
            "the",
            "broker",
            "did",
            "not",
            "return",
            "a",
            "value"
        ]
    },
    {
        "id": 312,
        "code": "public OptionalLong usableBytes() {\n    return usableBytes;\n}",
        "summary_tokens": [
            "the",
            "usable",
            "size",
            "on",
            "the",
            "volume",
            "this",
            "log",
            "directory",
            "is",
            "on",
            "or",
            "empty",
            "if",
            "the",
            "broker",
            "did",
            "not",
            "return",
            "a",
            "value"
        ]
    },
    {
        "id": 313,
        "code": "public Set<TopicPartition> topicPartitions() {\n    return topicPartitions;\n}",
        "summary_tokens": [
            "the",
            "topic",
            "partitions",
            "assigned",
            "to",
            "a",
            "group",
            "member"
        ]
    },
    {
        "id": 314,
        "code": "public String consumerId() {\n    return memberId;\n}",
        "summary_tokens": [
            "the",
            "consumer",
            "id",
            "of",
            "the",
            "group",
            "member"
        ]
    },
    {
        "id": 315,
        "code": "public Optional<String> groupInstanceId() {\n    return groupInstanceId;\n}",
        "summary_tokens": [
            "the",
            "instance",
            "id",
            "of",
            "the",
            "group",
            "member"
        ]
    },
    {
        "id": 316,
        "code": "public String clientId() {\n    return clientId;\n}",
        "summary_tokens": [
            "the",
            "client",
            "id",
            "of",
            "the",
            "group",
            "member"
        ]
    },
    {
        "id": 317,
        "code": "public String host() {\n    return host;\n}",
        "summary_tokens": [
            "the",
            "host",
            "where",
            "the",
            "group",
            "member",
            "is",
            "running"
        ]
    },
    {
        "id": 318,
        "code": "public MemberAssignment assignment() {\n    return assignment;\n}",
        "summary_tokens": [
            "the",
            "assignment",
            "of",
            "the",
            "group",
            "member"
        ]
    },
    {
        "id": 319,
        "code": "public static NewPartitions increaseTo(int totalCount, List<List<Integer>> newAssignments) {\n    return new NewPartitions(totalCount, newAssignments);\n}",
        "summary_tokens": [
            "p",
            "increase",
            "the",
            "partition",
            "count",
            "for",
            "a",
            "topic",
            "to",
            "the",
            "given",
            "total",
            "count",
            "assigning",
            "the",
            "new",
            "partitions",
            "according",
            "to",
            "the",
            "given",
            "new",
            "assignments"
        ]
    },
    {
        "id": 320,
        "code": "public int totalCount() {\n    return totalCount;\n}",
        "summary_tokens": [
            "the",
            "total",
            "number",
            "of",
            "partitions",
            "after",
            "the",
            "operation",
            "succeeds"
        ]
    },
    {
        "id": 321,
        "code": "public List<List<Integer>> assignments() {\n    return newAssignments;\n}",
        "summary_tokens": [
            "the",
            "replica",
            "assignments",
            "for",
            "the",
            "new",
            "partitions",
            "or",
            "null",
            "if",
            "the",
            "assignment",
            "will",
            "be",
            "done",
            "by",
            "the",
            "controller"
        ]
    },
    {
        "id": 322,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "the",
            "name",
            "of",
            "the",
            "topic",
            "to",
            "be",
            "created"
        ]
    },
    {
        "id": 323,
        "code": "public int numPartitions() {\n    return numPartitions.orElse(CreateTopicsRequest.NO_NUM_PARTITIONS);\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "partitions",
            "for",
            "the",
            "new",
            "topic",
            "or",
            "0",
            "if",
            "a",
            "replica",
            "assignment",
            "has",
            "been",
            "specified"
        ]
    },
    {
        "id": 324,
        "code": "public short replicationFactor() {\n    return replicationFactor.orElse(CreateTopicsRequest.NO_REPLICATION_FACTOR);\n}",
        "summary_tokens": [
            "the",
            "replication",
            "factor",
            "for",
            "the",
            "new",
            "topic",
            "or",
            "0",
            "if",
            "a",
            "replica",
            "assignment",
            "has",
            "been",
            "specified"
        ]
    },
    {
        "id": 325,
        "code": "public Map<Integer, List<Integer>> replicasAssignments() {\n    return replicasAssignments;\n}",
        "summary_tokens": [
            "a",
            "map",
            "from",
            "partition",
            "id",
            "to",
            "replica",
            "ids",
            "i"
        ]
    },
    {
        "id": 326,
        "code": "public Map<String, String> configs() {\n    return configs;\n}",
        "summary_tokens": [
            "the",
            "configuration",
            "for",
            "the",
            "new",
            "topic",
            "or",
            "null",
            "if",
            "no",
            "configs",
            "ever",
            "specified"
        ]
    },
    {
        "id": 327,
        "code": "public static OffsetSpec latest() {\n    return new LatestSpec();\n}",
        "summary_tokens": [
            "used",
            "to",
            "retrieve",
            "the",
            "latest",
            "offset",
            "of",
            "a",
            "partition"
        ]
    },
    {
        "id": 328,
        "code": "public static OffsetSpec earliest() {\n    return new EarliestSpec();\n}",
        "summary_tokens": [
            "used",
            "to",
            "retrieve",
            "the",
            "earliest",
            "offset",
            "of",
            "a",
            "partition"
        ]
    },
    {
        "id": 329,
        "code": "public static OffsetSpec forTimestamp(long timestamp) {\n    return new TimestampSpec(timestamp);\n}",
        "summary_tokens": [
            "used",
            "to",
            "retrieve",
            "the",
            "earliest",
            "offset",
            "whose",
            "timestamp",
            "is",
            "greater",
            "than",
            "or",
            "equal",
            "to",
            "the",
            "given",
            "timestamp",
            "in",
            "the",
            "corresponding",
            "partition",
            "timestamp",
            "in",
            "milliseconds"
        ]
    },
    {
        "id": 330,
        "code": "public static OffsetSpec maxTimestamp() {\n    return new MaxTimestampSpec();\n}",
        "summary_tokens": [
            "used",
            "to",
            "retrieve",
            "the",
            "offset",
            "with",
            "the",
            "largest",
            "timestamp",
            "of",
            "a",
            "partition",
            "as",
            "message",
            "timestamps",
            "can",
            "be",
            "specified",
            "client",
            "side",
            "this",
            "may",
            "not",
            "match",
            "the",
            "log",
            "end",
            "offset",
            "returned",
            "by",
            "latest",
            "spec"
        ]
    },
    {
        "id": 331,
        "code": "public List<Integer> replicas() {\n    return replicas;\n}",
        "summary_tokens": [
            "the",
            "brokers",
            "which",
            "this",
            "partition",
            "currently",
            "resides",
            "on"
        ]
    },
    {
        "id": 332,
        "code": "public List<Integer> addingReplicas() {\n    return addingReplicas;\n}",
        "summary_tokens": [
            "the",
            "brokers",
            "that",
            "we",
            "are",
            "adding",
            "this",
            "partition",
            "to",
            "as",
            "part",
            "of",
            "a",
            "reassignment"
        ]
    },
    {
        "id": 333,
        "code": "public List<Integer> removingReplicas() {\n    return removingReplicas;\n}",
        "summary_tokens": [
            "the",
            "brokers",
            "that",
            "we",
            "are",
            "removing",
            "this",
            "partition",
            "from",
            "as",
            "part",
            "of",
            "a",
            "reassignment"
        ]
    },
    {
        "id": 334,
        "code": "public long beforeOffset() {\n    return offset;\n}",
        "summary_tokens": [
            "the",
            "offset",
            "before",
            "which",
            "all",
            "records",
            "will",
            "be",
            "deleted"
        ]
    },
    {
        "id": 335,
        "code": "public void reason(final String reason) {\n    this.reason = reason;\n}",
        "summary_tokens": [
            "sets",
            "an",
            "optional",
            "reason"
        ]
    },
    {
        "id": 336,
        "code": "public KafkaFuture<Void> all() {\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n    this.future.whenComplete((memberErrors, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else {\n            if (removeAll()) {\n                for (Map.Entry<MemberIdentity, Errors> entry: memberErrors.entrySet()) {\n                    Exception exception = entry.getValue().exception();\n                    if (exception != null) {\n                        Throwable ex = new KafkaException(\"Encounter exception when trying to remove: \"\n                                + entry.getKey(), exception);\n                        result.completeExceptionally(ex);\n                        return;\n                    }\n                }\n            } else {\n                for (MemberToRemove memberToRemove : memberInfos) {\n                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n                        return;\n                    }\n                }\n            }\n            result.complete(null);\n        }\n    });\n    return result;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "indicates",
            "whether",
            "the",
            "request",
            "was",
            "0",
            "success",
            "i"
        ]
    },
    {
        "id": 337,
        "code": "public KafkaFuture<Void> memberResult(MemberToRemove member) {\n    if (removeAll()) {\n        throw new IllegalArgumentException(\"The method: memberResult is not applicable in 'removeAll' mode\");\n    }\n    if (!memberInfos.contains(member)) {\n        throw new IllegalArgumentException(\"Member \" + member + \" was not included in the original request\");\n    }\n\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n    this.future.whenComplete((memberErrors, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else if (!maybeCompleteExceptionally(memberErrors, member.toMemberIdentity(), result)) {\n            result.complete(null);\n        }\n    });\n    return result;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "selected",
            "member",
            "future"
        ]
    },
    {
        "id": 338,
        "code": "public KafkaFuture<Long> expiryTimestamp() {\n    return expiryTimestamp;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "future",
            "which",
            "yields",
            "expiry",
            "timestamp"
        ]
    },
    {
        "id": 339,
        "code": "public long size() {\n    return size;\n}",
        "summary_tokens": [
            "the",
            "total",
            "size",
            "of",
            "the",
            "log",
            "segments",
            "in",
            "this",
            "replica",
            "in",
            "bytes"
        ]
    },
    {
        "id": 340,
        "code": "public long offsetLag() {\n    return offsetLag;\n}",
        "summary_tokens": [
            "the",
            "lag",
            "of",
            "the",
            "log",
            "s",
            "leo",
            "with",
            "respect",
            "to",
            "the",
            "partition",
            "s",
            "high",
            "watermark",
            "if",
            "it",
            "is",
            "the",
            "current",
            "log",
            "for",
            "the",
            "partition",
            "or",
            "the",
            "current",
            "replica",
            "s",
            "leo",
            "if",
            "it",
            "is",
            "the",
            "is",
            "future",
            "future",
            "log",
            "for",
            "the",
            "partition"
        ]
    },
    {
        "id": 341,
        "code": "public boolean isFuture() {\n    return isFuture;\n}",
        "summary_tokens": [
            "whether",
            "this",
            "replica",
            "has",
            "been",
            "created",
            "by",
            "a",
            "alter",
            "replica",
            "log",
            "dirs",
            "request",
            "but",
            "not",
            "yet",
            "replaced",
            "the",
            "current",
            "replica",
            "on",
            "the",
            "broker"
        ]
    },
    {
        "id": 342,
        "code": "public int iterations() {\n    return iterations;\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "iterations",
            "used",
            "when",
            "creating",
            "the",
            "credential"
        ]
    },
    {
        "id": 343,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "the",
            "name",
            "of",
            "the",
            "topic"
        ]
    },
    {
        "id": 344,
        "code": "public boolean isInternal() {\n    return internal;\n}",
        "summary_tokens": [
            "whether",
            "the",
            "topic",
            "is",
            "internal",
            "to",
            "kafka"
        ]
    },
    {
        "id": 345,
        "code": "public List<TopicPartitionInfo> partitions() {\n    return partitions;\n}",
        "summary_tokens": [
            "a",
            "list",
            "of",
            "partitions",
            "where",
            "the",
            "index",
            "represents",
            "the",
            "partition",
            "id",
            "and",
            "the",
            "element",
            "contains",
            "leadership",
            "and",
            "replica",
            "information",
            "for",
            "that",
            "partition"
        ]
    },
    {
        "id": 346,
        "code": "public Set<AclOperation>  authorizedOperations() {\n    return authorizedOperations;\n}",
        "summary_tokens": [
            "authorized",
            "operations",
            "for",
            "this",
            "topic",
            "or",
            "null",
            "if",
            "this",
            "is",
            "not",
            "known"
        ]
    },
    {
        "id": 347,
        "code": "public Uuid topicId() {\n    return topicId;\n}",
        "summary_tokens": [
            "the",
            "id",
            "of",
            "the",
            "topic"
        ]
    },
    {
        "id": 348,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "the",
            "name",
            "of",
            "the",
            "topic"
        ]
    },
    {
        "id": 349,
        "code": "public boolean isInternal() {\n    return internal;\n}",
        "summary_tokens": [
            "whether",
            "the",
            "topic",
            "is",
            "internal",
            "to",
            "kafka"
        ]
    },
    {
        "id": 350,
        "code": "public KafkaFuture<Void> all() {\n    return future;\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "if",
            "the",
            "operation",
            "is",
            "successful"
        ]
    },
    {
        "id": 351,
        "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}",
        "summary_tokens": [
            "return",
            "a",
            "future",
            "which",
            "succeeds",
            "if",
            "all",
            "the",
            "feature",
            "updates",
            "succeed"
        ]
    },
    {
        "id": 352,
        "code": "public String user() {\n    return this.user;\n}",
        "summary_tokens": [
            "the",
            "always",
            "non",
            "null",
            "user"
        ]
    },
    {
        "id": 353,
        "code": "public ScramMechanism mechanism() {\n    return mechanism;\n}",
        "summary_tokens": [
            "the",
            "always",
            "non",
            "null",
            "mechanism"
        ]
    },
    {
        "id": 354,
        "code": "public ScramCredentialInfo credentialInfo() {\n    return info;\n}",
        "summary_tokens": [
            "the",
            "mechanism",
            "and",
            "iterations"
        ]
    },
    {
        "id": 355,
        "code": "public List<ScramCredentialInfo> credentialInfos() {\n    return credentialInfos;\n}",
        "summary_tokens": [
            "the",
            "always",
            "non",
            "null",
            "unmodifiable",
            "list",
            "of",
            "sasl",
            "scram",
            "credential",
            "representations",
            "for",
            "the",
            "user"
        ]
    },
    {
        "id": 356,
        "code": "private void map(K key, Integer brokerId) {\n    lookupMap.remove(key);\n    fulfillmentMap.put(new FulfillmentScope(brokerId), key);\n}",
        "summary_tokens": [
            "associate",
            "a",
            "key",
            "with",
            "a",
            "broker",
            "id"
        ]
    },
    {
        "id": 357,
        "code": "private void unmap(K key) {\n    fulfillmentMap.remove(key);\n\n    ApiRequestScope lookupScope = handler.lookupStrategy().lookupScope(key);\n    OptionalInt destinationBrokerId = lookupScope.destinationBrokerId();\n\n    if (destinationBrokerId.isPresent()) {\n        fulfillmentMap.put(new FulfillmentScope(destinationBrokerId.getAsInt()), key);\n    } else {\n        lookupMap.put(handler.lookupStrategy().lookupScope(key), key);\n    }\n}",
        "summary_tokens": [
            "disassociate",
            "a",
            "key",
            "from",
            "the",
            "currently",
            "mapped",
            "broker",
            "id"
        ]
    },
    {
        "id": 358,
        "code": "private void completeExceptionally(Map<K, Throwable> errors) {\n    if (!errors.isEmpty()) {\n        future.completeExceptionally(errors);\n        clear(errors.keySet());\n    }\n}",
        "summary_tokens": [
            "complete",
            "the",
            "future",
            "associated",
            "with",
            "the",
            "given",
            "key",
            "exceptionally"
        ]
    },
    {
        "id": 359,
        "code": "private void complete(Map<K, V> values) {\n    if (!values.isEmpty()) {\n        future.complete(values);\n        clear(values.keySet());\n    }\n}",
        "summary_tokens": [
            "complete",
            "the",
            "future",
            "associated",
            "with",
            "the",
            "given",
            "key"
        ]
    },
    {
        "id": 360,
        "code": "public List<RequestSpec<K>> poll() {\n    List<RequestSpec<K>> requests = new ArrayList<>();\n    collectLookupRequests(requests);\n    collectFulfillmentRequests(requests);\n    return requests;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "any",
            "requests",
            "need",
            "to",
            "be",
            "sent"
        ]
    },
    {
        "id": 361,
        "code": "public void onResponse(\n    long currentTimeMs,\n    RequestSpec<K> spec,\n    AbstractResponse response,\n    Node node\n) {\n    clearInflightRequest(currentTimeMs, spec);\n\n    if (spec.scope instanceof FulfillmentScope) {\n        AdminApiHandler.ApiResult<K, V> result = handler.handleResponse(\n            node,\n            spec.keys,\n            response\n        );\n        complete(result.completedKeys);\n        completeExceptionally(result.failedKeys);\n        retryLookup(result.unmappedKeys);\n    } else {\n        AdminApiLookupStrategy.LookupResult<K> result = handler.lookupStrategy().handleResponse(\n            spec.keys,\n            response\n        );\n\n        result.completedKeys.forEach(lookupMap::remove);\n        completeLookup(result.mappedKeys);\n        completeLookupExceptionally(result.failedKeys);\n    }\n}",
        "summary_tokens": [
            "callback",
            "that",
            "is",
            "invoked",
            "when",
            "a",
            "call",
            "returns",
            "a",
            "response",
            "successfully"
        ]
    },
    {
        "id": 362,
        "code": "public void onFailure(\n    long currentTimeMs,\n    RequestSpec<K> spec,\n    Throwable t\n) {\n    clearInflightRequest(currentTimeMs, spec);\n    if (t instanceof DisconnectException) {\n        log.debug(\"Node disconnected before response could be received for request {}. \" +\n            \"Will attempt retry\", spec.request);\n\n            \n            \n            \n        Set<K> keysToUnmap = spec.keys.stream()\n            .filter(future.lookupKeys()::contains)\n            .collect(Collectors.toSet());\n        retryLookup(keysToUnmap);\n\n    } else if (t instanceof NoBatchedFindCoordinatorsException || t instanceof NoBatchedOffsetFetchRequestException) {\n        ((CoordinatorStrategy) handler.lookupStrategy()).disableBatch();\n        Set<K> keysToUnmap = spec.keys.stream()\n            .filter(future.lookupKeys()::contains)\n            .collect(Collectors.toSet());\n        retryLookup(keysToUnmap);\n    } else {\n        Map<K, Throwable> errors = spec.keys.stream().collect(Collectors.toMap(\n            Function.identity(),\n            key -> t\n        ));\n\n        if (spec.scope instanceof FulfillmentScope) {\n            completeExceptionally(errors);\n        } else {\n            completeLookupExceptionally(errors);\n        }\n    }\n}",
        "summary_tokens": [
            "callback",
            "that",
            "is",
            "invoked",
            "when",
            "a",
            "call",
            "is",
            "failed"
        ]
    },
    {
        "id": 363,
        "code": "default void completeLookup(Map<K, Integer> brokerIdMapping) {\n}",
        "summary_tokens": [
            "invoked",
            "when",
            "lookup",
            "of",
            "a",
            "set",
            "of",
            "keys",
            "succeeds"
        ]
    },
    {
        "id": 364,
        "code": "default void completeLookupExceptionally(Map<K, Throwable> lookupErrors) {\n    completeExceptionally(lookupErrors);\n}",
        "summary_tokens": [
            "invoked",
            "when",
            "lookup",
            "fails",
            "with",
            "a",
            "fatal",
            "error",
            "on",
            "a",
            "set",
            "of",
            "keys"
        ]
    },
    {
        "id": 365,
        "code": "public long metadataFetchDelayMs(long now) {\n    switch (state) {\n        case QUIESCENT:\n                \n                \n                \n            return Math.max(delayBeforeNextAttemptMs(now), delayBeforeNextExpireMs(now));\n        case UPDATE_REQUESTED:\n                \n            return delayBeforeNextAttemptMs(now);\n        default:\n                \n            return Long.MAX_VALUE;\n    }\n}",
        "summary_tokens": [
            "determine",
            "if",
            "the",
            "admin",
            "client",
            "should",
            "fetch",
            "new",
            "metadata"
        ]
    },
    {
        "id": 366,
        "code": "public void transitionToUpdatePending(long now) {\n    this.state = State.UPDATE_PENDING;\n    this.lastMetadataFetchAttemptMs = now;\n}",
        "summary_tokens": [
            "transition",
            "into",
            "the",
            "update",
            "pending",
            "state"
        ]
    },
    {
        "id": 367,
        "code": "public void update(Cluster cluster, long now) {\n    if (cluster.isBootstrapConfigured()) {\n        log.debug(\"Setting bootstrap cluster metadata {}.\", cluster);\n    } else {\n        log.debug(\"Updating cluster metadata to {}\", cluster);\n        this.lastMetadataUpdateMs = now;\n    }\n\n    this.state = State.QUIESCENT;\n    this.authException = null;\n\n    if (!cluster.nodes().isEmpty()) {\n        this.cluster = cluster;\n    }\n}",
        "summary_tokens": [
            "receive",
            "new",
            "metadata",
            "and",
            "transition",
            "into",
            "the",
            "quiescent",
            "state"
        ]
    },
    {
        "id": 368,
        "code": "default OptionalInt destinationBrokerId() {\n    return OptionalInt.empty();\n}",
        "summary_tokens": [
            "get",
            "the",
            "target",
            "broker",
            "id",
            "that",
            "a",
            "request",
            "is",
            "intended",
            "for",
            "or",
            "empty",
            "if",
            "the",
            "request",
            "can",
            "be",
            "sent",
            "to",
            "any",
            "broker"
        ]
    },
    {
        "id": 369,
        "code": "default ByteBuffer subscriptionUserData(Set<String> topics) {\n    return null;\n}",
        "summary_tokens": [
            "return",
            "serialized",
            "data",
            "that",
            "will",
            "be",
            "included",
            "in",
            "the",
            "subscription",
            "sent",
            "to",
            "the",
            "leader",
            "and",
            "can",
            "be",
            "leveraged",
            "in",
            "assign",
            "cluster",
            "group",
            "subscription",
            "e"
        ]
    },
    {
        "id": 370,
        "code": "default void onAssignment(Assignment assignment, ConsumerGroupMetadata metadata) {\n}",
        "summary_tokens": [
            "callback",
            "which",
            "is",
            "invoked",
            "when",
            "a",
            "group",
            "member",
            "receives",
            "its",
            "assignment",
            "from",
            "the",
            "leader"
        ]
    },
    {
        "id": 371,
        "code": "default List<RebalanceProtocol> supportedProtocols() {\n    return Collections.singletonList(RebalanceProtocol.EAGER);\n}",
        "summary_tokens": [
            "indicate",
            "which",
            "rebalance",
            "protocol",
            "this",
            "assignor",
            "works",
            "with",
            "by",
            "default",
            "it",
            "should",
            "always",
            "work",
            "with",
            "rebalance",
            "protocol",
            "eager"
        ]
    },
    {
        "id": 372,
        "code": "default short version() {\n    return (short) 0;\n}",
        "summary_tokens": [
            "return",
            "the",
            "version",
            "of",
            "the",
            "assignor",
            "which",
            "indicates",
            "how",
            "the",
            "user",
            "metadata",
            "encodings",
            "and",
            "the",
            "assignment",
            "algorithm",
            "gets",
            "evolved"
        ]
    },
    {
        "id": 373,
        "code": "static List<ConsumerPartitionAssignor> getAssignorInstances(List<String> assignorClasses, Map<String, Object> configs) {\n    List<ConsumerPartitionAssignor> assignors = new ArrayList<>();\n        \n    Map<String, String> assignorNameMap = new HashMap<>();\n\n    if (assignorClasses == null)\n        return assignors;\n\n    for (Object klass : assignorClasses) {\n            \n        if (klass instanceof String) {\n            try {\n                klass = Class.forName((String) klass, true, Utils.getContextOrKafkaClassLoader());\n            } catch (ClassNotFoundException classNotFound) {\n                throw new KafkaException(klass + \" ClassNotFoundException exception occurred\", classNotFound);\n            }\n        }\n\n        if (klass instanceof Class<?>) {\n            Object assignor = Utils.newInstance((Class<?>) klass);\n            if (assignor instanceof Configurable)\n                ((Configurable) assignor).configure(configs);\n\n            if (assignor instanceof ConsumerPartitionAssignor) {\n                String assignorName = ((ConsumerPartitionAssignor) assignor).name();\n                if (assignorNameMap.containsKey(assignorName)) {\n                    throw new KafkaException(\"The assignor name: '\" + assignorName + \"' is used in more than one assignor: \" +\n                        assignorNameMap.get(assignorName) + \", \" + assignor.getClass().getName());\n                }\n                assignorNameMap.put(assignorName, assignor.getClass().getName());\n                assignors.add((ConsumerPartitionAssignor) assignor);\n            } else {\n                throw new KafkaException(klass + \" is not an instance of \" + ConsumerPartitionAssignor.class.getName());\n            }\n        } else {\n            throw new KafkaException(\"List contains element of type \" + klass.getClass().getName() + \", expected String or Class\");\n        }\n    }\n    return assignors;\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "configured",
            "instances",
            "of",
            "org"
        ]
    },
    {
        "id": 374,
        "code": "default void onPartitionsLost(Collection<TopicPartition> partitions) {\n    onPartitionsRevoked(partitions);\n}",
        "summary_tokens": [
            "a",
            "callback",
            "method",
            "you",
            "can",
            "implement",
            "to",
            "provide",
            "handling",
            "of",
            "cleaning",
            "up",
            "resources",
            "for",
            "partitions",
            "that",
            "have",
            "already",
            "been",
            "reassigned",
            "to",
            "other",
            "consumers"
        ]
    },
    {
        "id": 375,
        "code": "public String topic() {\n    return this.topic;\n}",
        "summary_tokens": [
            "the",
            "topic",
            "this",
            "record",
            "is",
            "received",
            "from",
            "never",
            "null"
        ]
    },
    {
        "id": 376,
        "code": "public int partition() {\n    return this.partition;\n}",
        "summary_tokens": [
            "the",
            "partition",
            "from",
            "which",
            "this",
            "record",
            "is",
            "received"
        ]
    },
    {
        "id": 377,
        "code": "public Headers headers() {\n    return headers;\n}",
        "summary_tokens": [
            "the",
            "headers",
            "never",
            "null"
        ]
    },
    {
        "id": 378,
        "code": "public K key() {\n    return key;\n}",
        "summary_tokens": [
            "the",
            "key",
            "or",
            "null",
            "if",
            "no",
            "key",
            "is",
            "specified"
        ]
    },
    {
        "id": 379,
        "code": "public long offset() {\n    return offset;\n}",
        "summary_tokens": [
            "the",
            "position",
            "of",
            "this",
            "record",
            "in",
            "the",
            "corresponding",
            "kafka",
            "partition"
        ]
    },
    {
        "id": 380,
        "code": "public long timestamp() {\n    return timestamp;\n}",
        "summary_tokens": [
            "the",
            "timestamp",
            "of",
            "this",
            "record"
        ]
    },
    {
        "id": 381,
        "code": "public TimestampType timestampType() {\n    return timestampType;\n}",
        "summary_tokens": [
            "the",
            "timestamp",
            "type",
            "of",
            "this",
            "record"
        ]
    },
    {
        "id": 382,
        "code": "public int serializedKeySize() {\n    return this.serializedKeySize;\n}",
        "summary_tokens": [
            "the",
            "size",
            "of",
            "the",
            "serialized",
            "uncompressed",
            "key",
            "in",
            "bytes"
        ]
    },
    {
        "id": 383,
        "code": "public int serializedValueSize() {\n    return this.serializedValueSize;\n}",
        "summary_tokens": [
            "the",
            "size",
            "of",
            "the",
            "serialized",
            "uncompressed",
            "value",
            "in",
            "bytes"
        ]
    },
    {
        "id": 384,
        "code": "public Optional<Integer> leaderEpoch() {\n    return leaderEpoch;\n}",
        "summary_tokens": [
            "get",
            "the",
            "leader",
            "epoch",
            "for",
            "the",
            "record",
            "if",
            "available"
        ]
    },
    {
        "id": 385,
        "code": "public Iterable<ConsumerRecord<K, V>> records(String topic) {\n    if (topic == null)\n        throw new IllegalArgumentException(\"Topic must be non-null.\");\n    List<List<ConsumerRecord<K, V>>> recs = new ArrayList<>();\n    for (Map.Entry<TopicPartition, List<ConsumerRecord<K, V>>> entry : records.entrySet()) {\n        if (entry.getKey().topic().equals(topic))\n            recs.add(entry.getValue());\n    }\n    return new ConcatenatedIterable<>(recs);\n}",
        "summary_tokens": [
            "get",
            "just",
            "the",
            "records",
            "for",
            "the",
            "given",
            "topic"
        ]
    },
    {
        "id": 386,
        "code": "public Set<TopicPartition> partitions() {\n    return Collections.unmodifiableSet(records.keySet());\n}",
        "summary_tokens": [
            "get",
            "the",
            "partitions",
            "which",
            "have",
            "records",
            "contained",
            "in",
            "this",
            "record",
            "set"
        ]
    },
    {
        "id": 387,
        "code": "public int count() {\n    int count = 0;\n    for (List<ConsumerRecord<K, V>> recs: this.records.values())\n        count += recs.size();\n    return count;\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "records",
            "for",
            "all",
            "topics"
        ]
    },
    {
        "id": 388,
        "code": "public Set<TopicPartition> assignment() {\n    acquireAndEnsureOpen();\n    try {\n        return Collections.unmodifiableSet(this.subscriptions.assignedPartitions());\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "partitions",
            "currently",
            "assigned",
            "to",
            "this",
            "consumer"
        ]
    },
    {
        "id": 389,
        "code": "public Set<String> subscription() {\n    acquireAndEnsureOpen();\n    try {\n        return Collections.unmodifiableSet(new HashSet<>(this.subscriptions.subscription()));\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "subscription"
        ]
    },
    {
        "id": 390,
        "code": "public void subscribe(Pattern pattern) {\n    subscribe(pattern, new NoOpConsumerRebalanceListener());\n}",
        "summary_tokens": [
            "subscribe",
            "to",
            "all",
            "topics",
            "matching",
            "specified",
            "pattern",
            "to",
            "get",
            "dynamically",
            "assigned",
            "partitions"
        ]
    },
    {
        "id": 391,
        "code": "public void unsubscribe() {\n    acquireAndEnsureOpen();\n    try {\n        fetcher.clearBufferedDataForUnassignedPartitions(Collections.emptySet());\n        if (this.coordinator != null) {\n            this.coordinator.onLeavePrepare();\n            this.coordinator.maybeLeaveGroup(\"the consumer unsubscribed from all topics\");\n        }\n        this.subscriptions.unsubscribe();\n        log.info(\"Unsubscribed all topics or patterns and assigned partitions\");\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "unsubscribe",
            "from",
            "topics",
            "currently",
            "subscribed",
            "with",
            "subscribe",
            "collection",
            "or",
            "subscribe",
            "pattern"
        ]
    },
    {
        "id": 392,
        "code": "public void assign(Collection<TopicPartition> partitions) {\n    acquireAndEnsureOpen();\n    try {\n        if (partitions == null) {\n            throw new IllegalArgumentException(\"Topic partition collection to assign to cannot be null\");\n        } else if (partitions.isEmpty()) {\n            this.unsubscribe();\n        } else {\n            for (TopicPartition tp : partitions) {\n                String topic = (tp != null) ? tp.topic() : null;\n                if (Utils.isBlank(topic))\n                    throw new IllegalArgumentException(\"Topic partitions to assign to cannot have null or empty topic\");\n            }\n            fetcher.clearBufferedDataForUnassignedPartitions(partitions);\n\n                \n                \n            if (coordinator != null)\n                this.coordinator.maybeAutoCommitOffsetsAsync(time.milliseconds());\n\n            log.info(\"Assigned to partition(s): {}\", Utils.join(partitions, \", \"));\n            if (this.subscriptions.assignFromUser(new HashSet<>(partitions)))\n                metadata.requestUpdateForNewTopics();\n        }\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "manually",
            "assign",
            "a",
            "list",
            "of",
            "partitions",
            "to",
            "this",
            "consumer"
        ]
    },
    {
        "id": 393,
        "code": "private ConsumerRecords<K, V> poll(final Timer timer, final boolean includeMetadataInTimeout) {\n    acquireAndEnsureOpen();\n    try {\n        this.kafkaConsumerMetrics.recordPollStart(timer.currentTimeMs());\n\n        if (this.subscriptions.hasNoSubscriptionOrUserAssignment()) {\n            throw new IllegalStateException(\"Consumer is not subscribed to any topics or assigned any partitions\");\n        }\n\n        do {\n            client.maybeTriggerWakeup();\n\n            if (includeMetadataInTimeout) {\n                    \n                updateAssignmentMetadataIfNeeded(timer, false);\n            } else {\n                while (!updateAssignmentMetadataIfNeeded(time.timer(Long.MAX_VALUE), true)) {\n                    log.warn(\"Still waiting for metadata\");\n                }\n            }\n\n            final Fetch<K, V> fetch = pollForFetches(timer);\n            if (!fetch.isEmpty()) {\n                    \n                    \n                    \n                    \n                    \n                    \n                if (fetcher.sendFetches() > 0 || client.hasPendingRequests()) {\n                    client.transmitSends();\n                }\n\n                if (fetch.records().isEmpty()) {\n                    log.trace(\"Returning empty records from `poll()` \"\n                            + \"since the consumer's position has advanced for at least one topic partition\");\n                }\n\n                return this.interceptors.onConsume(new ConsumerRecords<>(fetch.records()));\n            }\n        } while (timer.notExpired());\n\n        return ConsumerRecords.empty();\n    } finally {\n        release();\n        this.kafkaConsumerMetrics.recordPollEnd(timer.currentTimeMs());\n    }\n}",
        "summary_tokens": [
            "kafka",
            "exception",
            "if",
            "the",
            "rebalance",
            "callback",
            "throws",
            "exception"
        ]
    },
    {
        "id": 394,
        "code": "private Fetch<K, V> pollForFetches(Timer timer) {\n    long pollTimeout = coordinator == null ? timer.remainingMs() :\n            Math.min(coordinator.timeToNextPoll(timer.currentTimeMs()), timer.remainingMs());\n\n        \n    final Fetch<K, V> fetch = fetcher.collectFetch();\n    if (!fetch.isEmpty()) {\n        return fetch;\n    }\n\n        \n    fetcher.sendFetches();\n\n        \n        \n\n        \n        \n    if (!cachedSubscriptionHasAllFetchPositions && pollTimeout > retryBackoffMs) {\n        pollTimeout = retryBackoffMs;\n    }\n\n    log.trace(\"Polling for fetches with timeout {}\", pollTimeout);\n\n    Timer pollTimer = time.timer(pollTimeout);\n    client.poll(pollTimer, () -> {\n            \n            \n        return !fetcher.hasAvailableFetches();\n    });\n    timer.update(pollTimer.currentTimeMs());\n\n    return fetcher.collectFetch();\n}",
        "summary_tokens": [
            "kafka",
            "exception",
            "if",
            "the",
            "rebalance",
            "callback",
            "throws",
            "exception"
        ]
    },
    {
        "id": 395,
        "code": "public void commitSync(final Map<TopicPartition, OffsetAndMetadata> offsets, final Duration timeout) {\n    acquireAndEnsureOpen();\n    long commitStart = time.nanoseconds();\n    try {\n        maybeThrowInvalidGroupIdException();\n        offsets.forEach(this::updateLastSeenEpochIfNewer);\n        if (!coordinator.commitOffsetsSync(new HashMap<>(offsets), time.timer(timeout))) {\n            throw new TimeoutException(\"Timeout of \" + timeout.toMillis() + \"ms expired before successfully \" +\n                    \"committing offsets \" + offsets);\n        }\n    } finally {\n        kafkaConsumerMetrics.recordCommitSync(time.nanoseconds() - commitStart);\n        release();\n    }\n}",
        "summary_tokens": [
            "commit",
            "the",
            "specified",
            "offsets",
            "for",
            "the",
            "specified",
            "list",
            "of",
            "topics",
            "and",
            "partitions"
        ]
    },
    {
        "id": 396,
        "code": "public void commitAsync(final Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback) {\n    acquireAndEnsureOpen();\n    try {\n        maybeThrowInvalidGroupIdException();\n        log.debug(\"Committing offsets: {}\", offsets);\n        offsets.forEach(this::updateLastSeenEpochIfNewer);\n        coordinator.commitOffsetsAsync(new HashMap<>(offsets), callback);\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "commit",
            "the",
            "specified",
            "offsets",
            "for",
            "the",
            "specified",
            "list",
            "of",
            "topics",
            "and",
            "partitions",
            "to",
            "kafka"
        ]
    },
    {
        "id": 397,
        "code": "public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n    long offset = offsetAndMetadata.offset();\n    if (offset < 0) {\n        throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n    }\n\n    acquireAndEnsureOpen();\n    try {\n        if (offsetAndMetadata.leaderEpoch().isPresent()) {\n            log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                    offset, partition, offsetAndMetadata.leaderEpoch().get());\n        } else {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n        }\n        Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.currentLeader(partition);\n        SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                offsetAndMetadata.offset(),\n                offsetAndMetadata.leaderEpoch(),\n                currentLeaderAndEpoch);\n        this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n        this.subscriptions.seekUnvalidated(partition, newPosition);\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "overrides",
            "the",
            "fetch",
            "offsets",
            "that",
            "the",
            "consumer",
            "will",
            "use",
            "on",
            "the",
            "next",
            "poll",
            "duration",
            "poll",
            "timeout"
        ]
    },
    {
        "id": 398,
        "code": "public void seekToBeginning(Collection<TopicPartition> partitions) {\n    if (partitions == null)\n        throw new IllegalArgumentException(\"Partitions collection cannot be null\");\n\n    acquireAndEnsureOpen();\n    try {\n        Collection<TopicPartition> parts = partitions.size() == 0 ? this.subscriptions.assignedPartitions() : partitions;\n        subscriptions.requestOffsetReset(parts, OffsetResetStrategy.EARLIEST);\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "seek",
            "to",
            "the",
            "first",
            "offset",
            "for",
            "each",
            "of",
            "the",
            "given",
            "partitions"
        ]
    },
    {
        "id": 399,
        "code": "public void seekToEnd(Collection<TopicPartition> partitions) {\n    if (partitions == null)\n        throw new IllegalArgumentException(\"Partitions collection cannot be null\");\n\n    acquireAndEnsureOpen();\n    try {\n        Collection<TopicPartition> parts = partitions.size() == 0 ? this.subscriptions.assignedPartitions() : partitions;\n        subscriptions.requestOffsetReset(parts, OffsetResetStrategy.LATEST);\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "seek",
            "to",
            "the",
            "last",
            "offset",
            "for",
            "each",
            "of",
            "the",
            "given",
            "partitions"
        ]
    },
    {
        "id": 400,
        "code": "public long position(TopicPartition partition, final Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        if (!this.subscriptions.isAssigned(partition))\n            throw new IllegalStateException(\"You can only check the position for partitions assigned to this consumer.\");\n\n        Timer timer = time.timer(timeout);\n        do {\n            SubscriptionState.FetchPosition position = this.subscriptions.validPosition(partition);\n            if (position != null)\n                return position.offset;\n\n            updateFetchPositions(timer);\n            client.poll(timer);\n        } while (timer.notExpired());\n\n        throw new TimeoutException(\"Timeout of \" + timeout.toMillis() + \"ms expired before the position \" +\n                \"for partition \" + partition + \" could be determined\");\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "offset",
            "of",
            "the",
            "i",
            "next",
            "record",
            "i",
            "that",
            "will",
            "be",
            "fetched",
            "if",
            "a",
            "record",
            "with",
            "that",
            "offset",
            "exists"
        ]
    },
    {
        "id": 401,
        "code": "public Map<TopicPartition, OffsetAndMetadata> committed(final Set<TopicPartition> partitions, final Duration timeout) {\n    acquireAndEnsureOpen();\n    long start = time.nanoseconds();\n    try {\n        maybeThrowInvalidGroupIdException();\n        final Map<TopicPartition, OffsetAndMetadata> offsets;\n        offsets = coordinator.fetchCommittedOffsets(partitions, time.timer(timeout));\n        if (offsets == null) {\n            throw new TimeoutException(\"Timeout of \" + timeout.toMillis() + \"ms expired before the last \" +\n                \"committed offset for partitions \" + partitions + \" could be determined. Try tuning default.api.timeout.ms \" +\n                \"larger to relax the threshold.\");\n        } else {\n            offsets.forEach(this::updateLastSeenEpochIfNewer);\n            return offsets;\n        }\n    } finally {\n        kafkaConsumerMetrics.recordCommitted(time.nanoseconds() - start);\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "last",
            "committed",
            "offsets",
            "for",
            "the",
            "given",
            "partitions",
            "whether",
            "the",
            "commit",
            "happened",
            "by",
            "this",
            "process",
            "or",
            "another"
        ]
    },
    {
        "id": 402,
        "code": "public Map<MetricName, ? extends Metric> metrics() {\n    return Collections.unmodifiableMap(this.metrics.metrics());\n}",
        "summary_tokens": [
            "get",
            "the",
            "metrics",
            "kept",
            "by",
            "the",
            "consumer"
        ]
    },
    {
        "id": 403,
        "code": "public List<PartitionInfo> partitionsFor(String topic, Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        Cluster cluster = this.metadata.fetch();\n        List<PartitionInfo> parts = cluster.partitionsForTopic(topic);\n        if (!parts.isEmpty())\n            return parts;\n\n        Timer timer = time.timer(timeout);\n        Map<String, List<PartitionInfo>> topicMetadata = fetcher.getTopicMetadata(\n                new MetadataRequest.Builder(Collections.singletonList(topic), metadata.allowAutoTopicCreation()), timer);\n        return topicMetadata.getOrDefault(topic, Collections.emptyList());\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "metadata",
            "about",
            "the",
            "partitions",
            "for",
            "a",
            "given",
            "topic"
        ]
    },
    {
        "id": 404,
        "code": "public Map<String, List<PartitionInfo>> listTopics(Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        return fetcher.getAllTopicMetadata(time.timer(timeout));\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "metadata",
            "about",
            "partitions",
            "for",
            "all",
            "topics",
            "that",
            "the",
            "user",
            "is",
            "authorized",
            "to",
            "view"
        ]
    },
    {
        "id": 405,
        "code": "public void pause(Collection<TopicPartition> partitions) {\n    acquireAndEnsureOpen();\n    try {\n        log.debug(\"Pausing partitions {}\", partitions);\n        for (TopicPartition partition: partitions) {\n            subscriptions.pause(partition);\n        }\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "suspend",
            "fetching",
            "from",
            "the",
            "requested",
            "partitions"
        ]
    },
    {
        "id": 406,
        "code": "public void resume(Collection<TopicPartition> partitions) {\n    acquireAndEnsureOpen();\n    try {\n        log.debug(\"Resuming partitions {}\", partitions);\n        for (TopicPartition partition: partitions) {\n            subscriptions.resume(partition);\n        }\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "resume",
            "specified",
            "partitions",
            "which",
            "have",
            "been",
            "paused",
            "with",
            "pause",
            "collection"
        ]
    },
    {
        "id": 407,
        "code": "public Set<TopicPartition> paused() {\n    acquireAndEnsureOpen();\n    try {\n        return Collections.unmodifiableSet(subscriptions.pausedPartitions());\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "partitions",
            "that",
            "were",
            "previously",
            "paused",
            "by",
            "a",
            "call",
            "to",
            "pause",
            "collection"
        ]
    },
    {
        "id": 408,
        "code": "public Map<TopicPartition, OffsetAndTimestamp> offsetsForTimes(Map<TopicPartition, Long> timestampsToSearch, Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        for (Map.Entry<TopicPartition, Long> entry : timestampsToSearch.entrySet()) {\n                \n                \n            if (entry.getValue() < 0)\n                throw new IllegalArgumentException(\"The target time for partition \" + entry.getKey() + \" is \" +\n                        entry.getValue() + \". The target time cannot be negative.\");\n        }\n        return fetcher.offsetsForTimes(timestampsToSearch, time.timer(timeout));\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "look",
            "up",
            "the",
            "offsets",
            "for",
            "the",
            "given",
            "partitions",
            "by",
            "timestamp"
        ]
    },
    {
        "id": 409,
        "code": "public Map<TopicPartition, Long> beginningOffsets(Collection<TopicPartition> partitions, Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        return fetcher.beginningOffsets(partitions, time.timer(timeout));\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "first",
            "offset",
            "for",
            "the",
            "given",
            "partitions"
        ]
    },
    {
        "id": 410,
        "code": "public Map<TopicPartition, Long> endOffsets(Collection<TopicPartition> partitions, Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        return fetcher.endOffsets(partitions, time.timer(timeout));\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "end",
            "offsets",
            "for",
            "the",
            "given",
            "partitions"
        ]
    },
    {
        "id": 411,
        "code": "public OptionalLong currentLag(TopicPartition topicPartition) {\n    acquireAndEnsureOpen();\n    try {\n        final Long lag = subscriptions.partitionLag(topicPartition, isolationLevel);\n\n            \n            \n            \n            \n            \n        if (lag == null) {\n            if (subscriptions.partitionEndOffset(topicPartition, isolationLevel) == null &&\n                !subscriptions.partitionEndOffsetRequested(topicPartition)) {\n                log.info(\"Requesting the log end offset for {} in order to compute lag\", topicPartition);\n                subscriptions.requestPartitionEndOffset(topicPartition);\n                fetcher.endOffsets(Collections.singleton(topicPartition), time.timer(0L));\n            }\n\n            return OptionalLong.empty();\n        }\n\n        return OptionalLong.of(lag);\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "consumer",
            "s",
            "current",
            "lag",
            "on",
            "the",
            "partition"
        ]
    },
    {
        "id": 412,
        "code": "public ConsumerGroupMetadata groupMetadata() {\n    acquireAndEnsureOpen();\n    try {\n        maybeThrowInvalidGroupIdException();\n        return coordinator.groupMetadata();\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "current",
            "group",
            "metadata",
            "associated",
            "with",
            "this",
            "consumer"
        ]
    },
    {
        "id": 413,
        "code": "public void enforceRebalance(final String reason) {\n    acquireAndEnsureOpen();\n    try {\n        if (coordinator == null) {\n            throw new IllegalStateException(\"Tried to force a rebalance but consumer does not have a group.\");\n        }\n        coordinator.requestRejoin(reason == null || reason.isEmpty() ? DEFAULT_REASON : reason);\n    } finally {\n        release();\n    }\n}",
        "summary_tokens": [
            "alert",
            "the",
            "consumer",
            "to",
            "trigger",
            "a",
            "new",
            "rebalance",
            "by",
            "rejoining",
            "the",
            "group"
        ]
    },
    {
        "id": 414,
        "code": "public void close(Duration timeout) {\n    if (timeout.toMillis() < 0)\n        throw new IllegalArgumentException(\"The timeout cannot be negative.\");\n    acquire();\n    try {\n        if (!closed) {\n                \n                \n            close(timeout.toMillis(), false);\n        }\n    } finally {\n        closed = true;\n        release();\n    }\n}",
        "summary_tokens": [
            "tries",
            "to",
            "close",
            "the",
            "consumer",
            "cleanly",
            "within",
            "the",
            "specified",
            "timeout"
        ]
    },
    {
        "id": 415,
        "code": "private boolean updateFetchPositions(final Timer timer) {\n        \n    fetcher.validateOffsetsIfNeeded();\n\n    cachedSubscriptionHasAllFetchPositions = subscriptions.hasAllFetchPositions();\n    if (cachedSubscriptionHasAllFetchPositions) return true;\n\n        \n        \n        \n        \n        \n    if (coordinator != null && !coordinator.refreshCommittedOffsetsIfNeeded(timer)) return false;\n\n        \n        \n        \n    subscriptions.resetInitializingPositions();\n\n        \n        \n    fetcher.resetOffsetsIfNeeded();\n\n    return true;\n}",
        "summary_tokens": [
            "set",
            "the",
            "fetch",
            "position",
            "to",
            "the",
            "committed",
            "position",
            "if",
            "there",
            "is",
            "one",
            "or",
            "reset",
            "it",
            "using",
            "the",
            "offset",
            "reset",
            "policy",
            "the",
            "user",
            "has",
            "configured"
        ]
    },
    {
        "id": 416,
        "code": "private void acquireAndEnsureOpen() {\n    acquire();\n    if (this.closed) {\n        release();\n        throw new IllegalStateException(\"This consumer has already been closed.\");\n    }\n}",
        "summary_tokens": [
            "acquire",
            "the",
            "light",
            "lock",
            "and",
            "ensure",
            "that",
            "the",
            "consumer",
            "hasn",
            "t",
            "been",
            "closed"
        ]
    },
    {
        "id": 417,
        "code": "private void acquire() {\n    long threadId = Thread.currentThread().getId();\n    if (threadId != currentThread.get() && !currentThread.compareAndSet(NO_CURRENT_THREAD, threadId))\n        throw new ConcurrentModificationException(\"KafkaConsumer is not safe for multi-threaded access\");\n    refcount.incrementAndGet();\n}",
        "summary_tokens": [
            "acquire",
            "the",
            "light",
            "lock",
            "protecting",
            "this",
            "consumer",
            "from",
            "multi",
            "threaded",
            "access"
        ]
    },
    {
        "id": 418,
        "code": "private void release() {\n    if (refcount.decrementAndGet() == 0)\n        currentThread.set(NO_CURRENT_THREAD);\n}",
        "summary_tokens": [
            "release",
            "the",
            "light",
            "lock",
            "protecting",
            "the",
            "consumer",
            "from",
            "multi",
            "threaded",
            "access"
        ]
    },
    {
        "id": 419,
        "code": "public Map<TopicPartition, OffsetAndMetadata> divergentOffsets() {\n    return divergentOffsets;\n}",
        "summary_tokens": [
            "get",
            "the",
            "divergent",
            "offsets",
            "for",
            "the",
            "partitions",
            "which",
            "were",
            "truncated"
        ]
    },
    {
        "id": 420,
        "code": "public synchronized void rebalance(Collection<TopicPartition> newAssignment) {\n        \n    this.records.clear();\n    this.subscriptions.assignFromSubscribed(newAssignment);\n}",
        "summary_tokens": [
            "simulate",
            "a",
            "rebalance",
            "event"
        ]
    },
    {
        "id": 421,
        "code": "public synchronized void setException(KafkaException exception) {\n    setPollException(exception);\n}",
        "summary_tokens": [
            "use",
            "set",
            "poll",
            "exception",
            "kafka",
            "exception",
            "instead"
        ]
    },
    {
        "id": 422,
        "code": "public synchronized void schedulePollTask(Runnable task) {\n    synchronized (pollTasks) {\n        pollTasks.add(task);\n    }\n}",
        "summary_tokens": [
            "schedule",
            "a",
            "task",
            "to",
            "be",
            "executed",
            "during",
            "a",
            "poll"
        ]
    },
    {
        "id": 423,
        "code": "public Set<TopicPartition> partitions() {\n    return partitions;\n}",
        "summary_tokens": [
            "returns",
            "all",
            "partitions",
            "for",
            "which",
            "no",
            "offests",
            "are",
            "defined"
        ]
    },
    {
        "id": 424,
        "code": "public Optional<Integer> leaderEpoch() {\n    if (leaderEpoch == null || leaderEpoch < 0)\n        return Optional.empty();\n    return Optional.of(leaderEpoch);\n}",
        "summary_tokens": [
            "get",
            "the",
            "leader",
            "epoch",
            "of",
            "the",
            "previously",
            "consumed",
            "record",
            "if",
            "one",
            "is",
            "known"
        ]
    },
    {
        "id": 425,
        "code": "public Optional<Integer> leaderEpoch() {\n    return leaderEpoch;\n}",
        "summary_tokens": [
            "get",
            "the",
            "leader",
            "epoch",
            "corresponding",
            "to",
            "the",
            "offset",
            "that",
            "was",
            "found",
            "if",
            "one",
            "exists"
        ]
    },
    {
        "id": 426,
        "code": "public Map<TopicPartition, Long> offsetOutOfRangePartitions() {\n    return offsetOutOfRangePartitions;\n}",
        "summary_tokens": [
            "get",
            "a",
            "map",
            "of",
            "the",
            "topic",
            "partitions",
            "and",
            "the",
            "respective",
            "out",
            "of",
            "range",
            "fetch",
            "offsets"
        ]
    },
    {
        "id": 427,
        "code": "protected void onLeavePrepare() {}",
        "summary_tokens": [
            "invoked",
            "prior",
            "to",
            "each",
            "leave",
            "group",
            "event"
        ]
    },
    {
        "id": 428,
        "code": "protected synchronized boolean rejoinNeededOrPending() {\n        \n    return rejoinNeeded || joinFuture != null;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "group",
            "should",
            "be",
            "rejoined",
            "e"
        ]
    },
    {
        "id": 429,
        "code": "protected synchronized void pollHeartbeat(long now) {\n    if (heartbeatThread != null) {\n        if (heartbeatThread.hasFailed()) {\n                \n                \n            RuntimeException cause = heartbeatThread.failureCause();\n            heartbeatThread = null;\n            throw cause;\n        }\n            \n        if (heartbeat.shouldHeartbeat(now)) {\n            notify();\n        }\n        heartbeat.poll(now);\n    }\n}",
        "summary_tokens": [
            "check",
            "the",
            "status",
            "of",
            "the",
            "heartbeat",
            "thread",
            "if",
            "it",
            "is",
            "active",
            "and",
            "indicate",
            "the",
            "liveness",
            "of",
            "the",
            "client"
        ]
    },
    {
        "id": 430,
        "code": "boolean ensureActiveGroup(final Timer timer) {\n        \n        \n    if (!ensureCoordinatorReady(timer)) {\n        return false;\n    }\n\n    startHeartbeatThreadIfNeeded();\n    return joinGroupIfNeeded(timer);\n}",
        "summary_tokens": [
            "ensure",
            "the",
            "group",
            "is",
            "active",
            "i"
        ]
    },
    {
        "id": 431,
        "code": "boolean joinGroupIfNeeded(final Timer timer) {\n    while (rejoinNeededOrPending()) {\n        if (!ensureCoordinatorReady(timer)) {\n            return false;\n        }\n\n            \n            \n            \n            \n            \n        if (needsJoinPrepare) {\n                \n                \n            needsJoinPrepare = false;\n                \n            if (!onJoinPrepare(timer, generation.generationId, generation.memberId)) {\n                needsJoinPrepare = true;\n                    \n                return false;\n            }\n        }\n\n        final RequestFuture<ByteBuffer> future = initiateJoinGroup();\n        client.poll(future, timer);\n        if (!future.isDone()) {\n                \n            return false;\n        }\n\n        if (future.succeeded()) {\n            Generation generationSnapshot;\n            MemberState stateSnapshot;\n\n                \n                \n                \n                \n            synchronized (AbstractCoordinator.this) {\n                generationSnapshot = this.generation;\n                stateSnapshot = this.state;\n            }\n\n            if (!hasGenerationReset(generationSnapshot) && stateSnapshot == MemberState.STABLE) {\n                    \n                ByteBuffer memberAssignment = future.value().duplicate();\n\n                onJoinComplete(generationSnapshot.generationId, generationSnapshot.memberId, generationSnapshot.protocolName, memberAssignment);\n\n                    \n                    \n                    \n                    \n                resetJoinGroupFuture();\n                needsJoinPrepare = true;\n            } else {\n                final String reason = String.format(\"rebalance failed since the generation/state was \" +\n                        \"modified by heartbeat thread to %s/%s before the rebalance callback triggered\",\n                        generationSnapshot, stateSnapshot);\n\n                resetStateAndRejoin(reason, true);\n                resetJoinGroupFuture();\n            }\n        } else {\n            final RuntimeException exception = future.exception();\n\n            resetJoinGroupFuture();\n            synchronized (AbstractCoordinator.this) {\n                final String simpleName = exception.getClass().getSimpleName();\n                final String shortReason = String.format(\"rebalance failed due to %s\", simpleName);\n                final String fullReason = String.format(\"rebalance failed due to '%s' (%s)\",\n                    exception.getMessage(),\n                    simpleName);\n                requestRejoin(shortReason, fullReason);\n            }\n\n            if (exception instanceof UnknownMemberIdException ||\n                exception instanceof IllegalGenerationException ||\n                exception instanceof RebalanceInProgressException ||\n                exception instanceof MemberIdRequiredException)\n                continue;\n            else if (!future.isRetriable())\n                throw exception;\n\n            timer.sleep(rebalanceConfig.retryBackoffMs);\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "joins",
            "the",
            "group",
            "without",
            "starting",
            "the",
            "heartbeat",
            "thread"
        ]
    },
    {
        "id": 432,
        "code": "RequestFuture<ByteBuffer> sendJoinGroupRequest() {\n    if (coordinatorUnknown())\n        return RequestFuture.coordinatorNotAvailable();\n\n        \n    log.info(\"(Re-)joining group\");\n    JoinGroupRequest.Builder requestBuilder = new JoinGroupRequest.Builder(\n            new JoinGroupRequestData()\n                    .setGroupId(rebalanceConfig.groupId)\n                    .setSessionTimeoutMs(this.rebalanceConfig.sessionTimeoutMs)\n                    .setMemberId(this.generation.memberId)\n                    .setGroupInstanceId(this.rebalanceConfig.groupInstanceId.orElse(null))\n                    .setProtocolType(protocolType())\n                    .setProtocols(metadata())\n                    .setRebalanceTimeoutMs(this.rebalanceConfig.rebalanceTimeoutMs)\n                    .setReason(JoinGroupRequest.maybeTruncateReason(this.rejoinReason))\n    );\n\n    log.debug(\"Sending JoinGroup ({}) to coordinator {}\", requestBuilder, this.coordinator);\n\n        \n        \n    int joinGroupTimeoutMs = Math.max(\n        client.defaultRequestTimeoutMs(),\n        Math.max(\n            rebalanceConfig.rebalanceTimeoutMs + JOIN_GROUP_TIMEOUT_LAPSE,\n            rebalanceConfig.rebalanceTimeoutMs) \n        );\n    return client.send(coordinator, requestBuilder, joinGroupTimeoutMs)\n            .compose(new JoinGroupResponseHandler(generation));\n}",
        "summary_tokens": [
            "join",
            "the",
            "group",
            "and",
            "return",
            "the",
            "assignment",
            "for",
            "the",
            "next",
            "generation"
        ]
    },
    {
        "id": 433,
        "code": "private RequestFuture<Void> sendFindCoordinatorRequest(Node node) {\n        \n    log.debug(\"Sending FindCoordinator request to broker {}\", node);\n    FindCoordinatorRequestData data = new FindCoordinatorRequestData()\n            .setKeyType(CoordinatorType.GROUP.id())\n            .setKey(this.rebalanceConfig.groupId);\n    FindCoordinatorRequest.Builder requestBuilder = new FindCoordinatorRequest.Builder(data);\n    return client.send(node, requestBuilder)\n            .compose(new FindCoordinatorResponseHandler());\n}",
        "summary_tokens": [
            "discover",
            "the",
            "current",
            "coordinator",
            "for",
            "the",
            "group"
        ]
    },
    {
        "id": 434,
        "code": "public boolean coordinatorUnknown() {\n    return checkAndGetCoordinator() == null;\n}",
        "summary_tokens": [
            "check",
            "if",
            "we",
            "know",
            "who",
            "the",
            "coordinator",
            "is",
            "and",
            "we",
            "have",
            "an",
            "active",
            "connection",
            "true",
            "if",
            "the",
            "coordinator",
            "is",
            "unknown"
        ]
    },
    {
        "id": 435,
        "code": "protected synchronized Node checkAndGetCoordinator() {\n    if (coordinator != null && client.isUnavailable(coordinator)) {\n        markCoordinatorUnknown(true, \"coordinator unavailable\");\n        return null;\n    }\n    return this.coordinator;\n}",
        "summary_tokens": [
            "get",
            "the",
            "coordinator",
            "if",
            "its",
            "connection",
            "is",
            "still",
            "active"
        ]
    },
    {
        "id": 436,
        "code": "protected synchronized Generation generation() {\n    return generation;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "generation",
            "state",
            "regardless",
            "of",
            "whether",
            "it",
            "is",
            "currently",
            "stable"
        ]
    },
    {
        "id": 437,
        "code": "protected synchronized Generation generationIfStable() {\n    if (this.state != MemberState.STABLE)\n        return null;\n    return generation;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "generation",
            "state",
            "if",
            "the",
            "group",
            "is",
            "stable",
            "otherwise",
            "return",
            "null"
        ]
    },
    {
        "id": 438,
        "code": "public synchronized void requestRejoin(final String shortReason,\n                                       final String fullReason) {\n    log.info(\"Request joining group due to: {}\", fullReason);\n    this.rejoinReason = shortReason;\n    this.rejoinNeeded = true;\n}",
        "summary_tokens": [
            "request",
            "to",
            "rejoin",
            "the",
            "group"
        ]
    },
    {
        "id": 439,
        "code": "protected void close(Timer timer) {\n    try {\n        closeHeartbeatThread();\n    } finally {\n            \n            \n        synchronized (this) {\n            if (rebalanceConfig.leaveGroupOnClose) {\n                onLeavePrepare();\n                maybeLeaveGroup(\"the consumer is being closed\");\n            }\n\n                \n                \n                \n                \n            Node coordinator = checkAndGetCoordinator();\n            if (coordinator != null && !client.awaitPendingRequests(coordinator, timer))\n                log.warn(\"Close timed out with {} pending requests to coordinator, terminating client connections\",\n                        client.pendingRequestCount(coordinator));\n        }\n    }\n}",
        "summary_tokens": [
            "kafka",
            "exception",
            "if",
            "the",
            "rebalance",
            "callback",
            "throws",
            "exception"
        ]
    },
    {
        "id": 440,
        "code": "public synchronized RequestFuture<Void> maybeLeaveGroup(String leaveReason) {\n    RequestFuture<Void> future = null;\n\n        \n        \n        \n    if (isDynamicMember() && !coordinatorUnknown() &&\n        state != MemberState.UNJOINED && generation.hasMemberId()) {\n            \n            \n        log.info(\"Member {} sending LeaveGroup request to coordinator {} due to {}\",\n            generation.memberId, coordinator, leaveReason);\n        LeaveGroupRequest.Builder request = new LeaveGroupRequest.Builder(\n            rebalanceConfig.groupId,\n            Collections.singletonList(new MemberIdentity().setMemberId(generation.memberId).setReason(JoinGroupRequest.maybeTruncateReason(leaveReason)))\n        );\n\n        future = client.send(coordinator, request).compose(new LeaveGroupResponseHandler(generation));\n        client.pollNoWakeup();\n    }\n\n    resetGenerationOnLeaveGroup();\n\n    return future;\n}",
        "summary_tokens": [
            "sends",
            "leave",
            "group",
            "request",
            "and",
            "logs",
            "the",
            "leave",
            "reason",
            "unless",
            "this",
            "member",
            "is",
            "using",
            "static",
            "membership",
            "or",
            "is",
            "already",
            "not",
            "part",
            "of",
            "the",
            "group",
            "ie",
            "does",
            "not",
            "have",
            "a",
            "valid",
            "member",
            "id",
            "is",
            "in",
            "the",
            "unjoined",
            "state",
            "or",
            "the",
            "coordinator",
            "is",
            "unknown"
        ]
    },
    {
        "id": 441,
        "code": "final boolean hasMatchingGenerationId(int generationId) {\n    return !generation.equals(Generation.NO_GENERATION) && generation.generationId == generationId;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "given",
            "generation",
            "id",
            "is",
            "matching",
            "the",
            "record",
            "within",
            "current",
            "generation"
        ]
    },
    {
        "id": 442,
        "code": "final boolean hasValidMemberId() {\n    return !hasUnknownGeneration() && generation.hasMemberId();\n}",
        "summary_tokens": [
            "true",
            "if",
            "the",
            "current",
            "generation",
            "s",
            "member",
            "id",
            "is",
            "valid",
            "false",
            "otherwise"
        ]
    },
    {
        "id": 443,
        "code": "private boolean allSubscriptionsEqual(Set<String> allTopics,\n                                      Map<String, Subscription> subscriptions,\n                                      Map<String, List<TopicPartition>> consumerToOwnedPartitions,\n                                      Set<TopicPartition> partitionsWithMultiplePreviousOwners) {\n    Set<String> membersOfCurrentHighestGeneration = new HashSet<>();\n    boolean isAllSubscriptionsEqual = true;\n\n    Set<String> subscribedTopics = new HashSet<>();\n\n        \n        \n    Map<TopicPartition, String> allPreviousPartitionsToOwner = new HashMap<>();\n\n    for (Map.Entry<String, Subscription> subscriptionEntry : subscriptions.entrySet()) {\n        String consumer = subscriptionEntry.getKey();\n        Subscription subscription = subscriptionEntry.getValue();\n\n            \n        if (subscribedTopics.isEmpty()) {\n            subscribedTopics.addAll(subscription.topics());\n        } else if (isAllSubscriptionsEqual && !(subscription.topics().size() == subscribedTopics.size()\n            && subscribedTopics.containsAll(subscription.topics()))) {\n            isAllSubscriptionsEqual = false;\n        }\n\n        MemberData memberData = memberData(subscription);\n\n        List<TopicPartition> ownedPartitions = new ArrayList<>();\n        consumerToOwnedPartitions.put(consumer, ownedPartitions);\n\n            \n            \n        if (memberData.generation.isPresent() && memberData.generation.get() >= maxGeneration\n            || !memberData.generation.isPresent() && maxGeneration == DEFAULT_GENERATION) {\n\n                \n            if (memberData.generation.isPresent() && memberData.generation.get() > maxGeneration) {\n                allPreviousPartitionsToOwner.clear();\n                partitionsWithMultiplePreviousOwners.clear();\n                for (String droppedOutConsumer : membersOfCurrentHighestGeneration) {\n                    consumerToOwnedPartitions.get(droppedOutConsumer).clear();\n                }\n\n                membersOfCurrentHighestGeneration.clear();\n                maxGeneration = memberData.generation.get();\n            }\n\n            membersOfCurrentHighestGeneration.add(consumer);\n            for (final TopicPartition tp : memberData.partitions) {\n                    \n                if (allTopics.contains(tp.topic())) {\n                    String otherConsumer = allPreviousPartitionsToOwner.put(tp, consumer);\n                    if (otherConsumer == null) {\n                            \n                        ownedPartitions.add(tp);\n                    } else {\n                        log.error(\"Found multiple consumers {} and {} claiming the same TopicPartition {} in the \"\n                            + \"same generation {}, this will be invalidated and removed from their previous assignment.\",\n                                 consumer, otherConsumer, tp, maxGeneration);\n                        consumerToOwnedPartitions.get(otherConsumer).remove(tp);\n                        partitionsWithMultiplePreviousOwners.add(tp);\n                    }\n                }\n            }\n        }\n    }\n\n    return isAllSubscriptionsEqual;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "iff",
            "all",
            "consumers",
            "have",
            "an",
            "identical",
            "subscription"
        ]
    },
    {
        "id": 444,
        "code": "private Map<String, List<TopicPartition>> constrainedAssign(Map<String, Integer> partitionsPerTopic,\n                                                            Map<String, List<TopicPartition>> consumerToOwnedPartitions,\n                                                            Set<TopicPartition> partitionsWithMultiplePreviousOwners) {\n    if (log.isDebugEnabled()) {\n        log.debug(\"Performing constrained assign with partitionsPerTopic: {}, consumerToOwnedPartitions: {}.\",\n            partitionsPerTopic, consumerToOwnedPartitions);\n    }\n\n    Set<TopicPartition> allRevokedPartitions = new HashSet<>();\n\n        \n    List<String> unfilledMembersWithUnderMinQuotaPartitions = new LinkedList<>();\n    LinkedList<String> unfilledMembersWithExactlyMinQuotaPartitions = new LinkedList<>();\n\n    int numberOfConsumers = consumerToOwnedPartitions.size();\n    int totalPartitionsCount = partitionsPerTopic.values().stream().reduce(0, Integer::sum);\n\n    int minQuota = (int) Math.floor(((double) totalPartitionsCount) / numberOfConsumers);\n    int maxQuota = (int) Math.ceil(((double) totalPartitionsCount) / numberOfConsumers);\n        \n    int expectedNumMembersWithOverMinQuotaPartitions = totalPartitionsCount % numberOfConsumers;\n        \n    int currentNumMembersWithOverMinQuotaPartitions = 0;\n\n        \n    Map<String, List<TopicPartition>> assignment = new HashMap<>(\n        consumerToOwnedPartitions.keySet().stream().collect(Collectors.toMap(c -> c, c -> new ArrayList<>(maxQuota))));\n\n    List<TopicPartition> assignedPartitions = new ArrayList<>();\n        \n    for (Map.Entry<String, List<TopicPartition>> consumerEntry : consumerToOwnedPartitions.entrySet()) {\n        String consumer = consumerEntry.getKey();\n        List<TopicPartition> ownedPartitions = consumerEntry.getValue();\n\n        List<TopicPartition> consumerAssignment = assignment.get(consumer);\n\n        for (TopicPartition doublyClaimedPartition : partitionsWithMultiplePreviousOwners) {\n            if (ownedPartitions.contains(doublyClaimedPartition)) {\n                log.error(\"Found partition {} still claimed as owned by consumer {}, despite being claimed by multiple \"\n                             + \"consumers already in the same generation. Removing it from the ownedPartitions\",\n                         doublyClaimedPartition, consumer);\n                ownedPartitions.remove(doublyClaimedPartition);\n            }\n        }\n\n        if (ownedPartitions.size() < minQuota) {\n                \n                \n            if (ownedPartitions.size() > 0) {\n                consumerAssignment.addAll(ownedPartitions);\n                assignedPartitions.addAll(ownedPartitions);\n            }\n            unfilledMembersWithUnderMinQuotaPartitions.add(consumer);\n        } else if (ownedPartitions.size() >= maxQuota && currentNumMembersWithOverMinQuotaPartitions < expectedNumMembersWithOverMinQuotaPartitions) {\n                \n                \n            currentNumMembersWithOverMinQuotaPartitions++;\n            if (currentNumMembersWithOverMinQuotaPartitions == expectedNumMembersWithOverMinQuotaPartitions) {\n                unfilledMembersWithExactlyMinQuotaPartitions.clear();\n            }\n            List<TopicPartition> maxQuotaPartitions = ownedPartitions.subList(0, maxQuota);\n            consumerAssignment.addAll(maxQuotaPartitions);\n            assignedPartitions.addAll(maxQuotaPartitions);\n            allRevokedPartitions.addAll(ownedPartitions.subList(maxQuota, ownedPartitions.size()));\n        } else {\n                \n                \n            List<TopicPartition> minQuotaPartitions = ownedPartitions.subList(0, minQuota);\n            consumerAssignment.addAll(minQuotaPartitions);\n            assignedPartitions.addAll(minQuotaPartitions);\n            allRevokedPartitions.addAll(ownedPartitions.subList(minQuota, ownedPartitions.size()));\n                \n                \n                \n            if (currentNumMembersWithOverMinQuotaPartitions < expectedNumMembersWithOverMinQuotaPartitions) {\n                unfilledMembersWithExactlyMinQuotaPartitions.add(consumer);\n            }\n        }\n    }\n\n    List<TopicPartition> unassignedPartitions = getUnassignedPartitions(totalPartitionsCount, partitionsPerTopic, assignedPartitions);\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"After reassigning previously owned partitions, unfilled members: {}, unassigned partitions: {}, \" +\n            \"current assignment: {}\", unfilledMembersWithUnderMinQuotaPartitions, unassignedPartitions, assignment);\n    }\n\n    Collections.sort(unfilledMembersWithUnderMinQuotaPartitions);\n    Collections.sort(unfilledMembersWithExactlyMinQuotaPartitions);\n\n    Iterator<String> unfilledConsumerIter = unfilledMembersWithUnderMinQuotaPartitions.iterator();\n        \n    for (TopicPartition unassignedPartition : unassignedPartitions) {\n        String consumer;\n        if (unfilledConsumerIter.hasNext()) {\n            consumer = unfilledConsumerIter.next();\n        } else {\n            if (unfilledMembersWithUnderMinQuotaPartitions.isEmpty() && unfilledMembersWithExactlyMinQuotaPartitions.isEmpty()) {\n                    \n                    \n                int currentPartitionIndex = unassignedPartitions.indexOf(unassignedPartition);\n                log.error(\"No more unfilled consumers to be assigned. The remaining unassigned partitions are: {}\",\n                          unassignedPartitions.subList(currentPartitionIndex, unassignedPartitions.size()));\n                throw new IllegalStateException(\"No more unfilled consumers to be assigned.\");\n            } else if (unfilledMembersWithUnderMinQuotaPartitions.isEmpty()) {\n                consumer = unfilledMembersWithExactlyMinQuotaPartitions.poll();\n            } else {\n                unfilledConsumerIter = unfilledMembersWithUnderMinQuotaPartitions.iterator();\n                consumer = unfilledConsumerIter.next();\n            }\n        }\n\n        List<TopicPartition> consumerAssignment = assignment.get(consumer);\n        consumerAssignment.add(unassignedPartition);\n\n            \n            \n            \n        if (allRevokedPartitions.contains(unassignedPartition) || partitionsWithMultiplePreviousOwners.contains(unassignedPartition))\n            partitionsTransferringOwnership.put(unassignedPartition, consumer);\n\n        int currentAssignedCount = consumerAssignment.size();\n        if (currentAssignedCount == minQuota) {\n            unfilledConsumerIter.remove();\n            unfilledMembersWithExactlyMinQuotaPartitions.add(consumer);\n        } else if (currentAssignedCount == maxQuota) {\n            currentNumMembersWithOverMinQuotaPartitions++;\n            if (currentNumMembersWithOverMinQuotaPartitions == expectedNumMembersWithOverMinQuotaPartitions) {\n                    \n                    \n                    \n                    \n                if (unassignedPartitions.indexOf(unassignedPartition) != unassignedPartitions.size() - 1) {\n                    log.error(\"Filled the last member up to maxQuota but still had partitions remaining to assign, \"\n                                 + \"will continue but this indicates a bug in the assignment.\");\n                }\n            }\n        }\n    }\n\n    if (!unfilledMembersWithUnderMinQuotaPartitions.isEmpty()) {\n            \n            \n        if (currentNumMembersWithOverMinQuotaPartitions != expectedNumMembersWithOverMinQuotaPartitions) {\n            log.error(\"Current number of members with more than the minQuota partitions: {}, is less than the expected number \" +\n                \"of members with more than the minQuota partitions: {}, and no more partitions to be assigned to the remaining unfilled consumers: {}\",\n                currentNumMembersWithOverMinQuotaPartitions, expectedNumMembersWithOverMinQuotaPartitions, unfilledMembersWithUnderMinQuotaPartitions);\n            throw new IllegalStateException(\"We haven't reached the expected number of members with \" +\n                \"more than the minQuota partitions, but no more partitions to be assigned\");\n        } else {\n            for (String unfilledMember : unfilledMembersWithUnderMinQuotaPartitions) {\n                int assignedPartitionsCount = assignment.get(unfilledMember).size();\n                if (assignedPartitionsCount != minQuota) {\n                    log.error(\"Consumer: [{}] should have {} partitions, but got {} partitions, and no more partitions \" +\n                        \"to be assigned. The remaining unfilled consumers are: {}\", unfilledMember, minQuota, assignedPartitionsCount, unfilledMembersWithUnderMinQuotaPartitions);\n                    throw new IllegalStateException(String.format(\"Consumer: [%s] doesn't reach minQuota partitions, \" +\n                        \"and no more partitions to be assigned\", unfilledMember));\n                } else {\n                    log.trace(\"skip over this unfilled member: [{}] because we've reached the expected number of \" +\n                        \"members with more than the minQuota partitions, and this member already have minQuota partitions\", unfilledMember);\n                }\n            }\n        }\n    }\n\n    log.info(\"Final assignment of partitions to consumers: \\n{}\", assignment);\n\n    return assignment;\n}",
        "summary_tokens": [
            "this",
            "constrained",
            "assign",
            "optimizes",
            "the",
            "assignment",
            "algorithm",
            "when",
            "all",
            "consumers",
            "were",
            "subscribed",
            "to",
            "same",
            "set",
            "of",
            "topics"
        ]
    },
    {
        "id": 445,
        "code": "private Map<String, List<TopicPartition>> generalAssign(Map<String, Integer> partitionsPerTopic,\n                                                        Map<String, Subscription> subscriptions,\n                                                        Map<String, List<TopicPartition>> currentAssignment) {\n    if (log.isDebugEnabled()) {\n        log.debug(\"performing general assign. partitionsPerTopic: {}, subscriptions: {}, currentAssignment: {}\",\n            partitionsPerTopic, subscriptions, currentAssignment);\n    }\n\n    Map<TopicPartition, ConsumerGenerationPair> prevAssignment = new HashMap<>();\n    partitionMovements = new PartitionMovements();\n\n    prepopulateCurrentAssignments(subscriptions, prevAssignment);\n\n        \n    final Map<String, List<String>> topic2AllPotentialConsumers = new HashMap<>(partitionsPerTopic.keySet().size());\n        \n    final Map<String, List<String>> consumer2AllPotentialTopics = new HashMap<>(subscriptions.keySet().size());\n\n        \n    partitionsPerTopic.keySet().stream().forEach(\n        topicName -> topic2AllPotentialConsumers.put(topicName, new ArrayList<>()));\n\n    for (Entry<String, Subscription> entry: subscriptions.entrySet()) {\n        String consumerId = entry.getKey();\n        List<String> subscribedTopics = new ArrayList<>(entry.getValue().topics().size());\n        consumer2AllPotentialTopics.put(consumerId, subscribedTopics);\n        entry.getValue().topics().stream().filter(topic -> partitionsPerTopic.get(topic) != null).forEach(topic -> {\n            subscribedTopics.add(topic);\n            topic2AllPotentialConsumers.get(topic).add(consumerId);\n        });\n\n            \n        if (!currentAssignment.containsKey(consumerId))\n            currentAssignment.put(consumerId, new ArrayList<>());\n    }\n\n        \n    Map<TopicPartition, String> currentPartitionConsumer = new HashMap<>();\n    for (Map.Entry<String, List<TopicPartition>> entry: currentAssignment.entrySet())\n        for (TopicPartition topicPartition: entry.getValue())\n            currentPartitionConsumer.put(topicPartition, entry.getKey());\n\n    int totalPartitionsCount = partitionsPerTopic.values().stream().reduce(0, Integer::sum);\n    List<String> sortedAllTopics = new ArrayList<>(topic2AllPotentialConsumers.keySet());\n    Collections.sort(sortedAllTopics, new TopicComparator(topic2AllPotentialConsumers));\n    List<TopicPartition> sortedAllPartitions = getAllTopicPartitions(partitionsPerTopic, sortedAllTopics, totalPartitionsCount);\n\n        \n    List<TopicPartition> assignedPartitions = new ArrayList<>();\n    boolean revocationRequired = false;\n    for (Iterator<Entry<String, List<TopicPartition>>> it = currentAssignment.entrySet().iterator(); it.hasNext();) {\n        Map.Entry<String, List<TopicPartition>> entry = it.next();\n        Subscription consumerSubscription = subscriptions.get(entry.getKey());\n        if (consumerSubscription == null) {\n                \n            for (TopicPartition topicPartition: entry.getValue())\n                currentPartitionConsumer.remove(topicPartition);\n            it.remove();\n        } else {\n                \n            for (Iterator<TopicPartition> partitionIter = entry.getValue().iterator(); partitionIter.hasNext();) {\n                TopicPartition partition = partitionIter.next();\n                if (!topic2AllPotentialConsumers.containsKey(partition.topic())) {\n                        \n                    partitionIter.remove();\n                    currentPartitionConsumer.remove(partition);\n                } else if (!consumerSubscription.topics().contains(partition.topic())) {\n                        \n                    partitionIter.remove();\n                    revocationRequired = true;\n                } else {\n                        \n                        \n                        \n                    assignedPartitions.add(partition);\n                }\n            }\n        }\n    }\n\n        \n    List<TopicPartition> unassignedPartitions = getUnassignedPartitions(sortedAllPartitions, assignedPartitions, topic2AllPotentialConsumers);\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"unassigned Partitions: {}\", unassignedPartitions);\n    }\n\n        \n        \n        \n\n        \n    TreeSet<String> sortedCurrentSubscriptions = new TreeSet<>(new SubscriptionComparator(currentAssignment));\n    sortedCurrentSubscriptions.addAll(currentAssignment.keySet());\n\n    balance(currentAssignment, prevAssignment, sortedAllPartitions, unassignedPartitions, sortedCurrentSubscriptions,\n        consumer2AllPotentialTopics, topic2AllPotentialConsumers, currentPartitionConsumer, revocationRequired,\n        partitionsPerTopic, totalPartitionsCount);\n\n    log.info(\"Final assignment of partitions to consumers: \\n{}\", currentAssignment);\n\n    return currentAssignment;\n}",
        "summary_tokens": [
            "this",
            "general",
            "assign",
            "algorithm",
            "guarantees",
            "the",
            "assignment",
            "that",
            "is",
            "as",
            "balanced",
            "as",
            "possible"
        ]
    },
    {
        "id": 446,
        "code": "private List<TopicPartition> getUnassignedPartitions(int totalPartitionsCount,\n                                                     Map<String, Integer> partitionsPerTopic,\n                                                     List<TopicPartition> sortedAssignedPartitions) {\n    List<String> sortedAllTopics = new ArrayList<>(partitionsPerTopic.keySet());\n        \n    Collections.sort(sortedAllTopics);\n\n    if (sortedAssignedPartitions.isEmpty()) {\n            \n        return getAllTopicPartitions(partitionsPerTopic, sortedAllTopics, totalPartitionsCount);\n    }\n\n    List<TopicPartition> unassignedPartitions = new ArrayList<>(totalPartitionsCount - sortedAssignedPartitions.size());\n\n    Collections.sort(sortedAssignedPartitions, Comparator.comparing(TopicPartition::topic).thenComparing(TopicPartition::partition));\n\n    boolean shouldAddDirectly = false;\n    Iterator<TopicPartition> sortedAssignedPartitionsIter = sortedAssignedPartitions.iterator();\n    TopicPartition nextAssignedPartition = sortedAssignedPartitionsIter.next();\n\n    for (String topic : sortedAllTopics) {\n        int partitionCount = partitionsPerTopic.get(topic);\n        for (int i = 0; i < partitionCount; i++) {\n            if (shouldAddDirectly || !(nextAssignedPartition.topic().equals(topic) && nextAssignedPartition.partition() == i)) {\n                unassignedPartitions.add(new TopicPartition(topic, i));\n            } else {\n                    \n                if (sortedAssignedPartitionsIter.hasNext()) {\n                    nextAssignedPartition = sortedAssignedPartitionsIter.next();\n                } else {\n                        \n                    shouldAddDirectly = true;\n                }\n            }\n        }\n    }\n\n    return unassignedPartitions;\n}",
        "summary_tokens": [
            "get",
            "the",
            "unassigned",
            "partition",
            "list",
            "by",
            "computing",
            "the",
            "difference",
            "set",
            "of",
            "all",
            "sorted",
            "partitions",
            "and",
            "sorted",
            "assigned",
            "partitions"
        ]
    },
    {
        "id": 447,
        "code": "private void updatePrevAssignment(Map<TopicPartition, ConsumerGenerationPair> prevAssignment,\n                                  List<TopicPartition> partitions,\n                                  String consumer,\n                                  int generation) {\n    for (TopicPartition partition: partitions) {\n        if (prevAssignment.containsKey(partition)) {\n                \n            if (generation > prevAssignment.get(partition).generation) {\n                prevAssignment.put(partition, new ConsumerGenerationPair(consumer, generation));\n            }\n        } else {\n            prevAssignment.put(partition, new ConsumerGenerationPair(consumer, generation));\n        }\n    }\n}",
        "summary_tokens": [
            "update",
            "the",
            "prev",
            "assignment",
            "with",
            "the",
            "partitions",
            "consumer",
            "and",
            "generation",
            "in",
            "parameters"
        ]
    },
    {
        "id": 448,
        "code": "private void prepopulateCurrentAssignments(Map<String, Subscription> subscriptions,\n                                           Map<TopicPartition, ConsumerGenerationPair> prevAssignment) {\n        \n        \n        \n\n    for (Map.Entry<String, Subscription> subscriptionEntry: subscriptions.entrySet()) {\n        String consumer = subscriptionEntry.getKey();\n        Subscription subscription = subscriptionEntry.getValue();\n        if (subscription.userData() != null) {\n                \n            subscription.userData().rewind();\n        }\n        MemberData memberData = memberData(subscriptionEntry.getValue());\n\n            \n        if (memberData.generation.isPresent() && memberData.generation.get() < maxGeneration) {\n                \n            updatePrevAssignment(prevAssignment, memberData.partitions, consumer, memberData.generation.get());\n        } else if (!memberData.generation.isPresent() && maxGeneration > DEFAULT_GENERATION) {\n                \n                \n            updatePrevAssignment(prevAssignment, memberData.partitions, consumer, DEFAULT_GENERATION);\n        }\n    }\n}",
        "summary_tokens": [
            "filling",
            "in",
            "the",
            "prev",
            "assignment",
            "from",
            "the",
            "subscriptions"
        ]
    },
    {
        "id": 449,
        "code": "private boolean isBalanced(Map<String, List<TopicPartition>> currentAssignment,\n                           TreeSet<String> sortedCurrentSubscriptions,\n                           Map<String, List<String>> allSubscriptions,\n                           Map<String, Integer> partitionsPerTopic,\n                           int totalPartitionCount) {\n    int min = currentAssignment.get(sortedCurrentSubscriptions.first()).size();\n    int max = currentAssignment.get(sortedCurrentSubscriptions.last()).size();\n    if (min >= max - 1)\n            \n        return true;\n\n        \n    final Map<TopicPartition, String> allPartitions = new HashMap<>();\n    Set<Entry<String, List<TopicPartition>>> assignments = currentAssignment.entrySet();\n    for (Map.Entry<String, List<TopicPartition>> entry: assignments) {\n        List<TopicPartition> topicPartitions = entry.getValue();\n        for (TopicPartition topicPartition: topicPartitions) {\n            if (allPartitions.containsKey(topicPartition))\n                log.error(\"{} is assigned to more than one consumer.\", topicPartition);\n            allPartitions.put(topicPartition, entry.getKey());\n        }\n    }\n\n        \n        \n    for (String consumer: sortedCurrentSubscriptions) {\n        List<TopicPartition> consumerPartitions = currentAssignment.get(consumer);\n        int consumerPartitionCount = consumerPartitions.size();\n\n            \n        List<String> allSubscribedTopics = allSubscriptions.get(consumer);\n        int maxAssignmentSize = getMaxAssignmentSize(totalPartitionCount, allSubscribedTopics, partitionsPerTopic);\n\n        if (consumerPartitionCount == maxAssignmentSize)\n            continue;\n\n            \n        for (String topic: allSubscribedTopics) {\n            int partitionCount = partitionsPerTopic.get(topic);\n            for (int i = 0; i < partitionCount; i++) {\n                TopicPartition topicPartition = new TopicPartition(topic, i);\n                if (!currentAssignment.get(consumer).contains(topicPartition)) {\n                    String otherConsumer = allPartitions.get(topicPartition);\n                    int otherConsumerPartitionCount = currentAssignment.get(otherConsumer).size();\n                    if (consumerPartitionCount < otherConsumerPartitionCount) {\n                        log.debug(\"{} can be moved from consumer {} to consumer {} for a more balanced assignment.\",\n                            topicPartition, otherConsumer, consumer);\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "determine",
            "if",
            "the",
            "current",
            "assignment",
            "is",
            "a",
            "balanced",
            "one"
        ]
    },
    {
        "id": 450,
        "code": "private int getMaxAssignmentSize(int totalPartitionCount,\n                                 List<String> allSubscribedTopics,\n                                 Map<String, Integer> partitionsPerTopic) {\n    int maxAssignmentSize;\n    if (allSubscribedTopics.size() == partitionsPerTopic.size()) {\n        maxAssignmentSize = totalPartitionCount;\n    } else {\n        maxAssignmentSize = allSubscribedTopics.stream().map(topic -> partitionsPerTopic.get(topic)).reduce(0, Integer::sum);\n    }\n    return maxAssignmentSize;\n}",
        "summary_tokens": [
            "get",
            "the",
            "maximum",
            "assigned",
            "partition",
            "size",
            "of",
            "the",
            "all",
            "subscribed",
            "topics"
        ]
    },
    {
        "id": 451,
        "code": "private int getBalanceScore(Map<String, List<TopicPartition>> assignment) {\n    int score = 0;\n\n    Map<String, Integer> consumer2AssignmentSize = new HashMap<>();\n    for (Entry<String, List<TopicPartition>> entry: assignment.entrySet())\n        consumer2AssignmentSize.put(entry.getKey(), entry.getValue().size());\n\n    Iterator<Entry<String, Integer>> it = consumer2AssignmentSize.entrySet().iterator();\n    while (it.hasNext()) {\n        Entry<String, Integer> entry = it.next();\n        int consumerAssignmentSize = entry.getValue();\n        it.remove();\n        for (Entry<String, Integer> otherEntry: consumer2AssignmentSize.entrySet())\n            score += Math.abs(consumerAssignmentSize - otherEntry.getValue());\n    }\n\n    return score;\n}",
        "summary_tokens": [
            "the",
            "balance",
            "score",
            "of",
            "the",
            "given",
            "assignment",
            "as",
            "the",
            "sum",
            "of",
            "assigned",
            "partitions",
            "size",
            "difference",
            "of",
            "all",
            "consumer",
            "pairs"
        ]
    },
    {
        "id": 452,
        "code": "private void assignPartition(TopicPartition partition,\n                             TreeSet<String> sortedCurrentSubscriptions,\n                             Map<String, List<TopicPartition>> currentAssignment,\n                             Map<String, List<String>> consumer2AllPotentialTopics,\n                             Map<TopicPartition, String> currentPartitionConsumer) {\n    for (String consumer: sortedCurrentSubscriptions) {\n        if (consumer2AllPotentialTopics.get(consumer).contains(partition.topic())) {\n            sortedCurrentSubscriptions.remove(consumer);\n            currentAssignment.get(consumer).add(partition);\n            currentPartitionConsumer.put(partition, consumer);\n            sortedCurrentSubscriptions.add(consumer);\n            break;\n        }\n    }\n}",
        "summary_tokens": [
            "the",
            "assignment",
            "should",
            "improve",
            "the",
            "overall",
            "balance",
            "of",
            "the",
            "partition",
            "assignments",
            "to",
            "consumers"
        ]
    },
    {
        "id": 453,
        "code": "private void balance(Map<String, List<TopicPartition>> currentAssignment,\n                     Map<TopicPartition, ConsumerGenerationPair> prevAssignment,\n                     List<TopicPartition> sortedPartitions,\n                     List<TopicPartition> unassignedPartitions,\n                     TreeSet<String> sortedCurrentSubscriptions,\n                     Map<String, List<String>> consumer2AllPotentialTopics,\n                     Map<String, List<String>> topic2AllPotentialConsumers,\n                     Map<TopicPartition, String> currentPartitionConsumer,\n                     boolean revocationRequired,\n                     Map<String, Integer> partitionsPerTopic,\n                     int totalPartitionCount) {\n    boolean initializing = currentAssignment.get(sortedCurrentSubscriptions.last()).isEmpty();\n\n        \n    for (TopicPartition partition: unassignedPartitions) {\n            \n        if (topic2AllPotentialConsumers.get(partition.topic()).isEmpty())\n            continue;\n\n        assignPartition(partition, sortedCurrentSubscriptions, currentAssignment,\n            consumer2AllPotentialTopics, currentPartitionConsumer);\n    }\n\n        \n    Set<TopicPartition> fixedPartitions = new HashSet<>();\n    for (String topic: topic2AllPotentialConsumers.keySet())\n        if (!canParticipateInReassignment(topic, topic2AllPotentialConsumers)) {\n            for (int i = 0; i < partitionsPerTopic.get(topic); i++) {\n                fixedPartitions.add(new TopicPartition(topic, i));\n            }\n        }\n    sortedPartitions.removeAll(fixedPartitions);\n    unassignedPartitions.removeAll(fixedPartitions);\n\n        \n    Map<String, List<TopicPartition>> fixedAssignments = new HashMap<>();\n    for (String consumer: consumer2AllPotentialTopics.keySet())\n        if (!canParticipateInReassignment(consumer, currentAssignment,\n            consumer2AllPotentialTopics, topic2AllPotentialConsumers, partitionsPerTopic, totalPartitionCount)) {\n            sortedCurrentSubscriptions.remove(consumer);\n            fixedAssignments.put(consumer, currentAssignment.remove(consumer));\n        }\n\n        \n    Map<String, List<TopicPartition>> preBalanceAssignment = deepCopy(currentAssignment);\n    Map<TopicPartition, String> preBalancePartitionConsumers = new HashMap<>(currentPartitionConsumer);\n\n        \n    if (!revocationRequired) {\n        performReassignments(unassignedPartitions, currentAssignment, prevAssignment, sortedCurrentSubscriptions,\n            consumer2AllPotentialTopics, topic2AllPotentialConsumers, currentPartitionConsumer, partitionsPerTopic, totalPartitionCount);\n    }\n\n    boolean reassignmentPerformed = performReassignments(sortedPartitions, currentAssignment, prevAssignment, sortedCurrentSubscriptions,\n        consumer2AllPotentialTopics, topic2AllPotentialConsumers, currentPartitionConsumer, partitionsPerTopic, totalPartitionCount);\n\n        \n        \n    if (!initializing && reassignmentPerformed && getBalanceScore(currentAssignment) >= getBalanceScore(preBalanceAssignment)) {\n        deepCopy(preBalanceAssignment, currentAssignment);\n        currentPartitionConsumer.clear();\n        currentPartitionConsumer.putAll(preBalancePartitionConsumers);\n    }\n\n        \n    for (Entry<String, List<TopicPartition>> entry: fixedAssignments.entrySet()) {\n        String consumer = entry.getKey();\n        currentAssignment.put(consumer, entry.getValue());\n        sortedCurrentSubscriptions.add(consumer);\n    }\n\n    fixedAssignments.clear();\n}",
        "summary_tokens": [
            "balance",
            "the",
            "current",
            "assignment",
            "using",
            "the",
            "data",
            "structures",
            "created",
            "in",
            "the",
            "assign"
        ]
    },
    {
        "id": 454,
        "code": "public boolean poll(Timer timer, boolean waitForJoinGroup) {\n    maybeUpdateSubscriptionMetadata();\n\n    invokeCompletedOffsetCommitCallbacks();\n\n    if (subscriptions.hasAutoAssignedPartitions()) {\n        if (protocol == null) {\n            throw new IllegalStateException(\"User configured \" + ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG +\n                \" to empty while trying to subscribe for group protocol to auto assign partitions\");\n        }\n            \n            \n        pollHeartbeat(timer.currentTimeMs());\n        if (coordinatorUnknownAndUnready(timer)) {\n            return false;\n        }\n\n        if (rejoinNeededOrPending()) {\n                \n                \n                \n            if (subscriptions.hasPatternSubscription()) {\n                    \n                    \n                    \n                    \n                    \n                    \n                    \n                if (this.metadata.timeToAllowUpdate(timer.currentTimeMs()) == 0) {\n                    this.metadata.requestUpdate();\n                }\n\n                if (!client.ensureFreshMetadata(timer)) {\n                    return false;\n                }\n\n                maybeUpdateSubscriptionMetadata();\n            }\n\n                \n            if (!ensureActiveGroup(waitForJoinGroup ? timer : time.timer(0L))) {\n                    \n                    \n                timer.update(time.milliseconds());\n\n                return false;\n            }\n        }\n    } else {\n            \n            \n            \n            \n            \n            \n        if (metadata.updateRequested() && !client.hasReadyNodes(timer.currentTimeMs())) {\n            client.awaitMetadataUpdate(timer);\n        }\n\n            \n        client.pollNoWakeup();\n    }\n\n    maybeAutoCommitOffsetsAsync(timer.currentTimeMs());\n    return true;\n}",
        "summary_tokens": [
            "poll",
            "for",
            "coordinator",
            "events"
        ]
    },
    {
        "id": 455,
        "code": "public long timeToNextPoll(long now) {\n    if (!autoCommitEnabled)\n        return timeToNextHeartbeat(now);\n\n    return Math.min(nextAutoCommitTimer.remainingMs(), timeToNextHeartbeat(now));\n}",
        "summary_tokens": [
            "return",
            "the",
            "time",
            "to",
            "the",
            "next",
            "needed",
            "invocation",
            "of",
            "consumer",
            "network",
            "client",
            "poll",
            "timer"
        ]
    },
    {
        "id": 456,
        "code": "private void maybeUpdateGroupSubscription(String assignorName,\n                                          Map<String, Assignment> assignments,\n                                          Set<String> allSubscribedTopics) {\n    if (!isAssignFromSubscribedTopicsAssignor(assignorName)) {\n        Set<String> assignedTopics = new HashSet<>();\n        for (Assignment assigned : assignments.values()) {\n            for (TopicPartition tp : assigned.partitions())\n                assignedTopics.add(tp.topic());\n        }\n\n        if (!assignedTopics.containsAll(allSubscribedTopics)) {\n            SortedSet<String> notAssignedTopics = new TreeSet<>(allSubscribedTopics);\n            notAssignedTopics.removeAll(assignedTopics);\n            log.warn(\"The following subscribed topics are not assigned to any members: {} \", notAssignedTopics);\n        }\n\n        if (!allSubscribedTopics.containsAll(assignedTopics)) {\n            SortedSet<String> newlyAddedTopics = new TreeSet<>(assignedTopics);\n            newlyAddedTopics.removeAll(allSubscribedTopics);\n            log.info(\"The following not-subscribed topics are assigned, and their metadata will be \" +\n                \"fetched from the brokers: {}\", newlyAddedTopics);\n\n            allSubscribedTopics.addAll(newlyAddedTopics);\n            updateGroupSubscription(allSubscribedTopics);\n        }\n    }\n}",
        "summary_tokens": [
            "user",
            "customized",
            "assignor",
            "may",
            "have",
            "created",
            "some",
            "topics",
            "that",
            "are",
            "not",
            "in",
            "the",
            "subscription",
            "list",
            "and",
            "assign",
            "their",
            "partitions",
            "to",
            "the",
            "members",
            "in",
            "this",
            "case",
            "we",
            "would",
            "like",
            "to",
            "update",
            "the",
            "leader",
            "s",
            "own",
            "metadata",
            "with",
            "the",
            "newly",
            "added",
            "topics",
            "so",
            "that",
            "it",
            "will",
            "not",
            "trigger",
            "a",
            "subsequent",
            "rebalance",
            "when",
            "these",
            "topics",
            "gets",
            "updated",
            "from",
            "metadata",
            "refresh"
        ]
    },
    {
        "id": 457,
        "code": "private void validateCooperativeAssignment(final Map<String, List<TopicPartition>> ownedPartitions,\n                                           final Map<String, Assignment> assignments) {\n    Set<TopicPartition> totalRevokedPartitions = new HashSet<>();\n    SortedSet<TopicPartition> totalAddedPartitions = new TreeSet<>(COMPARATOR);\n    for (final Map.Entry<String, Assignment> entry : assignments.entrySet()) {\n        final Assignment assignment = entry.getValue();\n        final Set<TopicPartition> addedPartitions = new HashSet<>(assignment.partitions());\n        addedPartitions.removeAll(ownedPartitions.get(entry.getKey()));\n        final Set<TopicPartition> revokedPartitions = new HashSet<>(ownedPartitions.get(entry.getKey()));\n        revokedPartitions.removeAll(assignment.partitions());\n\n        totalAddedPartitions.addAll(addedPartitions);\n        totalRevokedPartitions.addAll(revokedPartitions);\n    }\n\n        \n        \n    totalAddedPartitions.retainAll(totalRevokedPartitions);\n    if (!totalAddedPartitions.isEmpty()) {\n        log.error(\"With the COOPERATIVE protocol, owned partitions cannot be \" +\n            \"reassigned to other members; however the assignor has reassigned partitions {} which are still owned \" +\n            \"by some members\", totalAddedPartitions);\n\n        throw new IllegalStateException(\"Assignor supporting the COOPERATIVE protocol violates its requirements\");\n    }\n}",
        "summary_tokens": [
            "used",
            "by",
            "cooperative",
            "rebalance",
            "protocol",
            "only"
        ]
    },
    {
        "id": 458,
        "code": "public boolean rejoinNeededOrPending() {\n    if (!subscriptions.hasAutoAssignedPartitions())\n        return false;\n\n        \n        \n    if (assignmentSnapshot != null && !assignmentSnapshot.matches(metadataSnapshot)) {\n        final String fullReason = String.format(\"cached metadata has changed from %s at the beginning of the rebalance to %s\",\n            assignmentSnapshot, metadataSnapshot);\n        requestRejoinIfNecessary(\"cached metadata has changed\", fullReason);\n        return true;\n    }\n\n        \n    if (joinedSubscription != null && !joinedSubscription.equals(subscriptions.subscription())) {\n        final String fullReason = String.format(\"subscription has changed from %s at the beginning of the rebalance to %s\",\n            joinedSubscription, subscriptions.subscription());\n        requestRejoinIfNecessary(\"subscription has changed\", fullReason);\n        return true;\n    }\n\n    return super.rejoinNeededOrPending();\n}",
        "summary_tokens": [
            "kafka",
            "exception",
            "if",
            "the",
            "callback",
            "throws",
            "exception"
        ]
    },
    {
        "id": 459,
        "code": "public boolean refreshCommittedOffsetsIfNeeded(Timer timer) {\n    final Set<TopicPartition> initializingPartitions = subscriptions.initializingPartitions();\n\n    final Map<TopicPartition, OffsetAndMetadata> offsets = fetchCommittedOffsets(initializingPartitions, timer);\n    if (offsets == null) return false;\n\n    for (final Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n        final TopicPartition tp = entry.getKey();\n        final OffsetAndMetadata offsetAndMetadata = entry.getValue();\n        if (offsetAndMetadata != null) {\n                \n            entry.getValue().leaderEpoch().ifPresent(epoch -> this.metadata.updateLastSeenEpochIfNewer(entry.getKey(), epoch));\n\n                \n                \n            if (this.subscriptions.isAssigned(tp)) {\n                final ConsumerMetadata.LeaderAndEpoch leaderAndEpoch = metadata.currentLeader(tp);\n                final SubscriptionState.FetchPosition position = new SubscriptionState.FetchPosition(\n                        offsetAndMetadata.offset(), offsetAndMetadata.leaderEpoch(),\n                        leaderAndEpoch);\n\n                this.subscriptions.seekUnvalidated(tp, position);\n\n                log.info(\"Setting offset for partition {} to the committed offset {}\", tp, position);\n            } else {\n                log.info(\"Ignoring the returned {} since its partition {} is no longer assigned\",\n                    offsetAndMetadata, tp);\n            }\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "refresh",
            "the",
            "committed",
            "offsets",
            "for",
            "provided",
            "partitions"
        ]
    },
    {
        "id": 460,
        "code": "public Map<TopicPartition, OffsetAndMetadata> fetchCommittedOffsets(final Set<TopicPartition> partitions,\n                                                                    final Timer timer) {\n    if (partitions.isEmpty()) return Collections.emptyMap();\n\n    final Generation generationForOffsetRequest = generationIfStable();\n    if (pendingCommittedOffsetRequest != null &&\n        !pendingCommittedOffsetRequest.sameRequest(partitions, generationForOffsetRequest)) {\n            \n        pendingCommittedOffsetRequest = null;\n    }\n\n    do {\n        if (!ensureCoordinatorReady(timer)) return null;\n\n            \n        final RequestFuture<Map<TopicPartition, OffsetAndMetadata>> future;\n        if (pendingCommittedOffsetRequest != null) {\n            future = pendingCommittedOffsetRequest.response;\n        } else {\n            future = sendOffsetFetchRequest(partitions);\n            pendingCommittedOffsetRequest = new PendingCommittedOffsetRequest(partitions, generationForOffsetRequest, future);\n        }\n        client.poll(future, timer);\n\n        if (future.isDone()) {\n            pendingCommittedOffsetRequest = null;\n\n            if (future.succeeded()) {\n                return future.value();\n            } else if (!future.isRetriable()) {\n                throw future.exception();\n            } else {\n                timer.sleep(rebalanceConfig.retryBackoffMs);\n            }\n        } else {\n            return null;\n        }\n    } while (timer.notExpired());\n    return null;\n}",
        "summary_tokens": [
            "fetch",
            "the",
            "current",
            "committed",
            "offsets",
            "from",
            "the",
            "coordinator",
            "for",
            "a",
            "set",
            "of",
            "partitions"
        ]
    },
    {
        "id": 461,
        "code": "public ConsumerGroupMetadata groupMetadata() {\n    return groupMetadata;\n}",
        "summary_tokens": [
            "return",
            "the",
            "consumer",
            "group",
            "metadata"
        ]
    },
    {
        "id": 462,
        "code": "public void close(final Timer timer) {\n        \n    client.disableWakeups();\n    try {\n        maybeAutoCommitOffsetsSync(timer);\n        while (pendingAsyncCommits.get() > 0 && timer.notExpired()) {\n            ensureCoordinatorReady(timer);\n            client.poll(timer);\n            invokeCompletedOffsetCommitCallbacks();\n        }\n    } finally {\n        super.close(timer);\n    }\n}",
        "summary_tokens": [
            "kafka",
            "exception",
            "if",
            "the",
            "rebalance",
            "callback",
            "throws",
            "exception"
        ]
    },
    {
        "id": 463,
        "code": "RequestFuture<Void> sendOffsetCommitRequest(final Map<TopicPartition, OffsetAndMetadata> offsets) {\n    if (offsets.isEmpty())\n        return RequestFuture.voidSuccess();\n\n    Node coordinator = checkAndGetCoordinator();\n    if (coordinator == null)\n        return RequestFuture.coordinatorNotAvailable();\n\n        \n    Map<String, OffsetCommitRequestData.OffsetCommitRequestTopic> requestTopicDataMap = new HashMap<>();\n    for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        OffsetAndMetadata offsetAndMetadata = entry.getValue();\n        if (offsetAndMetadata.offset() < 0) {\n            return RequestFuture.failure(new IllegalArgumentException(\"Invalid offset: \" + offsetAndMetadata.offset()));\n        }\n\n        OffsetCommitRequestData.OffsetCommitRequestTopic topic = requestTopicDataMap\n                .getOrDefault(topicPartition.topic(),\n                        new OffsetCommitRequestData.OffsetCommitRequestTopic()\n                                .setName(topicPartition.topic())\n                );\n\n        topic.partitions().add(new OffsetCommitRequestData.OffsetCommitRequestPartition()\n                .setPartitionIndex(topicPartition.partition())\n                .setCommittedOffset(offsetAndMetadata.offset())\n                .setCommittedLeaderEpoch(offsetAndMetadata.leaderEpoch().orElse(RecordBatch.NO_PARTITION_LEADER_EPOCH))\n                .setCommittedMetadata(offsetAndMetadata.metadata())\n        );\n        requestTopicDataMap.put(topicPartition.topic(), topic);\n    }\n\n    final Generation generation;\n    if (subscriptions.hasAutoAssignedPartitions()) {\n        generation = generationIfStable();\n            \n            \n        if (generation == null) {\n            log.info(\"Failing OffsetCommit request since the consumer is not part of an active group\");\n\n            if (rebalanceInProgress()) {\n                    \n                    \n                return RequestFuture.failure(new RebalanceInProgressException(\"Offset commit cannot be completed since the \" +\n                    \"consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance \" +\n                    \"by calling poll() and then retry the operation.\"));\n            } else {\n                return RequestFuture.failure(new CommitFailedException(\"Offset commit cannot be completed since the \" +\n                    \"consumer is not part of an active group for auto partition assignment; it is likely that the consumer \" +\n                    \"was kicked out of the group.\"));\n            }\n        }\n    } else {\n        generation = Generation.NO_GENERATION;\n    }\n\n    OffsetCommitRequest.Builder builder = new OffsetCommitRequest.Builder(\n            new OffsetCommitRequestData()\n                    .setGroupId(this.rebalanceConfig.groupId)\n                    .setGenerationId(generation.generationId)\n                    .setMemberId(generation.memberId)\n                    .setGroupInstanceId(rebalanceConfig.groupInstanceId.orElse(null))\n                    .setTopics(new ArrayList<>(requestTopicDataMap.values()))\n    );\n\n    log.trace(\"Sending OffsetCommit request with {} to coordinator {}\", offsets, coordinator);\n\n    return client.send(coordinator, builder)\n            .compose(new OffsetCommitResponseHandler(offsets, generation));\n}",
        "summary_tokens": [
            "commit",
            "offsets",
            "for",
            "the",
            "specified",
            "list",
            "of",
            "topics",
            "and",
            "partitions"
        ]
    },
    {
        "id": 464,
        "code": "private RequestFuture<Map<TopicPartition, OffsetAndMetadata>> sendOffsetFetchRequest(Set<TopicPartition> partitions) {\n    Node coordinator = checkAndGetCoordinator();\n    if (coordinator == null)\n        return RequestFuture.coordinatorNotAvailable();\n\n    log.debug(\"Fetching committed offsets for partitions: {}\", partitions);\n        \n    OffsetFetchRequest.Builder requestBuilder =\n        new OffsetFetchRequest.Builder(this.rebalanceConfig.groupId, true, new ArrayList<>(partitions), throwOnFetchStableOffsetsUnsupported);\n\n        \n    return client.send(coordinator, requestBuilder)\n            .compose(new OffsetFetchResponseHandler());\n}",
        "summary_tokens": [
            "fetch",
            "the",
            "committed",
            "offsets",
            "for",
            "a",
            "set",
            "of",
            "partitions"
        ]
    },
    {
        "id": 465,
        "code": "public ConsumerRecords<K, V> onConsume(ConsumerRecords<K, V> records) {\n    ConsumerRecords<K, V> interceptRecords = records;\n    for (ConsumerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            interceptRecords = interceptor.onConsume(interceptRecords);\n        } catch (Exception e) {\n                \n            log.warn(\"Error executing interceptor onConsume callback\", e);\n        }\n    }\n    return interceptRecords;\n}",
        "summary_tokens": [
            "this",
            "is",
            "called",
            "when",
            "the",
            "records",
            "are",
            "about",
            "to",
            "be",
            "returned",
            "to",
            "the",
            "user"
        ]
    },
    {
        "id": 466,
        "code": "public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n    for (ConsumerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            interceptor.onCommit(offsets);\n        } catch (Exception e) {\n                \n            log.warn(\"Error executing interceptor onCommit callback\", e);\n        }\n    }\n}",
        "summary_tokens": [
            "this",
            "is",
            "called",
            "when",
            "commit",
            "request",
            "returns",
            "successfully",
            "from",
            "the",
            "broker"
        ]
    },
    {
        "id": 467,
        "code": "public void close() {\n    for (ConsumerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            interceptor.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close consumer interceptor \", e);\n        }\n    }\n}",
        "summary_tokens": [
            "closes",
            "every",
            "interceptor",
            "in",
            "a",
            "container"
        ]
    },
    {
        "id": 468,
        "code": "public RequestFuture<ClientResponse> send(Node node,\n                                          AbstractRequest.Builder<?> requestBuilder,\n                                          int requestTimeoutMs) {\n    long now = time.milliseconds();\n    RequestFutureCompletionHandler completionHandler = new RequestFutureCompletionHandler();\n    ClientRequest clientRequest = client.newClientRequest(node.idString(), requestBuilder, now, true,\n        requestTimeoutMs, completionHandler);\n    unsent.put(node, clientRequest);\n\n        \n    client.wakeup();\n    return completionHandler.future;\n}",
        "summary_tokens": [
            "send",
            "a",
            "new",
            "request"
        ]
    },
    {
        "id": 469,
        "code": "public boolean awaitMetadataUpdate(Timer timer) {\n    int version = this.metadata.requestUpdate();\n    do {\n        poll(timer);\n    } while (this.metadata.updateVersion() == version && timer.notExpired());\n    return this.metadata.updateVersion() > version;\n}",
        "summary_tokens": [
            "block",
            "waiting",
            "on",
            "the",
            "metadata",
            "refresh",
            "with",
            "a",
            "timeout"
        ]
    },
    {
        "id": 470,
        "code": "boolean ensureFreshMetadata(Timer timer) {\n    if (this.metadata.updateRequested() || this.metadata.timeToNextUpdate(timer.currentTimeMs()) == 0) {\n        return awaitMetadataUpdate(timer);\n    } else {\n            \n        return true;\n    }\n}",
        "summary_tokens": [
            "ensure",
            "our",
            "metadata",
            "is",
            "fresh",
            "if",
            "an",
            "update",
            "is",
            "expected",
            "this",
            "will",
            "block",
            "until",
            "it",
            "has",
            "completed"
        ]
    },
    {
        "id": 471,
        "code": "public void wakeup() {\n        \n        \n    log.debug(\"Received user wakeup\");\n    this.wakeup.set(true);\n    this.client.wakeup();\n}",
        "summary_tokens": [
            "wakeup",
            "an",
            "active",
            "poll"
        ]
    },
    {
        "id": 472,
        "code": "public void poll(Timer timer, PollCondition pollCondition, boolean disableWakeup) {\n        \n    firePendingCompletedRequests();\n\n    lock.lock();\n    try {\n            \n        handlePendingDisconnects();\n\n            \n        long pollDelayMs = trySend(timer.currentTimeMs());\n\n            \n            \n            \n        if (pendingCompletion.isEmpty() && (pollCondition == null || pollCondition.shouldBlock())) {\n                \n            long pollTimeout = Math.min(timer.remainingMs(), pollDelayMs);\n            if (client.inFlightRequestCount() == 0)\n                pollTimeout = Math.min(pollTimeout, retryBackoffMs);\n            client.poll(pollTimeout, timer.currentTimeMs());\n        } else {\n            client.poll(0, timer.currentTimeMs());\n        }\n        timer.update();\n\n            \n            \n            \n        checkDisconnects(timer.currentTimeMs());\n        if (!disableWakeup) {\n                \n                \n            maybeTriggerWakeup();\n        }\n            \n        maybeThrowInterruptException();\n\n            \n            \n        trySend(timer.currentTimeMs());\n\n            \n        failExpiredRequests(timer.currentTimeMs());\n\n            \n        unsent.clean();\n    } finally {\n        lock.unlock();\n    }\n\n        \n    firePendingCompletedRequests();\n\n    metadata.maybeThrowAnyException();\n}",
        "summary_tokens": [
            "poll",
            "for",
            "any",
            "network",
            "io"
        ]
    },
    {
        "id": 473,
        "code": "public void pollNoWakeup() {\n    poll(time.timer(0), null, true);\n}",
        "summary_tokens": [
            "poll",
            "for",
            "network",
            "io",
            "and",
            "return",
            "immediately"
        ]
    },
    {
        "id": 474,
        "code": "public void transmitSends() {\n    Timer timer = time.timer(0);\n\n        \n        \n    lock.lock();\n    try {\n            \n        trySend(timer.currentTimeMs());\n\n        client.poll(0, timer.currentTimeMs());\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "poll",
            "for",
            "network",
            "io",
            "in",
            "best",
            "effort",
            "only",
            "trying",
            "to",
            "transmit",
            "the",
            "ready",
            "to",
            "send",
            "request",
            "do",
            "not",
            "check",
            "any",
            "pending",
            "requests",
            "or",
            "metadata",
            "errors",
            "so",
            "that",
            "no",
            "exception",
            "should",
            "ever",
            "be",
            "thrown",
            "also",
            "no",
            "wakeups",
            "be",
            "triggered",
            "and",
            "no",
            "interrupted",
            "exception",
            "either"
        ]
    },
    {
        "id": 475,
        "code": "public boolean awaitPendingRequests(Node node, Timer timer) {\n    while (hasPendingRequests(node) && timer.notExpired()) {\n        poll(timer);\n    }\n    return !hasPendingRequests(node);\n}",
        "summary_tokens": [
            "block",
            "until",
            "all",
            "pending",
            "requests",
            "from",
            "the",
            "given",
            "node",
            "have",
            "finished"
        ]
    },
    {
        "id": 476,
        "code": "public int pendingRequestCount() {\n    lock.lock();\n    try {\n        return unsent.requestCount() + client.inFlightRequestCount();\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "total",
            "count",
            "of",
            "pending",
            "requests",
            "from",
            "all",
            "nodes"
        ]
    },
    {
        "id": 477,
        "code": "public boolean hasPendingRequests() {\n    if (unsent.hasRequests())\n        return true;\n    lock.lock();\n    try {\n        return client.hasInFlightRequests();\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "check",
            "whether",
            "there",
            "is",
            "pending",
            "request"
        ]
    },
    {
        "id": 478,
        "code": "public boolean isUnavailable(Node node) {\n    lock.lock();\n    try {\n        return client.connectionFailed(node) && client.connectionDelay(node, time.milliseconds()) > 0;\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "code",
            "is",
            "disconnected",
            "and",
            "unavailable",
            "for",
            "immediate",
            "reconnection",
            "i"
        ]
    },
    {
        "id": 479,
        "code": "public void maybeThrowAuthFailure(Node node) {\n    lock.lock();\n    try {\n        AuthenticationException exception = client.authenticationException(node);\n        if (exception != null)\n            throw exception;\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "check",
            "for",
            "an",
            "authentication",
            "error",
            "on",
            "a",
            "given",
            "node",
            "and",
            "raise",
            "the",
            "exception",
            "if",
            "there",
            "is",
            "one"
        ]
    },
    {
        "id": 480,
        "code": "public void tryConnect(Node node) {\n    lock.lock();\n    try {\n        client.ready(node, time.milliseconds());\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "initiate",
            "a",
            "connection",
            "if",
            "currently",
            "possible"
        ]
    },
    {
        "id": 481,
        "code": "public void add(Fetch<K, V> fetch) {\n    Objects.requireNonNull(fetch);\n    addRecords(fetch.records);\n    this.positionAdvanced |= fetch.positionAdvanced;\n}",
        "summary_tokens": [
            "add",
            "another",
            "fetch",
            "to",
            "this",
            "one",
            "all",
            "of",
            "its",
            "records",
            "will",
            "be",
            "added",
            "to",
            "this",
            "fetch",
            "s",
            "records",
            "records",
            "and",
            "if",
            "the",
            "other",
            "fetch",
            "position",
            "advanced",
            "advanced",
            "the",
            "consume",
            "position",
            "for",
            "any",
            "topic",
            "partition",
            "this",
            "fetch",
            "will",
            "be",
            "marked",
            "as",
            "having",
            "advanced",
            "the",
            "consume",
            "position",
            "as",
            "well"
        ]
    },
    {
        "id": 482,
        "code": "public Map<TopicPartition, List<ConsumerRecord<K, V>>> records() {\n    return Collections.unmodifiableMap(records);\n}",
        "summary_tokens": [
            "all",
            "of",
            "the",
            "non",
            "control",
            "messages",
            "for",
            "this",
            "fetch",
            "grouped",
            "by",
            "partition"
        ]
    },
    {
        "id": 483,
        "code": "public boolean positionAdvanced() {\n    return positionAdvanced;\n}",
        "summary_tokens": [
            "whether",
            "the",
            "fetch",
            "caused",
            "the",
            "consumer",
            "s",
            "org"
        ]
    },
    {
        "id": 484,
        "code": "public int numRecords() {\n    return numRecords;\n}",
        "summary_tokens": [
            "the",
            "total",
            "number",
            "of",
            "non",
            "control",
            "messages",
            "for",
            "this",
            "fetch",
            "across",
            "all",
            "partitions"
        ]
    },
    {
        "id": 485,
        "code": "public boolean isEmpty() {\n    return numRecords == 0 && !positionAdvanced;\n}",
        "summary_tokens": [
            "true",
            "if",
            "and",
            "only",
            "if",
            "this",
            "fetch",
            "did",
            "not",
            "return",
            "any",
            "user",
            "visible",
            "i"
        ]
    },
    {
        "id": 486,
        "code": "protected boolean hasCompletedFetches() {\n    return !completedFetches.isEmpty();\n}",
        "summary_tokens": [
            "return",
            "whether",
            "we",
            "have",
            "any",
            "completed",
            "fetches",
            "pending",
            "return",
            "to",
            "the",
            "user"
        ]
    },
    {
        "id": 487,
        "code": "public boolean hasAvailableFetches() {\n    return completedFetches.stream().anyMatch(fetch -> subscriptions.isFetchable(fetch.partition));\n}",
        "summary_tokens": [
            "return",
            "whether",
            "we",
            "have",
            "any",
            "completed",
            "fetches",
            "that",
            "are",
            "fetchable"
        ]
    },
    {
        "id": 488,
        "code": "public synchronized int sendFetches() {\n        \n    sensors.maybeUpdateAssignment(subscriptions);\n\n    Map<Node, FetchSessionHandler.FetchRequestData> fetchRequestMap = prepareFetchRequests();\n    for (Map.Entry<Node, FetchSessionHandler.FetchRequestData> entry : fetchRequestMap.entrySet()) {\n        final Node fetchTarget = entry.getKey();\n        final FetchSessionHandler.FetchRequestData data = entry.getValue();\n        final short maxVersion;\n        if (!data.canUseTopicIds()) {\n            maxVersion = (short) 12;\n        } else {\n            maxVersion = ApiKeys.FETCH.latestVersion();\n        }\n        final FetchRequest.Builder request = FetchRequest.Builder\n                .forConsumer(maxVersion, this.maxWaitMs, this.minBytes, data.toSend())\n                .isolationLevel(isolationLevel)\n                .setMaxBytes(this.maxBytes)\n                .metadata(data.metadata())\n                .removed(data.toForget())\n                .replaced(data.toReplace())\n                .rackId(clientRackId);\n\n        if (log.isDebugEnabled()) {\n            log.debug(\"Sending {} {} to broker {}\", isolationLevel, data.toString(), fetchTarget);\n        }\n        RequestFuture<ClientResponse> future = client.send(fetchTarget, request);\n            \n            \n            \n            \n        this.nodesWithPendingFetchRequests.add(entry.getKey().id());\n        future.addListener(new RequestFutureListener<ClientResponse>() {\n            @Override\n            public void onSuccess(ClientResponse resp) {\n                synchronized (Fetcher.this) {\n                    try {\n                        FetchResponse response = (FetchResponse) resp.responseBody();\n                        FetchSessionHandler handler = sessionHandler(fetchTarget.id());\n                        if (handler == null) {\n                            log.error(\"Unable to find FetchSessionHandler for node {}. Ignoring fetch response.\",\n                                    fetchTarget.id());\n                            return;\n                        }\n                        if (!handler.handleResponse(response, resp.requestHeader().apiVersion())) {\n                            if (response.error() == Errors.FETCH_SESSION_TOPIC_ID_ERROR) {\n                                metadata.requestUpdate();\n                            }\n                            return;\n                        }\n\n                        Map<TopicPartition, FetchResponseData.PartitionData> responseData = response.responseData(handler.sessionTopicNames(), resp.requestHeader().apiVersion());\n                        Set<TopicPartition> partitions = new HashSet<>(responseData.keySet());\n                        FetchResponseMetricAggregator metricAggregator = new FetchResponseMetricAggregator(sensors, partitions);\n\n                        for (Map.Entry<TopicPartition, FetchResponseData.PartitionData> entry : responseData.entrySet()) {\n                            TopicPartition partition = entry.getKey();\n                            FetchRequest.PartitionData requestData = data.sessionPartitions().get(partition);\n                            if (requestData == null) {\n                                String message;\n                                if (data.metadata().isFull()) {\n                                    message = MessageFormatter.arrayFormat(\n                                            \"Response for missing full request partition: partition={}; metadata={}\",\n                                            new Object[]{partition, data.metadata()}).getMessage();\n                                } else {\n                                    message = MessageFormatter.arrayFormat(\n                                            \"Response for missing session request partition: partition={}; metadata={}; toSend={}; toForget={}; toReplace={}\",\n                                            new Object[]{partition, data.metadata(), data.toSend(), data.toForget(), data.toReplace()}).getMessage();\n                                }\n\n                                    \n                                throw new IllegalStateException(message);\n                            } else {\n                                long fetchOffset = requestData.fetchOffset;\n                                FetchResponseData.PartitionData partitionData = entry.getValue();\n\n                                log.debug(\"Fetch {} at offset {} for partition {} returned fetch data {}\",\n                                        isolationLevel, fetchOffset, partition, partitionData);\n\n                                Iterator<? extends RecordBatch> batches = FetchResponse.recordsOrFail(partitionData).batches().iterator();\n                                short responseVersion = resp.requestHeader().apiVersion();\n\n                                completedFetches.add(new CompletedFetch(partition, partitionData,\n                                        metricAggregator, batches, fetchOffset, responseVersion));\n                            }\n                        }\n\n                        sensors.fetchLatency.record(resp.requestLatencyMs());\n                    } finally {\n                        nodesWithPendingFetchRequests.remove(fetchTarget.id());\n                    }\n                }\n            }\n\n            @Override\n            public void onFailure(RuntimeException e) {\n                synchronized (Fetcher.this) {\n                    try {\n                        FetchSessionHandler handler = sessionHandler(fetchTarget.id());\n                        if (handler != null) {\n                            handler.handleError(e);\n                        }\n                    } finally {\n                        nodesWithPendingFetchRequests.remove(fetchTarget.id());\n                    }\n                }\n            }\n        });\n\n    }\n    return fetchRequestMap.size();\n}",
        "summary_tokens": [
            "set",
            "up",
            "a",
            "fetch",
            "request",
            "for",
            "any",
            "node",
            "that",
            "we",
            "have",
            "assigned",
            "partitions",
            "for",
            "which",
            "doesn",
            "t",
            "already",
            "have",
            "an",
            "in",
            "flight",
            "fetch",
            "or",
            "pending",
            "fetch",
            "data"
        ]
    },
    {
        "id": 489,
        "code": "public Map<String, List<PartitionInfo>> getAllTopicMetadata(Timer timer) {\n    return getTopicMetadata(MetadataRequest.Builder.allTopics(), timer);\n}",
        "summary_tokens": [
            "get",
            "topic",
            "metadata",
            "for",
            "all",
            "topics",
            "in",
            "the",
            "cluster",
            "timer",
            "timer",
            "bounding",
            "how",
            "long",
            "this",
            "method",
            "can",
            "block",
            "the",
            "map",
            "of",
            "topics",
            "with",
            "their",
            "partition",
            "information"
        ]
    },
    {
        "id": 490,
        "code": "public Map<String, List<PartitionInfo>> getTopicMetadata(MetadataRequest.Builder request, Timer timer) {\n        \n    if (!request.isAllTopics() && request.emptyTopicList())\n        return Collections.emptyMap();\n\n    do {\n        RequestFuture<ClientResponse> future = sendMetadataRequest(request);\n        client.poll(future, timer);\n\n        if (future.failed() && !future.isRetriable())\n            throw future.exception();\n\n        if (future.succeeded()) {\n            MetadataResponse response = (MetadataResponse) future.value().responseBody();\n            Cluster cluster = response.buildCluster();\n\n            Set<String> unauthorizedTopics = cluster.unauthorizedTopics();\n            if (!unauthorizedTopics.isEmpty())\n                throw new TopicAuthorizationException(unauthorizedTopics);\n\n            boolean shouldRetry = false;\n            Map<String, Errors> errors = response.errors();\n            if (!errors.isEmpty()) {\n                    \n                    \n\n                log.debug(\"Topic metadata fetch included errors: {}\", errors);\n\n                for (Map.Entry<String, Errors> errorEntry : errors.entrySet()) {\n                    String topic = errorEntry.getKey();\n                    Errors error = errorEntry.getValue();\n\n                    if (error == Errors.INVALID_TOPIC_EXCEPTION)\n                        throw new InvalidTopicException(\"Topic '\" + topic + \"' is invalid\");\n                    else if (error == Errors.UNKNOWN_TOPIC_OR_PARTITION)\n                            \n                            \n                        continue;\n                    else if (error.exception() instanceof RetriableException)\n                        shouldRetry = true;\n                    else\n                        throw new KafkaException(\"Unexpected error fetching metadata for topic \" + topic,\n                                error.exception());\n                }\n            }\n\n            if (!shouldRetry) {\n                HashMap<String, List<PartitionInfo>> topicsPartitionInfos = new HashMap<>();\n                for (String topic : cluster.topics())\n                    topicsPartitionInfos.put(topic, cluster.partitionsForTopic(topic));\n                return topicsPartitionInfos;\n            }\n        }\n\n        timer.sleep(retryBackoffMs);\n    } while (timer.notExpired());\n\n    throw new TimeoutException(\"Timeout expired while fetching topic metadata\");\n}",
        "summary_tokens": [
            "get",
            "metadata",
            "for",
            "all",
            "topics",
            "present",
            "in",
            "kafka",
            "cluster"
        ]
    },
    {
        "id": 491,
        "code": "private RequestFuture<ClientResponse> sendMetadataRequest(MetadataRequest.Builder request) {\n    final Node node = client.leastLoadedNode();\n    if (node == null)\n        return RequestFuture.noBrokersAvailable();\n    else\n        return client.send(node, request);\n}",
        "summary_tokens": [
            "send",
            "metadata",
            "request",
            "to",
            "least",
            "loaded",
            "node",
            "in",
            "kafka",
            "cluster",
            "asynchronously",
            "a",
            "future",
            "that",
            "indicates",
            "result",
            "of",
            "sent",
            "metadata",
            "request"
        ]
    },
    {
        "id": 492,
        "code": "public void resetOffsetsIfNeeded() {\n        \n    RuntimeException exception = cachedListOffsetsException.getAndSet(null);\n    if (exception != null)\n        throw exception;\n\n    Set<TopicPartition> partitions = subscriptions.partitionsNeedingReset(time.milliseconds());\n    if (partitions.isEmpty())\n        return;\n\n    final Map<TopicPartition, Long> offsetResetTimestamps = new HashMap<>();\n    for (final TopicPartition partition : partitions) {\n        Long timestamp = offsetResetStrategyTimestamp(partition);\n        if (timestamp != null)\n            offsetResetTimestamps.put(partition, timestamp);\n    }\n\n    resetOffsetsAsync(offsetResetTimestamps);\n}",
        "summary_tokens": [
            "reset",
            "offsets",
            "for",
            "all",
            "assigned",
            "partitions",
            "that",
            "require",
            "it"
        ]
    },
    {
        "id": 493,
        "code": "public void validateOffsetsIfNeeded() {\n    RuntimeException exception = cachedOffsetForLeaderException.getAndSet(null);\n    if (exception != null)\n        throw exception;\n\n        \n        \n    validatePositionsOnMetadataChange();\n\n        \n    Map<TopicPartition, FetchPosition> partitionsToValidate = subscriptions\n            .partitionsNeedingValidation(time.milliseconds())\n            .stream()\n            .filter(tp -> subscriptions.position(tp) != null)\n            .collect(Collectors.toMap(Function.identity(), subscriptions::position));\n\n    validateOffsetsAsync(partitionsToValidate);\n}",
        "summary_tokens": [
            "validate",
            "offsets",
            "for",
            "all",
            "assigned",
            "partitions",
            "for",
            "which",
            "a",
            "leader",
            "change",
            "has",
            "been",
            "detected"
        ]
    },
    {
        "id": 494,
        "code": "public Fetch<K, V> collectFetch() {\n    Fetch<K, V> fetch = Fetch.empty();\n    Queue<CompletedFetch> pausedCompletedFetches = new ArrayDeque<>();\n    int recordsRemaining = maxPollRecords;\n\n    try {\n        while (recordsRemaining > 0) {\n            if (nextInLineFetch == null || nextInLineFetch.isConsumed) {\n                CompletedFetch records = completedFetches.peek();\n                if (records == null) break;\n\n                if (records.notInitialized()) {\n                    try {\n                        nextInLineFetch = initializeCompletedFetch(records);\n                    } catch (Exception e) {\n                            \n                            \n                            \n                            \n                            \n                        FetchResponseData.PartitionData partition = records.partitionData;\n                        if (fetch.isEmpty() && FetchResponse.recordsOrFail(partition).sizeInBytes() == 0) {\n                            completedFetches.poll();\n                        }\n                        throw e;\n                    }\n                } else {\n                    nextInLineFetch = records;\n                }\n                completedFetches.poll();\n            } else if (subscriptions.isPaused(nextInLineFetch.partition)) {\n                    \n                    \n                log.debug(\"Skipping fetching records for assigned partition {} because it is paused\", nextInLineFetch.partition);\n                pausedCompletedFetches.add(nextInLineFetch);\n                nextInLineFetch = null;\n            } else {\n                Fetch<K, V> nextFetch = fetchRecords(nextInLineFetch, recordsRemaining);\n                recordsRemaining -= nextFetch.numRecords();\n                fetch.add(nextFetch);\n            }\n        }\n    } catch (KafkaException e) {\n        if (fetch.isEmpty())\n            throw e;\n    } finally {\n            \n            \n        completedFetches.addAll(pausedCompletedFetches);\n    }\n\n    return fetch;\n}",
        "summary_tokens": [
            "return",
            "the",
            "fetched",
            "records",
            "empty",
            "the",
            "record",
            "buffer",
            "and",
            "update",
            "the",
            "consumed",
            "position"
        ]
    },
    {
        "id": 495,
        "code": "private void validateOffsetsAsync(Map<TopicPartition, FetchPosition> partitionsToValidate) {\n    final Map<Node, Map<TopicPartition, FetchPosition>> regrouped =\n        regroupFetchPositionsByLeader(partitionsToValidate);\n\n    long nextResetTimeMs = time.milliseconds() + requestTimeoutMs;\n    regrouped.forEach((node, fetchPositions) -> {\n        if (node.isEmpty()) {\n            metadata.requestUpdate();\n            return;\n        }\n\n        NodeApiVersions nodeApiVersions = apiVersions.get(node.idString());\n        if (nodeApiVersions == null) {\n            client.tryConnect(node);\n            return;\n        }\n\n        if (!hasUsableOffsetForLeaderEpochVersion(nodeApiVersions)) {\n            log.debug(\"Skipping validation of fetch offsets for partitions {} since the broker does not \" +\n                          \"support the required protocol version (introduced in Kafka 2.3)\",\n                fetchPositions.keySet());\n            for (TopicPartition partition : fetchPositions.keySet()) {\n                subscriptions.completeValidation(partition);\n            }\n            return;\n        }\n\n        subscriptions.setNextAllowedRetry(fetchPositions.keySet(), nextResetTimeMs);\n\n        RequestFuture<OffsetForEpochResult> future =\n            offsetsForLeaderEpochClient.sendAsyncRequest(node, fetchPositions);\n\n        future.addListener(new RequestFutureListener<OffsetForEpochResult>() {\n            @Override\n            public void onSuccess(OffsetForEpochResult offsetsResult) {\n                List<SubscriptionState.LogTruncation> truncations = new ArrayList<>();\n                if (!offsetsResult.partitionsToRetry().isEmpty()) {\n                    subscriptions.setNextAllowedRetry(offsetsResult.partitionsToRetry(), time.milliseconds() + retryBackoffMs);\n                    metadata.requestUpdate();\n                }\n\n                    \n                    \n                    \n                    \n                    \n                    \n                offsetsResult.endOffsets().forEach((topicPartition, respEndOffset) -> {\n                    FetchPosition requestPosition = fetchPositions.get(topicPartition);\n                    Optional<SubscriptionState.LogTruncation> truncationOpt =\n                        subscriptions.maybeCompleteValidation(topicPartition, requestPosition, respEndOffset);\n                    truncationOpt.ifPresent(truncations::add);\n                });\n\n                if (!truncations.isEmpty()) {\n                    maybeSetOffsetForLeaderException(buildLogTruncationException(truncations));\n                }\n            }\n\n            @Override\n            public void onFailure(RuntimeException e) {\n                subscriptions.requestFailed(fetchPositions.keySet(), time.milliseconds() + retryBackoffMs);\n                metadata.requestUpdate();\n\n                if (!(e instanceof RetriableException)) {\n                    maybeSetOffsetForLeaderException(e);\n                }\n            }\n        });\n    });\n}",
        "summary_tokens": [
            "for",
            "each",
            "partition",
            "which",
            "needs",
            "validation",
            "make",
            "an",
            "asynchronous",
            "request",
            "to",
            "get",
            "the",
            "end",
            "offsets",
            "for",
            "the",
            "partition",
            "with",
            "the",
            "epoch",
            "less",
            "than",
            "or",
            "equal",
            "to",
            "the",
            "epoch",
            "the",
            "partition",
            "last",
            "saw"
        ]
    },
    {
        "id": 496,
        "code": "private RequestFuture<ListOffsetResult> sendListOffsetsRequests(final Map<TopicPartition, Long> timestampsToSearch,\n                                                                final boolean requireTimestamps) {\n    final Set<TopicPartition> partitionsToRetry = new HashSet<>();\n    Map<Node, Map<TopicPartition, ListOffsetsPartition>> timestampsToSearchByNode =\n            groupListOffsetRequests(timestampsToSearch, partitionsToRetry);\n    if (timestampsToSearchByNode.isEmpty())\n        return RequestFuture.failure(new StaleMetadataException());\n\n    final RequestFuture<ListOffsetResult> listOffsetRequestsFuture = new RequestFuture<>();\n    final Map<TopicPartition, ListOffsetData> fetchedTimestampOffsets = new HashMap<>();\n    final AtomicInteger remainingResponses = new AtomicInteger(timestampsToSearchByNode.size());\n\n    for (Map.Entry<Node, Map<TopicPartition, ListOffsetsPartition>> entry : timestampsToSearchByNode.entrySet()) {\n        RequestFuture<ListOffsetResult> future = sendListOffsetRequest(entry.getKey(), entry.getValue(), requireTimestamps);\n        future.addListener(new RequestFutureListener<ListOffsetResult>() {\n            @Override\n            public void onSuccess(ListOffsetResult partialResult) {\n                synchronized (listOffsetRequestsFuture) {\n                    fetchedTimestampOffsets.putAll(partialResult.fetchedOffsets);\n                    partitionsToRetry.addAll(partialResult.partitionsToRetry);\n\n                    if (remainingResponses.decrementAndGet() == 0 && !listOffsetRequestsFuture.isDone()) {\n                        ListOffsetResult result = new ListOffsetResult(fetchedTimestampOffsets, partitionsToRetry);\n                        listOffsetRequestsFuture.complete(result);\n                    }\n                }\n            }\n\n            @Override\n            public void onFailure(RuntimeException e) {\n                synchronized (listOffsetRequestsFuture) {\n                    if (!listOffsetRequestsFuture.isDone())\n                        listOffsetRequestsFuture.raise(e);\n                }\n            }\n        });\n    }\n    return listOffsetRequestsFuture;\n}",
        "summary_tokens": [
            "search",
            "the",
            "offsets",
            "by",
            "target",
            "times",
            "for",
            "the",
            "specified",
            "partitions"
        ]
    },
    {
        "id": 497,
        "code": "private Map<Node, Map<TopicPartition, ListOffsetsPartition>> groupListOffsetRequests(\n        Map<TopicPartition, Long> timestampsToSearch,\n        Set<TopicPartition> partitionsToRetry) {\n    final Map<TopicPartition, ListOffsetsPartition> partitionDataMap = new HashMap<>();\n    for (Map.Entry<TopicPartition, Long> entry: timestampsToSearch.entrySet()) {\n        TopicPartition tp  = entry.getKey();\n        Long offset = entry.getValue();\n        Metadata.LeaderAndEpoch leaderAndEpoch = metadata.currentLeader(tp);\n\n        if (!leaderAndEpoch.leader.isPresent()) {\n            log.debug(\"Leader for partition {} is unknown for fetching offset {}\", tp, offset);\n            metadata.requestUpdate();\n            partitionsToRetry.add(tp);\n        } else {\n            Node leader = leaderAndEpoch.leader.get();\n            if (client.isUnavailable(leader)) {\n                client.maybeThrowAuthFailure(leader);\n\n                    \n                    \n                    \n                log.debug(\"Leader {} for partition {} is unavailable for fetching offset until reconnect backoff expires\",\n                        leader, tp);\n                partitionsToRetry.add(tp);\n            } else {\n                int currentLeaderEpoch = leaderAndEpoch.epoch.orElse(ListOffsetsResponse.UNKNOWN_EPOCH);\n                partitionDataMap.put(tp, new ListOffsetsPartition()\n                        .setPartitionIndex(tp.partition())\n                        .setTimestamp(offset)\n                        .setCurrentLeaderEpoch(currentLeaderEpoch));\n            }\n        }\n    }\n    return regroupPartitionMapByNode(partitionDataMap);\n}",
        "summary_tokens": [
            "groups",
            "timestamps",
            "to",
            "search",
            "by",
            "node",
            "for",
            "topic",
            "partitions",
            "in",
            "timestamps",
            "to",
            "search",
            "that",
            "have",
            "leaders",
            "available"
        ]
    },
    {
        "id": 498,
        "code": "private RequestFuture<ListOffsetResult> sendListOffsetRequest(final Node node,\n                                                              final Map<TopicPartition, ListOffsetsPartition> timestampsToSearch,\n                                                              boolean requireTimestamp) {\n    ListOffsetsRequest.Builder builder = ListOffsetsRequest.Builder\n            .forConsumer(requireTimestamp, isolationLevel, false)\n            .setTargetTimes(ListOffsetsRequest.toListOffsetsTopics(timestampsToSearch));\n\n    log.debug(\"Sending ListOffsetRequest {} to broker {}\", builder, node);\n    return client.send(node, builder)\n            .compose(new RequestFutureAdapter<ClientResponse, ListOffsetResult>() {\n                @Override\n                public void onSuccess(ClientResponse response, RequestFuture<ListOffsetResult> future) {\n                    ListOffsetsResponse lor = (ListOffsetsResponse) response.responseBody();\n                    log.trace(\"Received ListOffsetResponse {} from broker {}\", lor, node);\n                    handleListOffsetResponse(lor, future);\n                }\n            });\n}",
        "summary_tokens": [
            "send",
            "the",
            "list",
            "offset",
            "request",
            "to",
            "a",
            "specific",
            "broker",
            "for",
            "the",
            "partitions",
            "and",
            "target",
            "timestamps"
        ]
    },
    {
        "id": 499,
        "code": "private void handleListOffsetResponse(ListOffsetsResponse listOffsetsResponse,\n                                      RequestFuture<ListOffsetResult> future) {\n    Map<TopicPartition, ListOffsetData> fetchedOffsets = new HashMap<>();\n    Set<TopicPartition> partitionsToRetry = new HashSet<>();\n    Set<String> unauthorizedTopics = new HashSet<>();\n\n    for (ListOffsetsTopicResponse topic : listOffsetsResponse.topics()) {\n        for (ListOffsetsPartitionResponse partition : topic.partitions()) {\n            TopicPartition topicPartition = new TopicPartition(topic.name(), partition.partitionIndex());\n            Errors error = Errors.forCode(partition.errorCode());\n            switch (error) {\n                case NONE:\n                    if (!partition.oldStyleOffsets().isEmpty()) {\n                            \n                        long offset;\n                        if (partition.oldStyleOffsets().size() > 1) {\n                            future.raise(new IllegalStateException(\"Unexpected partitionData response of length \" +\n                                    partition.oldStyleOffsets().size()));\n                            return;\n                        } else {\n                            offset = partition.oldStyleOffsets().get(0);\n                        }\n                        log.debug(\"Handling v0 ListOffsetResponse response for {}. Fetched offset {}\",\n                            topicPartition, offset);\n                        if (offset != ListOffsetsResponse.UNKNOWN_OFFSET) {\n                            ListOffsetData offsetData = new ListOffsetData(offset, null, Optional.empty());\n                            fetchedOffsets.put(topicPartition, offsetData);\n                        }\n                    } else {\n                            \n                        log.debug(\"Handling ListOffsetResponse response for {}. Fetched offset {}, timestamp {}\",\n                            topicPartition, partition.offset(), partition.timestamp());\n                        if (partition.offset() != ListOffsetsResponse.UNKNOWN_OFFSET) {\n                            Optional<Integer> leaderEpoch = (partition.leaderEpoch() == ListOffsetsResponse.UNKNOWN_EPOCH)\n                                    ? Optional.empty()\n                                    : Optional.of(partition.leaderEpoch());\n                            ListOffsetData offsetData = new ListOffsetData(partition.offset(), partition.timestamp(),\n                                leaderEpoch);\n                            fetchedOffsets.put(topicPartition, offsetData);\n                        }\n                    }\n                    break;\n                case UNSUPPORTED_FOR_MESSAGE_FORMAT:\n                        \n                        \n                        \n                    log.debug(\"Cannot search by timestamp for partition {} because the message format version \" +\n                                  \"is before 0.10.0\", topicPartition);\n                    break;\n                case NOT_LEADER_OR_FOLLOWER:\n                case REPLICA_NOT_AVAILABLE:\n                case KAFKA_STORAGE_ERROR:\n                case OFFSET_NOT_AVAILABLE:\n                case LEADER_NOT_AVAILABLE:\n                case FENCED_LEADER_EPOCH:\n                case UNKNOWN_LEADER_EPOCH:\n                    log.debug(\"Attempt to fetch offsets for partition {} failed due to {}, retrying.\",\n                        topicPartition, error);\n                    partitionsToRetry.add(topicPartition);\n                    break;\n                case UNKNOWN_TOPIC_OR_PARTITION:\n                    log.warn(\"Received unknown topic or partition error in ListOffset request for partition {}\", topicPartition);\n                    partitionsToRetry.add(topicPartition);\n                    break;\n                case TOPIC_AUTHORIZATION_FAILED:\n                    unauthorizedTopics.add(topicPartition.topic());\n                    break;\n                default:\n                    log.warn(\"Attempt to fetch offsets for partition {} failed due to unexpected exception: {}, retrying.\",\n                        topicPartition, error.message());\n                    partitionsToRetry.add(topicPartition);\n            }\n        }\n    }\n\n    if (!unauthorizedTopics.isEmpty())\n        future.raise(new TopicAuthorizationException(unauthorizedTopics));\n    else\n        future.complete(new ListOffsetResult(fetchedOffsets, partitionsToRetry));\n}",
        "summary_tokens": [
            "callback",
            "for",
            "the",
            "response",
            "of",
            "the",
            "list",
            "offset",
            "call",
            "above"
        ]
    },
    {
        "id": 500,
        "code": "Node selectReadReplica(TopicPartition partition, Node leaderReplica, long currentTimeMs) {\n    Optional<Integer> nodeId = subscriptions.preferredReadReplica(partition, currentTimeMs);\n    if (nodeId.isPresent()) {\n        Optional<Node> node = nodeId.flatMap(id -> metadata.fetch().nodeIfOnline(partition, id));\n        if (node.isPresent()) {\n            return node.get();\n        } else {\n            log.trace(\"Not fetching from {} for partition {} since it is marked offline or is missing from our metadata,\" +\n                      \" using the leader instead.\", nodeId, partition);\n            subscriptions.clearPreferredReadReplica(partition);\n            return leaderReplica;\n        }\n    } else {\n        return leaderReplica;\n    }\n}",
        "summary_tokens": [
            "determine",
            "which",
            "replica",
            "to",
            "read",
            "from"
        ]
    },
    {
        "id": 501,
        "code": "private void validatePositionsOnMetadataChange() {\n    int newMetadataUpdateVersion = metadata.updateVersion();\n    if (metadataUpdateVersion.getAndSet(newMetadataUpdateVersion) != newMetadataUpdateVersion) {\n        subscriptions.assignedPartitions().forEach(topicPartition -> {\n            ConsumerMetadata.LeaderAndEpoch leaderAndEpoch = metadata.currentLeader(topicPartition);\n            subscriptions.maybeValidatePositionForCurrentLeader(apiVersions, topicPartition, leaderAndEpoch);\n        });\n    }\n}",
        "summary_tokens": [
            "if",
            "we",
            "have",
            "seen",
            "new",
            "metadata",
            "as",
            "tracked",
            "by",
            "org"
        ]
    },
    {
        "id": 502,
        "code": "private Map<Node, FetchSessionHandler.FetchRequestData> prepareFetchRequests() {\n    Map<Node, FetchSessionHandler.Builder> fetchable = new LinkedHashMap<>();\n\n    validatePositionsOnMetadataChange();\n\n    long currentTimeMs = time.milliseconds();\n    Map<String, Uuid> topicIds = metadata.topicIds();\n\n    for (TopicPartition partition : fetchablePartitions()) {\n        FetchPosition position = this.subscriptions.position(partition);\n        if (position == null) {\n            throw new IllegalStateException(\"Missing position for fetchable partition \" + partition);\n        }\n\n        Optional<Node> leaderOpt = position.currentLeader.leader;\n        if (!leaderOpt.isPresent()) {\n            log.debug(\"Requesting metadata update for partition {} since the position {} is missing the current leader node\", partition, position);\n            metadata.requestUpdate();\n            continue;\n        }\n\n            \n        Node node = selectReadReplica(partition, leaderOpt.get(), currentTimeMs);\n        if (client.isUnavailable(node)) {\n            client.maybeThrowAuthFailure(node);\n\n                \n                \n            log.trace(\"Skipping fetch for partition {} because node {} is awaiting reconnect backoff\", partition, node);\n        } else if (this.nodesWithPendingFetchRequests.contains(node.id())) {\n            log.trace(\"Skipping fetch for partition {} because previous request to {} has not been processed\", partition, node);\n        } else {\n                \n            FetchSessionHandler.Builder builder = fetchable.get(node);\n            if (builder == null) {\n                int id = node.id();\n                FetchSessionHandler handler = sessionHandler(id);\n                if (handler == null) {\n                    handler = new FetchSessionHandler(logContext, id);\n                    sessionHandlers.put(id, handler);\n                }\n                builder = handler.newBuilder();\n                fetchable.put(node, builder);\n            }\n            builder.add(partition, new FetchRequest.PartitionData(\n                topicIds.getOrDefault(partition.topic(), Uuid.ZERO_UUID),\n                position.offset, FetchRequest.INVALID_LOG_START_OFFSET, this.fetchSize,\n                position.currentLeader.epoch, Optional.empty()));\n\n            log.debug(\"Added {} fetch request for partition {} at position {} to node {}\", isolationLevel,\n                partition, position, node);\n        }\n    }\n\n    Map<Node, FetchSessionHandler.FetchRequestData> reqs = new LinkedHashMap<>();\n    for (Map.Entry<Node, FetchSessionHandler.Builder> entry : fetchable.entrySet()) {\n        reqs.put(entry.getKey(), entry.getValue().build());\n    }\n    return reqs;\n}",
        "summary_tokens": [
            "create",
            "fetch",
            "requests",
            "for",
            "all",
            "nodes",
            "for",
            "which",
            "we",
            "have",
            "assigned",
            "partitions",
            "that",
            "have",
            "no",
            "existing",
            "requests",
            "in",
            "flight"
        ]
    },
    {
        "id": 503,
        "code": "private CompletedFetch initializeCompletedFetch(CompletedFetch nextCompletedFetch) {\n    TopicPartition tp = nextCompletedFetch.partition;\n    FetchResponseData.PartitionData partition = nextCompletedFetch.partitionData;\n    long fetchOffset = nextCompletedFetch.nextFetchOffset;\n    CompletedFetch completedFetch = null;\n    Errors error = Errors.forCode(partition.errorCode());\n\n    try {\n        if (!subscriptions.hasValidPosition(tp)) {\n                \n            log.debug(\"Ignoring fetched records for partition {} since it no longer has valid position\", tp);\n        } else if (error == Errors.NONE) {\n                \n                \n            FetchPosition position = subscriptions.position(tp);\n            if (position == null || position.offset != fetchOffset) {\n                log.debug(\"Discarding stale fetch response for partition {} since its offset {} does not match \" +\n                        \"the expected offset {}\", tp, fetchOffset, position);\n                return null;\n            }\n\n            log.trace(\"Preparing to read {} bytes of data for partition {} with offset {}\",\n                    FetchResponse.recordsSize(partition), tp, position);\n            Iterator<? extends RecordBatch> batches = FetchResponse.recordsOrFail(partition).batches().iterator();\n            completedFetch = nextCompletedFetch;\n\n            if (!batches.hasNext() && FetchResponse.recordsSize(partition) > 0) {\n                if (completedFetch.responseVersion < 3) {\n                        \n                    Map<TopicPartition, Long> recordTooLargePartitions = Collections.singletonMap(tp, fetchOffset);\n                    throw new RecordTooLargeException(\"There are some messages at [Partition=Offset]: \" +\n                            recordTooLargePartitions + \" whose size is larger than the fetch size \" + this.fetchSize +\n                            \" and hence cannot be returned. Please considering upgrading your broker to 0.10.1.0 or \" +\n                            \"newer to avoid this issue. Alternately, increase the fetch size on the client (using \" +\n                            ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG + \")\",\n                            recordTooLargePartitions);\n                } else {\n                        \n                    throw new KafkaException(\"Failed to make progress reading messages at \" + tp + \"=\" +\n                        fetchOffset + \". Received a non-empty fetch response from the server, but no \" +\n                        \"complete records were found.\");\n                }\n            }\n\n            if (partition.highWatermark() >= 0) {\n                log.trace(\"Updating high watermark for partition {} to {}\", tp, partition.highWatermark());\n                subscriptions.updateHighWatermark(tp, partition.highWatermark());\n            }\n\n            if (partition.logStartOffset() >= 0) {\n                log.trace(\"Updating log start offset for partition {} to {}\", tp, partition.logStartOffset());\n                subscriptions.updateLogStartOffset(tp, partition.logStartOffset());\n            }\n\n            if (partition.lastStableOffset() >= 0) {\n                log.trace(\"Updating last stable offset for partition {} to {}\", tp, partition.lastStableOffset());\n                subscriptions.updateLastStableOffset(tp, partition.lastStableOffset());\n            }\n\n            if (FetchResponse.isPreferredReplica(partition)) {\n                subscriptions.updatePreferredReadReplica(completedFetch.partition, partition.preferredReadReplica(), () -> {\n                    long expireTimeMs = time.milliseconds() + metadata.metadataExpireMs();\n                    log.debug(\"Updating preferred read replica for partition {} to {}, set to expire at {}\",\n                            tp, partition.preferredReadReplica(), expireTimeMs);\n                    return expireTimeMs;\n                });\n            }\n\n            nextCompletedFetch.initialized = true;\n        } else if (error == Errors.NOT_LEADER_OR_FOLLOWER ||\n                   error == Errors.REPLICA_NOT_AVAILABLE ||\n                   error == Errors.KAFKA_STORAGE_ERROR ||\n                   error == Errors.FENCED_LEADER_EPOCH ||\n                   error == Errors.OFFSET_NOT_AVAILABLE) {\n            log.debug(\"Error in fetch for partition {}: {}\", tp, error.exceptionName());\n            this.metadata.requestUpdate();\n        } else if (error == Errors.UNKNOWN_TOPIC_OR_PARTITION) {\n            log.warn(\"Received unknown topic or partition error in fetch for partition {}\", tp);\n            this.metadata.requestUpdate();\n        } else if (error == Errors.UNKNOWN_TOPIC_ID) {\n            log.warn(\"Received unknown topic ID error in fetch for partition {}\", tp);\n            this.metadata.requestUpdate();\n        } else if (error == Errors.INCONSISTENT_TOPIC_ID) {\n            log.warn(\"Received inconsistent topic ID error in fetch for partition {}\", tp);\n            this.metadata.requestUpdate();\n        } else if (error == Errors.OFFSET_OUT_OF_RANGE) {\n            Optional<Integer> clearedReplicaId = subscriptions.clearPreferredReadReplica(tp);\n            if (!clearedReplicaId.isPresent()) {\n                    \n                FetchPosition position = subscriptions.position(tp);\n                if (position == null || fetchOffset != position.offset) {\n                    log.debug(\"Discarding stale fetch response for partition {} since the fetched offset {} \" +\n                            \"does not match the current offset {}\", tp, fetchOffset, position);\n                } else {\n                    handleOffsetOutOfRange(position, tp);\n                }\n            } else {\n                log.debug(\"Unset the preferred read replica {} for partition {} since we got {} when fetching {}\",\n                        clearedReplicaId.get(), tp, error, fetchOffset);\n            }\n        } else if (error == Errors.TOPIC_AUTHORIZATION_FAILED) {\n                \n            log.warn(\"Not authorized to read from partition {}.\", tp);\n            throw new TopicAuthorizationException(Collections.singleton(tp.topic()));\n        } else if (error == Errors.UNKNOWN_LEADER_EPOCH) {\n            log.debug(\"Received unknown leader epoch error in fetch for partition {}\", tp);\n        } else if (error == Errors.UNKNOWN_SERVER_ERROR) {\n            log.warn(\"Unknown server error while fetching offset {} for topic-partition {}\",\n                    fetchOffset, tp);\n        } else if (error == Errors.CORRUPT_MESSAGE) {\n            throw new KafkaException(\"Encountered corrupt message when fetching offset \"\n                    + fetchOffset\n                    + \" for topic-partition \"\n                    + tp);\n        } else {\n            throw new IllegalStateException(\"Unexpected error code \"\n                    + error.code()\n                    + \" while fetching at offset \"\n                    + fetchOffset\n                    + \" from topic-partition \" + tp);\n        }\n    } finally {\n        if (completedFetch == null)\n            nextCompletedFetch.metricAggregator.record(tp, 0, 0);\n\n        if (error != Errors.NONE)\n                \n                \n            subscriptions.movePartitionToEnd(tp);\n    }\n\n    return completedFetch;\n}",
        "summary_tokens": [
            "initialize",
            "a",
            "completed",
            "fetch",
            "object"
        ]
    },
    {
        "id": 504,
        "code": "private ConsumerRecord<K, V> parseRecord(TopicPartition partition,\n                                         RecordBatch batch,\n                                         Record record) {\n    try {\n        long offset = record.offset();\n        long timestamp = record.timestamp();\n        Optional<Integer> leaderEpoch = maybeLeaderEpoch(batch.partitionLeaderEpoch());\n        TimestampType timestampType = batch.timestampType();\n        Headers headers = new RecordHeaders(record.headers());\n        ByteBuffer keyBytes = record.key();\n        byte[] keyByteArray = keyBytes == null ? null : Utils.toArray(keyBytes);\n        K key = keyBytes == null ? null : this.keyDeserializer.deserialize(partition.topic(), headers, keyByteArray);\n        ByteBuffer valueBytes = record.value();\n        byte[] valueByteArray = valueBytes == null ? null : Utils.toArray(valueBytes);\n        V value = valueBytes == null ? null : this.valueDeserializer.deserialize(partition.topic(), headers, valueByteArray);\n        return new ConsumerRecord<>(partition.topic(), partition.partition(), offset,\n                                    timestamp, timestampType,\n                                    keyByteArray == null ? ConsumerRecord.NULL_SIZE : keyByteArray.length,\n                                    valueByteArray == null ? ConsumerRecord.NULL_SIZE : valueByteArray.length,\n                                    key, value, headers, leaderEpoch);\n    } catch (RuntimeException e) {\n        throw new RecordDeserializationException(partition, record.offset(),\n            \"Error deserializing key/value for partition \" + partition +\n                \" at offset \" + record.offset() + \". If needed, please seek past the record to continue consumption.\", e);\n    }\n}",
        "summary_tokens": [
            "parse",
            "the",
            "record",
            "entry",
            "deserializing",
            "the",
            "key",
            "value",
            "fields",
            "if",
            "necessary"
        ]
    },
    {
        "id": 505,
        "code": "public void clearBufferedDataForUnassignedPartitions(Collection<TopicPartition> assignedPartitions) {\n    Iterator<CompletedFetch> completedFetchesItr = completedFetches.iterator();\n    while (completedFetchesItr.hasNext()) {\n        CompletedFetch records = completedFetchesItr.next();\n        TopicPartition tp = records.partition;\n        if (!assignedPartitions.contains(tp)) {\n            records.drain();\n            completedFetchesItr.remove();\n        }\n    }\n\n    if (nextInLineFetch != null && !assignedPartitions.contains(nextInLineFetch.partition)) {\n        nextInLineFetch.drain();\n        nextInLineFetch = null;\n    }\n}",
        "summary_tokens": [
            "clear",
            "the",
            "buffered",
            "data",
            "which",
            "are",
            "not",
            "a",
            "part",
            "of",
            "newly",
            "assigned",
            "partitions"
        ]
    },
    {
        "id": 506,
        "code": "public void clearBufferedDataForUnassignedTopics(Collection<String> assignedTopics) {\n    Set<TopicPartition> currentTopicPartitions = new HashSet<>();\n    for (TopicPartition tp : subscriptions.assignedPartitions()) {\n        if (assignedTopics.contains(tp.topic())) {\n            currentTopicPartitions.add(tp);\n        }\n    }\n    clearBufferedDataForUnassignedPartitions(currentTopicPartitions);\n}",
        "summary_tokens": [
            "clear",
            "the",
            "buffered",
            "data",
            "which",
            "are",
            "not",
            "a",
            "part",
            "of",
            "newly",
            "assigned",
            "topics"
        ]
    },
    {
        "id": 507,
        "code": "public boolean isDone() {\n    return result.get() != INCOMPLETE_SENTINEL;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "response",
            "is",
            "ready",
            "to",
            "be",
            "handled",
            "true",
            "if",
            "the",
            "response",
            "is",
            "ready",
            "false",
            "otherwise"
        ]
    },
    {
        "id": 508,
        "code": "public T value() {\n    if (!succeeded())\n        throw new IllegalStateException(\"Attempt to retrieve value from future which hasn't successfully completed\");\n    return (T) result.get();\n}",
        "summary_tokens": [
            "get",
            "the",
            "value",
            "corresponding",
            "to",
            "this",
            "request",
            "only",
            "available",
            "if",
            "the",
            "request",
            "succeeded",
            "the",
            "value",
            "set",
            "in",
            "complete",
            "object",
            "illegal",
            "state",
            "exception",
            "if",
            "the",
            "future",
            "is",
            "not",
            "complete",
            "or",
            "failed"
        ]
    },
    {
        "id": 509,
        "code": "public boolean succeeded() {\n    return isDone() && !failed();\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "request",
            "succeeded",
            "true",
            "if",
            "the",
            "request",
            "completed",
            "and",
            "was",
            "successful"
        ]
    },
    {
        "id": 510,
        "code": "public boolean failed() {\n    return result.get() instanceof RuntimeException;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "request",
            "failed"
        ]
    },
    {
        "id": 511,
        "code": "public boolean isRetriable() {\n    return exception() instanceof RetriableException;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "request",
            "is",
            "retriable",
            "convenience",
            "method",
            "for",
            "checking",
            "if",
            "the",
            "exception",
            "is",
            "an",
            "instance",
            "of",
            "retriable",
            "exception"
        ]
    },
    {
        "id": 512,
        "code": "public RuntimeException exception() {\n    if (!failed())\n        throw new IllegalStateException(\"Attempt to retrieve exception from future which hasn't failed\");\n    return (RuntimeException) result.get();\n}",
        "summary_tokens": [
            "get",
            "the",
            "exception",
            "from",
            "a",
            "failed",
            "result",
            "only",
            "available",
            "if",
            "the",
            "request",
            "failed",
            "the",
            "exception",
            "set",
            "in",
            "raise",
            "runtime",
            "exception",
            "illegal",
            "state",
            "exception",
            "if",
            "the",
            "future",
            "is",
            "not",
            "complete",
            "or",
            "completed",
            "successfully"
        ]
    },
    {
        "id": 513,
        "code": "public void complete(T value) {\n    try {\n        if (value instanceof RuntimeException)\n            throw new IllegalArgumentException(\"The argument to complete can not be an instance of RuntimeException\");\n\n        if (!result.compareAndSet(INCOMPLETE_SENTINEL, value))\n            throw new IllegalStateException(\"Invalid attempt to complete a request future which is already complete\");\n        fireSuccess();\n    } finally {\n        completedLatch.countDown();\n    }\n}",
        "summary_tokens": [
            "complete",
            "the",
            "request",
            "successfully"
        ]
    },
    {
        "id": 514,
        "code": "public void addListener(RequestFutureListener<T> listener) {\n    this.listeners.add(listener);\n    if (failed())\n        fireFailure();\n    else if (succeeded())\n        fireSuccess();\n}",
        "summary_tokens": [
            "add",
            "a",
            "listener",
            "which",
            "will",
            "be",
            "notified",
            "when",
            "the",
            "future",
            "completes",
            "listener",
            "non",
            "null",
            "listener",
            "to",
            "add"
        ]
    },
    {
        "id": 515,
        "code": "public <S> RequestFuture<S> compose(final RequestFutureAdapter<T, S> adapter) {\n    final RequestFuture<S> adapted = new RequestFuture<>();\n    addListener(new RequestFutureListener<T>() {\n        @Override\n        public void onSuccess(T value) {\n            adapter.onSuccess(value, adapted);\n        }\n\n        @Override\n        public void onFailure(RuntimeException e) {\n            adapter.onFailure(e, adapted);\n        }\n    });\n    return adapted;\n}",
        "summary_tokens": [
            "convert",
            "from",
            "a",
            "request",
            "future",
            "of",
            "one",
            "type",
            "to",
            "another",
            "type",
            "adapter",
            "the",
            "adapter",
            "which",
            "does",
            "the",
            "conversion",
            "s",
            "the",
            "type",
            "of",
            "the",
            "future",
            "adapted",
            "to",
            "the",
            "new",
            "future"
        ]
    },
    {
        "id": 516,
        "code": "synchronized int assignmentId() {\n    return assignmentId;\n}",
        "summary_tokens": [
            "monotonically",
            "increasing",
            "id",
            "which",
            "is",
            "incremented",
            "after",
            "every",
            "assignment",
            "change"
        ]
    },
    {
        "id": 517,
        "code": "private void setSubscriptionType(SubscriptionType type) {\n    if (this.subscriptionType == SubscriptionType.NONE)\n        this.subscriptionType = type;\n    else if (this.subscriptionType != type)\n        throw new IllegalStateException(SUBSCRIPTION_EXCEPTION_MESSAGE);\n}",
        "summary_tokens": [
            "this",
            "method",
            "sets",
            "the",
            "subscription",
            "type",
            "if",
            "it",
            "is",
            "not",
            "already",
            "set",
            "i"
        ]
    },
    {
        "id": 518,
        "code": "synchronized boolean groupSubscribe(Collection<String> topics) {\n    if (!hasAutoAssignedPartitions())\n        throw new IllegalStateException(SUBSCRIPTION_EXCEPTION_MESSAGE);\n    groupSubscription = new HashSet<>(topics);\n    return !subscription.containsAll(groupSubscription);\n}",
        "summary_tokens": [
            "set",
            "the",
            "current",
            "group",
            "subscription"
        ]
    },
    {
        "id": 519,
        "code": "synchronized void resetGroupSubscription() {\n    groupSubscription = Collections.emptySet();\n}",
        "summary_tokens": [
            "reset",
            "the",
            "group",
            "s",
            "subscription",
            "to",
            "only",
            "contain",
            "topics",
            "subscribed",
            "by",
            "this",
            "consumer"
        ]
    },
    {
        "id": 520,
        "code": "public synchronized boolean assignFromUser(Set<TopicPartition> partitions) {\n    setSubscriptionType(SubscriptionType.USER_ASSIGNED);\n\n    if (this.assignment.partitionSet().equals(partitions))\n        return false;\n\n    assignmentId++;\n\n        \n    Set<String> manualSubscribedTopics = new HashSet<>();\n    Map<TopicPartition, TopicPartitionState> partitionToState = new HashMap<>();\n    for (TopicPartition partition : partitions) {\n        TopicPartitionState state = assignment.stateValue(partition);\n        if (state == null)\n            state = new TopicPartitionState();\n        partitionToState.put(partition, state);\n\n        manualSubscribedTopics.add(partition.topic());\n    }\n\n    this.assignment.set(partitionToState);\n    return changeSubscription(manualSubscribedTopics);\n}",
        "summary_tokens": [
            "change",
            "the",
            "assignment",
            "to",
            "the",
            "specified",
            "partitions",
            "provided",
            "by",
            "the",
            "user",
            "note",
            "this",
            "is",
            "different",
            "from",
            "assign",
            "from",
            "subscribed",
            "collection",
            "whose",
            "input",
            "partitions",
            "are",
            "provided",
            "from",
            "the",
            "subscribed",
            "topics"
        ]
    },
    {
        "id": 521,
        "code": "public synchronized boolean checkAssignmentMatchedSubscription(Collection<TopicPartition> assignments) {\n    for (TopicPartition topicPartition : assignments) {\n        if (this.subscribedPattern != null) {\n            if (!this.subscribedPattern.matcher(topicPartition.topic()).matches()) {\n                log.info(\"Assigned partition {} for non-subscribed topic regex pattern; subscription pattern is {}\",\n                    topicPartition,\n                    this.subscribedPattern);\n\n                return false;\n            }\n        } else {\n            if (!this.subscription.contains(topicPartition.topic())) {\n                log.info(\"Assigned partition {} for non-subscribed topic; subscription is {}\", topicPartition, this.subscription);\n\n                return false;\n            }\n        }\n    }\n\n    return true;\n}",
        "summary_tokens": [
            "true",
            "if",
            "assignments",
            "matches",
            "subscription",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 522,
        "code": "public synchronized void assignFromSubscribed(Collection<TopicPartition> assignments) {\n    if (!this.hasAutoAssignedPartitions())\n        throw new IllegalArgumentException(\"Attempt to dynamically assign partitions while manual assignment in use\");\n\n    Map<TopicPartition, TopicPartitionState> assignedPartitionStates = new HashMap<>(assignments.size());\n    for (TopicPartition tp : assignments) {\n        TopicPartitionState state = this.assignment.stateValue(tp);\n        if (state == null)\n            state = new TopicPartitionState();\n        assignedPartitionStates.put(tp, state);\n    }\n\n    assignmentId++;\n    this.assignment.set(assignedPartitionStates);\n}",
        "summary_tokens": [
            "change",
            "the",
            "assignment",
            "to",
            "the",
            "specified",
            "partitions",
            "returned",
            "from",
            "the",
            "coordinator",
            "note",
            "this",
            "is",
            "different",
            "from",
            "assign",
            "from",
            "user",
            "set",
            "which",
            "directly",
            "set",
            "the",
            "assignment",
            "from",
            "user",
            "inputs"
        ]
    },
    {
        "id": 523,
        "code": "synchronized boolean hasPatternSubscription() {\n    return this.subscriptionType == SubscriptionType.AUTO_PATTERN;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "pattern",
            "subscription",
            "is",
            "in",
            "use"
        ]
    },
    {
        "id": 524,
        "code": "synchronized boolean matchesSubscribedPattern(String topic) {\n    Pattern pattern = this.subscribedPattern;\n    if (hasPatternSubscription() && pattern != null)\n        return pattern.matcher(topic).matches();\n    return false;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "a",
            "topic",
            "matches",
            "a",
            "subscribed",
            "pattern"
        ]
    },
    {
        "id": 525,
        "code": "synchronized Set<String> metadataTopics() {\n    if (groupSubscription.isEmpty())\n        return subscription;\n    else if (groupSubscription.containsAll(subscription))\n        return groupSubscription;\n    else {\n            \n            \n        Set<String> topics = new HashSet<>(groupSubscription);\n        topics.addAll(subscription);\n        return topics;\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "subscription",
            "topics",
            "for",
            "which",
            "metadata",
            "is",
            "required"
        ]
    },
    {
        "id": 526,
        "code": "public synchronized Set<TopicPartition> assignedPartitions() {\n    return new HashSet<>(this.assignment.partitionSet());\n}",
        "summary_tokens": [
            "a",
            "modifiable",
            "copy",
            "of",
            "the",
            "currently",
            "assigned",
            "partitions"
        ]
    },
    {
        "id": 527,
        "code": "public synchronized List<TopicPartition> assignedPartitionsList() {\n    return new ArrayList<>(this.assignment.partitionSet());\n}",
        "summary_tokens": [
            "a",
            "modifiable",
            "copy",
            "of",
            "the",
            "currently",
            "assigned",
            "partitions",
            "as",
            "a",
            "list"
        ]
    },
    {
        "id": 528,
        "code": "synchronized int numAssignedPartitions() {\n    return this.assignment.size();\n}",
        "summary_tokens": [
            "provides",
            "the",
            "number",
            "of",
            "assigned",
            "partitions",
            "in",
            "a",
            "thread",
            "safe",
            "manner"
        ]
    },
    {
        "id": 529,
        "code": "public synchronized boolean maybeValidatePositionForCurrentLeader(ApiVersions apiVersions,\n                                                                  TopicPartition tp,\n                                                                  Metadata.LeaderAndEpoch leaderAndEpoch) {\n    if (leaderAndEpoch.leader.isPresent()) {\n        NodeApiVersions nodeApiVersions = apiVersions.get(leaderAndEpoch.leader.get().idString());\n        if (nodeApiVersions == null || hasUsableOffsetForLeaderEpochVersion(nodeApiVersions)) {\n            return assignedState(tp).maybeValidatePosition(leaderAndEpoch);\n        } else {\n                \n            assignedState(tp).updatePositionLeaderNoValidation(leaderAndEpoch);\n            return false;\n        }\n    } else {\n        return assignedState(tp).maybeValidatePosition(leaderAndEpoch);\n    }\n}",
        "summary_tokens": [
            "enter",
            "the",
            "offset",
            "validation",
            "state",
            "if",
            "the",
            "leader",
            "for",
            "this",
            "partition",
            "is",
            "known",
            "to",
            "support",
            "a",
            "usable",
            "version",
            "of",
            "the",
            "offsets",
            "for",
            "leader",
            "epoch",
            "api"
        ]
    },
    {
        "id": 530,
        "code": "public synchronized Optional<LogTruncation> maybeCompleteValidation(TopicPartition tp,\n                                                                    FetchPosition requestPosition,\n                                                                    EpochEndOffset epochEndOffset) {\n    TopicPartitionState state = assignedStateOrNull(tp);\n    if (state == null) {\n        log.debug(\"Skipping completed validation for partition {} which is not currently assigned.\", tp);\n    } else if (!state.awaitingValidation()) {\n        log.debug(\"Skipping completed validation for partition {} which is no longer expecting validation.\", tp);\n    } else {\n        SubscriptionState.FetchPosition currentPosition = state.position;\n        if (!currentPosition.equals(requestPosition)) {\n            log.debug(\"Skipping completed validation for partition {} since the current position {} \" +\n                      \"no longer matches the position {} when the request was sent\",\n                      tp, currentPosition, requestPosition);\n        } else if (epochEndOffset.endOffset() == UNDEFINED_EPOCH_OFFSET ||\n                    epochEndOffset.leaderEpoch() == UNDEFINED_EPOCH) {\n            if (hasDefaultOffsetResetPolicy()) {\n                log.info(\"Truncation detected for partition {} at offset {}, resetting offset\",\n                         tp, currentPosition);\n                requestOffsetReset(tp);\n            } else {\n                log.warn(\"Truncation detected for partition {} at offset {}, but no reset policy is set\",\n                         tp, currentPosition);\n                return Optional.of(new LogTruncation(tp, requestPosition, Optional.empty()));\n            }\n        } else if (epochEndOffset.endOffset() < currentPosition.offset) {\n            if (hasDefaultOffsetResetPolicy()) {\n                SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                        epochEndOffset.endOffset(), Optional.of(epochEndOffset.leaderEpoch()),\n                        currentPosition.currentLeader);\n                log.info(\"Truncation detected for partition {} at offset {}, resetting offset to \" +\n                         \"the first offset known to diverge {}\", tp, currentPosition, newPosition);\n                state.seekValidated(newPosition);\n            } else {\n                OffsetAndMetadata divergentOffset = new OffsetAndMetadata(epochEndOffset.endOffset(),\n                    Optional.of(epochEndOffset.leaderEpoch()), null);\n                log.warn(\"Truncation detected for partition {} at offset {} (the end offset from the \" +\n                         \"broker is {}), but no reset policy is set\", tp, currentPosition, divergentOffset);\n                return Optional.of(new LogTruncation(tp, requestPosition, Optional.of(divergentOffset)));\n            }\n        } else {\n            state.completeValidation();\n        }\n    }\n\n    return Optional.empty();\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "complete",
            "validation",
            "with",
            "the",
            "end",
            "offset",
            "returned",
            "from",
            "the",
            "offset",
            "for",
            "leader",
            "epoch",
            "request"
        ]
    },
    {
        "id": 531,
        "code": "public synchronized void updatePreferredReadReplica(TopicPartition tp, int preferredReadReplicaId, LongSupplier timeMs) {\n    assignedState(tp).updatePreferredReadReplica(preferredReadReplicaId, timeMs);\n}",
        "summary_tokens": [
            "set",
            "the",
            "preferred",
            "read",
            "replica",
            "with",
            "a",
            "lease",
            "timeout"
        ]
    },
    {
        "id": 532,
        "code": "public synchronized Optional<Integer> preferredReadReplica(TopicPartition tp, long timeMs) {\n    final TopicPartitionState topicPartitionState = assignedStateOrNull(tp);\n    if (topicPartitionState == null) {\n        return Optional.empty();\n    } else {\n        return topicPartitionState.preferredReadReplica(timeMs);\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "preferred",
            "read",
            "replica"
        ]
    },
    {
        "id": 533,
        "code": "public synchronized Optional<Integer> clearPreferredReadReplica(TopicPartition tp) {\n    return assignedState(tp).clearPreferredReadReplica();\n}",
        "summary_tokens": [
            "unset",
            "the",
            "preferred",
            "read",
            "replica"
        ]
    },
    {
        "id": 534,
        "code": "private void warnIfPartitionerDeprecated() {\n        \n    if (partitioner instanceof org.apache.kafka.clients.producer.internals.DefaultPartitioner) {\n        log.warn(\"DefaultPartitioner is deprecated.  Please clear \" + ProducerConfig.PARTITIONER_CLASS_CONFIG\n                + \" configuration setting to get the default partitioning behavior\");\n    }\n    if (partitioner instanceof org.apache.kafka.clients.producer.UniformStickyPartitioner) {\n        log.warn(\"UniformStickyPartitioner is deprecated.  Please clear \" + ProducerConfig.PARTITIONER_CLASS_CONFIG\n                + \" configuration setting and set \" + ProducerConfig.PARTITIONER_IGNORE_KEYS_CONFIG\n                + \" to 'true' to get the uniform sticky partitioning behavior\");\n    }\n}",
        "summary_tokens": [
            "check",
            "if",
            "partitioner",
            "is",
            "deprecated",
            "and",
            "log",
            "a",
            "warning",
            "if",
            "it",
            "is"
        ]
    },
    {
        "id": 535,
        "code": "public void initTransactions() {\n    throwIfNoTransactionManager();\n    throwIfProducerClosed();\n    long now = time.nanoseconds();\n    TransactionalRequestResult result = transactionManager.initializeTransactions();\n    sender.wakeup();\n    result.await(maxBlockTimeMs, TimeUnit.MILLISECONDS);\n    producerMetrics.recordInit(time.nanoseconds() - now);\n}",
        "summary_tokens": [
            "needs",
            "to",
            "be",
            "called",
            "before",
            "any",
            "other",
            "methods",
            "when",
            "the",
            "transactional"
        ]
    },
    {
        "id": 536,
        "code": "public void beginTransaction() throws ProducerFencedException {\n    throwIfNoTransactionManager();\n    throwIfProducerClosed();\n    long now = time.nanoseconds();\n    transactionManager.beginTransaction();\n    producerMetrics.recordBeginTxn(time.nanoseconds() - now);\n}",
        "summary_tokens": [
            "should",
            "be",
            "called",
            "before",
            "the",
            "start",
            "of",
            "each",
            "new",
            "transaction"
        ]
    },
    {
        "id": 537,
        "code": "public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets,\n                                     ConsumerGroupMetadata groupMetadata) throws ProducerFencedException {\n    throwIfInvalidGroupMetadata(groupMetadata);\n    throwIfNoTransactionManager();\n    throwIfProducerClosed();\n\n    if (!offsets.isEmpty()) {\n        long start = time.nanoseconds();\n        TransactionalRequestResult result = transactionManager.sendOffsetsToTransaction(offsets, groupMetadata);\n        sender.wakeup();\n        result.await(maxBlockTimeMs, TimeUnit.MILLISECONDS);\n        producerMetrics.recordSendOffsets(time.nanoseconds() - start);\n    }\n}",
        "summary_tokens": [
            "sends",
            "a",
            "list",
            "of",
            "specified",
            "offsets",
            "to",
            "the",
            "consumer",
            "group",
            "coordinator",
            "and",
            "also",
            "marks",
            "those",
            "offsets",
            "as",
            "part",
            "of",
            "the",
            "current",
            "transaction"
        ]
    },
    {
        "id": 538,
        "code": "public void commitTransaction() throws ProducerFencedException {\n    throwIfNoTransactionManager();\n    throwIfProducerClosed();\n    long commitStart = time.nanoseconds();\n    TransactionalRequestResult result = transactionManager.beginCommit();\n    sender.wakeup();\n    result.await(maxBlockTimeMs, TimeUnit.MILLISECONDS);\n    producerMetrics.recordCommitTxn(time.nanoseconds() - commitStart);\n}",
        "summary_tokens": [
            "commits",
            "the",
            "ongoing",
            "transaction"
        ]
    },
    {
        "id": 539,
        "code": "public void abortTransaction() throws ProducerFencedException {\n    throwIfNoTransactionManager();\n    throwIfProducerClosed();\n    log.info(\"Aborting incomplete transaction\");\n    long abortStart = time.nanoseconds();\n    TransactionalRequestResult result = transactionManager.beginAbort();\n    sender.wakeup();\n    result.await(maxBlockTimeMs, TimeUnit.MILLISECONDS);\n    producerMetrics.recordAbortTxn(time.nanoseconds() - abortStart);\n}",
        "summary_tokens": [
            "aborts",
            "the",
            "ongoing",
            "transaction"
        ]
    },
    {
        "id": 540,
        "code": "public Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) {\n        \n    ProducerRecord<K, V> interceptedRecord = this.interceptors.onSend(record);\n    return doSend(interceptedRecord, callback);\n}",
        "summary_tokens": [
            "asynchronously",
            "send",
            "a",
            "record",
            "to",
            "a",
            "topic",
            "and",
            "invoke",
            "the",
            "provided",
            "callback",
            "when",
            "the",
            "send",
            "has",
            "been",
            "acknowledged"
        ]
    },
    {
        "id": 541,
        "code": "private void onNewBatch(String topic, Cluster cluster, int prevPartition) {\n    assert partitioner != null;\n    partitioner.onNewBatch(topic, cluster, prevPartition);\n}",
        "summary_tokens": [
            "call",
            "deprecated",
            "partitioner",
            "on",
            "new",
            "batch"
        ]
    },
    {
        "id": 542,
        "code": "private Future<RecordMetadata> doSend(ProducerRecord<K, V> record, Callback callback) {\n        \n        \n        \n    AppendCallbacks<K, V> appendCallbacks = new AppendCallbacks<K, V>(callback, this.interceptors, record);\n\n    try {\n        throwIfProducerClosed();\n            \n        long nowMs = time.milliseconds();\n        ClusterAndWaitTime clusterAndWaitTime;\n        try {\n            clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), nowMs, maxBlockTimeMs);\n        } catch (KafkaException e) {\n            if (metadata.isClosed())\n                throw new KafkaException(\"Producer closed while send in progress\", e);\n            throw e;\n        }\n        nowMs += clusterAndWaitTime.waitedOnMetadataMs;\n        long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);\n        Cluster cluster = clusterAndWaitTime.cluster;\n        byte[] serializedKey;\n        try {\n            serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());\n        } catch (ClassCastException cce) {\n            throw new SerializationException(\"Can't convert key of class \" + record.key().getClass().getName() +\n                    \" to class \" + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +\n                    \" specified in key.serializer\", cce);\n        }\n        byte[] serializedValue;\n        try {\n            serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());\n        } catch (ClassCastException cce) {\n            throw new SerializationException(\"Can't convert value of class \" + record.value().getClass().getName() +\n                    \" to class \" + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +\n                    \" specified in value.serializer\", cce);\n        }\n\n            \n            \n            \n        int partition = partition(record, serializedKey, serializedValue, cluster);\n\n        setReadOnly(record.headers());\n        Header[] headers = record.headers().toArray();\n\n        int serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),\n                compressionType, serializedKey, serializedValue, headers);\n        ensureValidRecordSize(serializedSize);\n        long timestamp = record.timestamp() == null ? nowMs : record.timestamp();\n\n            \n        boolean abortOnNewBatch = partitioner != null;\n\n            \n            \n        RecordAccumulator.RecordAppendResult result = accumulator.append(record.topic(), partition, timestamp, serializedKey,\n                serializedValue, headers, appendCallbacks, remainingWaitMs, abortOnNewBatch, nowMs, cluster);\n        assert appendCallbacks.getPartition() != RecordMetadata.UNKNOWN_PARTITION;\n\n        if (result.abortForNewBatch) {\n            int prevPartition = partition;\n            onNewBatch(record.topic(), cluster, prevPartition);\n            partition = partition(record, serializedKey, serializedValue, cluster);\n            if (log.isTraceEnabled()) {\n                log.trace(\"Retrying append due to new batch creation for topic {} partition {}. The old partition was {}\", record.topic(), partition, prevPartition);\n            }\n            result = accumulator.append(record.topic(), partition, timestamp, serializedKey,\n                serializedValue, headers, appendCallbacks, remainingWaitMs, false, nowMs, cluster);\n        }\n\n            \n            \n            \n            \n            \n        if (transactionManager != null) {\n            transactionManager.maybeAddPartition(appendCallbacks.topicPartition());\n        }\n\n        if (result.batchIsFull || result.newBatchCreated) {\n            log.trace(\"Waking up the sender since topic {} partition {} is either full or getting a new batch\", record.topic(), appendCallbacks.getPartition());\n            this.sender.wakeup();\n        }\n        return result.future;\n            \n            \n            \n    } catch (ApiException e) {\n        log.debug(\"Exception occurred during message send:\", e);\n        if (callback != null) {\n            TopicPartition tp = appendCallbacks.topicPartition();\n            RecordMetadata nullMetadata = new RecordMetadata(tp, -1, -1, RecordBatch.NO_TIMESTAMP, -1, -1);\n            callback.onCompletion(nullMetadata, e);\n        }\n        this.errors.record();\n        this.interceptors.onSendError(record, appendCallbacks.topicPartition(), e);\n        if (transactionManager != null) {\n            transactionManager.maybeTransitionToErrorState(e);\n        }\n        return new FutureFailure(e);\n    } catch (InterruptedException e) {\n        this.errors.record();\n        this.interceptors.onSendError(record, appendCallbacks.topicPartition(), e);\n        throw new InterruptException(e);\n    } catch (KafkaException e) {\n        this.errors.record();\n        this.interceptors.onSendError(record, appendCallbacks.topicPartition(), e);\n        throw e;\n    } catch (Exception e) {\n            \n        this.interceptors.onSendError(record, appendCallbacks.topicPartition(), e);\n        throw e;\n    }\n}",
        "summary_tokens": [
            "implementation",
            "of",
            "asynchronously",
            "send",
            "a",
            "record",
            "to",
            "a",
            "topic"
        ]
    },
    {
        "id": 543,
        "code": "private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long nowMs, long maxWaitMs) throws InterruptedException {\n        \n    Cluster cluster = metadata.fetch();\n\n    if (cluster.invalidTopics().contains(topic))\n        throw new InvalidTopicException(topic);\n\n    metadata.add(topic, nowMs);\n\n    Integer partitionsCount = cluster.partitionCountForTopic(topic);\n        \n        \n    if (partitionsCount != null && (partition == null || partition < partitionsCount))\n        return new ClusterAndWaitTime(cluster, 0);\n\n    long remainingWaitMs = maxWaitMs;\n    long elapsed = 0;\n        \n        \n        \n    long nowNanos = time.nanoseconds();\n    do {\n        if (partition != null) {\n            log.trace(\"Requesting metadata update for partition {} of topic {}.\", partition, topic);\n        } else {\n            log.trace(\"Requesting metadata update for topic {}.\", topic);\n        }\n        metadata.add(topic, nowMs + elapsed);\n        int version = metadata.requestUpdateForTopic(topic);\n        sender.wakeup();\n        try {\n            metadata.awaitUpdate(version, remainingWaitMs);\n        } catch (TimeoutException ex) {\n                \n            throw new TimeoutException(\n                    String.format(\"Topic %s not present in metadata after %d ms.\",\n                            topic, maxWaitMs));\n        }\n        cluster = metadata.fetch();\n        elapsed = time.milliseconds() - nowMs;\n        if (elapsed >= maxWaitMs) {\n            throw new TimeoutException(partitionsCount == null ?\n                    String.format(\"Topic %s not present in metadata after %d ms.\",\n                            topic, maxWaitMs) :\n                    String.format(\"Partition %d of topic %s with partition count %d is not present in metadata after %d ms.\",\n                            partition, topic, partitionsCount, maxWaitMs));\n        }\n        metadata.maybeThrowExceptionForTopic(topic);\n        remainingWaitMs = maxWaitMs - elapsed;\n        partitionsCount = cluster.partitionCountForTopic(topic);\n    } while (partitionsCount == null || (partition != null && partition >= partitionsCount));\n\n    producerMetrics.recordMetadataWait(time.nanoseconds() - nowNanos);\n\n    return new ClusterAndWaitTime(cluster, elapsed);\n}",
        "summary_tokens": [
            "wait",
            "for",
            "cluster",
            "metadata",
            "including",
            "partitions",
            "for",
            "the",
            "given",
            "topic",
            "to",
            "be",
            "available"
        ]
    },
    {
        "id": 544,
        "code": "private void ensureValidRecordSize(int size) {\n    if (size > maxRequestSize)\n        throw new RecordTooLargeException(\"The message is \" + size +\n                \" bytes when serialized which is larger than \" + maxRequestSize + \", which is the value of the \" +\n                ProducerConfig.MAX_REQUEST_SIZE_CONFIG + \" configuration.\");\n    if (size > totalMemorySize)\n        throw new RecordTooLargeException(\"The message is \" + size +\n                \" bytes when serialized which is larger than the total memory buffer you have configured with the \" +\n                ProducerConfig.BUFFER_MEMORY_CONFIG +\n                \" configuration.\");\n}",
        "summary_tokens": [
            "validate",
            "that",
            "the",
            "record",
            "size",
            "isn",
            "t",
            "too",
            "large"
        ]
    },
    {
        "id": 545,
        "code": "public void flush() {\n    log.trace(\"Flushing accumulated records in producer.\");\n\n    long start = time.nanoseconds();\n    this.accumulator.beginFlush();\n    this.sender.wakeup();\n    try {\n        this.accumulator.awaitFlushCompletion();\n    } catch (InterruptedException e) {\n        throw new InterruptException(\"Flush interrupted.\", e);\n    } finally {\n        producerMetrics.recordFlush(time.nanoseconds() - start);\n    }\n}",
        "summary_tokens": [
            "invoking",
            "this",
            "method",
            "makes",
            "all",
            "buffered",
            "records",
            "immediately",
            "available",
            "to",
            "send",
            "even",
            "if",
            "code",
            "linger"
        ]
    },
    {
        "id": 546,
        "code": "public List<PartitionInfo> partitionsFor(String topic) {\n    Objects.requireNonNull(topic, \"topic cannot be null\");\n    try {\n        return waitOnMetadata(topic, null, time.milliseconds(), maxBlockTimeMs).cluster.partitionsForTopic(topic);\n    } catch (InterruptedException e) {\n        throw new InterruptException(e);\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "partition",
            "metadata",
            "for",
            "the",
            "given",
            "topic"
        ]
    },
    {
        "id": 547,
        "code": "public Map<MetricName, ? extends Metric> metrics() {\n    return Collections.unmodifiableMap(this.metrics.metrics());\n}",
        "summary_tokens": [
            "get",
            "the",
            "full",
            "set",
            "of",
            "internal",
            "metrics",
            "maintained",
            "by",
            "the",
            "producer"
        ]
    },
    {
        "id": 548,
        "code": "public void close(Duration timeout) {\n    close(timeout, false);\n}",
        "summary_tokens": [
            "this",
            "method",
            "waits",
            "up",
            "to",
            "code",
            "timeout",
            "code",
            "for",
            "the",
            "producer",
            "to",
            "complete",
            "the",
            "sending",
            "of",
            "all",
            "incomplete",
            "requests"
        ]
    },
    {
        "id": 549,
        "code": "private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {\n    if (record.partition() != null)\n        return record.partition();\n\n    if (partitioner != null) {\n        int customPartition = partitioner.partition(\n            record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n        if (customPartition < 0) {\n            throw new IllegalArgumentException(String.format(\n                \"The partitioner generated an invalid partition number: %d. Partition number should always be non-negative.\", customPartition));\n        }\n        return customPartition;\n    }\n\n    if (serializedKey != null && !partitionerIgnoreKeys) {\n            \n        return BuiltInPartitioner.partitionForKey(serializedKey, cluster.partitionsForTopic(record.topic()).size());\n    } else {\n        return RecordMetadata.UNKNOWN_PARTITION;\n    }\n}",
        "summary_tokens": [
            "computes",
            "partition",
            "for",
            "given",
            "record"
        ]
    },
    {
        "id": 550,
        "code": "public synchronized Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) {\n    if (this.closed) {\n        throw new IllegalStateException(\"MockProducer is already closed.\");\n    }\n\n    if (this.producerFenced) {\n        throw new KafkaException(\"MockProducer is fenced.\", new ProducerFencedException(\"Fenced\"));\n    }\n    if (this.sendException != null) {\n        throw this.sendException;\n    }\n\n    int partition = 0;\n    if (!this.cluster.partitionsForTopic(record.topic()).isEmpty())\n        partition = partition(record, this.cluster);\n    else {\n            \n        keySerializer.serialize(record.topic(), record.key());\n        valueSerializer.serialize(record.topic(), record.value());\n    }\n            \n    TopicPartition topicPartition = new TopicPartition(record.topic(), partition);\n    ProduceRequestResult result = new ProduceRequestResult(topicPartition);\n    FutureRecordMetadata future = new FutureRecordMetadata(result, 0, RecordBatch.NO_TIMESTAMP,\n            0, 0, Time.SYSTEM);\n    long offset = nextOffset(topicPartition);\n    long baseOffset = Math.max(0, offset - Integer.MAX_VALUE);\n    int batchIndex = (int) Math.min(Integer.MAX_VALUE, offset);\n    Completion completion = new Completion(offset, new RecordMetadata(topicPartition, baseOffset, batchIndex,\n            RecordBatch.NO_TIMESTAMP, 0, 0), result, callback, topicPartition);\n\n    if (!this.transactionInFlight)\n        this.sent.add(record);\n    else\n        this.uncommittedSends.add(record);\n\n    if (autoComplete)\n        completion.complete(null);\n    else\n        this.completions.addLast(completion);\n\n    return future;\n}",
        "summary_tokens": [
            "adds",
            "the",
            "record",
            "to",
            "the",
            "list",
            "of",
            "sent",
            "records"
        ]
    },
    {
        "id": 551,
        "code": "private long nextOffset(TopicPartition tp) {\n    Long offset = this.offsets.get(tp);\n    if (offset == null) {\n        this.offsets.put(tp, 1L);\n        return 0L;\n    } else {\n        Long next = offset + 1;\n        this.offsets.put(tp, next);\n        return offset;\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "next",
            "offset",
            "for",
            "this",
            "topic",
            "partition"
        ]
    },
    {
        "id": 552,
        "code": "public void setMockMetrics(MetricName name, Metric metric) {\n    mockMetrics.put(name, metric);\n}",
        "summary_tokens": [
            "set",
            "a",
            "mock",
            "metric",
            "for",
            "testing",
            "purpose"
        ]
    },
    {
        "id": 553,
        "code": "public synchronized List<ProducerRecord<K, V>> history() {\n    return new ArrayList<>(this.sent);\n}",
        "summary_tokens": [
            "get",
            "the",
            "list",
            "of",
            "sent",
            "records",
            "since",
            "the",
            "last",
            "call",
            "to",
            "clear"
        ]
    },
    {
        "id": 554,
        "code": "public synchronized List<Map<String, Map<TopicPartition, OffsetAndMetadata>>> consumerGroupOffsetsHistory() {\n    return new ArrayList<>(this.consumerGroupOffsets);\n}",
        "summary_tokens": [
            "get",
            "the",
            "list",
            "of",
            "committed",
            "consumer",
            "group",
            "offsets",
            "since",
            "the",
            "last",
            "call",
            "to",
            "clear"
        ]
    },
    {
        "id": 555,
        "code": "public synchronized void clear() {\n    this.sent.clear();\n    this.uncommittedSends.clear();\n    this.sentOffsets = false;\n    this.completions.clear();\n    this.consumerGroupOffsets.clear();\n    this.uncommittedConsumerGroupOffsets.clear();\n}",
        "summary_tokens": [
            "clear",
            "the",
            "stored",
            "history",
            "of",
            "sent",
            "records",
            "consumer",
            "group",
            "offsets"
        ]
    },
    {
        "id": 556,
        "code": "public synchronized boolean completeNext() {\n    return errorNext(null);\n}",
        "summary_tokens": [
            "complete",
            "the",
            "earliest",
            "uncompleted",
            "call",
            "successfully"
        ]
    },
    {
        "id": 557,
        "code": "public synchronized boolean errorNext(RuntimeException e) {\n    Completion completion = this.completions.pollFirst();\n    if (completion != null) {\n        completion.complete(e);\n        return true;\n    } else {\n        return false;\n    }\n}",
        "summary_tokens": [
            "complete",
            "the",
            "earliest",
            "uncompleted",
            "call",
            "with",
            "the",
            "given",
            "error"
        ]
    },
    {
        "id": 558,
        "code": "private int partition(ProducerRecord<K, V> record, Cluster cluster) {\n    Integer partition = record.partition();\n    String topic = record.topic();\n    if (partition != null) {\n        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\n        int numPartitions = partitions.size();\n            \n        if (partition < 0 || partition >= numPartitions)\n            throw new IllegalArgumentException(\"Invalid partition given with record: \" + partition\n                                               + \" is not in the range [0...\"\n                                               + numPartitions\n                                               + \"].\");\n        return partition;\n    }\n    byte[] keyBytes = keySerializer.serialize(topic, record.headers(), record.key());\n    byte[] valueBytes = valueSerializer.serialize(topic, record.headers(), record.value());\n    return this.partitioner.partition(topic, record.key(), keyBytes, record.value(), valueBytes, cluster);\n}",
        "summary_tokens": [
            "computes",
            "partition",
            "for",
            "given",
            "record"
        ]
    },
    {
        "id": 559,
        "code": "default void onNewBatch(String topic, Cluster cluster, int prevPartition) {\n}",
        "summary_tokens": [
            "note",
            "this",
            "method",
            "is",
            "only",
            "implemented",
            "in",
            "defatult",
            "partitioner",
            "and",
            "uniform",
            "sticky",
            "partitioner",
            "which",
            "are",
            "now",
            "deprecated"
        ]
    },
    {
        "id": 560,
        "code": "public String topic() {\n    return topic;\n}",
        "summary_tokens": [
            "the",
            "topic",
            "this",
            "record",
            "is",
            "being",
            "sent",
            "to"
        ]
    },
    {
        "id": 561,
        "code": "public K key() {\n    return key;\n}",
        "summary_tokens": [
            "the",
            "key",
            "or",
            "null",
            "if",
            "no",
            "key",
            "is",
            "specified"
        ]
    },
    {
        "id": 562,
        "code": "public Long timestamp() {\n    return timestamp;\n}",
        "summary_tokens": [
            "the",
            "timestamp",
            "which",
            "is",
            "in",
            "milliseconds",
            "since",
            "epoch"
        ]
    },
    {
        "id": 563,
        "code": "public Integer partition() {\n    return partition;\n}",
        "summary_tokens": [
            "the",
            "partition",
            "to",
            "which",
            "the",
            "record",
            "will",
            "be",
            "sent",
            "or",
            "null",
            "if",
            "no",
            "partition",
            "was",
            "specified"
        ]
    },
    {
        "id": 564,
        "code": "public boolean hasOffset() {\n    return this.offset != ProduceResponse.INVALID_OFFSET;\n}",
        "summary_tokens": [
            "indicates",
            "whether",
            "the",
            "record",
            "metadata",
            "includes",
            "the",
            "offset"
        ]
    },
    {
        "id": 565,
        "code": "public long offset() {\n    return this.offset;\n}",
        "summary_tokens": [
            "the",
            "offset",
            "of",
            "the",
            "record",
            "in",
            "the",
            "topic",
            "partition"
        ]
    },
    {
        "id": 566,
        "code": "public boolean hasTimestamp() {\n    return this.timestamp != RecordBatch.NO_TIMESTAMP;\n}",
        "summary_tokens": [
            "indicates",
            "whether",
            "the",
            "record",
            "metadata",
            "includes",
            "the",
            "timestamp"
        ]
    },
    {
        "id": 567,
        "code": "public long timestamp() {\n    return this.timestamp;\n}",
        "summary_tokens": [
            "the",
            "timestamp",
            "of",
            "the",
            "record",
            "in",
            "the",
            "topic",
            "partition"
        ]
    },
    {
        "id": 568,
        "code": "public int serializedKeySize() {\n    return this.serializedKeySize;\n}",
        "summary_tokens": [
            "the",
            "size",
            "of",
            "the",
            "serialized",
            "uncompressed",
            "key",
            "in",
            "bytes"
        ]
    },
    {
        "id": 569,
        "code": "public int serializedValueSize() {\n    return this.serializedValueSize;\n}",
        "summary_tokens": [
            "the",
            "size",
            "of",
            "the",
            "serialized",
            "uncompressed",
            "value",
            "in",
            "bytes"
        ]
    },
    {
        "id": 570,
        "code": "public String topic() {\n    return this.topicPartition.topic();\n}",
        "summary_tokens": [
            "the",
            "topic",
            "the",
            "record",
            "was",
            "appended",
            "to"
        ]
    },
    {
        "id": 571,
        "code": "public int partition() {\n    return this.topicPartition.partition();\n}",
        "summary_tokens": [
            "the",
            "partition",
            "the",
            "record",
            "was",
            "sent",
            "to"
        ]
    },
    {
        "id": 572,
        "code": "public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\n    int numPartitions = partitions.size();\n    int nextValue = nextValue(topic);\n    List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);\n    if (!availablePartitions.isEmpty()) {\n        int part = Utils.toPositive(nextValue) % availablePartitions.size();\n        return availablePartitions.get(part).partition();\n    } else {\n            \n        return Utils.toPositive(nextValue) % numPartitions;\n    }\n}",
        "summary_tokens": [
            "compute",
            "the",
            "partition",
            "for",
            "the",
            "given",
            "record"
        ]
    },
    {
        "id": 573,
        "code": "public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n    return stickyPartitionCache.partition(topic, cluster);\n}",
        "summary_tokens": [
            "compute",
            "the",
            "partition",
            "for",
            "the",
            "given",
            "record"
        ]
    },
    {
        "id": 574,
        "code": "public void onNewBatch(String topic, Cluster cluster, int prevPartition) {\n    stickyPartitionCache.nextPartition(topic, cluster, prevPartition);\n}",
        "summary_tokens": [
            "if",
            "a",
            "batch",
            "completed",
            "for",
            "the",
            "current",
            "sticky",
            "partition",
            "change",
            "the",
            "sticky",
            "partition"
        ]
    },
    {
        "id": 575,
        "code": "public ByteBuffer allocate(int size, long maxTimeToBlockMs) throws InterruptedException {\n    if (size > this.totalMemory)\n        throw new IllegalArgumentException(\"Attempt to allocate \" + size\n                                           + \" bytes, but there is a hard limit of \"\n                                           + this.totalMemory\n                                           + \" on memory allocations.\");\n\n    ByteBuffer buffer = null;\n    this.lock.lock();\n\n    if (this.closed) {\n        this.lock.unlock();\n        throw new KafkaException(\"Producer closed while allocating memory\");\n    }\n\n    try {\n            \n        if (size == poolableSize && !this.free.isEmpty())\n            return this.free.pollFirst();\n\n            \n            \n        int freeListSize = freeSize() * this.poolableSize;\n        if (this.nonPooledAvailableMemory + freeListSize >= size) {\n                \n                \n            freeUp(size);\n            this.nonPooledAvailableMemory -= size;\n        } else {\n                \n            int accumulated = 0;\n            Condition moreMemory = this.lock.newCondition();\n            try {\n                long remainingTimeToBlockNs = TimeUnit.MILLISECONDS.toNanos(maxTimeToBlockMs);\n                this.waiters.addLast(moreMemory);\n                    \n                    \n                while (accumulated < size) {\n                    long startWaitNs = time.nanoseconds();\n                    long timeNs;\n                    boolean waitingTimeElapsed;\n                    try {\n                        waitingTimeElapsed = !moreMemory.await(remainingTimeToBlockNs, TimeUnit.NANOSECONDS);\n                    } finally {\n                        long endWaitNs = time.nanoseconds();\n                        timeNs = Math.max(0L, endWaitNs - startWaitNs);\n                        recordWaitTime(timeNs);\n                    }\n\n                    if (this.closed)\n                        throw new KafkaException(\"Producer closed while allocating memory\");\n\n                    if (waitingTimeElapsed) {\n                        this.metrics.sensor(\"buffer-exhausted-records\").record();\n                        throw new BufferExhaustedException(\"Failed to allocate \" + size + \" bytes within the configured max blocking time \"\n                            + maxTimeToBlockMs + \" ms. Total memory: \" + totalMemory() + \" bytes. Available memory: \" + availableMemory()\n                            + \" bytes. Poolable size: \" + poolableSize() + \" bytes\");\n                    }\n\n                    remainingTimeToBlockNs -= timeNs;\n\n                        \n                        \n                    if (accumulated == 0 && size == this.poolableSize && !this.free.isEmpty()) {\n                            \n                        buffer = this.free.pollFirst();\n                        accumulated = size;\n                    } else {\n                            \n                            \n                        freeUp(size - accumulated);\n                        int got = (int) Math.min(size - accumulated, this.nonPooledAvailableMemory);\n                        this.nonPooledAvailableMemory -= got;\n                        accumulated += got;\n                    }\n                }\n                    \n                accumulated = 0;\n            } finally {\n                    \n                this.nonPooledAvailableMemory += accumulated;\n                this.waiters.remove(moreMemory);\n            }\n        }\n    } finally {\n            \n            \n        try {\n            if (!(this.nonPooledAvailableMemory == 0 && this.free.isEmpty()) && !this.waiters.isEmpty())\n                this.waiters.peekFirst().signal();\n        } finally {\n                \n            lock.unlock();\n        }\n    }\n\n    if (buffer == null)\n        return safeAllocateByteBuffer(size);\n    else\n        return buffer;\n}",
        "summary_tokens": [
            "allocate",
            "a",
            "buffer",
            "of",
            "the",
            "given",
            "size"
        ]
    },
    {
        "id": 576,
        "code": "private void freeUp(int size) {\n    while (!this.free.isEmpty() && this.nonPooledAvailableMemory < size)\n        this.nonPooledAvailableMemory += this.free.pollLast().capacity();\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "ensure",
            "we",
            "have",
            "at",
            "least",
            "the",
            "requested",
            "number",
            "of",
            "bytes",
            "of",
            "memory",
            "for",
            "allocation",
            "by",
            "deallocating",
            "pooled",
            "buffers",
            "if",
            "needed"
        ]
    },
    {
        "id": 577,
        "code": "public void deallocate(ByteBuffer buffer, int size) {\n    lock.lock();\n    try {\n        if (size == this.poolableSize && size == buffer.capacity()) {\n            buffer.clear();\n            this.free.add(buffer);\n        } else {\n            this.nonPooledAvailableMemory += size;\n        }\n        Condition moreMem = this.waiters.peekFirst();\n        if (moreMem != null)\n            moreMem.signal();\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "return",
            "buffers",
            "to",
            "the",
            "pool"
        ]
    },
    {
        "id": 578,
        "code": "public long availableMemory() {\n    lock.lock();\n    try {\n        return this.nonPooledAvailableMemory + freeSize() * (long) this.poolableSize;\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "the",
            "total",
            "free",
            "memory",
            "both",
            "unallocated",
            "and",
            "in",
            "the",
            "free",
            "list"
        ]
    },
    {
        "id": 579,
        "code": "public long unallocatedMemory() {\n    lock.lock();\n    try {\n        return this.nonPooledAvailableMemory;\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "unallocated",
            "memory",
            "not",
            "in",
            "the",
            "free",
            "list",
            "or",
            "in",
            "use"
        ]
    },
    {
        "id": 580,
        "code": "public int queued() {\n    lock.lock();\n    try {\n        return this.waiters.size();\n    } finally {\n        lock.unlock();\n    }\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "threads",
            "blocked",
            "waiting",
            "on",
            "memory"
        ]
    },
    {
        "id": 581,
        "code": "public int poolableSize() {\n    return this.poolableSize;\n}",
        "summary_tokens": [
            "the",
            "buffer",
            "size",
            "that",
            "will",
            "be",
            "retained",
            "in",
            "the",
            "free",
            "list",
            "after",
            "use"
        ]
    },
    {
        "id": 582,
        "code": "public long totalMemory() {\n    return this.totalMemory;\n}",
        "summary_tokens": [
            "the",
            "total",
            "memory",
            "managed",
            "by",
            "this",
            "pool"
        ]
    },
    {
        "id": 583,
        "code": "public void close() {\n    this.lock.lock();\n    this.closed = true;\n    try {\n        for (Condition waiter : this.waiters)\n            waiter.signal();\n    } finally {\n        this.lock.unlock();\n    }\n}",
        "summary_tokens": [
            "closes",
            "the",
            "buffer",
            "pool"
        ]
    },
    {
        "id": 584,
        "code": "private int nextPartition(Cluster cluster) {\n    int random = mockRandom != null ? mockRandom.get() : Utils.toPositive(ThreadLocalRandom.current().nextInt());\n\n        \n    PartitionLoadStats partitionLoadStats = this.partitionLoadStats;\n    int partition;\n\n    if (partitionLoadStats == null) {\n            \n            \n        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);\n        if (availablePartitions.size() > 0) {\n            partition = availablePartitions.get(random % availablePartitions.size()).partition();\n        } else {\n                \n            List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\n            partition = random % partitions.size();\n        }\n    } else {\n            \n            \n        assert partitionLoadStats.length > 0;\n\n        int[] cumulativeFrequencyTable = partitionLoadStats.cumulativeFrequencyTable;\n        int weightedRandom = random % cumulativeFrequencyTable[partitionLoadStats.length - 1];\n\n            \n            \n        int searchResult = Arrays.binarySearch(cumulativeFrequencyTable, 0, partitionLoadStats.length, weightedRandom);\n\n            \n            \n            \n            \n            \n            \n            \n            \n            \n        int partitionIndex = Math.abs(searchResult + 1);\n        assert partitionIndex < partitionLoadStats.length;\n        partition = partitionLoadStats.partitionIds[partitionIndex];\n    }\n\n    log.trace(\"Switching to partition {} in topic {}\", partition, topic);\n    return partition;\n}",
        "summary_tokens": [
            "calculate",
            "the",
            "next",
            "partition",
            "for",
            "the",
            "topic",
            "based",
            "on",
            "the",
            "partition",
            "load",
            "stats"
        ]
    },
    {
        "id": 585,
        "code": "StickyPartitionInfo peekCurrentPartitionInfo(Cluster cluster) {\n    StickyPartitionInfo partitionInfo = stickyPartitionInfo.get();\n    if (partitionInfo != null)\n        return partitionInfo;\n\n        \n    partitionInfo = new StickyPartitionInfo(nextPartition(cluster));\n    if (stickyPartitionInfo.compareAndSet(null, partitionInfo))\n        return partitionInfo;\n\n        \n    return stickyPartitionInfo.get();\n}",
        "summary_tokens": [
            "peek",
            "currently",
            "chosen",
            "sticky",
            "partition"
        ]
    },
    {
        "id": 586,
        "code": "boolean isPartitionChanged(StickyPartitionInfo partitionInfo) {\n        \n    return partitionInfo != null && stickyPartitionInfo.get() != partitionInfo;\n}",
        "summary_tokens": [
            "check",
            "if",
            "partition",
            "is",
            "changed",
            "by",
            "a",
            "concurrent",
            "thread"
        ]
    },
    {
        "id": 587,
        "code": "void updatePartitionInfo(StickyPartitionInfo partitionInfo, int appendedBytes, Cluster cluster) {\n        \n    if (partitionInfo == null)\n        return;\n\n    assert partitionInfo == stickyPartitionInfo.get();\n    int producedBytes = partitionInfo.producedBytes.addAndGet(appendedBytes);\n    if (producedBytes >= stickyBatchSize) {\n            \n        StickyPartitionInfo newPartitionInfo = new StickyPartitionInfo(nextPartition(cluster));\n        stickyPartitionInfo.set(newPartitionInfo);\n    }\n}",
        "summary_tokens": [
            "update",
            "partition",
            "info",
            "with",
            "the",
            "number",
            "of",
            "bytes",
            "appended",
            "and",
            "maybe",
            "switch",
            "partition"
        ]
    },
    {
        "id": 588,
        "code": "public void updatePartitionLoadStats(int[] queueSizes, int[] partitionIds, int length) {\n    if (queueSizes == null) {\n        log.trace(\"No load stats for topic {}, not using adaptive\", topic);\n        partitionLoadStats = null;\n        return;\n    }\n    assert queueSizes.length == partitionIds.length;\n    assert length <= queueSizes.length;\n\n        \n        \n        \n        \n        \n        \n        \n    if (length < 1 || queueSizes.length < 2) {\n        log.trace(\"The number of partitions is too small: available={}, all={}, not using adaptive for topic {}\",\n                length, queueSizes.length, topic);\n        partitionLoadStats = null;\n        return;\n    }\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n\n        \n    int maxSizePlus1 = queueSizes[0];\n    boolean allEqual = true;\n    for (int i = 1; i < length; i++) {\n        if (queueSizes[i] != maxSizePlus1)\n            allEqual = false;\n        if (queueSizes[i] > maxSizePlus1)\n            maxSizePlus1 = queueSizes[i];\n    }\n    ++maxSizePlus1;\n\n    if (allEqual && length == queueSizes.length) {\n            \n            \n            \n        log.trace(\"All queue lengths are the same, not using adaptive for topic {}\", topic);\n        partitionLoadStats = null;\n        return;\n    }\n\n        \n    queueSizes[0] = maxSizePlus1 - queueSizes[0];\n    for (int i = 1; i < length; i++) {\n        queueSizes[i] = maxSizePlus1 - queueSizes[i] + queueSizes[i - 1];\n    }\n    log.trace(\"Partition load stats for topic {}: CFT={}, IDs={}, length={}\",\n            topic, queueSizes, partitionIds, length);\n    partitionLoadStats = new PartitionLoadStats(queueSizes, partitionIds, length);\n}",
        "summary_tokens": [
            "update",
            "partition",
            "load",
            "stats",
            "from",
            "the",
            "queue",
            "sizes",
            "of",
            "each",
            "partition",
            "note",
            "queue",
            "sizes",
            "are",
            "modified",
            "in",
            "place",
            "to",
            "avoid",
            "allocations"
        ]
    },
    {
        "id": 589,
        "code": "public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster,\n                     int numPartitions) {\n    if (keyBytes == null) {\n        return stickyPartitionCache.partition(topic, cluster);\n    }\n    return BuiltInPartitioner.partitionForKey(keyBytes, numPartitions);\n}",
        "summary_tokens": [
            "compute",
            "the",
            "partition",
            "for",
            "the",
            "given",
            "record"
        ]
    },
    {
        "id": 590,
        "code": "public void onNewBatch(String topic, Cluster cluster, int prevPartition) {\n    stickyPartitionCache.nextPartition(topic, cluster, prevPartition);\n}",
        "summary_tokens": [
            "if",
            "a",
            "batch",
            "completed",
            "for",
            "the",
            "current",
            "sticky",
            "partition",
            "change",
            "the",
            "sticky",
            "partition"
        ]
    },
    {
        "id": 591,
        "code": "void chain(FutureRecordMetadata futureRecordMetadata) {\n    if (nextRecordMetadata == null)\n        nextRecordMetadata = futureRecordMetadata;\n    else\n        nextRecordMetadata.chain(futureRecordMetadata);\n}",
        "summary_tokens": [
            "this",
            "method",
            "is",
            "used",
            "when",
            "we",
            "have",
            "to",
            "split",
            "a",
            "large",
            "batch",
            "in",
            "smaller",
            "ones"
        ]
    },
    {
        "id": 592,
        "code": "public void set(long baseOffset, long logAppendTime, Function<Integer, RuntimeException> errorsByIndex) {\n    this.baseOffset = baseOffset;\n    this.logAppendTime = logAppendTime;\n    this.errorsByIndex = errorsByIndex;\n}",
        "summary_tokens": [
            "set",
            "the",
            "result",
            "of",
            "the",
            "produce",
            "request"
        ]
    },
    {
        "id": 593,
        "code": "public void done() {\n    if (baseOffset == null)\n        throw new IllegalStateException(\"The method `set` must be invoked before this method.\");\n    this.latch.countDown();\n}",
        "summary_tokens": [
            "mark",
            "this",
            "request",
            "as",
            "complete",
            "and",
            "unblock",
            "any",
            "threads",
            "waiting",
            "on",
            "its",
            "completion"
        ]
    },
    {
        "id": 594,
        "code": "public boolean await(long timeout, TimeUnit unit) throws InterruptedException {\n    return latch.await(timeout, unit);\n}",
        "summary_tokens": [
            "await",
            "the",
            "completion",
            "of",
            "this",
            "request",
            "up",
            "to",
            "the",
            "given",
            "time",
            "interval",
            "timeout",
            "the",
            "maximum",
            "time",
            "to",
            "wait",
            "unit",
            "the",
            "unit",
            "for",
            "the",
            "max",
            "time",
            "true",
            "if",
            "the",
            "request",
            "completed",
            "false",
            "if",
            "we",
            "timed",
            "out"
        ]
    },
    {
        "id": 595,
        "code": "public long baseOffset() {\n    return baseOffset;\n}",
        "summary_tokens": [
            "the",
            "base",
            "offset",
            "for",
            "the",
            "request",
            "the",
            "first",
            "offset",
            "in",
            "the",
            "record",
            "set"
        ]
    },
    {
        "id": 596,
        "code": "public boolean hasLogAppendTime() {\n    return logAppendTime != RecordBatch.NO_TIMESTAMP;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "log",
            "append",
            "time",
            "is",
            "being",
            "used",
            "for",
            "this",
            "topic"
        ]
    },
    {
        "id": 597,
        "code": "public long logAppendTime() {\n    return logAppendTime;\n}",
        "summary_tokens": [
            "the",
            "log",
            "append",
            "time",
            "or",
            "0",
            "if",
            "create",
            "time",
            "is",
            "being",
            "used"
        ]
    },
    {
        "id": 598,
        "code": "public RuntimeException error(int batchIndex) {\n    if (errorsByIndex == null) {\n        return null;\n    } else {\n        return errorsByIndex.apply(batchIndex);\n    }\n}",
        "summary_tokens": [
            "the",
            "error",
            "thrown",
            "generally",
            "on",
            "the",
            "server",
            "while",
            "processing",
            "this",
            "request"
        ]
    },
    {
        "id": 599,
        "code": "public TopicPartition topicPartition() {\n    return topicPartition;\n}",
        "summary_tokens": [
            "the",
            "topic",
            "and",
            "partition",
            "to",
            "which",
            "the",
            "record",
            "was",
            "appended"
        ]
    },
    {
        "id": 600,
        "code": "public boolean completed() {\n    return this.latch.getCount() == 0L;\n}",
        "summary_tokens": [
            "has",
            "the",
            "request",
            "completed"
        ]
    },
    {
        "id": 601,
        "code": "public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long now) {\n    if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) {\n        return null;\n    } else {\n        this.recordsBuilder.append(timestamp, key, value, headers);\n        this.maxRecordSize = Math.max(this.maxRecordSize, AbstractRecords.estimateSizeInBytesUpperBound(magic(),\n                recordsBuilder.compressionType(), key, value, headers));\n        this.lastAppendTime = now;\n        FutureRecordMetadata future = new FutureRecordMetadata(this.produceFuture, this.recordCount,\n                                                               timestamp,\n                                                               key == null ? -1 : key.length,\n                                                               value == null ? -1 : value.length,\n                                                               Time.SYSTEM);\n            \n            \n        thunks.add(new Thunk(callback, future));\n        this.recordCount++;\n        return future;\n    }\n}",
        "summary_tokens": [
            "append",
            "the",
            "record",
            "to",
            "the",
            "current",
            "record",
            "set",
            "and",
            "return",
            "the",
            "relative",
            "offset",
            "within",
            "that",
            "record",
            "set"
        ]
    },
    {
        "id": 602,
        "code": "private boolean tryAppendForSplit(long timestamp, ByteBuffer key, ByteBuffer value, Header[] headers, Thunk thunk) {\n    if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) {\n        return false;\n    } else {\n            \n        this.recordsBuilder.append(timestamp, key, value, headers);\n        this.maxRecordSize = Math.max(this.maxRecordSize, AbstractRecords.estimateSizeInBytesUpperBound(magic(),\n                recordsBuilder.compressionType(), key, value, headers));\n        FutureRecordMetadata future = new FutureRecordMetadata(this.produceFuture, this.recordCount,\n                                                               timestamp,\n                                                               key == null ? -1 : key.remaining(),\n                                                               value == null ? -1 : value.remaining(),\n                                                               Time.SYSTEM);\n            \n        thunk.future.chain(future);\n        this.thunks.add(thunk);\n        this.recordCount++;\n        return true;\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "is",
            "only",
            "used",
            "by",
            "split",
            "int",
            "when",
            "splitting",
            "a",
            "large",
            "batch",
            "to",
            "smaller",
            "ones"
        ]
    },
    {
        "id": 603,
        "code": "public void abort(RuntimeException exception) {\n    if (!finalState.compareAndSet(null, FinalState.ABORTED))\n        throw new IllegalStateException(\"Batch has already been completed in final state \" + finalState.get());\n\n    log.trace(\"Aborting batch for partition {}\", topicPartition, exception);\n    completeFutureAndFireCallbacks(ProduceResponse.INVALID_OFFSET, RecordBatch.NO_TIMESTAMP, index -> exception);\n}",
        "summary_tokens": [
            "abort",
            "the",
            "batch",
            "and",
            "complete",
            "the",
            "future",
            "and",
            "callbacks"
        ]
    },
    {
        "id": 604,
        "code": "public boolean isDone() {\n    return finalState() != null;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "batch",
            "has",
            "been",
            "completed",
            "either",
            "successfully",
            "or",
            "exceptionally"
        ]
    },
    {
        "id": 605,
        "code": "public boolean complete(long baseOffset, long logAppendTime) {\n    return done(baseOffset, logAppendTime, null, null);\n}",
        "summary_tokens": [
            "complete",
            "the",
            "batch",
            "successfully"
        ]
    },
    {
        "id": 606,
        "code": "public boolean completeExceptionally(\n    RuntimeException topLevelException,\n    Function<Integer, RuntimeException> recordExceptions\n) {\n    Objects.requireNonNull(topLevelException);\n    Objects.requireNonNull(recordExceptions);\n    return done(ProduceResponse.INVALID_OFFSET, RecordBatch.NO_TIMESTAMP, topLevelException, recordExceptions);\n}",
        "summary_tokens": [
            "complete",
            "the",
            "batch",
            "exceptionally"
        ]
    },
    {
        "id": 607,
        "code": "private boolean done(\n    long baseOffset,\n    long logAppendTime,\n    RuntimeException topLevelException,\n    Function<Integer, RuntimeException> recordExceptions\n) {\n    final FinalState tryFinalState = (topLevelException == null) ? FinalState.SUCCEEDED : FinalState.FAILED;\n    if (tryFinalState == FinalState.SUCCEEDED) {\n        log.trace(\"Successfully produced messages to {} with base offset {}.\", topicPartition, baseOffset);\n    } else {\n        log.trace(\"Failed to produce messages to {} with base offset {}.\", topicPartition, baseOffset, topLevelException);\n    }\n\n    if (this.finalState.compareAndSet(null, tryFinalState)) {\n        completeFutureAndFireCallbacks(baseOffset, logAppendTime, recordExceptions);\n        return true;\n    }\n\n    if (this.finalState.get() != FinalState.SUCCEEDED) {\n        if (tryFinalState == FinalState.SUCCEEDED) {\n                \n            log.debug(\"ProduceResponse returned {} for {} after batch with base offset {} had already been {}.\",\n                tryFinalState, topicPartition, baseOffset, this.finalState.get());\n        } else {\n                \n            log.debug(\"Ignored state transition {} -> {} for {} batch with base offset {}\",\n                this.finalState.get(), tryFinalState, topicPartition, baseOffset);\n        }\n    } else {\n            \n        throw new IllegalStateException(\"A \" + this.finalState.get() + \" batch must not attempt another state change to \" + tryFinalState);\n    }\n    return false;\n}",
        "summary_tokens": [
            "finalize",
            "the",
            "state",
            "of",
            "a",
            "batch"
        ]
    },
    {
        "id": 608,
        "code": "public boolean inRetry() {\n    return this.retry;\n}",
        "summary_tokens": [
            "returns",
            "if",
            "the",
            "batch",
            "is",
            "been",
            "retried",
            "for",
            "sending",
            "to",
            "kafka"
        ]
    },
    {
        "id": 609,
        "code": "public void closeForRecordAppends() {\n    recordsBuilder.closeForRecordAppends();\n}",
        "summary_tokens": [
            "release",
            "resources",
            "required",
            "for",
            "record",
            "appends",
            "e"
        ]
    },
    {
        "id": 610,
        "code": "public void abortRecordAppends() {\n    recordsBuilder.abort();\n}",
        "summary_tokens": [
            "abort",
            "the",
            "record",
            "builder",
            "and",
            "reset",
            "the",
            "state",
            "of",
            "the",
            "underlying",
            "buffer"
        ]
    },
    {
        "id": 611,
        "code": "public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record) {\n    ProducerRecord<K, V> interceptRecord = record;\n    for (ProducerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            interceptRecord = interceptor.onSend(interceptRecord);\n        } catch (Exception e) {\n                \n                \n            if (record != null)\n                log.warn(\"Error executing interceptor onSend callback for topic: {}, partition: {}\", record.topic(), record.partition(), e);\n            else\n                log.warn(\"Error executing interceptor onSend callback\", e);\n        }\n    }\n    return interceptRecord;\n}",
        "summary_tokens": [
            "this",
            "is",
            "called",
            "when",
            "client",
            "sends",
            "the",
            "record",
            "to",
            "kafka",
            "producer",
            "before",
            "key",
            "and",
            "value",
            "gets",
            "serialized"
        ]
    },
    {
        "id": 612,
        "code": "public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    for (ProducerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            interceptor.onAcknowledgement(metadata, exception);\n        } catch (Exception e) {\n                \n            log.warn(\"Error executing interceptor onAcknowledgement callback\", e);\n        }\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "is",
            "called",
            "when",
            "the",
            "record",
            "sent",
            "to",
            "the",
            "server",
            "has",
            "been",
            "acknowledged",
            "or",
            "when",
            "sending",
            "the",
            "record",
            "fails",
            "before",
            "it",
            "gets",
            "sent",
            "to",
            "the",
            "server"
        ]
    },
    {
        "id": 613,
        "code": "public void onSendError(ProducerRecord<K, V> record, TopicPartition interceptTopicPartition, Exception exception) {\n    for (ProducerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            if (record == null && interceptTopicPartition == null) {\n                interceptor.onAcknowledgement(null, exception);\n            } else {\n                if (interceptTopicPartition == null) {\n                    interceptTopicPartition = extractTopicPartition(record);\n                }\n                interceptor.onAcknowledgement(new RecordMetadata(interceptTopicPartition, -1, -1,\n                                RecordBatch.NO_TIMESTAMP, -1, -1), exception);\n            }\n        } catch (Exception e) {\n                \n            log.warn(\"Error executing interceptor onAcknowledgement callback\", e);\n        }\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "is",
            "called",
            "when",
            "sending",
            "the",
            "record",
            "fails",
            "in",
            "producer",
            "interceptor",
            "on",
            "send",
            "producer",
            "record",
            "method"
        ]
    },
    {
        "id": 614,
        "code": "public void close() {\n    for (ProducerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            interceptor.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close producer interceptor \", e);\n        }\n    }\n}",
        "summary_tokens": [
            "closes",
            "every",
            "interceptor",
            "in",
            "a",
            "container"
        ]
    },
    {
        "id": 615,
        "code": "public synchronized void awaitUpdate(final int lastVersion, final long timeoutMs) throws InterruptedException {\n    long currentTimeMs = time.milliseconds();\n    long deadlineMs = currentTimeMs + timeoutMs < 0 ? Long.MAX_VALUE : currentTimeMs + timeoutMs;\n    time.waitObject(this, () -> {\n            \n        maybeThrowFatalException();\n        return updateVersion() > lastVersion || isClosed();\n    }, deadlineMs);\n\n    if (isClosed())\n        throw new KafkaException(\"Requested metadata update after close\");\n}",
        "summary_tokens": [
            "wait",
            "for",
            "metadata",
            "update",
            "until",
            "the",
            "current",
            "version",
            "is",
            "larger",
            "than",
            "the",
            "last",
            "version",
            "we",
            "know",
            "of"
        ]
    },
    {
        "id": 616,
        "code": "public synchronized void close() {\n    super.close();\n    notifyAll();\n}",
        "summary_tokens": [
            "close",
            "this",
            "instance",
            "and",
            "notify",
            "any",
            "awaiting",
            "threads"
        ]
    },
    {
        "id": 617,
        "code": "public RecordAppendResult append(String topic,\n                                 int partition,\n                                 long timestamp,\n                                 byte[] key,\n                                 byte[] value,\n                                 Header[] headers,\n                                 AppendCallbacks callbacks,\n                                 long maxTimeToBlock,\n                                 boolean abortOnNewBatch,\n                                 long nowMs,\n                                 Cluster cluster) throws InterruptedException {\n    TopicInfo topicInfo = topicInfoMap.computeIfAbsent(topic, k -> new TopicInfo(logContext, k, batchSize));\n\n        \n        \n    appendsInProgress.incrementAndGet();\n    ByteBuffer buffer = null;\n    if (headers == null) headers = Record.EMPTY_HEADERS;\n    try {\n            \n        while (true) {\n                \n                \n                \n                \n            final BuiltInPartitioner.StickyPartitionInfo partitionInfo;\n            final int effectivePartition;\n            if (partition == RecordMetadata.UNKNOWN_PARTITION) {\n                partitionInfo = topicInfo.builtInPartitioner.peekCurrentPartitionInfo(cluster);\n                effectivePartition = partitionInfo.partition();\n            } else {\n                partitionInfo = null;\n                effectivePartition = partition;\n            }\n\n                \n            setPartition(callbacks, effectivePartition);\n\n                \n            Deque<ProducerBatch> dq = topicInfo.batches.computeIfAbsent(effectivePartition, k -> new ArrayDeque<>());\n            synchronized (dq) {\n                    \n                if (topicInfo.builtInPartitioner.isPartitionChanged(partitionInfo)) {\n                    log.trace(\"Partition {} for topic {} switched by a concurrent append, retrying\",\n                            partitionInfo.partition(), topic);\n                    continue;\n                }\n                RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callbacks, dq, nowMs);\n                if (appendResult != null) {\n                    topicInfo.builtInPartitioner.updatePartitionInfo(partitionInfo, appendResult.appendedBytes, cluster);\n                    return appendResult;\n                }\n            }\n\n                \n            if (abortOnNewBatch) {\n                    \n                return new RecordAppendResult(null, false, false, true, 0);\n            }\n\n            if (buffer == null) {\n                byte maxUsableMagic = apiVersions.maxUsableProduceMagic();\n                int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));\n                log.trace(\"Allocating a new {} byte message buffer for topic {} partition {} with remaining timeout {}ms\", size, topic, partition, maxTimeToBlock);\n                    \n                buffer = free.allocate(size, maxTimeToBlock);\n                    \n                    \n                    \n                nowMs = time.milliseconds();\n            }\n\n            synchronized (dq) {\n                    \n                if (topicInfo.builtInPartitioner.isPartitionChanged(partitionInfo)) {\n                    log.trace(\"Partition {} for topic {} switched by a concurrent append, retrying\",\n                            partitionInfo.partition(), topic);\n                    continue;\n                }\n                RecordAppendResult appendResult = appendNewBatch(topic, effectivePartition, dq, timestamp, key, value, headers, callbacks, buffer, nowMs);\n                    \n                if (appendResult.newBatchCreated)\n                    buffer = null;\n                topicInfo.builtInPartitioner.updatePartitionInfo(partitionInfo, appendResult.appendedBytes, cluster);\n                return appendResult;\n            }\n        }\n    } finally {\n        free.deallocate(buffer);\n        appendsInProgress.decrementAndGet();\n    }\n}",
        "summary_tokens": [
            "add",
            "a",
            "record",
            "to",
            "the",
            "accumulator",
            "return",
            "the",
            "append",
            "result",
            "p",
            "the",
            "append",
            "result",
            "will",
            "contain",
            "the",
            "future",
            "metadata",
            "and",
            "flag",
            "for",
            "whether",
            "the",
            "appended",
            "batch",
            "is",
            "full",
            "or",
            "a",
            "new",
            "batch",
            "is",
            "created",
            "p"
        ]
    },
    {
        "id": 618,
        "code": "private RecordAppendResult appendNewBatch(String topic,\n                                          int partition,\n                                          Deque<ProducerBatch> dq,\n                                          long timestamp,\n                                          byte[] key,\n                                          byte[] value,\n                                          Header[] headers,\n                                          AppendCallbacks callbacks,\n                                          ByteBuffer buffer,\n                                          long nowMs) {\n    assert partition != RecordMetadata.UNKNOWN_PARTITION;\n\n    RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callbacks, dq, nowMs);\n    if (appendResult != null) {\n            \n        return appendResult;\n    }\n\n    MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, apiVersions.maxUsableProduceMagic());\n    ProducerBatch batch = new ProducerBatch(new TopicPartition(topic, partition), recordsBuilder, nowMs);\n    FutureRecordMetadata future = Objects.requireNonNull(batch.tryAppend(timestamp, key, value, headers,\n            callbacks, nowMs));\n\n    dq.addLast(batch);\n    incomplete.add(batch);\n\n    return new RecordAppendResult(future, dq.size() > 1 || batch.isFull(), true, false, batch.estimatedSizeInBytes());\n}",
        "summary_tokens": [
            "append",
            "a",
            "new",
            "batch",
            "to",
            "the",
            "queue"
        ]
    },
    {
        "id": 619,
        "code": "private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers,\n                                     Callback callback, Deque<ProducerBatch> deque, long nowMs) {\n    if (closed)\n        throw new KafkaException(\"Producer closed while send in progress\");\n    ProducerBatch last = deque.peekLast();\n    if (last != null) {\n        int initialBytes = last.estimatedSizeInBytes();\n        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, headers, callback, nowMs);\n        if (future == null) {\n            last.closeForRecordAppends();\n        } else {\n            int appendedBytes = last.estimatedSizeInBytes() - initialBytes;\n            return new RecordAppendResult(future, deque.size() > 1 || last.isFull(), false, false, appendedBytes);\n        }\n    }\n    return null;\n}",
        "summary_tokens": [
            "try",
            "to",
            "append",
            "to",
            "a",
            "producer",
            "batch"
        ]
    },
    {
        "id": 620,
        "code": "public List<ProducerBatch> expiredBatches(long now) {\n    List<ProducerBatch> expiredBatches = new ArrayList<>();\n    for (TopicInfo topicInfo : topicInfoMap.values()) {\n        for (Deque<ProducerBatch> deque : topicInfo.batches.values()) {\n                \n            synchronized (deque) {\n                while (!deque.isEmpty()) {\n                    ProducerBatch batch = deque.getFirst();\n                    if (batch.hasReachedDeliveryTimeout(deliveryTimeoutMs, now)) {\n                        deque.poll();\n                        batch.abortRecordAppends();\n                        expiredBatches.add(batch);\n                    } else {\n                        maybeUpdateNextBatchExpiryTime(batch);\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    return expiredBatches;\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "batches",
            "which",
            "have",
            "been",
            "sitting",
            "in",
            "the",
            "accumulator",
            "too",
            "long",
            "and",
            "need",
            "to",
            "be",
            "expired"
        ]
    },
    {
        "id": 621,
        "code": "public void reenqueue(ProducerBatch batch, long now) {\n    batch.reenqueued(now);\n    Deque<ProducerBatch> deque = getOrCreateDeque(batch.topicPartition);\n    synchronized (deque) {\n        if (transactionManager != null)\n            insertInSequenceOrder(deque, batch);\n        else\n            deque.addFirst(batch);\n    }\n}",
        "summary_tokens": [
            "re",
            "enqueue",
            "the",
            "given",
            "record",
            "batch",
            "in",
            "the",
            "accumulator"
        ]
    },
    {
        "id": 622,
        "code": "public int splitAndReenqueue(ProducerBatch bigBatch) {\n        \n        \n        \n    CompressionRatioEstimator.setEstimation(bigBatch.topicPartition.topic(), compression,\n                                            Math.max(1.0f, (float) bigBatch.compressionRatio()));\n    Deque<ProducerBatch> dq = bigBatch.split(this.batchSize);\n    int numSplitBatches = dq.size();\n    Deque<ProducerBatch> partitionDequeue = getOrCreateDeque(bigBatch.topicPartition);\n    while (!dq.isEmpty()) {\n        ProducerBatch batch = dq.pollLast();\n        incomplete.add(batch);\n            \n        synchronized (partitionDequeue) {\n            if (transactionManager != null) {\n                    \n                transactionManager.addInFlightBatch(batch);\n                insertInSequenceOrder(partitionDequeue, batch);\n            } else {\n                partitionDequeue.addFirst(batch);\n            }\n        }\n    }\n    return numSplitBatches;\n}",
        "summary_tokens": [
            "split",
            "the",
            "big",
            "batch",
            "that",
            "has",
            "been",
            "rejected",
            "and",
            "reenqueue",
            "the",
            "split",
            "batches",
            "in",
            "to",
            "the",
            "accumulator"
        ]
    },
    {
        "id": 623,
        "code": "private long batchReady(long nowMs, boolean exhausted, TopicPartition part, Node leader,\n                        long waitedTimeMs, boolean backingOff, boolean full,\n                        long nextReadyCheckDelayMs, Set<Node> readyNodes) {\n    if (!readyNodes.contains(leader) && !isMuted(part)) {\n        long timeToWaitMs = backingOff ? retryBackoffMs : lingerMs;\n        boolean expired = waitedTimeMs >= timeToWaitMs;\n        boolean transactionCompleting = transactionManager != null && transactionManager.isCompleting();\n        boolean sendable = full\n                || expired\n                || exhausted\n                || closed\n                || flushInProgress()\n                || transactionCompleting;\n        if (sendable && !backingOff) {\n            readyNodes.add(leader);\n        } else {\n            long timeLeftMs = Math.max(timeToWaitMs - waitedTimeMs, 0);\n                \n                \n                \n            nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);\n        }\n    }\n    return nextReadyCheckDelayMs;\n}",
        "summary_tokens": [
            "add",
            "the",
            "leader",
            "to",
            "the",
            "ready",
            "nodes",
            "if",
            "the",
            "batch",
            "is",
            "ready"
        ]
    },
    {
        "id": 624,
        "code": "private long partitionReady(Cluster cluster, long nowMs, String topic,\n                            TopicInfo topicInfo,\n                            long nextReadyCheckDelayMs, Set<Node> readyNodes, Set<String> unknownLeaderTopics) {\n    ConcurrentMap<Integer, Deque<ProducerBatch>> batches = topicInfo.batches;\n        \n    int[] queueSizes = null;\n    int[] partitionIds = null;\n    if (enableAdaptivePartitioning && batches.size() >= cluster.partitionsForTopic(topic).size()) {\n            \n            \n            \n            \n            \n        queueSizes = new int[batches.size()];\n        partitionIds = new int[queueSizes.length];\n    }\n\n    int queueSizesIndex = -1;\n    boolean exhausted = this.free.queued() > 0;\n    for (Map.Entry<Integer, Deque<ProducerBatch>> entry : batches.entrySet()) {\n        TopicPartition part = new TopicPartition(topic, entry.getKey());\n            \n            \n        Node leader = cluster.leaderFor(part);\n        if (leader != null && queueSizes != null) {\n            ++queueSizesIndex;\n            assert queueSizesIndex < queueSizes.length;\n            partitionIds[queueSizesIndex] = part.partition();\n        }\n\n        Deque<ProducerBatch> deque = entry.getValue();\n\n        final long waitedTimeMs;\n        final boolean backingOff;\n        final int dequeSize;\n        final boolean full;\n\n            \n\n            \n            \n            \n\n        synchronized (deque) {\n                \n                \n            ProducerBatch batch = deque.peekFirst();\n            if (batch == null) {\n                continue;\n            }\n\n            waitedTimeMs = batch.waitedTimeMs(nowMs);\n            backingOff = batch.attempts() > 0 && waitedTimeMs < retryBackoffMs;\n            dequeSize = deque.size();\n            full = dequeSize > 1 || batch.isFull();\n        }\n\n        if (leader == null) {\n                \n                \n            unknownLeaderTopics.add(part.topic());\n        } else {\n            if (queueSizes != null)\n                queueSizes[queueSizesIndex] = dequeSize;\n            if (partitionAvailabilityTimeoutMs > 0) {\n                    \n                    \n                NodeLatencyStats nodeLatencyStats = nodeStats.get(leader.id());\n                if (nodeLatencyStats != null) {\n                        \n                        \n                        \n                    long readyTimeMs = nodeLatencyStats.readyTimeMs;\n                    if (readyTimeMs - nodeLatencyStats.drainTimeMs > partitionAvailabilityTimeoutMs)\n                        --queueSizesIndex;\n                }\n            }\n\n            nextReadyCheckDelayMs = batchReady(nowMs, exhausted, part, leader, waitedTimeMs, backingOff,\n                full, nextReadyCheckDelayMs, readyNodes);\n        }\n    }\n\n        \n        \n        \n    topicInfo.builtInPartitioner.updatePartitionLoadStats(queueSizes, partitionIds, queueSizesIndex + 1);\n    return nextReadyCheckDelayMs;\n}",
        "summary_tokens": [
            "iterate",
            "over",
            "partitions",
            "to",
            "see",
            "which",
            "one",
            "have",
            "batches",
            "ready",
            "and",
            "collect",
            "leaders",
            "of",
            "those",
            "partitions",
            "into",
            "the",
            "set",
            "of",
            "ready",
            "nodes"
        ]
    },
    {
        "id": 625,
        "code": "public ReadyCheckResult ready(Cluster cluster, long nowMs) {\n    Set<Node> readyNodes = new HashSet<>();\n    long nextReadyCheckDelayMs = Long.MAX_VALUE;\n    Set<String> unknownLeaderTopics = new HashSet<>();\n        \n        \n    for (Map.Entry<String, TopicInfo> topicInfoEntry : this.topicInfoMap.entrySet()) {\n        final String topic = topicInfoEntry.getKey();\n        nextReadyCheckDelayMs = partitionReady(cluster, nowMs, topic, topicInfoEntry.getValue(), nextReadyCheckDelayMs, readyNodes, unknownLeaderTopics);\n    }\n    return new ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeaderTopics);\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "nodes",
            "whose",
            "partitions",
            "are",
            "ready",
            "to",
            "be",
            "sent",
            "and",
            "the",
            "earliest",
            "time",
            "at",
            "which",
            "any",
            "non",
            "sendable",
            "partition",
            "will",
            "be",
            "ready",
            "also",
            "return",
            "the",
            "flag",
            "for",
            "whether",
            "there",
            "are",
            "any",
            "unknown",
            "leaders",
            "for",
            "the",
            "accumulated",
            "partition",
            "batches"
        ]
    },
    {
        "id": 626,
        "code": "public boolean hasUndrained() {\n    for (TopicInfo topicInfo : topicInfoMap.values()) {\n        for (Deque<ProducerBatch> deque : topicInfo.batches.values()) {\n            synchronized (deque) {\n                if (!deque.isEmpty())\n                    return true;\n            }\n        }\n    }\n    return false;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "there",
            "are",
            "any",
            "batches",
            "which",
            "haven",
            "t",
            "been",
            "drained"
        ]
    },
    {
        "id": 627,
        "code": "public Map<Integer, List<ProducerBatch>> drain(Cluster cluster, Set<Node> nodes, int maxSize, long now) {\n    if (nodes.isEmpty())\n        return Collections.emptyMap();\n\n    Map<Integer, List<ProducerBatch>> batches = new HashMap<>();\n    for (Node node : nodes) {\n        List<ProducerBatch> ready = drainBatchesForOneNode(cluster, node, maxSize, now);\n        batches.put(node.id(), ready);\n    }\n    return batches;\n}",
        "summary_tokens": [
            "drain",
            "all",
            "the",
            "data",
            "for",
            "the",
            "given",
            "nodes",
            "and",
            "collate",
            "them",
            "into",
            "a",
            "list",
            "of",
            "batches",
            "that",
            "will",
            "fit",
            "within",
            "the",
            "specified",
            "size",
            "on",
            "a",
            "per",
            "node",
            "basis"
        ]
    },
    {
        "id": 628,
        "code": "public long nextExpiryTimeMs() {\n    return this.nextBatchExpiryTimeMs;\n}",
        "summary_tokens": [
            "the",
            "earliest",
            "absolute",
            "time",
            "a",
            "batch",
            "will",
            "expire",
            "in",
            "milliseconds"
        ]
    },
    {
        "id": 629,
        "code": "private Deque<ProducerBatch> getOrCreateDeque(TopicPartition tp) {\n    TopicInfo topicInfo = topicInfoMap.computeIfAbsent(tp.topic(), k -> new TopicInfo(logContext, k, batchSize));\n    return topicInfo.batches.computeIfAbsent(tp.partition(), k -> new ArrayDeque<>());\n}",
        "summary_tokens": [
            "get",
            "the",
            "deque",
            "for",
            "the",
            "given",
            "topic",
            "partition",
            "creating",
            "it",
            "if",
            "necessary"
        ]
    },
    {
        "id": 630,
        "code": "public void deallocate(ProducerBatch batch) {\n    incomplete.remove(batch);\n        \n        \n    if (!batch.isSplitBatch())\n        free.deallocate(batch.buffer(), batch.initialCapacity());\n}",
        "summary_tokens": [
            "deallocate",
            "the",
            "record",
            "batch"
        ]
    },
    {
        "id": 631,
        "code": "long bufferPoolAvailableMemory() {\n    return free.availableMemory();\n}",
        "summary_tokens": [
            "package",
            "private",
            "for",
            "unit",
            "test"
        ]
    },
    {
        "id": 632,
        "code": "boolean flushInProgress() {\n    return flushesInProgress.get() > 0;\n}",
        "summary_tokens": [
            "are",
            "there",
            "any",
            "threads",
            "currently",
            "waiting",
            "on",
            "a",
            "flush"
        ]
    },
    {
        "id": 633,
        "code": "public void beginFlush() {\n    this.flushesInProgress.getAndIncrement();\n}",
        "summary_tokens": [
            "initiate",
            "the",
            "flushing",
            "of",
            "data",
            "from",
            "the",
            "accumulator"
        ]
    },
    {
        "id": 634,
        "code": "private boolean appendsInProgress() {\n    return appendsInProgress.get() > 0;\n}",
        "summary_tokens": [
            "are",
            "there",
            "any",
            "threads",
            "currently",
            "appending",
            "messages"
        ]
    },
    {
        "id": 635,
        "code": "public void awaitFlushCompletion() throws InterruptedException {\n    try {\n            \n            \n            \n            \n        for (ProduceRequestResult result : this.incomplete.requestResults())\n            result.await();\n    } finally {\n        this.flushesInProgress.decrementAndGet();\n    }\n}",
        "summary_tokens": [
            "mark",
            "all",
            "partitions",
            "as",
            "ready",
            "to",
            "send",
            "and",
            "block",
            "until",
            "the",
            "send",
            "is",
            "complete"
        ]
    },
    {
        "id": 636,
        "code": "public boolean hasIncomplete() {\n    return !this.incomplete.isEmpty();\n}",
        "summary_tokens": [
            "check",
            "whether",
            "there",
            "are",
            "any",
            "pending",
            "batches",
            "whether",
            "sent",
            "or",
            "unsent"
        ]
    },
    {
        "id": 637,
        "code": "public void abortIncompleteBatches() {\n        \n        \n        \n        \n    do {\n        abortBatches();\n    } while (appendsInProgress());\n        \n        \n        \n    abortBatches();\n    this.topicInfoMap.clear();\n}",
        "summary_tokens": [
            "this",
            "function",
            "is",
            "only",
            "called",
            "when",
            "sender",
            "is",
            "closed",
            "forcefully"
        ]
    },
    {
        "id": 638,
        "code": "void abortBatches(final RuntimeException reason) {\n    for (ProducerBatch batch : incomplete.copyAll()) {\n        Deque<ProducerBatch> dq = getDeque(batch.topicPartition);\n        synchronized (dq) {\n            batch.abortRecordAppends();\n            dq.remove(batch);\n        }\n        batch.abort(reason);\n        deallocate(batch);\n    }\n}",
        "summary_tokens": [
            "abort",
            "all",
            "incomplete",
            "batches",
            "whether",
            "they",
            "have",
            "been",
            "sent",
            "or",
            "not"
        ]
    },
    {
        "id": 639,
        "code": "void abortUndrainedBatches(RuntimeException reason) {\n    for (ProducerBatch batch : incomplete.copyAll()) {\n        Deque<ProducerBatch> dq = getDeque(batch.topicPartition);\n        boolean aborted = false;\n        synchronized (dq) {\n            if ((transactionManager != null && !batch.hasSequence()) || (transactionManager == null && !batch.isClosed())) {\n                aborted = true;\n                batch.abortRecordAppends();\n                dq.remove(batch);\n            }\n        }\n        if (aborted) {\n            batch.abort(reason);\n            deallocate(batch);\n        }\n    }\n}",
        "summary_tokens": [
            "abort",
            "any",
            "batches",
            "which",
            "have",
            "not",
            "been",
            "drained"
        ]
    },
    {
        "id": 640,
        "code": "public void close() {\n    this.closed = true;\n    this.free.close();\n}",
        "summary_tokens": [
            "close",
            "this",
            "accumulator",
            "and",
            "force",
            "all",
            "the",
            "record",
            "buffers",
            "to",
            "be",
            "drained"
        ]
    },
    {
        "id": 641,
        "code": "private List<ProducerBatch> getExpiredInflightBatches(long now) {\n    List<ProducerBatch> expiredBatches = new ArrayList<>();\n\n    for (Iterator<Map.Entry<TopicPartition, List<ProducerBatch>>> batchIt = inFlightBatches.entrySet().iterator(); batchIt.hasNext();) {\n        Map.Entry<TopicPartition, List<ProducerBatch>> entry = batchIt.next();\n        List<ProducerBatch> partitionInFlightBatches = entry.getValue();\n        if (partitionInFlightBatches != null) {\n            Iterator<ProducerBatch> iter = partitionInFlightBatches.iterator();\n            while (iter.hasNext()) {\n                ProducerBatch batch = iter.next();\n                if (batch.hasReachedDeliveryTimeout(accumulator.getDeliveryTimeoutMs(), now)) {\n                    iter.remove();\n                        \n                        \n                        \n                    if (!batch.isDone()) {\n                        expiredBatches.add(batch);\n                    } else {\n                        throw new IllegalStateException(batch.topicPartition + \" batch created at \" +\n                            batch.createdMs + \" gets unexpected final state \" + batch.finalState());\n                    }\n                } else {\n                    accumulator.maybeUpdateNextBatchExpiryTime(batch);\n                    break;\n                }\n            }\n            if (partitionInFlightBatches.isEmpty()) {\n                batchIt.remove();\n            }\n        }\n    }\n    return expiredBatches;\n}",
        "summary_tokens": [
            "get",
            "the",
            "in",
            "flight",
            "batches",
            "that",
            "has",
            "reached",
            "delivery",
            "timeout"
        ]
    },
    {
        "id": 642,
        "code": "public void run() {\n    log.debug(\"Starting Kafka producer I/O thread.\");\n\n        \n    while (running) {\n        try {\n            runOnce();\n        } catch (Exception e) {\n            log.error(\"Uncaught error in kafka producer I/O thread: \", e);\n        }\n    }\n\n    log.debug(\"Beginning shutdown of Kafka producer I/O thread, sending remaining records.\");\n\n        \n        \n        \n    while (!forceClose && ((this.accumulator.hasUndrained() || this.client.inFlightRequestCount() > 0) || hasPendingTransactionalRequests())) {\n        try {\n            runOnce();\n        } catch (Exception e) {\n            log.error(\"Uncaught error in kafka producer I/O thread: \", e);\n        }\n    }\n\n        \n    while (!forceClose && transactionManager != null && transactionManager.hasOngoingTransaction()) {\n        if (!transactionManager.isCompleting()) {\n            log.info(\"Aborting incomplete transaction due to shutdown\");\n            transactionManager.beginAbort();\n        }\n        try {\n            runOnce();\n        } catch (Exception e) {\n            log.error(\"Uncaught error in kafka producer I/O thread: \", e);\n        }\n    }\n\n    if (forceClose) {\n            \n            \n        if (transactionManager != null) {\n            log.debug(\"Aborting incomplete transactional requests due to forced shutdown\");\n            transactionManager.close();\n        }\n        log.debug(\"Aborting incomplete batches due to forced shutdown\");\n        this.accumulator.abortIncompleteBatches();\n    }\n    try {\n        this.client.close();\n    } catch (Exception e) {\n        log.error(\"Failed to close network client\", e);\n    }\n\n    log.debug(\"Shutdown of Kafka producer I/O thread has completed.\");\n}",
        "summary_tokens": [
            "the",
            "main",
            "run",
            "loop",
            "for",
            "the",
            "sender",
            "thread"
        ]
    },
    {
        "id": 643,
        "code": "void runOnce() {\n    if (transactionManager != null) {\n        try {\n            transactionManager.maybeResolveSequences();\n\n                \n            if (transactionManager.hasFatalError()) {\n                RuntimeException lastError = transactionManager.lastError();\n                if (lastError != null)\n                    maybeAbortBatches(lastError);\n                client.poll(retryBackoffMs, time.milliseconds());\n                return;\n            }\n\n                \n                \n            transactionManager.bumpIdempotentEpochAndResetIdIfNeeded();\n\n            if (maybeSendAndPollTransactionalRequest()) {\n                return;\n            }\n        } catch (AuthenticationException e) {\n                \n            log.trace(\"Authentication exception while processing transactional request\", e);\n            transactionManager.authenticationFailed(e);\n        }\n    }\n\n    long currentTimeMs = time.milliseconds();\n    long pollTimeout = sendProducerData(currentTimeMs);\n    client.poll(pollTimeout, currentTimeMs);\n}",
        "summary_tokens": [
            "run",
            "a",
            "single",
            "iteration",
            "of",
            "sending"
        ]
    },
    {
        "id": 644,
        "code": "private boolean maybeSendAndPollTransactionalRequest() {\n    if (transactionManager.hasInFlightRequest()) {\n            \n        client.poll(retryBackoffMs, time.milliseconds());\n        return true;\n    }\n\n    if (transactionManager.hasAbortableError() || transactionManager.isAborting()) {\n        if (accumulator.hasIncomplete()) {\n                \n            RuntimeException exception = transactionManager.lastError();\n                \n                \n            if (exception == null) {\n                exception = new TransactionAbortedException();\n            }\n            accumulator.abortUndrainedBatches(exception);\n        }\n    }\n\n    TransactionManager.TxnRequestHandler nextRequestHandler = transactionManager.nextRequest(accumulator.hasIncomplete());\n    if (nextRequestHandler == null)\n        return false;\n\n    AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n    Node targetNode = null;\n    try {\n        FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n        targetNode = coordinatorType != null ?\n                transactionManager.coordinator(coordinatorType) :\n                client.leastLoadedNode(time.milliseconds());\n        if (targetNode != null) {\n            if (!awaitNodeReady(targetNode, coordinatorType)) {\n                log.trace(\"Target node {} not ready within request timeout, will retry when node is ready.\", targetNode);\n                maybeFindCoordinatorAndRetry(nextRequestHandler);\n                return true;\n            }\n        } else if (coordinatorType != null) {\n            log.trace(\"Coordinator not known for {}, will retry {} after finding coordinator.\", coordinatorType, requestBuilder.apiKey());\n            maybeFindCoordinatorAndRetry(nextRequestHandler);\n            return true;\n        } else {\n            log.trace(\"No nodes available to send requests, will poll and retry when until a node is ready.\");\n            transactionManager.retry(nextRequestHandler);\n            client.poll(retryBackoffMs, time.milliseconds());\n            return true;\n        }\n\n        if (nextRequestHandler.isRetry())\n            time.sleep(nextRequestHandler.retryBackoffMs());\n\n        long currentTimeMs = time.milliseconds();\n        ClientRequest clientRequest = client.newClientRequest(targetNode.idString(), requestBuilder, currentTimeMs,\n            true, requestTimeoutMs, nextRequestHandler);\n        log.debug(\"Sending transactional request {} to node {} with correlation ID {}\", requestBuilder, targetNode, clientRequest.correlationId());\n        client.send(clientRequest, currentTimeMs);\n        transactionManager.setInFlightCorrelationId(clientRequest.correlationId());\n        client.poll(retryBackoffMs, time.milliseconds());\n        return true;\n    } catch (IOException e) {\n        log.debug(\"Disconnect from {} while trying to send request {}. Going \" +\n                \"to back off and retry.\", targetNode, requestBuilder, e);\n            \n        maybeFindCoordinatorAndRetry(nextRequestHandler);\n        return true;\n    }\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "a",
            "transactional",
            "request",
            "is",
            "sent",
            "or",
            "polled",
            "or",
            "if",
            "a",
            "find",
            "coordinator",
            "request",
            "is",
            "enqueued"
        ]
    },
    {
        "id": 645,
        "code": "public void initiateClose() {\n        \n        \n    this.accumulator.close();\n    this.running = false;\n    this.wakeup();\n}",
        "summary_tokens": [
            "start",
            "closing",
            "the",
            "sender",
            "won",
            "t",
            "actually",
            "complete",
            "until",
            "all",
            "data",
            "is",
            "sent",
            "out"
        ]
    },
    {
        "id": 646,
        "code": "public void forceClose() {\n    this.forceClose = true;\n    initiateClose();\n}",
        "summary_tokens": [
            "closes",
            "the",
            "sender",
            "without",
            "sending",
            "out",
            "any",
            "pending",
            "messages"
        ]
    },
    {
        "id": 647,
        "code": "private void handleProduceResponse(ClientResponse response, Map<TopicPartition, ProducerBatch> batches, long now) {\n    RequestHeader requestHeader = response.requestHeader();\n    int correlationId = requestHeader.correlationId();\n    if (response.wasDisconnected()) {\n        log.trace(\"Cancelled request with header {} due to node {} being disconnected\",\n            requestHeader, response.destination());\n        for (ProducerBatch batch : batches.values())\n            completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NETWORK_EXCEPTION, String.format(\"Disconnected from node %s\", response.destination())),\n                    correlationId, now);\n    } else if (response.versionMismatch() != null) {\n        log.warn(\"Cancelled request {} due to a version mismatch with node {}\",\n                response, response.destination(), response.versionMismatch());\n        for (ProducerBatch batch : batches.values())\n            completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.UNSUPPORTED_VERSION), correlationId, now);\n    } else {\n        log.trace(\"Received produce response from node {} with correlation id {}\", response.destination(), correlationId);\n            \n        if (response.hasResponse()) {\n                \n                \n            ProduceResponse produceResponse = (ProduceResponse) response.responseBody();\n            produceResponse.data().responses().forEach(r -> r.partitionResponses().forEach(p -> {\n                TopicPartition tp = new TopicPartition(r.name(), p.index());\n                ProduceResponse.PartitionResponse partResp = new ProduceResponse.PartitionResponse(\n                        Errors.forCode(p.errorCode()),\n                        p.baseOffset(),\n                        p.logAppendTimeMs(),\n                        p.logStartOffset(),\n                        p.recordErrors()\n                            .stream()\n                            .map(e -> new ProduceResponse.RecordError(e.batchIndex(), e.batchIndexErrorMessage()))\n                            .collect(Collectors.toList()),\n                        p.errorMessage());\n                ProducerBatch batch = batches.get(tp);\n                completeBatch(batch, partResp, correlationId, now);\n            }));\n            this.sensors.recordLatency(response.destination(), response.requestLatencyMs());\n        } else {\n                \n            for (ProducerBatch batch : batches.values()) {\n                completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NONE), correlationId, now);\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "handle",
            "a",
            "produce",
            "response"
        ]
    },
    {
        "id": 648,
        "code": "private void completeBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response, long correlationId,\n                           long now) {\n    Errors error = response.error;\n\n    if (error == Errors.MESSAGE_TOO_LARGE && batch.recordCount > 1 && !batch.isDone() &&\n            (batch.magic() >= RecordBatch.MAGIC_VALUE_V2 || batch.isCompressed())) {\n            \n            \n        log.warn(\n            \"Got error produce response in correlation id {} on topic-partition {}, splitting and retrying ({} attempts left). Error: {}\",\n            correlationId,\n            batch.topicPartition,\n            this.retries - batch.attempts(),\n            formatErrMsg(response));\n        if (transactionManager != null)\n            transactionManager.removeInFlightBatch(batch);\n        this.accumulator.splitAndReenqueue(batch);\n        maybeRemoveAndDeallocateBatch(batch);\n        this.sensors.recordBatchSplit();\n    } else if (error != Errors.NONE) {\n        if (canRetry(batch, response, now)) {\n            log.warn(\n                \"Got error produce response with correlation id {} on topic-partition {}, retrying ({} attempts left). Error: {}\",\n                correlationId,\n                batch.topicPartition,\n                this.retries - batch.attempts() - 1,\n                formatErrMsg(response));\n            reenqueueBatch(batch, now);\n        } else if (error == Errors.DUPLICATE_SEQUENCE_NUMBER) {\n                \n                \n                \n                \n                \n            completeBatch(batch, response);\n        } else {\n                \n                \n                \n            failBatch(batch, response, batch.attempts() < this.retries);\n        }\n        if (error.exception() instanceof InvalidMetadataException) {\n            if (error.exception() instanceof UnknownTopicOrPartitionException) {\n                log.warn(\"Received unknown topic or partition error in produce request on partition {}. The \" +\n                        \"topic-partition may not exist or the user may not have Describe access to it\",\n                    batch.topicPartition);\n            } else {\n                log.warn(\"Received invalid metadata error in produce request on partition {} due to {}. Going \" +\n                        \"to request metadata update now\", batch.topicPartition,\n                        error.exception(response.errorMessage).toString());\n            }\n            metadata.requestUpdate();\n        }\n    } else {\n        completeBatch(batch, response);\n    }\n\n        \n    if (guaranteeMessageOrder)\n        this.accumulator.unmutePartition(batch.topicPartition);\n}",
        "summary_tokens": [
            "complete",
            "or",
            "retry",
            "the",
            "given",
            "batch",
            "of",
            "records"
        ]
    },
    {
        "id": 649,
        "code": "private String formatErrMsg(ProduceResponse.PartitionResponse response) {\n    String errorMessageSuffix = (response.errorMessage == null || response.errorMessage.isEmpty()) ?\n            \"\" : String.format(\". Error Message: %s\", response.errorMessage);\n    return String.format(\"%s%s\", response.error, errorMessageSuffix);\n}",
        "summary_tokens": [
            "format",
            "the",
            "error",
            "from",
            "a",
            "produce",
            "response"
        ]
    },
    {
        "id": 650,
        "code": "private boolean canRetry(ProducerBatch batch, ProduceResponse.PartitionResponse response, long now) {\n    return !batch.hasReachedDeliveryTimeout(accumulator.getDeliveryTimeoutMs(), now) &&\n        batch.attempts() < this.retries &&\n        !batch.isDone() &&\n        (transactionManager == null ?\n                response.error.exception() instanceof RetriableException :\n                transactionManager.canRetry(response, batch));\n}",
        "summary_tokens": [
            "we",
            "can",
            "retry",
            "a",
            "send",
            "if",
            "the",
            "error",
            "is",
            "transient",
            "and",
            "the",
            "number",
            "of",
            "attempts",
            "taken",
            "is",
            "fewer",
            "than",
            "the",
            "maximum",
            "allowed"
        ]
    },
    {
        "id": 651,
        "code": "private void sendProduceRequests(Map<Integer, List<ProducerBatch>> collated, long now) {\n    for (Map.Entry<Integer, List<ProducerBatch>> entry : collated.entrySet())\n        sendProduceRequest(now, entry.getKey(), acks, requestTimeoutMs, entry.getValue());\n}",
        "summary_tokens": [
            "transfer",
            "the",
            "record",
            "batches",
            "into",
            "a",
            "list",
            "of",
            "produce",
            "requests",
            "on",
            "a",
            "per",
            "node",
            "basis"
        ]
    },
    {
        "id": 652,
        "code": "private void sendProduceRequest(long now, int destination, short acks, int timeout, List<ProducerBatch> batches) {\n    if (batches.isEmpty())\n        return;\n\n    final Map<TopicPartition, ProducerBatch> recordsByPartition = new HashMap<>(batches.size());\n\n        \n    byte minUsedMagic = apiVersions.maxUsableProduceMagic();\n    for (ProducerBatch batch : batches) {\n        if (batch.magic() < minUsedMagic)\n            minUsedMagic = batch.magic();\n    }\n    ProduceRequestData.TopicProduceDataCollection tpd = new ProduceRequestData.TopicProduceDataCollection();\n    for (ProducerBatch batch : batches) {\n        TopicPartition tp = batch.topicPartition;\n        MemoryRecords records = batch.records();\n\n            \n            \n            \n            \n            \n            \n            \n        if (!records.hasMatchingMagic(minUsedMagic))\n            records = batch.records().downConvert(minUsedMagic, 0, time).records();\n        ProduceRequestData.TopicProduceData tpData = tpd.find(tp.topic());\n        if (tpData == null) {\n            tpData = new ProduceRequestData.TopicProduceData().setName(tp.topic());\n            tpd.add(tpData);\n        }\n        tpData.partitionData().add(new ProduceRequestData.PartitionProduceData()\n                .setIndex(tp.partition())\n                .setRecords(records));\n        recordsByPartition.put(tp, batch);\n    }\n\n    String transactionalId = null;\n    if (transactionManager != null && transactionManager.isTransactional()) {\n        transactionalId = transactionManager.transactionalId();\n    }\n\n    ProduceRequest.Builder requestBuilder = ProduceRequest.forMagic(minUsedMagic,\n            new ProduceRequestData()\n                    .setAcks(acks)\n                    .setTimeoutMs(timeout)\n                    .setTransactionalId(transactionalId)\n                    .setTopicData(tpd));\n    RequestCompletionHandler callback = response -> handleProduceResponse(response, recordsByPartition, time.milliseconds());\n\n    String nodeId = Integer.toString(destination);\n    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0,\n            requestTimeoutMs, callback);\n    client.send(clientRequest, now);\n    log.trace(\"Sent produce request to {}: {}\", nodeId, requestBuilder);\n}",
        "summary_tokens": [
            "create",
            "a",
            "produce",
            "request",
            "from",
            "the",
            "given",
            "record",
            "batches"
        ]
    },
    {
        "id": 653,
        "code": "public void wakeup() {\n    this.client.wakeup();\n}",
        "summary_tokens": [
            "wake",
            "up",
            "the",
            "selector",
            "associated",
            "with",
            "this",
            "send",
            "thread"
        ]
    },
    {
        "id": 654,
        "code": "synchronized ProducerIdAndEpoch producerIdAndEpoch(TopicPartition topicPartition) {\n    return txnPartitionMap.getOrCreate(topicPartition).producerIdAndEpoch;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "current",
            "producer",
            "id",
            "epoch",
            "of",
            "the",
            "given",
            "topic",
            "partition"
        ]
    },
    {
        "id": 655,
        "code": "private void setProducerIdAndEpoch(ProducerIdAndEpoch producerIdAndEpoch) {\n    log.info(\"ProducerId set to {} with epoch {}\", producerIdAndEpoch.producerId, producerIdAndEpoch.epoch);\n    this.producerIdAndEpoch = producerIdAndEpoch;\n}",
        "summary_tokens": [
            "set",
            "the",
            "producer",
            "id",
            "and",
            "epoch",
            "atomically"
        ]
    },
    {
        "id": 656,
        "code": "private void resetIdempotentProducerId() {\n    if (isTransactional())\n        throw new IllegalStateException(\"Cannot reset producer state for a transactional producer. \" +\n                \"You must either abort the ongoing transaction or reinitialize the transactional producer instead\");\n    log.debug(\"Resetting idempotent producer ID. ID and epoch before reset are {}\", this.producerIdAndEpoch);\n    setProducerIdAndEpoch(ProducerIdAndEpoch.NONE);\n    transitionTo(State.UNINITIALIZED);\n}",
        "summary_tokens": [
            "this",
            "method",
            "resets",
            "the",
            "producer",
            "id",
            "and",
            "epoch",
            "and",
            "sets",
            "the",
            "state",
            "to",
            "uninitialized",
            "which",
            "will",
            "trigger",
            "a",
            "new",
            "init",
            "producer",
            "id",
            "request"
        ]
    },
    {
        "id": 657,
        "code": "synchronized Integer sequenceNumber(TopicPartition topicPartition) {\n    return txnPartitionMap.getOrCreate(topicPartition).nextSequence;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "next",
            "sequence",
            "number",
            "to",
            "be",
            "written",
            "to",
            "the",
            "given",
            "topic",
            "partition"
        ]
    },
    {
        "id": 658,
        "code": "synchronized int firstInFlightSequence(TopicPartition topicPartition) {\n    if (!hasInflightBatches(topicPartition))\n        return RecordBatch.NO_SEQUENCE;\n\n    SortedSet<ProducerBatch> inflightBatches = txnPartitionMap.get(topicPartition).inflightBatchesBySequence;\n    if (inflightBatches.isEmpty())\n        return RecordBatch.NO_SEQUENCE;\n    else\n        return inflightBatches.first().baseSequence();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "first",
            "inflight",
            "sequence",
            "for",
            "a",
            "given",
            "partition"
        ]
    },
    {
        "id": 659,
        "code": "public static Cluster empty() {\n    return new Cluster(null, new ArrayList<>(0), new ArrayList<>(0), Collections.emptySet(),\n        Collections.emptySet(), null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "empty",
            "cluster",
            "instance",
            "with",
            "no",
            "nodes",
            "and",
            "no",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 660,
        "code": "public static Cluster bootstrap(List<InetSocketAddress> addresses) {\n    List<Node> nodes = new ArrayList<>();\n    int nodeId = -1;\n    for (InetSocketAddress address : addresses)\n        nodes.add(new Node(nodeId--, address.getHostString(), address.getPort()));\n    return new Cluster(null, true, nodes, new ArrayList<>(0),\n        Collections.emptySet(), Collections.emptySet(), Collections.emptySet(), null, Collections.emptyMap());\n}",
        "summary_tokens": [
            "create",
            "a",
            "bootstrap",
            "cluster",
            "using",
            "the",
            "given",
            "list",
            "of",
            "host",
            "ports",
            "addresses",
            "the",
            "addresses",
            "a",
            "cluster",
            "for",
            "these",
            "hosts",
            "ports"
        ]
    },
    {
        "id": 661,
        "code": "public Cluster withPartitions(Map<TopicPartition, PartitionInfo> partitions) {\n    Map<TopicPartition, PartitionInfo> combinedPartitions = new HashMap<>(this.partitionsByTopicPartition);\n    combinedPartitions.putAll(partitions);\n    return new Cluster(clusterResource.clusterId(), this.nodes, combinedPartitions.values(),\n            new HashSet<>(this.unauthorizedTopics), new HashSet<>(this.invalidTopics),\n            new HashSet<>(this.internalTopics), this.controller);\n}",
        "summary_tokens": [
            "return",
            "a",
            "copy",
            "of",
            "this",
            "cluster",
            "combined",
            "with",
            "partitions"
        ]
    },
    {
        "id": 662,
        "code": "public List<Node> nodes() {\n    return this.nodes;\n}",
        "summary_tokens": [
            "the",
            "known",
            "set",
            "of",
            "nodes"
        ]
    },
    {
        "id": 663,
        "code": "public Node nodeById(int id) {\n    return this.nodesById.get(id);\n}",
        "summary_tokens": [
            "get",
            "the",
            "node",
            "by",
            "the",
            "node",
            "id",
            "or",
            "null",
            "if",
            "the",
            "node",
            "is",
            "not",
            "online",
            "or",
            "does",
            "not",
            "exist",
            "id",
            "the",
            "id",
            "of",
            "the",
            "node",
            "the",
            "node",
            "or",
            "null",
            "if",
            "the",
            "node",
            "is",
            "not",
            "online",
            "or",
            "does",
            "not",
            "exist"
        ]
    },
    {
        "id": 664,
        "code": "public Optional<Node> nodeIfOnline(TopicPartition partition, int id) {\n    Node node = nodeById(id);\n    PartitionInfo partitionInfo = partition(partition);\n    if (node != null && partitionInfo != null && !Arrays.asList(partitionInfo.offlineReplicas()).contains(node)) {\n        return Optional.of(node);\n    } else {\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "node",
            "by",
            "node",
            "id",
            "if",
            "the",
            "replica",
            "for",
            "the",
            "given",
            "partition",
            "is",
            "online",
            "partition",
            "id",
            "the",
            "node"
        ]
    },
    {
        "id": 665,
        "code": "public Node leaderFor(TopicPartition topicPartition) {\n    PartitionInfo info = partitionsByTopicPartition.get(topicPartition);\n    if (info == null)\n        return null;\n    else\n        return info.leader();\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "leader",
            "for",
            "the",
            "given",
            "topic",
            "partition",
            "topic",
            "partition",
            "the",
            "topic",
            "and",
            "partition",
            "we",
            "want",
            "to",
            "know",
            "the",
            "leader",
            "for",
            "the",
            "node",
            "that",
            "is",
            "the",
            "leader",
            "for",
            "this",
            "topic",
            "partition",
            "or",
            "null",
            "if",
            "there",
            "is",
            "currently",
            "no",
            "leader"
        ]
    },
    {
        "id": 666,
        "code": "public PartitionInfo partition(TopicPartition topicPartition) {\n    return partitionsByTopicPartition.get(topicPartition);\n}",
        "summary_tokens": [
            "get",
            "the",
            "metadata",
            "for",
            "the",
            "specified",
            "partition",
            "topic",
            "partition",
            "the",
            "topic",
            "and",
            "partition",
            "to",
            "fetch",
            "info",
            "for",
            "the",
            "metadata",
            "about",
            "the",
            "given",
            "topic",
            "and",
            "partition",
            "or",
            "null",
            "if",
            "none",
            "is",
            "found"
        ]
    },
    {
        "id": 667,
        "code": "public List<PartitionInfo> partitionsForTopic(String topic) {\n    return partitionsByTopic.getOrDefault(topic, Collections.emptyList());\n}",
        "summary_tokens": [
            "get",
            "the",
            "list",
            "of",
            "partitions",
            "for",
            "this",
            "topic",
            "topic",
            "the",
            "topic",
            "name",
            "a",
            "list",
            "of",
            "partitions"
        ]
    },
    {
        "id": 668,
        "code": "public Integer partitionCountForTopic(String topic) {\n    List<PartitionInfo> partitions = this.partitionsByTopic.get(topic);\n    return partitions == null ? null : partitions.size();\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "partitions",
            "for",
            "the",
            "given",
            "topic"
        ]
    },
    {
        "id": 669,
        "code": "public List<PartitionInfo> availablePartitionsForTopic(String topic) {\n    return availablePartitionsByTopic.getOrDefault(topic, Collections.emptyList());\n}",
        "summary_tokens": [
            "get",
            "the",
            "list",
            "of",
            "available",
            "partitions",
            "for",
            "this",
            "topic",
            "topic",
            "the",
            "topic",
            "name",
            "a",
            "list",
            "of",
            "partitions"
        ]
    },
    {
        "id": 670,
        "code": "public List<PartitionInfo> partitionsForNode(int nodeId) {\n    return partitionsByNode.getOrDefault(nodeId, Collections.emptyList());\n}",
        "summary_tokens": [
            "get",
            "the",
            "list",
            "of",
            "partitions",
            "whose",
            "leader",
            "is",
            "this",
            "node",
            "node",
            "id",
            "the",
            "node",
            "id",
            "a",
            "list",
            "of",
            "partitions"
        ]
    },
    {
        "id": 671,
        "code": "public String clusterId() {\n    return clusterId;\n}",
        "summary_tokens": [
            "return",
            "the",
            "cluster",
            "id"
        ]
    },
    {
        "id": 672,
        "code": "public Optional<String> listenerName() {\n    return Optional.ofNullable(listenerName);\n}",
        "summary_tokens": [
            "returns",
            "the",
            "listener",
            "name",
            "of",
            "this",
            "endpoint"
        ]
    },
    {
        "id": 673,
        "code": "public SecurityProtocol securityProtocol() {\n    return securityProtocol;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "security",
            "protocol",
            "of",
            "this",
            "endpoint"
        ]
    },
    {
        "id": 674,
        "code": "public String host() {\n    return host;\n}",
        "summary_tokens": [
            "returns",
            "advertised",
            "host",
            "name",
            "of",
            "this",
            "endpoint"
        ]
    },
    {
        "id": 675,
        "code": "public int port() {\n    return port;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "port",
            "to",
            "which",
            "the",
            "listener",
            "is",
            "bound"
        ]
    },
    {
        "id": 676,
        "code": "default void configure(Map<String, ?> configs) {}",
        "summary_tokens": [
            "configures",
            "the",
            "message",
            "formatter",
            "configs",
            "map",
            "to",
            "configure",
            "the",
            "formatter"
        ]
    },
    {
        "id": 677,
        "code": "public String name() {\n    return this.name;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "the",
            "metric"
        ]
    },
    {
        "id": 678,
        "code": "public String group() {\n    return this.group;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "the",
            "group"
        ]
    },
    {
        "id": 679,
        "code": "public String description() {\n    return this.description;\n}",
        "summary_tokens": [
            "get",
            "the",
            "description",
            "of",
            "the",
            "metric"
        ]
    },
    {
        "id": 680,
        "code": "public Set<String> tags() {\n    return tags;\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "tag",
            "names",
            "for",
            "the",
            "metric"
        ]
    },
    {
        "id": 681,
        "code": "public boolean isEmpty() {\n    return host == null || host.isEmpty() || port < 0;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "this",
            "node",
            "is",
            "empty",
            "which",
            "may",
            "be",
            "the",
            "case",
            "if",
            "no",
            "node",
            "is",
            "used",
            "as",
            "a",
            "placeholder",
            "in",
            "a",
            "response",
            "payload",
            "with",
            "an",
            "error"
        ]
    },
    {
        "id": 682,
        "code": "public int id() {\n    return id;\n}",
        "summary_tokens": [
            "the",
            "node",
            "id",
            "of",
            "this",
            "node"
        ]
    },
    {
        "id": 683,
        "code": "public String idString() {\n    return idString;\n}",
        "summary_tokens": [
            "string",
            "representation",
            "of",
            "the",
            "node",
            "id"
        ]
    },
    {
        "id": 684,
        "code": "public String host() {\n    return host;\n}",
        "summary_tokens": [
            "the",
            "host",
            "name",
            "for",
            "this",
            "node"
        ]
    },
    {
        "id": 685,
        "code": "public int port() {\n    return port;\n}",
        "summary_tokens": [
            "the",
            "port",
            "for",
            "this",
            "node"
        ]
    },
    {
        "id": 686,
        "code": "public boolean hasRack() {\n    return rack != null;\n}",
        "summary_tokens": [
            "true",
            "if",
            "this",
            "node",
            "has",
            "a",
            "defined",
            "rack"
        ]
    },
    {
        "id": 687,
        "code": "public String rack() {\n    return rack;\n}",
        "summary_tokens": [
            "the",
            "rack",
            "for",
            "this",
            "node"
        ]
    },
    {
        "id": 688,
        "code": "public Node leader() {\n    return leader;\n}",
        "summary_tokens": [
            "the",
            "node",
            "id",
            "of",
            "the",
            "node",
            "currently",
            "acting",
            "as",
            "a",
            "leader",
            "for",
            "this",
            "partition",
            "or",
            "null",
            "if",
            "there",
            "is",
            "no",
            "leader"
        ]
    },
    {
        "id": 689,
        "code": "public Node[] replicas() {\n    return replicas;\n}",
        "summary_tokens": [
            "the",
            "complete",
            "set",
            "of",
            "replicas",
            "for",
            "this",
            "partition",
            "regardless",
            "of",
            "whether",
            "they",
            "are",
            "alive",
            "or",
            "up",
            "to",
            "date"
        ]
    },
    {
        "id": 690,
        "code": "public Node[] inSyncReplicas() {\n    return inSyncReplicas;\n}",
        "summary_tokens": [
            "the",
            "subset",
            "of",
            "the",
            "replicas",
            "that",
            "are",
            "in",
            "sync",
            "that",
            "is",
            "caught",
            "up",
            "to",
            "the",
            "leader",
            "and",
            "ready",
            "to",
            "take",
            "over",
            "as",
            "leader",
            "if",
            "the",
            "leader",
            "should",
            "fail"
        ]
    },
    {
        "id": 691,
        "code": "public Node[] offlineReplicas() {\n    return offlineReplicas;\n}",
        "summary_tokens": [
            "the",
            "subset",
            "of",
            "the",
            "replicas",
            "that",
            "are",
            "offline"
        ]
    },
    {
        "id": 692,
        "code": "public static TopicIdCollection ofTopicIds(Collection<Uuid> topics) {\n    return new TopicIdCollection(topics);\n}",
        "summary_tokens": [
            "a",
            "collection",
            "of",
            "topics",
            "defined",
            "by",
            "topic",
            "id"
        ]
    },
    {
        "id": 693,
        "code": "public static TopicNameCollection ofTopicNames(Collection<String> topics) {\n    return new TopicNameCollection(topics);\n}",
        "summary_tokens": [
            "a",
            "collection",
            "of",
            "topics",
            "defined",
            "by",
            "topic",
            "name"
        ]
    },
    {
        "id": 694,
        "code": "public Uuid topicId() {\n    return topicId;\n}",
        "summary_tokens": [
            "universally",
            "unique",
            "id",
            "representing",
            "this",
            "topic",
            "partition"
        ]
    },
    {
        "id": 695,
        "code": "public String topic() {\n    return topicPartition.topic();\n}",
        "summary_tokens": [
            "the",
            "topic",
            "name",
            "or",
            "null",
            "if",
            "it",
            "is",
            "unknown"
        ]
    },
    {
        "id": 696,
        "code": "public TopicPartition topicPartition() {\n    return topicPartition;\n}",
        "summary_tokens": [
            "topic",
            "partition",
            "representing",
            "this",
            "instance"
        ]
    },
    {
        "id": 697,
        "code": "public int partition() {\n    return partition;\n}",
        "summary_tokens": [
            "return",
            "the",
            "partition",
            "id"
        ]
    },
    {
        "id": 698,
        "code": "public Node leader() {\n    return leader;\n}",
        "summary_tokens": [
            "return",
            "the",
            "leader",
            "of",
            "the",
            "partition",
            "or",
            "null",
            "if",
            "there",
            "is",
            "none"
        ]
    },
    {
        "id": 699,
        "code": "public List<Node> replicas() {\n    return replicas;\n}",
        "summary_tokens": [
            "return",
            "the",
            "replicas",
            "of",
            "the",
            "partition",
            "in",
            "the",
            "same",
            "order",
            "as",
            "the",
            "replica",
            "assignment"
        ]
    },
    {
        "id": 700,
        "code": "public List<Node> isr() {\n    return isr;\n}",
        "summary_tokens": [
            "return",
            "the",
            "in",
            "sync",
            "replicas",
            "of",
            "the",
            "partition"
        ]
    },
    {
        "id": 701,
        "code": "public static Uuid randomUuid() {\n    Uuid uuid = unsafeRandomUuid();\n    while (uuid.equals(METADATA_TOPIC_ID) || uuid.equals(ZERO_UUID) || uuid.toString().startsWith(\"-\")) {\n        uuid = unsafeRandomUuid();\n    }\n    return uuid;\n}",
        "summary_tokens": [
            "static",
            "factory",
            "to",
            "retrieve",
            "a",
            "type",
            "0",
            "pseudo",
            "randomly",
            "generated",
            "uuid"
        ]
    },
    {
        "id": 702,
        "code": "public long getMostSignificantBits() {\n    return this.mostSignificantBits;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "most",
            "significant",
            "bits",
            "of",
            "the",
            "uuid",
            "s",
            "0",
            "value"
        ]
    },
    {
        "id": 703,
        "code": "public long getLeastSignificantBits() {\n    return this.leastSignificantBits;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "least",
            "significant",
            "bits",
            "of",
            "the",
            "uuid",
            "s",
            "0",
            "value"
        ]
    },
    {
        "id": 704,
        "code": "public boolean equals(Object obj) {\n    if ((null == obj) || (obj.getClass() != this.getClass()))\n        return false;\n    Uuid id = (Uuid) obj;\n    return this.mostSignificantBits == id.mostSignificantBits &&\n            this.leastSignificantBits == id.leastSignificantBits;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "iff",
            "obj",
            "is",
            "another",
            "uuid",
            "represented",
            "by",
            "the",
            "same",
            "two",
            "long",
            "values"
        ]
    },
    {
        "id": 705,
        "code": "public int hashCode() {\n    long xor = mostSignificantBits ^ leastSignificantBits;\n    return (int) (xor >> 32) ^ (int) xor;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "hash",
            "code",
            "for",
            "this",
            "uuid"
        ]
    },
    {
        "id": 706,
        "code": "public String toString() {\n    return Base64.getUrlEncoder().withoutPadding().encodeToString(getBytesFromUuid());\n}",
        "summary_tokens": [
            "returns",
            "a",
            "base",
            "0",
            "string",
            "encoding",
            "of",
            "the",
            "uuid"
        ]
    },
    {
        "id": 707,
        "code": "public static Uuid fromString(String str) {\n    if (str.length() > 24) {\n        throw new IllegalArgumentException(\"Input string with prefix `\"\n            + str.substring(0, 24) + \"` is too long to be decoded as a base64 UUID\");\n    }\n\n    ByteBuffer uuidBytes = ByteBuffer.wrap(Base64.getUrlDecoder().decode(str));\n    if (uuidBytes.remaining() != 16) {\n        throw new IllegalArgumentException(\"Input string `\" + str + \"` decoded as \"\n            + uuidBytes.remaining() + \" bytes, which is not equal to the expected 16 bytes \"\n            + \"of a base64-encoded UUID\");\n    }\n\n    return new Uuid(uuidBytes.getLong(), uuidBytes.getLong());\n}",
        "summary_tokens": [
            "creates",
            "a",
            "uuid",
            "based",
            "on",
            "a",
            "base",
            "0",
            "string",
            "encoding",
            "used",
            "in",
            "the",
            "to",
            "string",
            "method"
        ]
    },
    {
        "id": 708,
        "code": "public String principal() {\n    return data.principal();\n}",
        "summary_tokens": [
            "return",
            "the",
            "principal",
            "for",
            "this",
            "entry"
        ]
    },
    {
        "id": 709,
        "code": "public String host() {\n    return data.host();\n}",
        "summary_tokens": [
            "return",
            "the",
            "host",
            "or",
            "for",
            "all",
            "hosts"
        ]
    },
    {
        "id": 710,
        "code": "public AclOperation operation() {\n    return data.operation();\n}",
        "summary_tokens": [
            "return",
            "the",
            "acl",
            "operation"
        ]
    },
    {
        "id": 711,
        "code": "public AclPermissionType permissionType() {\n    return data.permissionType();\n}",
        "summary_tokens": [
            "return",
            "the",
            "acl",
            "permission",
            "type"
        ]
    },
    {
        "id": 712,
        "code": "public AccessControlEntryFilter toFilter() {\n    return new AccessControlEntryFilter(data);\n}",
        "summary_tokens": [
            "create",
            "a",
            "filter",
            "which",
            "matches",
            "only",
            "this",
            "access",
            "control",
            "entry"
        ]
    },
    {
        "id": 713,
        "code": "public boolean isUnknown() {\n    return data.isUnknown();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "acl",
            "resource",
            "has",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 714,
        "code": "public String findIndefiniteField() {\n    if (principal() == null)\n        return \"Principal is NULL\";\n    if (host() == null)\n        return \"Host is NULL\";\n    if (operation() == AclOperation.ANY)\n        return \"Operation is ANY\";\n    if (operation() == AclOperation.UNKNOWN)\n        return \"Operation is UNKNOWN\";\n    if (permissionType() == AclPermissionType.ANY)\n        return \"Permission type is ANY\";\n    if (permissionType() == AclPermissionType.UNKNOWN)\n        return \"Permission type is UNKNOWN\";\n    return null;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "string",
            "describing",
            "an",
            "any",
            "or",
            "unknown",
            "field",
            "or",
            "null",
            "if",
            "there",
            "is",
            "no",
            "such",
            "field"
        ]
    },
    {
        "id": 715,
        "code": "boolean isUnknown() {\n    return operation.isUnknown() || permissionType.isUnknown();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "there",
            "are",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 716,
        "code": "public String principal() {\n    return data.principal();\n}",
        "summary_tokens": [
            "return",
            "the",
            "principal",
            "or",
            "null"
        ]
    },
    {
        "id": 717,
        "code": "public String host() {\n    return data.host();\n}",
        "summary_tokens": [
            "return",
            "the",
            "host",
            "or",
            "null"
        ]
    },
    {
        "id": 718,
        "code": "public AclOperation operation() {\n    return data.operation();\n}",
        "summary_tokens": [
            "return",
            "the",
            "acl",
            "operation"
        ]
    },
    {
        "id": 719,
        "code": "public AclPermissionType permissionType() {\n    return data.permissionType();\n}",
        "summary_tokens": [
            "return",
            "the",
            "acl",
            "permission",
            "type"
        ]
    },
    {
        "id": 720,
        "code": "public boolean isUnknown() {\n    return data.isUnknown();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "there",
            "are",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 721,
        "code": "public boolean matches(AccessControlEntry other) {\n    if ((principal() != null) && (!principal().equals(other.principal())))\n        return false;\n    if ((host() != null) && (!host().equals(other.host())))\n        return false;\n    if ((operation() != AclOperation.ANY) && (!operation().equals(other.operation())))\n        return false;\n    return (permissionType() == AclPermissionType.ANY) || (permissionType().equals(other.permissionType()));\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "filter",
            "matches",
            "the",
            "given",
            "access",
            "control",
            "entry"
        ]
    },
    {
        "id": 722,
        "code": "public boolean matchesAtMostOne() {\n    return findIndefiniteField() == null;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "filter",
            "could",
            "only",
            "match",
            "one",
            "ace",
            "in",
            "other",
            "words",
            "if",
            "there",
            "are",
            "no",
            "any",
            "or",
            "unknown",
            "fields"
        ]
    },
    {
        "id": 723,
        "code": "public String findIndefiniteField() {\n    return data.findIndefiniteField();\n}",
        "summary_tokens": [
            "returns",
            "a",
            "string",
            "describing",
            "an",
            "any",
            "or",
            "unknown",
            "field",
            "or",
            "null",
            "if",
            "there",
            "is",
            "no",
            "such",
            "field"
        ]
    },
    {
        "id": 724,
        "code": "public boolean isUnknown() {\n    return pattern.isUnknown() || entry.isUnknown();\n}",
        "summary_tokens": [
            "true",
            "if",
            "this",
            "binding",
            "has",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 725,
        "code": "public ResourcePattern pattern() {\n    return pattern;\n}",
        "summary_tokens": [
            "the",
            "resource",
            "pattern",
            "for",
            "this",
            "binding"
        ]
    },
    {
        "id": 726,
        "code": "public final AccessControlEntry entry() {\n    return entry;\n}",
        "summary_tokens": [
            "the",
            "access",
            "control",
            "entry",
            "for",
            "this",
            "binding"
        ]
    },
    {
        "id": 727,
        "code": "public AclBindingFilter toFilter() {\n    return new AclBindingFilter(pattern.toFilter(), entry.toFilter());\n}",
        "summary_tokens": [
            "create",
            "a",
            "filter",
            "which",
            "matches",
            "only",
            "this",
            "acl",
            "binding"
        ]
    },
    {
        "id": 728,
        "code": "public boolean isUnknown() {\n    return patternFilter.isUnknown() || entryFilter.isUnknown();\n}",
        "summary_tokens": [
            "true",
            "if",
            "this",
            "filter",
            "has",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 729,
        "code": "public ResourcePatternFilter patternFilter() {\n    return patternFilter;\n}",
        "summary_tokens": [
            "the",
            "resource",
            "pattern",
            "filter"
        ]
    },
    {
        "id": 730,
        "code": "public final AccessControlEntryFilter entryFilter() {\n    return entryFilter;\n}",
        "summary_tokens": [
            "the",
            "access",
            "control",
            "entry",
            "filter"
        ]
    },
    {
        "id": 731,
        "code": "public boolean matchesAtMostOne() {\n    return patternFilter.matchesAtMostOne() && entryFilter.matchesAtMostOne();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "resource",
            "and",
            "entry",
            "filters",
            "can",
            "only",
            "match",
            "one",
            "ace"
        ]
    },
    {
        "id": 732,
        "code": "public String findIndefiniteField() {\n    String indefinite = patternFilter.findIndefiniteField();\n    if (indefinite != null)\n        return indefinite;\n    return entryFilter.findIndefiniteField();\n}",
        "summary_tokens": [
            "return",
            "a",
            "string",
            "describing",
            "an",
            "any",
            "or",
            "unknown",
            "field",
            "or",
            "null",
            "if",
            "there",
            "is",
            "no",
            "such",
            "field"
        ]
    },
    {
        "id": 733,
        "code": "public boolean matches(AclBinding binding) {\n    return patternFilter.matches(binding.pattern()) && entryFilter.matches(binding.entry());\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "resource",
            "filter",
            "matches",
            "the",
            "binding",
            "s",
            "resource",
            "and",
            "the",
            "entry",
            "filter",
            "matches",
            "binding",
            "s",
            "entry"
        ]
    },
    {
        "id": 734,
        "code": "public boolean ignoreFlagDescriptorChecksum() {\n    return this.ignoreFlagDescriptorChecksum;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "kafka",
            "lz",
            "0",
            "block",
            "input",
            "stream",
            "is",
            "configured",
            "to",
            "ignore",
            "the",
            "frame",
            "descriptor",
            "checksum",
            "which",
            "is",
            "useful",
            "for",
            "compatibility",
            "with",
            "old",
            "client",
            "implementations",
            "that",
            "use",
            "incorrect",
            "checksum",
            "calculations"
        ]
    },
    {
        "id": 735,
        "code": "private void readHeader() throws IOException {\n        \n    if (in.remaining() < 6) {\n        throw new IOException(PREMATURE_EOS);\n    }\n\n    if (MAGIC != in.getInt()) {\n        throw new IOException(NOT_SUPPORTED);\n    }\n        \n    in.mark();\n\n    flg = FLG.fromByte(in.get());\n    maxBlockSize = BD.fromByte(in.get()).getBlockMaximumSize();\n\n    if (flg.isContentSizeSet()) {\n        if (in.remaining() < 8) {\n            throw new IOException(PREMATURE_EOS);\n        }\n        in.position(in.position() + 8);\n    }\n\n        \n\n        \n    if (ignoreFlagDescriptorChecksum) {\n        in.position(in.position() + 1);\n        return;\n    }\n\n    int len = in.position() - in.reset().position();\n\n    int hash = CHECKSUM.hash(in, in.position(), len, 0);\n    in.position(in.position() + len);\n    if (in.get() != (byte) ((hash >> 8) & 0xFF)) {\n        throw new IOException(DESCRIPTOR_HASH_MISMATCH);\n    }\n}",
        "summary_tokens": [
            "reads",
            "the",
            "magic",
            "number",
            "and",
            "frame",
            "descriptor",
            "from",
            "input",
            "buffer"
        ]
    },
    {
        "id": 736,
        "code": "private void readBlock() throws IOException {\n    if (in.remaining() < 4) {\n        throw new IOException(PREMATURE_EOS);\n    }\n\n    int blockSize = in.getInt();\n    boolean compressed = (blockSize & LZ4_FRAME_INCOMPRESSIBLE_MASK) == 0;\n    blockSize &= ~LZ4_FRAME_INCOMPRESSIBLE_MASK;\n\n        \n    if (blockSize == 0) {\n        finished = true;\n        if (flg.isContentChecksumSet())\n            in.getInt(); \n        return;\n    } else if (blockSize > maxBlockSize) {\n        throw new IOException(String.format(\"Block size %d exceeded max: %d\", blockSize, maxBlockSize));\n    }\n\n    if (in.remaining() < blockSize) {\n        throw new IOException(PREMATURE_EOS);\n    }\n\n    if (compressed) {\n        try {\n            final int bufferSize = DECOMPRESSOR.decompress(in, in.position(), blockSize, decompressionBuffer, 0,\n                maxBlockSize);\n            decompressionBuffer.position(0);\n            decompressionBuffer.limit(bufferSize);\n            decompressedBuffer = decompressionBuffer;\n        } catch (LZ4Exception e) {\n            throw new IOException(e);\n        }\n    } else {\n        decompressedBuffer = in.slice();\n        decompressedBuffer.limit(blockSize);\n    }\n\n        \n    if (flg.isBlockChecksumSet()) {\n        int hash = CHECKSUM.hash(in, in.position(), blockSize, 0);\n        in.position(in.position() + blockSize);\n        if (hash != in.getInt()) {\n            throw new IOException(BLOCK_HASH_MISMATCH);\n        }\n    } else {\n        in.position(in.position() + blockSize);\n    }\n}",
        "summary_tokens": [
            "decompresses",
            "if",
            "necessary",
            "buffered",
            "data",
            "optionally",
            "computes",
            "and",
            "validates",
            "a",
            "xxhash",
            "0",
            "checksum",
            "and",
            "writes",
            "the",
            "result",
            "to",
            "a",
            "buffer"
        ]
    },
    {
        "id": 737,
        "code": "static void detectBrokenLz4Version() {\n    byte[] source = new byte[]{1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3};\n    final LZ4Compressor compressor = LZ4Factory.fastestInstance().fastCompressor();\n\n    final byte[] compressed = new byte[compressor.maxCompressedLength(source.length)];\n    final int compressedLength = compressor.compress(source, 0, source.length, compressed, 0,\n                                                     compressed.length);\n\n        \n        \n        \n    final byte[] zeroes = {0, 0, 0, 0, 0};\n    ByteBuffer nonZeroOffsetBuffer = ByteBuffer\n        .allocate(zeroes.length + compressed.length) \n        .put(zeroes) \n        .slice() \n        .put(compressed); \n\n    ByteBuffer dest = ByteBuffer.allocate(source.length);\n    try {\n        DECOMPRESSOR.decompress(nonZeroOffsetBuffer, 0, compressedLength, dest, 0, source.length);\n    } catch (Exception e) {\n        throw new RuntimeException(\"Kafka has detected detected a buggy lz4-java library (< 1.4.x) on the classpath.\"\n                                   + \" If you are using Kafka client libraries, make sure your application does not\"\n                                   + \" accidentally override the version provided by Kafka or include multiple versions\"\n                                   + \" of the library on the classpath. The lz4-java version on the classpath should\"\n                                   + \" match the version the Kafka client libraries depend on. Adding -verbose:class\"\n                                   + \" to your JVM arguments may help understand which lz4-java version is getting loaded.\", e);\n    }\n}",
        "summary_tokens": [
            "checks",
            "whether",
            "the",
            "version",
            "of",
            "lz",
            "0",
            "on",
            "the",
            "classpath",
            "has",
            "the",
            "fix",
            "for",
            "reading",
            "from",
            "byte",
            "buffers",
            "with",
            "non",
            "zero",
            "array",
            "offsets",
            "see",
            "https",
            "github"
        ]
    },
    {
        "id": 738,
        "code": "public boolean useBrokenFlagDescriptorChecksum() {\n    return this.useBrokenFlagDescriptorChecksum;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "kafka",
            "lz",
            "0",
            "block",
            "input",
            "stream",
            "is",
            "configured",
            "to",
            "write",
            "an",
            "incorrect",
            "frame",
            "descriptor",
            "checksum",
            "which",
            "is",
            "useful",
            "for",
            "compatibility",
            "with",
            "old",
            "client",
            "implementations"
        ]
    },
    {
        "id": 739,
        "code": "private void writeHeader() throws IOException {\n    ByteUtils.writeUnsignedIntLE(buffer, 0, MAGIC);\n    bufferOffset = 4;\n    buffer[bufferOffset++] = flg.toByte();\n    buffer[bufferOffset++] = bd.toByte();\n        \n\n        \n    int offset = 4;\n    int len = bufferOffset - offset;\n    if (this.useBrokenFlagDescriptorChecksum) {\n        len += offset;\n        offset = 0;\n    }\n    byte hash = (byte) ((checksum.hash(buffer, offset, len, 0) >> 8) & 0xFF);\n    buffer[bufferOffset++] = hash;\n\n        \n    out.write(buffer, 0, bufferOffset);\n    bufferOffset = 0;\n}",
        "summary_tokens": [
            "writes",
            "the",
            "magic",
            "number",
            "and",
            "frame",
            "descriptor",
            "to",
            "the",
            "underlying",
            "output",
            "stream"
        ]
    },
    {
        "id": 740,
        "code": "private void writeBlock() throws IOException {\n    if (bufferOffset == 0) {\n        return;\n    }\n\n    int compressedLength = compressor.compress(buffer, 0, bufferOffset, compressedBuffer, 0);\n    byte[] bufferToWrite = compressedBuffer;\n    int compressMethod = 0;\n\n        \n    if (compressedLength >= bufferOffset) {\n        bufferToWrite = buffer;\n        compressedLength = bufferOffset;\n        compressMethod = LZ4_FRAME_INCOMPRESSIBLE_MASK;\n    }\n\n        \n    ByteUtils.writeUnsignedIntLE(out, compressedLength | compressMethod);\n    out.write(bufferToWrite, 0, compressedLength);\n\n        \n    if (flg.isBlockChecksumSet()) {\n        int hash = checksum.hash(bufferToWrite, 0, compressedLength, 0);\n        ByteUtils.writeUnsignedIntLE(out, hash);\n    }\n    bufferOffset = 0;\n}",
        "summary_tokens": [
            "compresses",
            "buffered",
            "data",
            "optionally",
            "computes",
            "an",
            "xxhash",
            "0",
            "checksum",
            "and",
            "writes",
            "the",
            "result",
            "to",
            "the",
            "underlying",
            "output",
            "stream"
        ]
    },
    {
        "id": 741,
        "code": "private void writeEndMark() throws IOException {\n    ByteUtils.writeUnsignedIntLE(out, 0);\n        \n}",
        "summary_tokens": [
            "similar",
            "to",
            "the",
            "write",
            "block",
            "method"
        ]
    },
    {
        "id": 742,
        "code": "private void ensureNotFinished() {\n    if (finished) {\n        throw new IllegalStateException(CLOSED_STREAM);\n    }\n}",
        "summary_tokens": [
            "a",
            "simple",
            "state",
            "check",
            "to",
            "ensure",
            "the",
            "stream",
            "is",
            "still",
            "open"
        ]
    },
    {
        "id": 743,
        "code": "protected Map<String, Object> postProcessParsedConfig(Map<String, Object> parsedValues) {\n    return Collections.emptyMap();\n}",
        "summary_tokens": [
            "called",
            "directly",
            "after",
            "user",
            "configs",
            "got",
            "parsed",
            "and",
            "thus",
            "default",
            "values",
            "got",
            "set"
        ]
    },
    {
        "id": 744,
        "code": "public Map<String, String> originalsStrings() {\n    Map<String, String> copy = new RecordingMap<>();\n    for (Map.Entry<String, ?> entry : originals.entrySet()) {\n        if (!(entry.getValue() instanceof String))\n            throw new ClassCastException(\"Non-string value found in original settings for key \" + entry.getKey() +\n                    \": \" + (entry.getValue() == null ? null : entry.getValue().getClass().getName()));\n        copy.put(entry.getKey(), (String) entry.getValue());\n    }\n    return copy;\n}",
        "summary_tokens": [
            "get",
            "all",
            "the",
            "original",
            "settings",
            "ensuring",
            "that",
            "all",
            "values",
            "are",
            "of",
            "type",
            "string"
        ]
    },
    {
        "id": 745,
        "code": "public Map<String, Object> originalsWithPrefix(String prefix, boolean strip) {\n    Map<String, Object> result = new RecordingMap<>(prefix, false);\n    for (Map.Entry<String, ?> entry : originals.entrySet()) {\n        if (entry.getKey().startsWith(prefix) && entry.getKey().length() > prefix.length()) {\n            if (strip)\n                result.put(entry.getKey().substring(prefix.length()), entry.getValue());\n            else\n                result.put(entry.getKey(), entry.getValue());\n        }\n    }\n    return result;\n}",
        "summary_tokens": [
            "gets",
            "all",
            "original",
            "settings",
            "with",
            "the",
            "given",
            "prefix"
        ]
    },
    {
        "id": 746,
        "code": "public Map<String, Object> valuesWithPrefixOverride(String prefix) {\n    Map<String, Object> result = new RecordingMap<>(values(), prefix, true);\n    for (Map.Entry<String, ?> entry : originals.entrySet()) {\n        if (entry.getKey().startsWith(prefix) && entry.getKey().length() > prefix.length()) {\n            String keyWithNoPrefix = entry.getKey().substring(prefix.length());\n            ConfigDef.ConfigKey configKey = definition.configKeys().get(keyWithNoPrefix);\n            if (configKey != null)\n                result.put(keyWithNoPrefix, definition.parseValue(configKey, entry.getValue(), true));\n            else {\n                String keyWithNoSecondaryPrefix = keyWithNoPrefix.substring(keyWithNoPrefix.indexOf('.') + 1);\n                configKey = definition.configKeys().get(keyWithNoSecondaryPrefix);\n                if (configKey != null)\n                    result.put(keyWithNoPrefix, definition.parseValue(configKey, entry.getValue(), true));\n            }\n        }\n    }\n    return result;\n}",
        "summary_tokens": [
            "put",
            "all",
            "keys",
            "that",
            "do",
            "not",
            "start",
            "with",
            "prefix",
            "and",
            "their",
            "parsed",
            "values",
            "in",
            "the",
            "result",
            "map",
            "and",
            "then",
            "put",
            "all",
            "the",
            "remaining",
            "keys",
            "with",
            "the",
            "prefix",
            "stripped",
            "and",
            "their",
            "parsed",
            "values",
            "in",
            "the",
            "result",
            "map"
        ]
    },
    {
        "id": 747,
        "code": "public Map<String, Object> valuesWithPrefixAllOrNothing(String prefix) {\n    Map<String, Object> withPrefix = originalsWithPrefix(prefix, true);\n\n    if (withPrefix.isEmpty()) {\n        return new RecordingMap<>(values(), \"\", true);\n    } else {\n        Map<String, Object> result = new RecordingMap<>(prefix, true);\n\n        for (Map.Entry<String, ?> entry : withPrefix.entrySet()) {\n            ConfigDef.ConfigKey configKey = definition.configKeys().get(entry.getKey());\n            if (configKey != null)\n                result.put(entry.getKey(), definition.parseValue(configKey, entry.getValue(), true));\n        }\n\n        return result;\n    }\n}",
        "summary_tokens": [
            "if",
            "at",
            "least",
            "one",
            "key",
            "with",
            "prefix",
            "exists",
            "all",
            "prefixed",
            "values",
            "will",
            "be",
            "parsed",
            "and",
            "put",
            "into",
            "map"
        ]
    },
    {
        "id": 748,
        "code": "public void logUnused() {\n    Set<String> unusedkeys = unused();\n    if (!unusedkeys.isEmpty()) {\n        log.warn(\"These configurations '{}' were supplied but are not used yet.\", unusedkeys);\n    }\n}",
        "summary_tokens": [
            "log",
            "warnings",
            "for",
            "any",
            "unused",
            "configurations"
        ]
    },
    {
        "id": 749,
        "code": "public <T> T getConfiguredInstance(String key, Class<T> t, Map<String, Object> configOverrides) {\n    Class<?> c = getClass(key);\n\n    return getConfiguredInstance(c, t, originals(configOverrides));\n}",
        "summary_tokens": [
            "get",
            "a",
            "configured",
            "instance",
            "of",
            "the",
            "give",
            "class",
            "specified",
            "by",
            "the",
            "given",
            "configuration",
            "key"
        ]
    },
    {
        "id": 750,
        "code": "public <T> List<T> getConfiguredInstances(List<String> classNames, Class<T> t, Map<String, Object> configOverrides) {\n    List<T> objects = new ArrayList<>();\n    if (classNames == null)\n        return objects;\n    Map<String, Object> configPairs = originals();\n    configPairs.putAll(configOverrides);\n    for (Object klass : classNames) {\n        Object o = getConfiguredInstance(klass, t, configPairs);\n        objects.add(t.cast(o));\n    }\n    return objects;\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "configured",
            "instances",
            "of",
            "the",
            "given",
            "class",
            "specified",
            "by",
            "the",
            "given",
            "configuration",
            "key"
        ]
    },
    {
        "id": 751,
        "code": "private  Map<String, ?> resolveConfigVariables(Map<String, ?> configProviderProps, Map<String, Object> originals) {\n    Map<String, String> providerConfigString;\n    Map<String, ?> configProperties;\n    Map<String, Object> resolvedOriginals = new HashMap<>();\n        \n    Map<String, String> indirectVariables = extractPotentialVariables(originals);\n\n    resolvedOriginals.putAll(originals);\n    if (configProviderProps == null || configProviderProps.isEmpty()) {\n        providerConfigString = indirectVariables;\n        configProperties = originals;\n    } else {\n        providerConfigString = extractPotentialVariables(configProviderProps);\n        configProperties = configProviderProps;\n    }\n    Map<String, ConfigProvider> providers = instantiateConfigProviders(providerConfigString, configProperties);\n\n    if (!providers.isEmpty()) {\n        ConfigTransformer configTransformer = new ConfigTransformer(providers);\n        ConfigTransformerResult result = configTransformer.transform(indirectVariables);\n        if (!result.data().isEmpty()) {\n            resolvedOriginals.putAll(result.data());\n        }\n    }\n    providers.values().forEach(x -> Utils.closeQuietly(x, \"config provider\"));\n\n    return new ResolvingMap<>(resolvedOriginals, originals);\n}",
        "summary_tokens": [
            "instantiates",
            "given",
            "list",
            "of",
            "config",
            "providers",
            "and",
            "fetches",
            "the",
            "actual",
            "values",
            "of",
            "config",
            "variables",
            "from",
            "the",
            "config",
            "providers"
        ]
    },
    {
        "id": 752,
        "code": "private Map<String, ConfigProvider> instantiateConfigProviders(Map<String, String> indirectConfigs, Map<String, ?> providerConfigProperties) {\n    final String configProviders = indirectConfigs.get(CONFIG_PROVIDERS_CONFIG);\n\n    if (configProviders == null || configProviders.isEmpty()) {\n        return Collections.emptyMap();\n    }\n\n    Map<String, String> providerMap = new HashMap<>();\n\n    for (String provider: configProviders.split(\",\")) {\n        String providerClass = providerClassProperty(provider);\n        if (indirectConfigs.containsKey(providerClass))\n            providerMap.put(provider, indirectConfigs.get(providerClass));\n\n    }\n        \n    Map<String, ConfigProvider> configProviderInstances = new HashMap<>();\n    for (Map.Entry<String, String> entry : providerMap.entrySet()) {\n        try {\n            String prefix = CONFIG_PROVIDERS_CONFIG + \".\" + entry.getKey() + CONFIG_PROVIDERS_PARAM;\n            Map<String, ?> configProperties = configProviderProperties(prefix, providerConfigProperties);\n            ConfigProvider provider = Utils.newInstance(entry.getValue(), ConfigProvider.class);\n            provider.configure(configProperties);\n            configProviderInstances.put(entry.getKey(), provider);\n        } catch (ClassNotFoundException e) {\n            log.error(\"Could not load config provider class \" + entry.getValue(), e);\n            throw new ConfigException(providerClassProperty(entry.getKey()), entry.getValue(), \"Could not load config provider class or one of its dependencies\");\n        }\n    }\n\n    return configProviderInstances;\n}",
        "summary_tokens": [
            "instantiates",
            "and",
            "configures",
            "the",
            "config",
            "providers"
        ]
    },
    {
        "id": 753,
        "code": "public Long ttl() {\n    return ttl;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "ttl",
            "in",
            "milliseconds"
        ]
    },
    {
        "id": 754,
        "code": "public Set<String> names() {\n    return Collections.unmodifiableSet(configKeys.keySet());\n}",
        "summary_tokens": [
            "returns",
            "unmodifiable",
            "set",
            "of",
            "properties",
            "names",
            "defined",
            "in",
            "this",
            "config",
            "def"
        ]
    },
    {
        "id": 755,
        "code": "public ConfigDef define(String name, Type type, Importance importance, String documentation) {\n    return define(name, type, NO_DEFAULT_VALUE, null, importance, documentation);\n}",
        "summary_tokens": [
            "define",
            "a",
            "new",
            "configuration",
            "with",
            "no",
            "default",
            "value",
            "and",
            "no",
            "special",
            "validation",
            "logic",
            "name",
            "the",
            "name",
            "of",
            "the",
            "config",
            "parameter",
            "type",
            "the",
            "type",
            "of",
            "the",
            "config",
            "importance",
            "the",
            "importance",
            "of",
            "this",
            "config",
            "is",
            "this",
            "something",
            "you",
            "will",
            "likely",
            "need",
            "to",
            "change"
        ]
    },
    {
        "id": 756,
        "code": "public ConfigDef defineInternal(final String name, final Type type, final Object defaultValue, final Validator validator, final Importance importance, final String documentation) {\n    return define(new ConfigKey(name, type, defaultValue, validator, importance, documentation, \"\", -1, Width.NONE, name, Collections.<String>emptyList(), null, true));\n}",
        "summary_tokens": [
            "define",
            "a",
            "new",
            "internal",
            "configuration"
        ]
    },
    {
        "id": 757,
        "code": "public Map<String, ConfigKey> configKeys() {\n    return configKeys;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configuration",
            "keys",
            "a",
            "map",
            "containing",
            "all",
            "configuration",
            "keys"
        ]
    },
    {
        "id": 758,
        "code": "public List<String> groups() {\n    return groups;\n}",
        "summary_tokens": [
            "get",
            "the",
            "groups",
            "for",
            "the",
            "configuration",
            "a",
            "list",
            "of",
            "group",
            "names"
        ]
    },
    {
        "id": 759,
        "code": "public ConfigDef withClientSslSupport() {\n    SslConfigs.addClientSslSupport(this);\n    return this;\n}",
        "summary_tokens": [
            "add",
            "standard",
            "ssl",
            "client",
            "configuration",
            "options"
        ]
    },
    {
        "id": 760,
        "code": "public ConfigDef withClientSaslSupport() {\n    SaslConfigs.addClientSaslSupport(this);\n    return this;\n}",
        "summary_tokens": [
            "add",
            "standard",
            "sasl",
            "client",
            "configuration",
            "options"
        ]
    },
    {
        "id": 761,
        "code": "public Map<String, Object> parse(Map<?, ?> props) {\n        \n    List<String> undefinedConfigKeys = undefinedDependentConfigs();\n    if (!undefinedConfigKeys.isEmpty()) {\n        String joined = Utils.join(undefinedConfigKeys, \",\");\n        throw new ConfigException(\"Some configurations in are referred in the dependents, but not defined: \" + joined);\n    }\n        \n    Map<String, Object> values = new HashMap<>();\n    for (ConfigKey key : configKeys.values())\n        values.put(key.name, parseValue(key, props.get(key.name), props.containsKey(key.name)));\n    return values;\n}",
        "summary_tokens": [
            "parse",
            "and",
            "validate",
            "configs",
            "against",
            "this",
            "configuration",
            "definition"
        ]
    },
    {
        "id": 762,
        "code": "public List<ConfigValue> validate(Map<String, String> props) {\n    return new ArrayList<>(validateAll(props).values());\n}",
        "summary_tokens": [
            "validate",
            "the",
            "current",
            "configuration",
            "values",
            "with",
            "the",
            "configuration",
            "definition"
        ]
    },
    {
        "id": 763,
        "code": "public static Object parseType(String name, Object value, Type type) {\n    try {\n        if (value == null) return null;\n\n        String trimmed = null;\n        if (value instanceof String)\n            trimmed = ((String) value).trim();\n\n        switch (type) {\n            case BOOLEAN:\n                if (value instanceof String) {\n                    if (trimmed.equalsIgnoreCase(\"true\"))\n                        return true;\n                    else if (trimmed.equalsIgnoreCase(\"false\"))\n                        return false;\n                    else\n                        throw new ConfigException(name, value, \"Expected value to be either true or false\");\n                } else if (value instanceof Boolean)\n                    return value;\n                else\n                    throw new ConfigException(name, value, \"Expected value to be either true or false\");\n            case PASSWORD:\n                if (value instanceof Password)\n                    return value;\n                else if (value instanceof String)\n                    return new Password(trimmed);\n                else\n                    throw new ConfigException(name, value, \"Expected value to be a string, but it was a \" + value.getClass().getName());\n            case STRING:\n                if (value instanceof String)\n                    return trimmed;\n                else\n                    throw new ConfigException(name, value, \"Expected value to be a string, but it was a \" + value.getClass().getName());\n            case INT:\n                if (value instanceof Integer) {\n                    return value;\n                } else if (value instanceof String) {\n                    return Integer.parseInt(trimmed);\n                } else {\n                    throw new ConfigException(name, value, \"Expected value to be a 32-bit integer, but it was a \" + value.getClass().getName());\n                }\n            case SHORT:\n                if (value instanceof Short) {\n                    return value;\n                } else if (value instanceof String) {\n                    return Short.parseShort(trimmed);\n                } else {\n                    throw new ConfigException(name, value, \"Expected value to be a 16-bit integer (short), but it was a \" + value.getClass().getName());\n                }\n            case LONG:\n                if (value instanceof Integer)\n                    return ((Integer) value).longValue();\n                if (value instanceof Long)\n                    return value;\n                else if (value instanceof String)\n                    return Long.parseLong(trimmed);\n                else\n                    throw new ConfigException(name, value, \"Expected value to be a 64-bit integer (long), but it was a \" + value.getClass().getName());\n            case DOUBLE:\n                if (value instanceof Number)\n                    return ((Number) value).doubleValue();\n                else if (value instanceof String)\n                    return Double.parseDouble(trimmed);\n                else\n                    throw new ConfigException(name, value, \"Expected value to be a double, but it was a \" + value.getClass().getName());\n            case LIST:\n                if (value instanceof List)\n                    return value;\n                else if (value instanceof String)\n                    if (trimmed.isEmpty())\n                        return Collections.emptyList();\n                    else\n                        return Arrays.asList(COMMA_WITH_WHITESPACE.split(trimmed, -1));\n                else\n                    throw new ConfigException(name, value, \"Expected a comma separated list.\");\n            case CLASS:\n                if (value instanceof Class)\n                    return value;\n                else if (value instanceof String) {\n                    ClassLoader contextOrKafkaClassLoader = Utils.getContextOrKafkaClassLoader();\n                        \n                        \n                        \n                    Class<?> klass = contextOrKafkaClassLoader.loadClass(trimmed);\n                        \n                        \n                    return Class.forName(klass.getName(), true, contextOrKafkaClassLoader);\n                } else\n                    throw new ConfigException(name, value, \"Expected a Class instance or class name.\");\n            default:\n                throw new IllegalStateException(\"Unknown type.\");\n        }\n    } catch (NumberFormatException e) {\n        throw new ConfigException(name, value, \"Not a number of type \" + type);\n    } catch (ClassNotFoundException e) {\n        throw new ConfigException(name, value, \"Class \" + value + \" could not be found.\");\n    }\n}",
        "summary_tokens": [
            "parse",
            "a",
            "value",
            "according",
            "to",
            "its",
            "expected",
            "type"
        ]
    },
    {
        "id": 764,
        "code": "public static  Map<String, String> convertToStringMapWithPasswordValues(Map<String, ?> configs) {\n    Map<String, String> result = new HashMap<>();\n    for (Map.Entry<String, ?> entry : configs.entrySet()) {\n        Object value = entry.getValue();\n        String strValue;\n        if (value instanceof Password)\n            strValue = ((Password) value).value();\n        else if (value instanceof List)\n            strValue = convertToString(value, Type.LIST);\n        else if (value instanceof Class)\n            strValue = convertToString(value, Type.CLASS);\n        else\n            strValue = convertToString(value, null);\n        if (strValue != null)\n            result.put(entry.getKey(), strValue);\n    }\n    return result;\n}",
        "summary_tokens": [
            "converts",
            "a",
            "map",
            "of",
            "config",
            "key",
            "value",
            "pairs",
            "to",
            "a",
            "map",
            "of",
            "strings",
            "where",
            "each",
            "value",
            "is",
            "converted",
            "to",
            "a",
            "string"
        ]
    },
    {
        "id": 765,
        "code": "public String toHtmlTable(Map<String, String> dynamicUpdateModes) {\n    boolean hasUpdateModes = !dynamicUpdateModes.isEmpty();\n    List<ConfigKey> configs = sortedConfigs();\n    StringBuilder b = new StringBuilder();\n    b.append(\"<table class=\\\"data-table\\\"><tbody>\\n\");\n    b.append(\"<tr>\\n\");\n        \n    for (String headerName : headers()) {\n        addHeader(b, headerName);\n    }\n    if (hasUpdateModes)\n        addHeader(b, \"Dynamic Update Mode\");\n    b.append(\"</tr>\\n\");\n    for (ConfigKey key : configs) {\n        if (key.internalConfig) {\n            continue;\n        }\n        b.append(\"<tr>\\n\");\n            \n        for (String headerName : headers()) {\n            addColumnValue(b, getConfigValue(key, headerName));\n            b.append(\"</td>\");\n        }\n        if (hasUpdateModes) {\n            String updateMode = dynamicUpdateModes.get(key.name);\n            if (updateMode == null)\n                updateMode = \"read-only\";\n            addColumnValue(b, updateMode);\n        }\n        b.append(\"</tr>\\n\");\n    }\n    b.append(\"</tbody></table>\");\n    return b.toString();\n}",
        "summary_tokens": [
            "converts",
            "this",
            "config",
            "into",
            "an",
            "html",
            "table",
            "that",
            "can",
            "be",
            "embedded",
            "into",
            "docs"
        ]
    },
    {
        "id": 766,
        "code": "public String toRst() {\n    StringBuilder b = new StringBuilder();\n    for (ConfigKey key : sortedConfigs()) {\n        if (key.internalConfig) {\n            continue;\n        }\n        getConfigKeyRst(key, b);\n        b.append(\"\\n\");\n    }\n    return b.toString();\n}",
        "summary_tokens": [
            "get",
            "the",
            "configs",
            "formatted",
            "with",
            "re",
            "structured",
            "text",
            "suitable",
            "for",
            "embedding",
            "in",
            "sphinx",
            "documentation"
        ]
    },
    {
        "id": 767,
        "code": "public String toEnrichedRst() {\n    StringBuilder b = new StringBuilder();\n\n    String lastKeyGroupName = \"\";\n    for (ConfigKey key : sortedConfigs()) {\n        if (key.internalConfig) {\n            continue;\n        }\n        if (key.group != null) {\n            if (!lastKeyGroupName.equalsIgnoreCase(key.group)) {\n                b.append(key.group).append(\"\\n\");\n\n                char[] underLine = new char[key.group.length()];\n                Arrays.fill(underLine, '^');\n                b.append(new String(underLine)).append(\"\\n\\n\");\n            }\n            lastKeyGroupName = key.group;\n        }\n\n        getConfigKeyRst(key, b);\n\n        if (key.dependents != null && key.dependents.size() > 0) {\n            int j = 0;\n            b.append(\"  * Dependents: \");\n            for (String dependent : key.dependents) {\n                b.append(\"``\");\n                b.append(dependent);\n                if (++j == key.dependents.size())\n                    b.append(\"``\");\n                else\n                    b.append(\"``, \");\n            }\n            b.append(\"\\n\");\n        }\n        b.append(\"\\n\");\n    }\n    return b.toString();\n}",
        "summary_tokens": [
            "configs",
            "with",
            "new",
            "metadata",
            "group",
            "order",
            "in",
            "group",
            "dependents",
            "formatted",
            "with",
            "re",
            "structured",
            "text",
            "suitable",
            "for",
            "embedding",
            "in",
            "sphinx",
            "documentation"
        ]
    },
    {
        "id": 768,
        "code": "private void getConfigKeyRst(ConfigKey key, StringBuilder b) {\n    b.append(\"``\").append(key.name).append(\"``\").append(\"\\n\");\n    if (key.documentation != null) {\n        for (String docLine : key.documentation.split(\"\\n\")) {\n            if (docLine.length() == 0) {\n                continue;\n            }\n            b.append(\"  \").append(docLine).append(\"\\n\\n\");\n        }\n    } else {\n        b.append(\"\\n\");\n    }\n    b.append(\"  * Type: \").append(getConfigValue(key, \"Type\")).append(\"\\n\");\n    if (key.hasDefault()) {\n        b.append(\"  * Default: \").append(getConfigValue(key, \"Default\")).append(\"\\n\");\n    }\n    if (key.validator != null) {\n        b.append(\"  * Valid Values: \").append(getConfigValue(key, \"Valid Values\")).append(\"\\n\");\n    }\n    b.append(\"  * Importance: \").append(getConfigValue(key, \"Importance\")).append(\"\\n\");\n}",
        "summary_tokens": [
            "shared",
            "content",
            "on",
            "rst",
            "and",
            "enriched",
            "rst"
        ]
    },
    {
        "id": 769,
        "code": "private List<ConfigKey> sortedConfigs() {\n    final Map<String, Integer> groupOrd = new HashMap<>(groups.size());\n    int ord = 0;\n    for (String group: groups) {\n        groupOrd.put(group, ord++);\n    }\n\n    List<ConfigKey> configs = new ArrayList<>(configKeys.values());\n    Collections.sort(configs, (k1, k2) -> compare(k1, k2, groupOrd));\n    return configs;\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "configs",
            "sorted",
            "taking",
            "the",
            "group",
            "and",
            "order",
            "in",
            "group",
            "into",
            "account"
        ]
    },
    {
        "id": 770,
        "code": "private static Validator embeddedValidator(final String keyPrefix, final Validator base) {\n    if (base == null) return null;\n    return new Validator() {\n        public void ensureValid(String name, Object value) {\n            base.ensureValid(name.substring(keyPrefix.length()), value);\n        }\n\n        @Override\n        public String toString() {\n            return base.toString();\n        }\n    };\n}",
        "summary_tokens": [
            "returns",
            "a",
            "new",
            "validator",
            "instance",
            "that",
            "delegates",
            "to",
            "the",
            "base",
            "validator",
            "but",
            "unprefixes",
            "the",
            "config",
            "name",
            "along",
            "the",
            "way"
        ]
    },
    {
        "id": 771,
        "code": "private static List<String> embeddedDependents(final String keyPrefix, final List<String> dependents) {\n    if (dependents == null) return null;\n    final List<String> updatedDependents = new ArrayList<>(dependents.size());\n    for (String dependent : dependents) {\n        updatedDependents.add(keyPrefix + dependent);\n    }\n    return updatedDependents;\n}",
        "summary_tokens": [
            "updated",
            "list",
            "of",
            "dependent",
            "configs",
            "with",
            "the",
            "specified",
            "prefix",
            "added"
        ]
    },
    {
        "id": 772,
        "code": "private static Recommender embeddedRecommender(final String keyPrefix, final Recommender base) {\n    if (base == null) return null;\n    return new Recommender() {\n        private String unprefixed(String k) {\n            return k.substring(keyPrefix.length());\n        }\n\n        private Map<String, Object> unprefixed(Map<String, Object> parsedConfig) {\n            final Map<String, Object> unprefixedParsedConfig = new HashMap<>(parsedConfig.size());\n            for (Map.Entry<String, Object> e : parsedConfig.entrySet()) {\n                if (e.getKey().startsWith(keyPrefix)) {\n                    unprefixedParsedConfig.put(unprefixed(e.getKey()), e.getValue());\n                }\n            }\n            return unprefixedParsedConfig;\n        }\n\n        @Override\n        public List<Object> validValues(String name, Map<String, Object> parsedConfig) {\n            return base.validValues(unprefixed(name), unprefixed(parsedConfig));\n        }\n\n        @Override\n        public boolean visible(String name, Map<String, Object> parsedConfig) {\n            return base.visible(unprefixed(name), unprefixed(parsedConfig));\n        }\n    };\n}",
        "summary_tokens": [
            "returns",
            "a",
            "new",
            "recommender",
            "instance",
            "that",
            "delegates",
            "to",
            "the",
            "base",
            "recommender",
            "but",
            "unprefixes",
            "the",
            "input",
            "parameters",
            "along",
            "the",
            "way"
        ]
    },
    {
        "id": 773,
        "code": "public String toHtml(int headerDepth, Function<String, String> idGenerator,\n                     Map<String, String> dynamicUpdateModes) {\n    boolean hasUpdateModes = !dynamicUpdateModes.isEmpty();\n    List<ConfigKey> configs = sortedConfigs();\n    StringBuilder b = new StringBuilder();\n    b.append(\"<ul class=\\\"config-list\\\">\\n\");\n    for (ConfigKey key : configs) {\n        if (key.internalConfig) {\n            continue;\n        }\n        b.append(\"<li>\\n\");\n        b.append(String.format(\"<h%1$d>\" +\n                \"<a id=\\\"%3$s\\\"></a><a id=\\\"%2$s\\\" href=\\\"#%2$s\\\">%3$s</a>\" +\n                \"</h%1$d>%n\", headerDepth, idGenerator.apply(key.name), key.name));\n        b.append(\"<p>\");\n        if (key.documentation != null) {\n            b.append(key.documentation.replaceAll(\"\\n\", \"<br>\"));\n        }\n        b.append(\"</p>\\n\");\n\n        b.append(\"<table>\" +\n                \"<tbody>\\n\");\n        for (String detail : headers()) {\n            if (detail.equals(\"Name\") || detail.equals(\"Description\")) continue;\n            addConfigDetail(b, detail, getConfigValue(key, detail));\n        }\n        if (hasUpdateModes) {\n            String updateMode = dynamicUpdateModes.get(key.name);\n            if (updateMode == null)\n                updateMode = \"read-only\";\n            addConfigDetail(b, \"Update Mode\", updateMode);\n        }\n        b.append(\"</tbody></table>\\n\");\n        b.append(\"</li>\\n\");\n    }\n    b.append(\"</ul>\\n\");\n    return b.toString();\n}",
        "summary_tokens": [
            "converts",
            "this",
            "config",
            "into",
            "an",
            "html",
            "list",
            "that",
            "can",
            "be",
            "embedded",
            "into",
            "docs"
        ]
    },
    {
        "id": 774,
        "code": "public Type type() {\n    return type;\n}",
        "summary_tokens": [
            "return",
            "the",
            "resource",
            "type"
        ]
    },
    {
        "id": 775,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "return",
            "the",
            "resource",
            "name"
        ]
    },
    {
        "id": 776,
        "code": "public boolean isDefault() {\n    return name.isEmpty();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "the",
            "default",
            "resource",
            "of",
            "a",
            "resource",
            "type"
        ]
    },
    {
        "id": 777,
        "code": "public ConfigTransformerResult transform(Map<String, String> configs) {\n    Map<String, Map<String, Set<String>>> keysByProvider = new HashMap<>();\n    Map<String, Map<String, Map<String, String>>> lookupsByProvider = new HashMap<>();\n\n        \n    for (Map.Entry<String, String> config : configs.entrySet()) {\n        if (config.getValue() != null) {\n            List<ConfigVariable> vars = getVars(config.getValue(), DEFAULT_PATTERN);\n            for (ConfigVariable var : vars) {\n                Map<String, Set<String>> keysByPath = keysByProvider.computeIfAbsent(var.providerName, k -> new HashMap<>());\n                Set<String> keys = keysByPath.computeIfAbsent(var.path, k -> new HashSet<>());\n                keys.add(var.variable);\n            }\n        }\n    }\n\n        \n    Map<String, Long> ttls = new HashMap<>();\n    for (Map.Entry<String, Map<String, Set<String>>> entry : keysByProvider.entrySet()) {\n        String providerName = entry.getKey();\n        ConfigProvider provider = configProviders.get(providerName);\n        Map<String, Set<String>> keysByPath = entry.getValue();\n        if (provider != null && keysByPath != null) {\n            for (Map.Entry<String, Set<String>> pathWithKeys : keysByPath.entrySet()) {\n                String path = pathWithKeys.getKey();\n                Set<String> keys = new HashSet<>(pathWithKeys.getValue());\n                ConfigData configData = provider.get(path, keys);\n                Map<String, String> data = configData.data();\n                Long ttl = configData.ttl();\n                if (ttl != null && ttl >= 0) {\n                    ttls.put(path, ttl);\n                }\n                Map<String, Map<String, String>> keyValuesByPath =\n                        lookupsByProvider.computeIfAbsent(providerName, k -> new HashMap<>());\n                keyValuesByPath.put(path, data);\n            }\n        }\n    }\n\n        \n    Map<String, String> data = new HashMap<>(configs);\n    for (Map.Entry<String, String> config : configs.entrySet()) {\n        data.put(config.getKey(), replace(lookupsByProvider, config.getValue(), DEFAULT_PATTERN));\n    }\n    return new ConfigTransformerResult(data, ttls);\n}",
        "summary_tokens": [
            "transforms",
            "the",
            "given",
            "configuration",
            "data",
            "by",
            "using",
            "the",
            "config",
            "provider",
            "instances",
            "to",
            "look",
            "up",
            "values",
            "to",
            "replace",
            "the",
            "variables",
            "in",
            "the",
            "pattern"
        ]
    },
    {
        "id": 778,
        "code": "public Map<String, String> data() {\n    return data;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "transformed",
            "data",
            "with",
            "variables",
            "replaced",
            "with",
            "corresponding",
            "values",
            "from",
            "the",
            "config",
            "provider",
            "instances",
            "if",
            "found"
        ]
    },
    {
        "id": 779,
        "code": "public Map<String, Long> ttls() {\n    return ttls;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "ttl",
            "values",
            "in",
            "milliseconds",
            "returned",
            "from",
            "the",
            "config",
            "provider",
            "instances",
            "for",
            "a",
            "given",
            "set",
            "of",
            "paths"
        ]
    },
    {
        "id": 780,
        "code": "default void subscribe(String path, Set<String> keys, ConfigChangeCallback callback) {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "subscribes",
            "to",
            "changes",
            "for",
            "the",
            "given",
            "keys",
            "at",
            "the",
            "given",
            "path",
            "optional",
            "operation"
        ]
    },
    {
        "id": 781,
        "code": "default void unsubscribe(String path, Set<String> keys, ConfigChangeCallback callback) {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "unsubscribes",
            "to",
            "changes",
            "for",
            "the",
            "given",
            "keys",
            "at",
            "the",
            "given",
            "path",
            "optional",
            "operation"
        ]
    },
    {
        "id": 782,
        "code": "default void unsubscribeAll() {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "clears",
            "all",
            "subscribers",
            "optional",
            "operation"
        ]
    },
    {
        "id": 783,
        "code": "public ConfigData get(String path, Set<String> keys) {\n    return get(path, pathname ->\n            Files.isRegularFile(pathname)\n                    && keys.contains(pathname.getFileName().toString()));\n}",
        "summary_tokens": [
            "retrieves",
            "the",
            "data",
            "contained",
            "in",
            "the",
            "regular",
            "files",
            "named",
            "by",
            "keys",
            "in",
            "the",
            "directory",
            "given",
            "by",
            "path"
        ]
    },
    {
        "id": 784,
        "code": "public ConfigData get(String path, Set<String> keys) {\n    Map<String, String> data = new HashMap<>();\n    if (path == null || path.isEmpty()) {\n        return new ConfigData(data);\n    }\n    try (Reader reader = reader(path)) {\n        Properties properties = new Properties();\n        properties.load(reader);\n        for (String key : keys) {\n            String value = properties.getProperty(key);\n            if (value != null) {\n                data.put(key, value);\n            }\n        }\n        return new ConfigData(data);\n    } catch (IOException e) {\n        log.error(\"Could not read properties from file {}\", path, e);\n        throw new ConfigException(\"Could not read properties from file \" + path);\n    }\n}",
        "summary_tokens": [
            "retrieves",
            "the",
            "data",
            "with",
            "the",
            "given",
            "keys",
            "at",
            "the",
            "given",
            "properties",
            "file"
        ]
    },
    {
        "id": 785,
        "code": "public String toString() {\n    return HIDDEN;\n}",
        "summary_tokens": [
            "returns",
            "hidden",
            "password",
            "string"
        ]
    },
    {
        "id": 786,
        "code": "public String value() {\n    return value;\n}",
        "summary_tokens": [
            "returns",
            "real",
            "password",
            "string"
        ]
    },
    {
        "id": 787,
        "code": "public String resource() {\n    return this.resource;\n}",
        "summary_tokens": [
            "the",
            "potentially",
            "null",
            "resource",
            "that",
            "was",
            "referred",
            "to",
            "twice"
        ]
    },
    {
        "id": 788,
        "code": "public String groupId() {\n    return groupId;\n}",
        "summary_tokens": [
            "return",
            "the",
            "group",
            "id",
            "that",
            "failed",
            "authorization"
        ]
    },
    {
        "id": 789,
        "code": "public String resource() {\n    return this.resource;\n}",
        "summary_tokens": [
            "the",
            "potentially",
            "null",
            "resource",
            "that",
            "was",
            "not",
            "found"
        ]
    },
    {
        "id": 790,
        "code": "public Set<String> unauthorizedTopics() {\n    return unauthorizedTopics;\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "topics",
            "which",
            "failed",
            "authorization"
        ]
    },
    {
        "id": 791,
        "code": "public static Features<SupportedVersionRange> supportedFeatures(Map<String, SupportedVersionRange> features) {\n    return new Features<>(features);\n}",
        "summary_tokens": [
            "features",
            "map",
            "of",
            "feature",
            "name",
            "to",
            "supported",
            "version",
            "range"
        ]
    },
    {
        "id": 792,
        "code": "public VersionRangeType get(String feature) {\n    return features.get(feature);\n}",
        "summary_tokens": [
            "feature",
            "name",
            "of",
            "the",
            "feature"
        ]
    },
    {
        "id": 793,
        "code": "public Map<String, Map<String, Short>> toMap() {\n    return features.entrySet().stream().collect(\n        Collectors.toMap(\n            Map.Entry::getKey,\n            entry -> entry.getValue().toMap()));\n}",
        "summary_tokens": [
            "a",
            "map",
            "representation",
            "of",
            "the",
            "underlying",
            "features"
        ]
    },
    {
        "id": 794,
        "code": "public static Features<SupportedVersionRange> fromSupportedFeaturesMap(\n    Map<String, Map<String, Short>> featuresMap) {\n    return fromFeaturesMap(featuresMap, SupportedVersionRange::fromMap);\n}",
        "summary_tokens": [
            "converts",
            "from",
            "a",
            "map",
            "to",
            "features",
            "supported",
            "version",
            "range"
        ]
    },
    {
        "id": 795,
        "code": "public boolean isIncompatibleWith(short version) {\n    return min() > version || max() < version;\n}",
        "summary_tokens": [
            "checks",
            "if",
            "the",
            "version",
            "level",
            "does",
            "not",
            "fall",
            "within",
            "the",
            "min",
            "max",
            "range",
            "of",
            "this",
            "supported",
            "version",
            "range"
        ]
    },
    {
        "id": 796,
        "code": "public void maybeAdd(Object candidate) {\n    if (candidate instanceof ClusterResourceListener) {\n        clusterResourceListeners.add((ClusterResourceListener) candidate);\n    }\n}",
        "summary_tokens": [
            "add",
            "only",
            "if",
            "the",
            "candidate",
            "implements",
            "cluster",
            "resource",
            "listener"
        ]
    },
    {
        "id": 797,
        "code": "public void maybeAddAll(List<?> candidateList) {\n    for (Object candidate : candidateList) {\n        this.maybeAdd(candidate);\n    }\n}",
        "summary_tokens": [
            "add",
            "all",
            "items",
            "who",
            "implement",
            "cluster",
            "resource",
            "listener",
            "from",
            "the",
            "list"
        ]
    },
    {
        "id": 798,
        "code": "public void onUpdate(ClusterResource cluster) {\n    for (ClusterResourceListener clusterResourceListener : clusterResourceListeners) {\n        clusterResourceListener.onUpdate(cluster);\n    }\n}",
        "summary_tokens": [
            "send",
            "the",
            "updated",
            "cluster",
            "metadata",
            "to",
            "all",
            "cluster",
            "resource",
            "listener"
        ]
    },
    {
        "id": 799,
        "code": "boolean kafkaComplete(T value) {\n    return super.complete(value);\n}",
        "summary_tokens": [
            "completes",
            "this",
            "future",
            "normally"
        ]
    },
    {
        "id": 800,
        "code": "boolean kafkaCompleteExceptionally(Throwable throwable) {\n    return super.completeExceptionally(throwable);\n}",
        "summary_tokens": [
            "completes",
            "this",
            "future",
            "exceptionally"
        ]
    },
    {
        "id": 801,
        "code": "public <R> KafkaFuture<R> thenApply(BaseFunction<T, R> function) {\n    CompletableFuture<R> appliedFuture = completableFuture.thenApply(value -> {\n        try {\n            return function.apply(value);\n        } catch (Throwable t) {\n            if (t instanceof CompletionException) {\n                    \n                    \n                    \n                    \n                    \n                throw new CompletionException(t);\n            } else {\n                throw t;\n            }\n        }\n    });\n    return new KafkaFutureImpl<>(true, toKafkaCompletableFuture(appliedFuture));\n}",
        "summary_tokens": [
            "returns",
            "a",
            "new",
            "kafka",
            "future",
            "that",
            "when",
            "this",
            "future",
            "completes",
            "normally",
            "is",
            "executed",
            "with",
            "this",
            "futures",
            "s",
            "result",
            "as",
            "the",
            "argument",
            "to",
            "the",
            "supplied",
            "function"
        ]
    },
    {
        "id": 802,
        "code": "public boolean cancel(boolean mayInterruptIfRunning) {\n    return completableFuture.cancel(mayInterruptIfRunning);\n}",
        "summary_tokens": [
            "if",
            "not",
            "already",
            "completed",
            "completes",
            "this",
            "future",
            "with",
            "a",
            "cancellation",
            "exception"
        ]
    },
    {
        "id": 803,
        "code": "private void maybeThrowCancellationException(Throwable cause) {\n    if (cause instanceof CancellationException) {\n        throw (CancellationException) cause;\n    }\n}",
        "summary_tokens": [
            "we",
            "need",
            "to",
            "deal",
            "with",
            "differences",
            "between",
            "kafka",
            "future",
            "s",
            "historic",
            "api",
            "and",
            "the",
            "api",
            "of",
            "completable",
            "future",
            "completable",
            "future",
            "get",
            "does",
            "not",
            "wrap",
            "cancellation",
            "exception",
            "in",
            "execution",
            "exception",
            "nor",
            "does",
            "kafka",
            "future"
        ]
    },
    {
        "id": 804,
        "code": "public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException,\n        TimeoutException {\n    try {\n        return completableFuture.get(timeout, unit);\n    } catch (ExecutionException e) {\n        maybeThrowCancellationException(e.getCause());\n        throw e;\n    }\n}",
        "summary_tokens": [
            "waits",
            "if",
            "necessary",
            "for",
            "at",
            "most",
            "the",
            "given",
            "time",
            "for",
            "this",
            "future",
            "to",
            "complete",
            "and",
            "then",
            "returns",
            "its",
            "result",
            "if",
            "available"
        ]
    },
    {
        "id": 805,
        "code": "public T getNow(T valueIfAbsent) throws ExecutionException {\n    try {\n        return completableFuture.getNow(valueIfAbsent);\n    } catch (CompletionException e) {\n        maybeThrowCancellationException(e.getCause());\n            \n            \n            \n        throw new ExecutionException(e.getCause());\n    }\n}",
        "summary_tokens": [
            "returns",
            "the",
            "result",
            "value",
            "or",
            "throws",
            "any",
            "encountered",
            "exception",
            "if",
            "completed",
            "else",
            "returns",
            "the",
            "given",
            "value",
            "if",
            "absent"
        ]
    },
    {
        "id": 806,
        "code": "public boolean isCancelled() {\n    if (isDependant) {\n            \n            \n            \n            \n            \n            \n        try {\n            completableFuture.getNow(null);\n            return false;\n        } catch (Exception e) {\n            return e instanceof CompletionException\n                    && e.getCause() instanceof CancellationException;\n        }\n    } else {\n        return completableFuture.isCancelled();\n    }\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "completable",
            "future",
            "was",
            "cancelled",
            "before",
            "it",
            "completed",
            "normally"
        ]
    },
    {
        "id": 807,
        "code": "public boolean isCompletedExceptionally() {\n    return completableFuture.isCompletedExceptionally();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "completable",
            "future",
            "completed",
            "exceptionally",
            "in",
            "any",
            "way"
        ]
    },
    {
        "id": 808,
        "code": "public boolean isDone() {\n    return completableFuture.isDone();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "completed",
            "in",
            "any",
            "fashion",
            "normally",
            "exceptionally",
            "or",
            "via",
            "cancellation"
        ]
    },
    {
        "id": 809,
        "code": "public Set<TopicPartition> partitionSet() {\n    return partitionSetView;\n}",
        "summary_tokens": [
            "returns",
            "an",
            "unmodifiable",
            "view",
            "of",
            "the",
            "partitions",
            "in",
            "random",
            "order"
        ]
    },
    {
        "id": 810,
        "code": "public List<S> partitionStateValues() {\n    return new ArrayList<>(map.values());\n}",
        "summary_tokens": [
            "returns",
            "the",
            "partition",
            "state",
            "values",
            "in",
            "order"
        ]
    },
    {
        "id": 811,
        "code": "public int size() {\n    return size;\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "partitions",
            "that",
            "are",
            "currently",
            "being",
            "tracked"
        ]
    },
    {
        "id": 812,
        "code": "public void set(Map<TopicPartition, S> partitionToState) {\n    map.clear();\n    update(partitionToState);\n    updateSize();\n}",
        "summary_tokens": [
            "update",
            "the",
            "builder",
            "to",
            "have",
            "the",
            "received",
            "map",
            "as",
            "its",
            "state",
            "i"
        ]
    },
    {
        "id": 813,
        "code": "public static boolean hasCollisionChars(String topic) {\n    return topic.contains(\"_\") || topic.contains(\".\");\n}",
        "summary_tokens": [
            "due",
            "to",
            "limitations",
            "in",
            "metric",
            "names",
            "topics",
            "with",
            "a",
            "period"
        ]
    },
    {
        "id": 814,
        "code": "public static String unifyCollisionChars(String topic) {\n    return topic.replace('.', '_');\n}",
        "summary_tokens": [
            "unify",
            "topic",
            "name",
            "with",
            "a",
            "period"
        ]
    },
    {
        "id": 815,
        "code": "public static boolean hasCollision(String topicA, String topicB) {\n    return unifyCollisionChars(topicA).equals(unifyCollisionChars(topicB));\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "topic",
            "names",
            "collide",
            "due",
            "to",
            "a",
            "period"
        ]
    },
    {
        "id": 816,
        "code": "static boolean containsValidPattern(String topic) {\n    for (int i = 0; i < topic.length(); ++i) {\n        char c = topic.charAt(i);\n\n            \n        boolean validChar = (c >= 'a' && c <= 'z') || (c >= '0' && c <= '9') || (c >= 'A' && c <= 'Z') || c == '.' ||\n                c == '_' || c == '-';\n        if (!validChar)\n            return false;\n    }\n    return true;\n}",
        "summary_tokens": [
            "valid",
            "characters",
            "for",
            "kafka",
            "topics",
            "are",
            "the",
            "ascii",
            "alphanumerics"
        ]
    },
    {
        "id": 817,
        "code": "static String getMBeanName(String prefix, MetricName metricName) {\n    StringBuilder mBeanName = new StringBuilder();\n    mBeanName.append(prefix);\n    mBeanName.append(\":type=\");\n    mBeanName.append(metricName.group());\n    for (Map.Entry<String, String> entry : metricName.tags().entrySet()) {\n        if (entry.getKey().length() <= 0 || entry.getValue().length() <= 0)\n            continue;\n        mBeanName.append(\",\");\n        mBeanName.append(entry.getKey());\n        mBeanName.append(\"=\");\n        mBeanName.append(Sanitizer.jmxSanitize(entry.getValue()));\n    }\n    return mBeanName.toString();\n}",
        "summary_tokens": [
            "metric",
            "name",
            "standard",
            "jmx",
            "mbean",
            "name",
            "in",
            "the",
            "following",
            "format",
            "domain",
            "name",
            "type",
            "metric",
            "type",
            "key",
            "0",
            "val",
            "0",
            "key",
            "0",
            "val",
            "0"
        ]
    },
    {
        "id": 818,
        "code": "public MetricName metricName(String name, String group, Map<String, String> tags) {\n    return metricName(name, group, \"\", tags);\n}",
        "summary_tokens": [
            "create",
            "a",
            "metric",
            "name",
            "with",
            "the",
            "given",
            "name",
            "group",
            "and",
            "tags",
            "plus",
            "default",
            "tags",
            "specified",
            "in",
            "the",
            "metric",
            "configuration"
        ]
    },
    {
        "id": 819,
        "code": "public static String toHtmlTable(String domain, Iterable<MetricNameTemplate> allMetrics) {\n    Map<String, Map<String, String>> beansAndAttributes = new TreeMap<>();\n    \n    try (Metrics metrics = new Metrics()) {\n        for (MetricNameTemplate template : allMetrics) {\n            Map<String, String> tags = new LinkedHashMap<>();\n            for (String s : template.tags()) {\n                tags.put(s, \"{\" + s + \"}\");\n            }\n    \n            MetricName metricName = metrics.metricName(template.name(), template.group(), template.description(), tags);\n            String mBeanName = JmxReporter.getMBeanName(domain, metricName);\n            if (!beansAndAttributes.containsKey(mBeanName)) {\n                beansAndAttributes.put(mBeanName, new TreeMap<>());\n            }\n            Map<String, String> attrAndDesc = beansAndAttributes.get(mBeanName);\n            if (!attrAndDesc.containsKey(template.name())) {\n                attrAndDesc.put(template.name(), template.description());\n            } else {\n                throw new IllegalArgumentException(\"mBean '\" + mBeanName + \"' attribute '\" + template.name() + \"' is defined twice.\");\n            }\n        }\n    }\n        \n    StringBuilder b = new StringBuilder();\n    b.append(\"<table class=\\\"data-table\\\"><tbody>\\n\");\n    \n    for (Entry<String, Map<String, String>> e : beansAndAttributes.entrySet()) {\n        b.append(\"<tr>\\n\");\n        b.append(\"<td colspan=3 class=\\\"mbeanName\\\" style=\\\"background-color:#ccc; font-weight: bold;\\\">\");\n        b.append(e.getKey());\n        b.append(\"</td>\");\n        b.append(\"</tr>\\n\");\n            \n        b.append(\"<tr>\\n\");\n        b.append(\"<th style=\\\"width: 90px\\\"></th>\\n\");\n        b.append(\"<th>Attribute name</th>\\n\");\n        b.append(\"<th>Description</th>\\n\");\n        b.append(\"</tr>\\n\");\n            \n        for (Entry<String, String> e2 : e.getValue().entrySet()) {\n            b.append(\"<tr>\\n\");\n            b.append(\"<td></td>\");\n            b.append(\"<td>\");\n            b.append(e2.getKey());\n            b.append(\"</td>\");\n            b.append(\"<td>\");\n            b.append(e2.getValue());\n            b.append(\"</td>\");\n            b.append(\"</tr>\\n\");\n        }\n    \n    }\n    b.append(\"</tbody></table>\");\n    \n    return b.toString();\n    \n}",
        "summary_tokens": [
            "use",
            "the",
            "specified",
            "domain",
            "and",
            "metric",
            "name",
            "templates",
            "to",
            "generate",
            "an",
            "html",
            "table",
            "documenting",
            "the",
            "metrics"
        ]
    },
    {
        "id": 820,
        "code": "public Sensor getSensor(String name) {\n    return this.sensors.get(Objects.requireNonNull(name));\n}",
        "summary_tokens": [
            "get",
            "the",
            "sensor",
            "with",
            "the",
            "given",
            "name",
            "if",
            "it",
            "exists",
            "name",
            "the",
            "name",
            "of",
            "the",
            "sensor",
            "return",
            "the",
            "sensor",
            "or",
            "null",
            "if",
            "no",
            "such",
            "sensor",
            "exists"
        ]
    },
    {
        "id": 821,
        "code": "public synchronized Sensor sensor(String name, MetricConfig config, long inactiveSensorExpirationTimeSeconds, Sensor... parents) {\n    return this.sensor(name, config, inactiveSensorExpirationTimeSeconds, Sensor.RecordingLevel.INFO, parents);\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "a",
            "sensor",
            "with",
            "the",
            "given",
            "unique",
            "name",
            "and",
            "zero",
            "or",
            "more",
            "parent",
            "sensors"
        ]
    },
    {
        "id": 822,
        "code": "public void removeSensor(String name) {\n    Sensor sensor = sensors.get(name);\n    if (sensor != null) {\n        List<Sensor> childSensors = null;\n        synchronized (sensor) {\n            synchronized (this) {\n                if (sensors.remove(name, sensor)) {\n                    for (KafkaMetric metric : sensor.metrics())\n                        removeMetric(metric.metricName());\n                    log.trace(\"Removed sensor with name {}\", name);\n                    childSensors = childrenSensors.remove(sensor);\n                    for (final Sensor parent : sensor.parents()) {\n                        childrenSensors.getOrDefault(parent, emptyList()).remove(sensor);\n                    }\n                }\n            }\n        }\n        if (childSensors != null) {\n            for (Sensor childSensor : childSensors)\n                removeSensor(childSensor.name());\n        }\n    }\n}",
        "summary_tokens": [
            "remove",
            "a",
            "sensor",
            "if",
            "it",
            "exists",
            "associated",
            "metrics",
            "and",
            "its",
            "children"
        ]
    },
    {
        "id": 823,
        "code": "public void addMetric(MetricName metricName, MetricValueProvider<?> metricValueProvider) {\n    addMetric(metricName, null, metricValueProvider);\n}",
        "summary_tokens": [
            "add",
            "a",
            "metric",
            "to",
            "monitor",
            "an",
            "object",
            "that",
            "implements",
            "metric",
            "value",
            "provider"
        ]
    },
    {
        "id": 824,
        "code": "public KafkaMetric addMetricIfAbsent(MetricName metricName, MetricConfig config, MetricValueProvider<?> metricValueProvider) {\n    KafkaMetric metric = new KafkaMetric(new Object(),\n            Objects.requireNonNull(metricName),\n            Objects.requireNonNull(metricValueProvider),\n            config == null ? this.config : config,\n            time);\n\n    KafkaMetric existingMetric = registerMetric(metric);\n    return existingMetric == null ? metric : existingMetric;\n}",
        "summary_tokens": [
            "create",
            "or",
            "get",
            "an",
            "existing",
            "metric",
            "to",
            "monitor",
            "an",
            "object",
            "that",
            "implements",
            "metric",
            "value",
            "provider"
        ]
    },
    {
        "id": 825,
        "code": "public synchronized KafkaMetric removeMetric(MetricName metricName) {\n    KafkaMetric metric = this.metrics.remove(metricName);\n    if (metric != null) {\n        for (MetricsReporter reporter : reporters) {\n            try {\n                reporter.metricRemoval(metric);\n            } catch (Exception e) {\n                log.error(\"Error when removing metric from \" + reporter.getClass().getName(), e);\n            }\n        }\n        log.trace(\"Removed metric named {}\", metricName);\n    }\n    return metric;\n}",
        "summary_tokens": [
            "remove",
            "a",
            "metric",
            "if",
            "it",
            "exists",
            "and",
            "return",
            "it"
        ]
    },
    {
        "id": 826,
        "code": "public synchronized void addReporter(MetricsReporter reporter) {\n    Objects.requireNonNull(reporter).init(new ArrayList<>(metrics.values()));\n    this.reporters.add(reporter);\n}",
        "summary_tokens": [
            "add",
            "a",
            "metric",
            "reporter"
        ]
    },
    {
        "id": 827,
        "code": "public synchronized void removeReporter(MetricsReporter reporter) {\n    if (this.reporters.remove(reporter)) {\n        reporter.close();\n    }\n}",
        "summary_tokens": [
            "remove",
            "a",
            "metric",
            "reporter"
        ]
    },
    {
        "id": 828,
        "code": "synchronized KafkaMetric registerMetric(KafkaMetric metric) {\n    MetricName metricName = metric.metricName();\n    KafkaMetric existingMetric = this.metrics.putIfAbsent(metricName, metric);\n    if (existingMetric != null) {\n        return existingMetric;\n    }\n        \n    for (MetricsReporter reporter : reporters) {\n        try {\n            reporter.metricChange(metric);\n        } catch (Exception e) {\n            log.error(\"Error when registering metric on \" + reporter.getClass().getName(), e);\n        }\n    }\n    log.trace(\"Registered metric named {}\", metricName);\n    return null;\n}",
        "summary_tokens": [
            "register",
            "a",
            "metric",
            "if",
            "not",
            "present",
            "or",
            "return",
            "the",
            "already",
            "existing",
            "metric",
            "with",
            "the",
            "same",
            "name"
        ]
    },
    {
        "id": 829,
        "code": "public Map<MetricName, KafkaMetric> metrics() {\n    return this.metrics;\n}",
        "summary_tokens": [
            "get",
            "all",
            "the",
            "metrics",
            "currently",
            "maintained",
            "indexed",
            "by",
            "metric",
            "name"
        ]
    },
    {
        "id": 830,
        "code": "public void close() {\n    if (this.metricsScheduler != null) {\n        this.metricsScheduler.shutdown();\n        try {\n            this.metricsScheduler.awaitTermination(30, TimeUnit.SECONDS);\n        } catch (InterruptedException ex) {\n                \n            Thread.currentThread().interrupt();\n        }\n    }\n    log.info(\"Metrics scheduler closed\");\n\n    for (MetricsReporter reporter : reporters) {\n        try {\n            log.info(\"Closing reporter {}\", reporter.getClass().getName());\n            reporter.close();\n        } catch (Exception e) {\n            log.error(\"Error when closing \" + reporter.getClass().getName(), e);\n        }\n    }\n    log.info(\"Metrics reporters closed\");\n}",
        "summary_tokens": [
            "close",
            "this",
            "metrics",
            "repository"
        ]
    },
    {
        "id": 831,
        "code": "default void contextChange(MetricsContext metricsContext) {\n}",
        "summary_tokens": [
            "sets",
            "the",
            "context",
            "labels",
            "for",
            "the",
            "service",
            "or",
            "library",
            "exposing",
            "metrics"
        ]
    },
    {
        "id": 832,
        "code": "public String name() {\n    return this.name;\n}",
        "summary_tokens": [
            "the",
            "name",
            "this",
            "sensor",
            "is",
            "registered",
            "with"
        ]
    },
    {
        "id": 833,
        "code": "public boolean shouldRecord() {\n    return this.recordingLevel.shouldRecord(config.recordLevel().id);\n}",
        "summary_tokens": [
            "true",
            "if",
            "the",
            "sensor",
            "s",
            "record",
            "level",
            "indicates",
            "that",
            "the",
            "metric",
            "will",
            "be",
            "recorded",
            "false",
            "otherwise"
        ]
    },
    {
        "id": 834,
        "code": "public void record(double value, long timeMs, boolean checkQuotas) {\n    if (shouldRecord()) {\n        recordInternal(value, timeMs, checkQuotas);\n    }\n}",
        "summary_tokens": [
            "record",
            "a",
            "value",
            "at",
            "a",
            "known",
            "time"
        ]
    },
    {
        "id": 835,
        "code": "public void checkQuotas() {\n    checkQuotas(time.milliseconds());\n}",
        "summary_tokens": [
            "check",
            "if",
            "we",
            "have",
            "violated",
            "our",
            "quota",
            "for",
            "any",
            "metric",
            "that",
            "has",
            "a",
            "configured",
            "quota"
        ]
    },
    {
        "id": 836,
        "code": "public synchronized boolean add(final MetricName metricName, final MeasurableStat stat, final MetricConfig config) {\n    if (hasExpired()) {\n        return false;\n    } else if (metrics.containsKey(metricName)) {\n        return true;\n    } else {\n        final MetricConfig statConfig = config == null ? this.config : config;\n        final KafkaMetric metric = new KafkaMetric(\n            metricLock(),\n            Objects.requireNonNull(metricName),\n            Objects.requireNonNull(stat),\n            statConfig,\n            time\n        );\n        KafkaMetric existingMetric = registry.registerMetric(metric);\n        if (existingMetric != null) {\n            throw new IllegalArgumentException(\"A metric named '\" + metricName + \"' already exists, can't register another one.\");\n        }\n        metrics.put(metric.metricName(), metric);\n        stats.add(new StatAndConfig(Objects.requireNonNull(stat), metric::config));\n        return true;\n    }\n}",
        "summary_tokens": [
            "register",
            "a",
            "metric",
            "with",
            "this",
            "sensor"
        ]
    },
    {
        "id": 837,
        "code": "public synchronized boolean hasMetrics() {\n    return !metrics.isEmpty();\n}",
        "summary_tokens": [
            "return",
            "if",
            "metrics",
            "were",
            "registered",
            "with",
            "this",
            "sensor"
        ]
    },
    {
        "id": 838,
        "code": "public boolean hasExpired() {\n    return (time.milliseconds() - this.lastRecordTime) > this.inactiveSensorExpirationTimeMs;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "sensor",
            "is",
            "eligible",
            "for",
            "removal",
            "due",
            "to",
            "inactivity"
        ]
    },
    {
        "id": 839,
        "code": "private Object metricLock() {\n    return metricLock;\n}",
        "summary_tokens": [
            "kafka",
            "metrics",
            "of",
            "sensors",
            "which",
            "use",
            "sampled",
            "stat",
            "should",
            "be",
            "synchronized",
            "on",
            "the",
            "same",
            "lock",
            "for",
            "sensor",
            "record",
            "and",
            "metric",
            "value",
            "read",
            "to",
            "allow",
            "concurrent",
            "reads",
            "and",
            "updates"
        ]
    },
    {
        "id": 840,
        "code": "private void performPendingMetricsOperations() {\n    modifyMetricsLock.lock();\n    try {\n        log.trace(\"{}: entering performPendingMetricsOperations\", suiteName);\n        for (PendingMetricsChange change = pending.pollLast();\n             change != null;\n             change = pending.pollLast()) {\n            if (change.provider == null) {\n                if (log.isTraceEnabled()) {\n                    log.trace(\"{}: removing metric {}\", suiteName, change.metricName);\n                }\n                metrics.removeMetric(change.metricName);\n            } else {\n                if (log.isTraceEnabled()) {\n                    log.trace(\"{}: adding metric {}\", suiteName, change.metricName);\n                }\n                metrics.addMetric(change.metricName, change.provider);\n            }\n        }\n        log.trace(\"{}: leaving performPendingMetricsOperations\", suiteName);\n    } finally {\n        modifyMetricsLock.unlock();\n    }\n}",
        "summary_tokens": [
            "perform",
            "pending",
            "metrics",
            "additions",
            "or",
            "removals"
        ]
    },
    {
        "id": 841,
        "code": "public int maxEntries() {\n    return maxEntries;\n}",
        "summary_tokens": [
            "get",
            "the",
            "maximum",
            "number",
            "of",
            "metrics",
            "this",
            "suite",
            "can",
            "create"
        ]
    },
    {
        "id": 842,
        "code": "synchronized Map<K, Integer> values() {\n    HashMap<K, Integer> values = new HashMap<>();\n    for (Map.Entry<K, StoredIntGauge> entry : gauges.entrySet()) {\n        values.put(entry.getKey(), entry.getValue().value());\n    }\n    return values;\n}",
        "summary_tokens": [
            "return",
            "a",
            "map",
            "from",
            "keys",
            "to",
            "current",
            "reference",
            "counts"
        ]
    },
    {
        "id": 843,
        "code": "public static double convert(long timeMs, TimeUnit unit) {\n    switch (unit) {\n        case NANOSECONDS:\n            return timeMs * 1000.0 * 1000.0;\n        case MICROSECONDS:\n            return timeMs * 1000.0;\n        case MILLISECONDS:\n            return timeMs;\n        case SECONDS:\n            return timeMs / 1000.0;\n        case MINUTES:\n            return timeMs / (60.0 * 1000.0);\n        case HOURS:\n            return timeMs / (60.0 * 60.0 * 1000.0);\n        case DAYS:\n            return timeMs / (24.0 * 60.0 * 60.0 * 1000.0);\n        default:\n            throw new IllegalStateException(\"Unknown unit: \" + unit);\n    }\n}",
        "summary_tokens": [
            "converts",
            "the",
            "provided",
            "time",
            "from",
            "milliseconds",
            "to",
            "the",
            "requested",
            "time",
            "unit"
        ]
    },
    {
        "id": 844,
        "code": "public static Map<String, String> getTags(String... keyValue) {\n    if ((keyValue.length % 2) != 0)\n        throw new IllegalArgumentException(\"keyValue needs to be specified in pairs\");\n    Map<String, String> tags = new LinkedHashMap<>(keyValue.length / 2);\n\n    for (int i = 0; i < keyValue.length; i += 2)\n        tags.put(keyValue[i], keyValue[i + 1]);\n    return tags;\n}",
        "summary_tokens": [
            "create",
            "a",
            "set",
            "of",
            "tags",
            "using",
            "the",
            "supplied",
            "key",
            "and",
            "value",
            "pairs"
        ]
    },
    {
        "id": 845,
        "code": "public static Frequencies forBooleanValues(MetricName falseMetricName, MetricName trueMetricName) {\n    List<Frequency> frequencies = new ArrayList<>();\n    if (falseMetricName != null) {\n        frequencies.add(new Frequency(falseMetricName, 0.0));\n    }\n    if (trueMetricName != null) {\n        frequencies.add(new Frequency(trueMetricName, 1.0));\n    }\n    if (frequencies.isEmpty()) {\n        throw new IllegalArgumentException(\"Must specify at least one metric name\");\n    }\n    Frequency[] frequencyArray = frequencies.toArray(new Frequency[0]);\n    return new Frequencies(2, 0.0, 1.0, frequencyArray);\n}",
        "summary_tokens": [
            "create",
            "a",
            "frequencies",
            "instance",
            "with",
            "metrics",
            "for",
            "the",
            "frequency",
            "of",
            "a",
            "boolean",
            "sensor",
            "that",
            "records",
            "0"
        ]
    },
    {
        "id": 846,
        "code": "public double frequency(MetricConfig config, long now, double centerValue) {\n    purgeObsoleteSamples(config, now);\n    long totalCount = 0;\n    for (Sample sample : samples) {\n        totalCount += sample.eventCount;\n    }\n    if (totalCount == 0) {\n        return 0.0d;\n    }\n        \n    float count = 0.0f;\n    int binNum = binScheme.toBin(centerValue);\n    for (Sample s : samples) {\n        HistogramSample sample = (HistogramSample) s;\n        float[] hist = sample.histogram.counts();\n        count += hist[binNum];\n    }\n        \n    return count / (double) totalCount;\n}",
        "summary_tokens": [
            "return",
            "the",
            "computed",
            "frequency",
            "describing",
            "the",
            "number",
            "of",
            "occurrences",
            "of",
            "the",
            "values",
            "in",
            "the",
            "bucket",
            "for",
            "the",
            "given",
            "center",
            "point",
            "relative",
            "to",
            "the",
            "total",
            "number",
            "of",
            "occurrences",
            "in",
            "the",
            "samples"
        ]
    },
    {
        "id": 847,
        "code": "public MetricName name() {\n    return this.name;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "this",
            "metric"
        ]
    },
    {
        "id": 848,
        "code": "public double centerValue() {\n    return this.centerValue;\n}",
        "summary_tokens": [
            "get",
            "the",
            "value",
            "of",
            "this",
            "metrics",
            "center",
            "point"
        ]
    },
    {
        "id": 849,
        "code": "default void handleAuthenticationFailure() throws IOException {\n}",
        "summary_tokens": [
            "perform",
            "any",
            "processing",
            "related",
            "to",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 850,
        "code": "default Long serverSessionExpirationTimeNanos() {\n    return null;\n}",
        "summary_tokens": [
            "return",
            "the",
            "session",
            "expiration",
            "time",
            "if",
            "any",
            "otherwise",
            "null"
        ]
    },
    {
        "id": 851,
        "code": "default Long clientSessionReauthenticationTimeNanos() {\n    return null;\n}",
        "summary_tokens": [
            "return",
            "the",
            "time",
            "on",
            "or",
            "after",
            "which",
            "a",
            "client",
            "should",
            "re",
            "authenticate",
            "this",
            "session",
            "if",
            "any",
            "otherwise",
            "null"
        ]
    },
    {
        "id": 852,
        "code": "default Long reauthenticationLatencyMs() {\n    return null;\n}",
        "summary_tokens": [
            "return",
            "the",
            "number",
            "of",
            "milliseconds",
            "that",
            "elapsed",
            "while",
            "re",
            "authenticating",
            "this",
            "session",
            "from",
            "the",
            "perspective",
            "of",
            "this",
            "instance",
            "if",
            "applicable",
            "otherwise",
            "null"
        ]
    },
    {
        "id": 853,
        "code": "default Optional<NetworkReceive> pollResponseReceivedDuringReauthentication() {\n    return Optional.empty();\n}",
        "summary_tokens": [
            "return",
            "the",
            "next",
            "always",
            "non",
            "null",
            "but",
            "possibly",
            "empty",
            "client",
            "side",
            "network",
            "receive",
            "response",
            "that",
            "arrived",
            "during",
            "re",
            "authentication",
            "that",
            "is",
            "unrelated",
            "to",
            "re",
            "authentication",
            "if",
            "any"
        ]
    },
    {
        "id": 854,
        "code": "default boolean connectedClientSupportsReauthentication() {\n    return false;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "is",
            "a",
            "server",
            "side",
            "authenticator",
            "and",
            "the",
            "connected",
            "client",
            "has",
            "indicated",
            "that",
            "it",
            "supports",
            "re",
            "authentication",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 855,
        "code": "public static ChannelBuilder clientChannelBuilder(\n        SecurityProtocol securityProtocol,\n        JaasContext.Type contextType,\n        AbstractConfig config,\n        ListenerName listenerName,\n        String clientSaslMechanism,\n        Time time,\n        boolean saslHandshakeRequestEnable,\n        LogContext logContext) {\n\n    if (securityProtocol == SecurityProtocol.SASL_PLAINTEXT || securityProtocol == SecurityProtocol.SASL_SSL) {\n        if (contextType == null)\n            throw new IllegalArgumentException(\"`contextType` must be non-null if `securityProtocol` is `\" + securityProtocol + \"`\");\n        if (clientSaslMechanism == null)\n            throw new IllegalArgumentException(\"`clientSaslMechanism` must be non-null in client mode if `securityProtocol` is `\" + securityProtocol + \"`\");\n    }\n    return create(securityProtocol, Mode.CLIENT, contextType, config, listenerName, false, clientSaslMechanism,\n            saslHandshakeRequestEnable, null, null, time, logContext, null);\n}",
        "summary_tokens": [
            "security",
            "protocol",
            "the",
            "security",
            "protocol",
            "context",
            "type",
            "the",
            "context",
            "type",
            "it",
            "must",
            "be",
            "non",
            "null",
            "if",
            "security",
            "protocol",
            "is",
            "sasl",
            "it",
            "is",
            "ignored",
            "otherwise",
            "config",
            "client",
            "config",
            "listener",
            "name",
            "the",
            "listener",
            "name",
            "if",
            "context",
            "type",
            "is",
            "server",
            "or",
            "null",
            "otherwise",
            "client",
            "sasl",
            "mechanism",
            "sasl",
            "mechanism",
            "if",
            "mode",
            "is",
            "client",
            "ignored",
            "otherwise",
            "time",
            "the",
            "time",
            "instance",
            "sasl",
            "handshake",
            "request",
            "enable",
            "flag",
            "to",
            "enable",
            "sasl",
            "handshake",
            "requests",
            "disabled",
            "only",
            "for",
            "sasl",
            "inter",
            "broker",
            "connections",
            "with",
            "inter",
            "broker",
            "protocol",
            "version",
            "0"
        ]
    },
    {
        "id": 856,
        "code": "public static ChannelBuilder serverChannelBuilder(ListenerName listenerName,\n                                                  boolean isInterBrokerListener,\n                                                  SecurityProtocol securityProtocol,\n                                                  AbstractConfig config,\n                                                  CredentialCache credentialCache,\n                                                  DelegationTokenCache tokenCache,\n                                                  Time time,\n                                                  LogContext logContext,\n                                                  Supplier<ApiVersionsResponse> apiVersionSupplier) {\n    return create(securityProtocol, Mode.SERVER, JaasContext.Type.SERVER, config, listenerName,\n            isInterBrokerListener, null, true, credentialCache,\n            tokenCache, time, logContext, apiVersionSupplier);\n}",
        "summary_tokens": [
            "listener",
            "name",
            "the",
            "listener",
            "name",
            "is",
            "inter",
            "broker",
            "listener",
            "whether",
            "or",
            "not",
            "this",
            "listener",
            "is",
            "used",
            "for",
            "inter",
            "broker",
            "requests",
            "security",
            "protocol",
            "the",
            "security",
            "protocol",
            "config",
            "server",
            "config",
            "credential",
            "cache",
            "credential",
            "cache",
            "for",
            "sasl",
            "scram",
            "if",
            "scram",
            "is",
            "enabled",
            "token",
            "cache",
            "delegation",
            "token",
            "cache",
            "time",
            "the",
            "time",
            "instance",
            "log",
            "context",
            "the",
            "log",
            "context",
            "instance",
            "api",
            "version",
            "supplier",
            "supplier",
            "for",
            "api",
            "versions",
            "responses",
            "sent",
            "prior",
            "to",
            "authentication"
        ]
    },
    {
        "id": 857,
        "code": "static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n    Map<String, Object> parsedConfigs;\n    if (listenerName == null)\n        parsedConfigs = (Map<String, Object>) config.values();\n    else\n        parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\n\n    config.originals().entrySet().stream()\n        .filter(e -> !parsedConfigs.containsKey(e.getKey())) \n            \n        .filter(e -> !(listenerName != null && e.getKey().startsWith(listenerName.configPrefix()) &&\n            parsedConfigs.containsKey(e.getKey().substring(listenerName.configPrefix().length()))))\n            \n        .filter(e -> !(listenerName != null && parsedConfigs.containsKey(e.getKey().substring(e.getKey().indexOf('.') + 1))))\n        .forEach(e -> parsedConfigs.put(e.getKey(), e.getValue()));\n    return parsedConfigs;\n}",
        "summary_tokens": [
            "a",
            "mutable",
            "recording",
            "map"
        ]
    },
    {
        "id": 858,
        "code": "public KafkaPrincipal principal() {\n    return authenticator.principal();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "principal",
            "returned",
            "by",
            "authenticator"
        ]
    },
    {
        "id": 859,
        "code": "public void prepare() throws AuthenticationException, IOException {\n    boolean authenticating = false;\n    try {\n        if (!transportLayer.ready())\n            transportLayer.handshake();\n        if (transportLayer.ready() && !authenticator.complete()) {\n            authenticating = true;\n            authenticator.authenticate();\n        }\n    } catch (AuthenticationException e) {\n            \n            \n        String remoteDesc = remoteAddress != null ? remoteAddress.toString() : null;\n        state = new ChannelState(ChannelState.State.AUTHENTICATION_FAILED, e, remoteDesc);\n        if (authenticating) {\n            delayCloseOnAuthenticationFailure();\n            throw new DelayedResponseAuthenticationException(e);\n        }\n        throw e;\n    }\n    if (ready()) {\n        ++successfulAuthentications;\n        state = ChannelState.READY;\n    }\n}",
        "summary_tokens": [
            "does",
            "handshake",
            "of",
            "transport",
            "layer",
            "and",
            "authentication",
            "using",
            "configured",
            "authenticator"
        ]
    },
    {
        "id": 860,
        "code": "void mute() {\n    if (muteState == ChannelMuteState.NOT_MUTED) {\n        if (!disconnected) transportLayer.removeInterestOps(SelectionKey.OP_READ);\n        muteState = ChannelMuteState.MUTED;\n    }\n}",
        "summary_tokens": [
            "externally",
            "muting",
            "a",
            "channel",
            "should",
            "be",
            "done",
            "via",
            "selector",
            "to",
            "ensure",
            "proper",
            "state",
            "handling"
        ]
    },
    {
        "id": 861,
        "code": "private void delayCloseOnAuthenticationFailure() {\n    transportLayer.removeInterestOps(SelectionKey.OP_WRITE);\n}",
        "summary_tokens": [
            "delay",
            "channel",
            "close",
            "on",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 862,
        "code": "void completeCloseOnAuthenticationFailure() throws IOException {\n    transportLayer.addInterestOps(SelectionKey.OP_WRITE);\n        \n    authenticator.handleAuthenticationFailure();\n}",
        "summary_tokens": [
            "finish",
            "up",
            "any",
            "processing",
            "on",
            "prepare",
            "failure"
        ]
    },
    {
        "id": 863,
        "code": "public boolean isMuted() {\n    return muteState != ChannelMuteState.NOT_MUTED;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "channel",
            "has",
            "been",
            "explicitly",
            "muted",
            "using",
            "kafka",
            "channel",
            "mute"
        ]
    },
    {
        "id": 864,
        "code": "public InetAddress socketAddress() {\n    return transportLayer.socketChannel().socket().getInetAddress();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "address",
            "to",
            "which",
            "this",
            "channel",
            "s",
            "socket",
            "is",
            "connected",
            "or",
            "null",
            "if",
            "the",
            "socket",
            "has",
            "never",
            "been",
            "connected"
        ]
    },
    {
        "id": 865,
        "code": "public void addNetworkThreadTimeNanos(long nanos) {\n    networkThreadTimeNanos += nanos;\n}",
        "summary_tokens": [
            "accumulates",
            "network",
            "thread",
            "time",
            "for",
            "this",
            "channel"
        ]
    },
    {
        "id": 866,
        "code": "public long getAndResetNetworkThreadTimeNanos() {\n    long current = networkThreadTimeNanos;\n    networkThreadTimeNanos = 0;\n    return current;\n}",
        "summary_tokens": [
            "returns",
            "accumulated",
            "network",
            "thread",
            "time",
            "for",
            "this",
            "channel",
            "and",
            "resets",
            "the",
            "value",
            "to",
            "zero"
        ]
    },
    {
        "id": 867,
        "code": "public boolean hasBytesBuffered() {\n    return transportLayer.hasBytesBuffered();\n}",
        "summary_tokens": [
            "true",
            "if",
            "underlying",
            "transport",
            "has",
            "bytes",
            "remaining",
            "to",
            "be",
            "read",
            "from",
            "any",
            "underlying",
            "intermediate",
            "buffers"
        ]
    },
    {
        "id": 868,
        "code": "public int successfulAuthentications() {\n    return successfulAuthentications;\n}",
        "summary_tokens": [
            "return",
            "the",
            "number",
            "of",
            "times",
            "this",
            "instance",
            "has",
            "successfully",
            "authenticated"
        ]
    },
    {
        "id": 869,
        "code": "public boolean maybeBeginServerReauthentication(NetworkReceive saslHandshakeNetworkReceive,\n        Supplier<Long> nowNanosSupplier) throws AuthenticationException, IOException {\n    if (!ready())\n        throw new IllegalStateException(\n                \"KafkaChannel should be \\\"ready\\\" when processing SASL Handshake for potential re-authentication\");\n        \n    if (authenticator.serverSessionExpirationTimeNanos() == null)\n        return false;\n        \n    long nowNanos = nowNanosSupplier.get();\n        \n    if (lastReauthenticationStartNanos != 0\n            && nowNanos - lastReauthenticationStartNanos < MIN_REAUTH_INTERVAL_ONE_SECOND_NANOS)\n        return false;\n    lastReauthenticationStartNanos = nowNanos;\n    swapAuthenticatorsAndBeginReauthentication(\n            new ReauthenticationContext(authenticator, saslHandshakeNetworkReceive, nowNanos));\n    return true;\n}",
        "summary_tokens": [
            "if",
            "this",
            "is",
            "a",
            "server",
            "side",
            "connection",
            "that",
            "has",
            "an",
            "expiration",
            "time",
            "and",
            "at",
            "least",
            "0",
            "second",
            "has",
            "passed",
            "since",
            "the",
            "prior",
            "re",
            "authentication",
            "if",
            "any",
            "started",
            "then",
            "begin",
            "the",
            "process",
            "of",
            "re",
            "authenticating",
            "the",
            "connection",
            "and",
            "return",
            "true",
            "otherwise",
            "return",
            "false"
        ]
    },
    {
        "id": 870,
        "code": "public boolean maybeBeginClientReauthentication(Supplier<Long> nowNanosSupplier)\n        throws AuthenticationException, IOException {\n    if (!ready())\n        throw new IllegalStateException(\n                \"KafkaChannel should always be \\\"ready\\\" when it is checked for possible re-authentication\");\n    if (muteState != ChannelMuteState.NOT_MUTED || midWrite\n            || authenticator.clientSessionReauthenticationTimeNanos() == null)\n        return false;\n        \n    long nowNanos = nowNanosSupplier.get();\n    if (nowNanos < authenticator.clientSessionReauthenticationTimeNanos())\n        return false;\n    swapAuthenticatorsAndBeginReauthentication(new ReauthenticationContext(authenticator, receive, nowNanos));\n    receive = null;\n    return true;\n}",
        "summary_tokens": [
            "if",
            "this",
            "is",
            "a",
            "client",
            "side",
            "connection",
            "that",
            "is",
            "not",
            "muted",
            "there",
            "is",
            "no",
            "in",
            "progress",
            "write",
            "and",
            "there",
            "is",
            "a",
            "session",
            "expiration",
            "time",
            "defined",
            "that",
            "has",
            "past",
            "then",
            "begin",
            "the",
            "process",
            "of",
            "re",
            "authenticating",
            "the",
            "connection",
            "and",
            "return",
            "true",
            "otherwise",
            "return",
            "false"
        ]
    },
    {
        "id": 871,
        "code": "public Long reauthenticationLatencyMs() {\n    return authenticator.reauthenticationLatencyMs();\n}",
        "summary_tokens": [
            "return",
            "the",
            "number",
            "of",
            "milliseconds",
            "that",
            "elapsed",
            "while",
            "re",
            "authenticating",
            "this",
            "session",
            "from",
            "the",
            "perspective",
            "of",
            "this",
            "instance",
            "if",
            "applicable",
            "otherwise",
            "null"
        ]
    },
    {
        "id": 872,
        "code": "public boolean serverAuthenticationSessionExpired(long nowNanos) {\n    Long serverSessionExpirationTimeNanos = authenticator.serverSessionExpirationTimeNanos();\n    return serverSessionExpirationTimeNanos != null && nowNanos - serverSessionExpirationTimeNanos > 0;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "is",
            "a",
            "server",
            "side",
            "channel",
            "and",
            "the",
            "given",
            "time",
            "is",
            "past",
            "the",
            "session",
            "expiration",
            "time",
            "if",
            "any",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 873,
        "code": "public Optional<NetworkReceive> pollResponseReceivedDuringReauthentication() {\n    return authenticator.pollResponseReceivedDuringReauthentication();\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "but",
            "possibly",
            "empty",
            "client",
            "side",
            "network",
            "receive",
            "response",
            "that",
            "arrived",
            "during",
            "re",
            "authentication",
            "but",
            "is",
            "unrelated",
            "to",
            "re",
            "authentication"
        ]
    },
    {
        "id": 874,
        "code": "boolean connectedClientSupportsReauthentication() {\n    return authenticator.connectedClientSupportsReauthentication();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "is",
            "a",
            "server",
            "side",
            "channel",
            "and",
            "the",
            "connected",
            "client",
            "has",
            "indicated",
            "that",
            "it",
            "supports",
            "re",
            "authentication",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 875,
        "code": "public static ListenerName forSecurityProtocol(SecurityProtocol securityProtocol) {\n    return new ListenerName(securityProtocol.name);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "with",
            "the",
            "security",
            "protocol",
            "name",
            "as",
            "the",
            "value"
        ]
    },
    {
        "id": 876,
        "code": "public static ListenerName normalised(String value) {\n    return new ListenerName(value.toUpperCase(Locale.ROOT));\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "with",
            "the",
            "provided",
            "value",
            "converted",
            "to",
            "uppercase"
        ]
    },
    {
        "id": 877,
        "code": "public int size() {\n    return payload().limit() + size.limit();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "total",
            "size",
            "of",
            "the",
            "receive",
            "including",
            "payload",
            "and",
            "size",
            "buffer",
            "for",
            "use",
            "in",
            "metrics"
        ]
    },
    {
        "id": 878,
        "code": "",
        "summary_tokens": [
            "performs",
            "ssl",
            "handshake",
            "hence",
            "is",
            "a",
            "no",
            "op",
            "for",
            "the",
            "non",
            "secure",
            "implementation"
        ]
    },
    {
        "id": 879,
        "code": "public long read(ByteBuffer[] dsts, int offset, int length) throws IOException {\n    return socketChannel.read(dsts, offset, length);\n}",
        "summary_tokens": [
            "reads",
            "a",
            "sequence",
            "of",
            "bytes",
            "from",
            "this",
            "channel",
            "into",
            "a",
            "subsequence",
            "of",
            "the",
            "given",
            "buffers"
        ]
    },
    {
        "id": 880,
        "code": "public long write(ByteBuffer[] srcs, int offset, int length) throws IOException {\n    return socketChannel.write(srcs, offset, length);\n}",
        "summary_tokens": [
            "writes",
            "a",
            "sequence",
            "of",
            "bytes",
            "to",
            "this",
            "channel",
            "from",
            "the",
            "subsequence",
            "of",
            "the",
            "given",
            "buffers"
        ]
    },
    {
        "id": 881,
        "code": "public boolean hasPendingWrites() {\n    return false;\n}",
        "summary_tokens": [
            "always",
            "returns",
            "false",
            "as",
            "there",
            "will",
            "be",
            "not",
            "be",
            "any",
            "pending",
            "writes",
            "since",
            "we",
            "directly",
            "write",
            "to",
            "socket",
            "channel"
        ]
    },
    {
        "id": 882,
        "code": "public Principal peerPrincipal() {\n    return principal;\n}",
        "summary_tokens": [
            "returns",
            "anonymous",
            "as",
            "principal"
        ]
    },
    {
        "id": 883,
        "code": "public void addInterestOps(int ops) {\n    key.interestOps(key.interestOps() | ops);\n\n}",
        "summary_tokens": [
            "adds",
            "the",
            "interest",
            "ops",
            "to",
            "selection",
            "key"
        ]
    },
    {
        "id": 884,
        "code": "public void removeInterestOps(int ops) {\n    key.interestOps(key.interestOps() & ~ops);\n}",
        "summary_tokens": [
            "removes",
            "the",
            "interest",
            "ops",
            "from",
            "selection",
            "key"
        ]
    },
    {
        "id": 885,
        "code": "public NetworkReceive networkReceive() {\n    return networkReceive;\n}",
        "summary_tokens": [
            "return",
            "the",
            "applicable",
            "network",
            "receive",
            "instance",
            "if",
            "any"
        ]
    },
    {
        "id": 886,
        "code": "public Authenticator previousAuthenticator() {\n    return previousAuthenticator;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "authenticator",
            "that",
            "was",
            "previously",
            "used",
            "to",
            "authenticate",
            "the",
            "channel"
        ]
    },
    {
        "id": 887,
        "code": "public long reauthenticationBeginNanos() {\n    return reauthenticationBeginNanos;\n}",
        "summary_tokens": [
            "return",
            "the",
            "time",
            "when",
            "re",
            "authentication",
            "began"
        ]
    },
    {
        "id": 888,
        "code": "public void close() throws IOException {\n    State prevState = state;\n    if (state == State.CLOSING) return;\n    state = State.CLOSING;\n    sslEngine.closeOutbound();\n    try {\n        if (prevState != State.NOT_INITIALIZED && isConnected()) {\n            if (!flush(netWriteBuffer)) {\n                throw new IOException(\"Remaining data in the network buffer, can't send SSL close message.\");\n            }\n                \n            netWriteBuffer.clear();\n                \n            SSLEngineResult wrapResult = sslEngine.wrap(ByteUtils.EMPTY_BUF, netWriteBuffer);\n                \n            if (wrapResult.getStatus() != SSLEngineResult.Status.CLOSED) {\n                throw new IOException(\"Unexpected status returned by SSLEngine.wrap, expected CLOSED, received \" +\n                        wrapResult.getStatus() + \". Will not send close message to peer.\");\n            }\n            netWriteBuffer.flip();\n            flush(netWriteBuffer);\n        }\n    } catch (IOException ie) {\n        log.debug(\"Failed to send SSL Close message\", ie);\n    } finally {\n        socketChannel.socket().close();\n        socketChannel.close();\n        netReadBuffer = null;\n        netWriteBuffer = null;\n        appReadBuffer = null;\n        if (fileChannelBuffer != null) {\n            ByteBufferUnmapper.unmap(\"fileChannelBuffer\", fileChannelBuffer);\n            fileChannelBuffer = null;\n        }\n    }\n}",
        "summary_tokens": [
            "sends",
            "an",
            "ssl",
            "close",
            "message",
            "and",
            "closes",
            "socket",
            "channel"
        ]
    },
    {
        "id": 889,
        "code": "public boolean hasPendingWrites() {\n    return netWriteBuffer.hasRemaining();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "there",
            "are",
            "any",
            "pending",
            "contents",
            "in",
            "net",
            "write",
            "buffer"
        ]
    },
    {
        "id": 890,
        "code": "protected int readFromSocketChannel() throws IOException {\n    return socketChannel.read(netReadBuffer);\n}",
        "summary_tokens": [
            "reads",
            "available",
            "bytes",
            "from",
            "socket",
            "channel",
            "to",
            "net",
            "read",
            "buffer"
        ]
    },
    {
        "id": 891,
        "code": "protected boolean flush(ByteBuffer buf) throws IOException {\n    int remaining = buf.remaining();\n    if (remaining > 0) {\n        int written = socketChannel.write(buf);\n        return written >= remaining;\n    }\n    return true;\n}",
        "summary_tokens": [
            "flushes",
            "the",
            "buffer",
            "to",
            "the",
            "network",
            "non",
            "blocking"
        ]
    },
    {
        "id": 892,
        "code": "public void handshake() throws IOException {\n    if (state == State.NOT_INITIALIZED) {\n        try {\n            startHandshake();\n        } catch (SSLException e) {\n            maybeProcessHandshakeFailure(e, false, null);\n        }\n    }\n    if (ready())\n        throw renegotiationException();\n    if (state == State.CLOSING)\n        throw closingException();\n\n    int read = 0;\n    boolean readable = key.isReadable();\n    try {\n            \n            \n            \n        if (readable)\n            read = readFromSocketChannel();\n\n        doHandshake();\n        if (ready())\n            updateBytesBuffered(true);\n    } catch (SSLException e) {\n        maybeProcessHandshakeFailure(e, true, null);\n    } catch (IOException e) {\n        maybeThrowSslAuthenticationException();\n\n            \n            \n        try {\n            do {\n                log.trace(\"Process any available bytes from peer, netReadBuffer {} netWriterBuffer {} handshakeStatus {} readable? {}\",\n                    netReadBuffer, netWriteBuffer, handshakeStatus, readable);\n                handshakeWrapAfterFailure(false);\n                handshakeUnwrap(false, true);\n            } while (readable && readFromSocketChannel() > 0);\n        } catch (SSLException e1) {\n            maybeProcessHandshakeFailure(e1, false, e);\n        }\n\n            \n        throw e;\n    }\n\n        \n    if (read == -1) {\n        maybeThrowSslAuthenticationException();\n        throw new EOFException(\"EOF during handshake, handshake status is \" + handshakeStatus);\n    }\n}",
        "summary_tokens": [
            "performs",
            "ssl",
            "handshake",
            "non",
            "blocking"
        ]
    },
    {
        "id": 893,
        "code": "private HandshakeStatus runDelegatedTasks() {\n    for (;;) {\n        Runnable task = delegatedTask();\n        if (task == null) {\n            break;\n        }\n        task.run();\n    }\n    return sslEngine.getHandshakeStatus();\n}",
        "summary_tokens": [
            "executes",
            "the",
            "sslengine",
            "tasks",
            "needed"
        ]
    },
    {
        "id": 894,
        "code": "private void handshakeFinished() throws IOException {\n        \n        \n        \n    if (handshakeResult.getHandshakeStatus() == HandshakeStatus.FINISHED) {\n            \n            \n        if (netWriteBuffer.hasRemaining())\n            key.interestOps(key.interestOps() | SelectionKey.OP_WRITE);\n        else {\n            state = sslEngine.getSession().getProtocol().equals(TLS13) ? State.POST_HANDSHAKE : State.READY;\n            key.interestOps(key.interestOps() & ~SelectionKey.OP_WRITE);\n            SSLSession session = sslEngine.getSession();\n            log.debug(\"SSL handshake completed successfully with peerHost '{}' peerPort {} peerPrincipal '{}' cipherSuite '{}'\",\n                    session.getPeerHost(), session.getPeerPort(), peerPrincipal(), session.getCipherSuite());\n            metadataRegistry.registerCipherInformation(\n                new CipherInformation(session.getCipherSuite(),  session.getProtocol()));\n        }\n\n        log.trace(\"SSLHandshake FINISHED channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {} \",\n                  channelId, appReadBuffer.position(), netReadBuffer.position(), netWriteBuffer.position());\n    } else {\n        throw new IOException(\"NOT_HANDSHAKING during handshake\");\n    }\n}",
        "summary_tokens": [
            "checks",
            "if",
            "the",
            "handshake",
            "status",
            "is",
            "finished",
            "sets",
            "the",
            "interest",
            "ops",
            "for",
            "the",
            "selection",
            "key"
        ]
    },
    {
        "id": 895,
        "code": "private SSLEngineResult handshakeWrap(boolean doWrite) throws IOException {\n    log.trace(\"SSLHandshake handshakeWrap {}\", channelId);\n    if (netWriteBuffer.hasRemaining())\n        throw new IllegalStateException(\"handshakeWrap called with netWriteBuffer not empty\");\n        \n        \n    netWriteBuffer.clear();\n    SSLEngineResult result;\n    try {\n        result = sslEngine.wrap(ByteUtils.EMPTY_BUF, netWriteBuffer);\n    } finally {\n            \n        netWriteBuffer.flip();\n    }\n    handshakeStatus = result.getHandshakeStatus();\n    if (result.getStatus() == SSLEngineResult.Status.OK &&\n        result.getHandshakeStatus() == HandshakeStatus.NEED_TASK) {\n        handshakeStatus = runDelegatedTasks();\n    }\n\n    if (doWrite) flush(netWriteBuffer);\n    return result;\n}",
        "summary_tokens": [
            "performs",
            "the",
            "wrap",
            "function",
            "do",
            "write",
            "boolean",
            "sslengine",
            "result",
            "ioexception"
        ]
    },
    {
        "id": 896,
        "code": "private SSLEngineResult handshakeUnwrap(boolean doRead, boolean ignoreHandshakeStatus) throws IOException {\n    log.trace(\"SSLHandshake handshakeUnwrap {}\", channelId);\n    SSLEngineResult result;\n    int read = 0;\n    if (doRead)\n        read = readFromSocketChannel();\n    boolean cont;\n    do {\n            \n        int position = netReadBuffer.position();\n        netReadBuffer.flip();\n        result = sslEngine.unwrap(netReadBuffer, appReadBuffer);\n        netReadBuffer.compact();\n        handshakeStatus = result.getHandshakeStatus();\n        if (result.getStatus() == SSLEngineResult.Status.OK &&\n            result.getHandshakeStatus() == HandshakeStatus.NEED_TASK) {\n            handshakeStatus = runDelegatedTasks();\n        }\n        cont = (result.getStatus() == SSLEngineResult.Status.OK &&\n                handshakeStatus == HandshakeStatus.NEED_UNWRAP) ||\n                (ignoreHandshakeStatus && netReadBuffer.position() != position);\n        log.trace(\"SSLHandshake handshakeUnwrap: handshakeStatus {} status {}\", handshakeStatus, result.getStatus());\n    } while (netReadBuffer.position() != 0 && cont);\n\n        \n        \n    if (read == -1)\n        throw new EOFException(\"EOF during handshake, handshake status is \" + handshakeStatus);\n\n    return result;\n}",
        "summary_tokens": [
            "perform",
            "handshake",
            "unwrap",
            "do",
            "read",
            "boolean",
            "if",
            "true",
            "read",
            "more",
            "from",
            "the",
            "socket",
            "channel",
            "ignore",
            "handshake",
            "status",
            "if",
            "true",
            "continue",
            "to",
            "unwrap",
            "if",
            "data",
            "available",
            "regardless",
            "of",
            "handshake",
            "status",
            "sslengine",
            "result",
            "ioexception"
        ]
    },
    {
        "id": 897,
        "code": "public long read(ByteBuffer[] dsts, int offset, int length) throws IOException {\n    if ((offset < 0) || (length < 0) || (offset > dsts.length - length))\n        throw new IndexOutOfBoundsException();\n\n    int totalRead = 0;\n    int i = offset;\n    while (i < length) {\n        if (dsts[i].hasRemaining()) {\n            int read = read(dsts[i]);\n            if (read > 0)\n                totalRead += read;\n            else\n                break;\n        }\n        if (!dsts[i].hasRemaining()) {\n            i++;\n        }\n    }\n    return totalRead;\n}",
        "summary_tokens": [
            "reads",
            "a",
            "sequence",
            "of",
            "bytes",
            "from",
            "this",
            "channel",
            "into",
            "a",
            "subsequence",
            "of",
            "the",
            "given",
            "buffers"
        ]
    },
    {
        "id": 898,
        "code": "public long write(ByteBuffer[] srcs) throws IOException {\n    return write(srcs, 0, srcs.length);\n}",
        "summary_tokens": [
            "writes",
            "a",
            "sequence",
            "of",
            "bytes",
            "to",
            "this",
            "channel",
            "from",
            "the",
            "given",
            "buffers"
        ]
    },
    {
        "id": 899,
        "code": "public Principal peerPrincipal() {\n    try {\n        return sslEngine.getSession().getPeerPrincipal();\n    } catch (SSLPeerUnverifiedException se) {\n        log.debug(\"SSL peer is not authenticated, returning ANONYMOUS instead\");\n        return KafkaPrincipal.ANONYMOUS;\n    }\n}",
        "summary_tokens": [
            "sslsession",
            "s",
            "peer",
            "principal",
            "for",
            "the",
            "remote",
            "host"
        ]
    },
    {
        "id": 900,
        "code": "public SSLSession sslSession() throws IllegalStateException {\n    return sslEngine.getSession();\n}",
        "summary_tokens": [
            "returns",
            "an",
            "ssl",
            "session",
            "after",
            "the",
            "handshake",
            "is",
            "established",
            "throws",
            "illegal",
            "state",
            "exception",
            "if",
            "the",
            "handshake",
            "is",
            "not",
            "established"
        ]
    },
    {
        "id": 901,
        "code": "public void addInterestOps(int ops) {\n    if (!key.isValid())\n        throw new CancelledKeyException();\n    else if (!ready())\n        throw new IllegalStateException(\"handshake is not completed\");\n\n    key.interestOps(key.interestOps() | ops);\n}",
        "summary_tokens": [
            "adds",
            "interest",
            "ops",
            "to",
            "selection",
            "key",
            "of",
            "the",
            "transport",
            "layer",
            "ops",
            "selection",
            "key",
            "interest",
            "ops"
        ]
    },
    {
        "id": 902,
        "code": "public void removeInterestOps(int ops) {\n    if (!key.isValid())\n        throw new CancelledKeyException();\n    else if (!ready())\n        throw new IllegalStateException(\"handshake is not completed\");\n\n    key.interestOps(key.interestOps() & ~ops);\n}",
        "summary_tokens": [
            "removes",
            "interest",
            "ops",
            "to",
            "selection",
            "key",
            "of",
            "the",
            "transport",
            "layer",
            "ops",
            "selection",
            "key",
            "interest",
            "ops"
        ]
    },
    {
        "id": 903,
        "code": "protected Runnable delegatedTask() {\n    return sslEngine.getDelegatedTask();\n}",
        "summary_tokens": [
            "returns",
            "delegated",
            "task",
            "for",
            "the",
            "sslengine"
        ]
    },
    {
        "id": 904,
        "code": "private int readFromAppBuffer(ByteBuffer dst) {\n    appReadBuffer.flip();\n    int remaining = Math.min(appReadBuffer.remaining(), dst.remaining());\n    if (remaining > 0) {\n        int limit = appReadBuffer.limit();\n        appReadBuffer.limit(appReadBuffer.position() + remaining);\n        dst.put(appReadBuffer);\n        appReadBuffer.limit(limit);\n    }\n    appReadBuffer.compact();\n    return remaining;\n}",
        "summary_tokens": [
            "transfers",
            "app",
            "read",
            "buffer",
            "contents",
            "decrypted",
            "data",
            "into",
            "dst",
            "bytebuffer",
            "dst",
            "byte",
            "buffer"
        ]
    },
    {
        "id": 905,
        "code": "private void handshakeFailure(SSLException sslException, boolean flush) throws IOException {\n        \n    log.debug(\"SSL Handshake failed\", sslException);\n    sslEngine.closeOutbound();\n    try {\n        sslEngine.closeInbound();\n    } catch (SSLException e) {\n        log.debug(\"SSLEngine.closeInBound() raised an exception.\", e);\n    }\n\n    state = State.HANDSHAKE_FAILED;\n    handshakeException = new SslAuthenticationException(\"SSL handshake failed\", sslException);\n\n        \n        \n        \n    if (!flush || handshakeWrapAfterFailure(flush))\n        throw handshakeException;\n    else\n        log.debug(\"Delay propagation of handshake exception till {} bytes remaining are flushed\", netWriteBuffer.remaining());\n}",
        "summary_tokens": [
            "ssl",
            "exceptions",
            "are",
            "propagated",
            "as",
            "authentication",
            "failures",
            "so",
            "that",
            "clients",
            "can",
            "avoid",
            "retries",
            "and",
            "report",
            "the",
            "failure"
        ]
    },
    {
        "id": 906,
        "code": "private boolean handshakeWrapAfterFailure(boolean doWrite) {\n    try {\n        log.trace(\"handshakeWrapAfterFailure status {} doWrite {}\", handshakeStatus, doWrite);\n        while (handshakeStatus == HandshakeStatus.NEED_WRAP && (!doWrite || flush(netWriteBuffer))) {\n            if (!doWrite)\n                clearWriteBuffer();\n            handshakeWrap(doWrite);\n        }\n    } catch (Exception e) {\n        log.debug(\"Failed to wrap and flush all bytes before closing channel\", e);\n        clearWriteBuffer();\n    }\n    if (!doWrite)\n        clearWriteBuffer();\n    return !netWriteBuffer.hasRemaining();\n}",
        "summary_tokens": [
            "perform",
            "handshake",
            "wrap",
            "after",
            "an",
            "sslexception",
            "or",
            "any",
            "ioexception"
        ]
    },
    {
        "id": 907,
        "code": "default int size(ObjectSerializationCache cache, short version) {\n    MessageSizeAccumulator size = new MessageSizeAccumulator();\n    addSize(size, cache, version);\n    return size.totalSize();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "bytes",
            "it",
            "would",
            "take",
            "to",
            "write",
            "out",
            "this",
            "message"
        ]
    },
    {
        "id": 908,
        "code": "public int totalSize() {\n    return totalSize;\n}",
        "summary_tokens": [
            "get",
            "the",
            "total",
            "size",
            "of",
            "the",
            "message"
        ]
    },
    {
        "id": 909,
        "code": "public int sizeExcludingZeroCopy() {\n    return totalSize - zeroCopySize;\n}",
        "summary_tokens": [
            "size",
            "excluding",
            "zero",
            "copy",
            "fields",
            "as",
            "specified",
            "by",
            "zero",
            "copy",
            "size"
        ]
    },
    {
        "id": 910,
        "code": "public int zeroCopySize() {\n    return zeroCopySize;\n}",
        "summary_tokens": [
            "get",
            "the",
            "total",
            "zero",
            "copy",
            "size",
            "of",
            "the",
            "message"
        ]
    },
    {
        "id": 911,
        "code": "public static byte[] byteBufferToArray(ByteBuffer buf) {\n    byte[] arr = new byte[buf.remaining()];\n    int prevPosition = buf.position();\n    try {\n        buf.get(arr);\n    } finally {\n        buf.position(prevPosition);\n    }\n    return arr;\n}",
        "summary_tokens": [
            "copy",
            "a",
            "byte",
            "buffer",
            "into",
            "an",
            "array"
        ]
    },
    {
        "id": 912,
        "code": "public static boolean compareRawTaggedFields(List<RawTaggedField> first,\n                                             List<RawTaggedField> second) {\n    if (first == null) {\n        return second == null || second.isEmpty();\n    } else if (second == null) {\n        return first.isEmpty();\n    } else {\n        return first.equals(second);\n    }\n}",
        "summary_tokens": [
            "compare",
            "two",
            "raw",
            "tagged",
            "fields",
            "lists"
        ]
    },
    {
        "id": 913,
        "code": "default Uuid readUuid() {\n    return new Uuid(readLong(), readLong());\n}",
        "summary_tokens": [
            "read",
            "a",
            "uuid",
            "with",
            "the",
            "most",
            "significant",
            "digits",
            "first"
        ]
    },
    {
        "id": 914,
        "code": "public void writeByteBuffer(ByteBuffer buf) {\n    flushPendingBuffer();\n    addBuffer(buf.duplicate());\n}",
        "summary_tokens": [
            "write",
            "a",
            "byte",
            "buffer"
        ]
    },
    {
        "id": 915,
        "code": "public void writeRecords(BaseRecords records) {\n    if (records instanceof MemoryRecords) {\n        flushPendingBuffer();\n        addBuffer(((MemoryRecords) records).buffer());\n    } else if (records instanceof UnalignedMemoryRecords) {\n        flushPendingBuffer();\n        addBuffer(((UnalignedMemoryRecords) records).buffer());\n    } else {\n        flushPendingSend();\n        addSend(records.toSend());\n    }\n}",
        "summary_tokens": [
            "write",
            "a",
            "record",
            "set"
        ]
    },
    {
        "id": 916,
        "code": "public void write(ByteBuffer buffer, Object o) {\n    Struct r = (Struct) o;\n    for (BoundField field : fields) {\n        try {\n            Object value = field.def.type.validate(r.get(field));\n            field.def.type.write(buffer, value);\n        } catch (Exception e) {\n            throw new SchemaException(\"Error writing field '\" + field.def.name + \"': \" +\n                                      (e.getMessage() == null ? e.getClass().getName() : e.getMessage()));\n        }\n    }\n}",
        "summary_tokens": [
            "write",
            "a",
            "struct",
            "to",
            "the",
            "buffer"
        ]
    },
    {
        "id": 917,
        "code": "public Struct read(ByteBuffer buffer) {\n    if (cachedStruct != null) {\n        return cachedStruct;\n    }\n    Object[] objects = new Object[fields.length];\n    for (int i = 0; i < fields.length; i++) {\n        try {\n            if (tolerateMissingFieldsWithDefaults) {\n                if (buffer.hasRemaining()) {\n                    objects[i] = fields[i].def.type.read(buffer);\n                } else if (fields[i].def.hasDefaultValue) {\n                    objects[i] = fields[i].def.defaultValue;\n                } else {\n                    throw new SchemaException(\"Missing value for field '\" + fields[i].def.name +\n                            \"' which has no default value.\");\n                }\n            } else {\n                objects[i] = fields[i].def.type.read(buffer);\n            }\n        } catch (Exception e) {\n            throw new SchemaException(\"Error reading field '\" + fields[i].def.name + \"': \" +\n                                      (e.getMessage() == null ? e.getClass().getName() : e.getMessage()));\n        }\n    }\n    return new Struct(this, objects);\n}",
        "summary_tokens": [
            "read",
            "a",
            "struct",
            "from",
            "the",
            "buffer"
        ]
    },
    {
        "id": 918,
        "code": "public int sizeOf(Object o) {\n    int size = 0;\n    Struct r = (Struct) o;\n    for (BoundField field : fields) {\n        try {\n            size += field.def.type.sizeOf(r.get(field));\n        } catch (Exception e) {\n            throw new SchemaException(\"Error computing size for field '\" + field.def.name + \"': \" +\n                    (e.getMessage() == null ? e.getClass().getName() : e.getMessage()));\n        }\n    }\n    return size;\n}",
        "summary_tokens": [
            "the",
            "size",
            "of",
            "the",
            "given",
            "record"
        ]
    },
    {
        "id": 919,
        "code": "public int numFields() {\n    return this.fields.length;\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "fields",
            "in",
            "this",
            "schema"
        ]
    },
    {
        "id": 920,
        "code": "public BoundField get(String name) {\n    return this.fieldsByName.get(name);\n}",
        "summary_tokens": [
            "get",
            "a",
            "field",
            "by",
            "its",
            "name"
        ]
    },
    {
        "id": 921,
        "code": "public BoundField[] fields() {\n    return this.fields;\n}",
        "summary_tokens": [
            "get",
            "all",
            "the",
            "fields",
            "in",
            "this",
            "schema"
        ]
    },
    {
        "id": 922,
        "code": "public String toString() {\n    StringBuilder b = new StringBuilder();\n    b.append('{');\n    for (int i = 0; i < this.fields.length; i++) {\n        b.append(this.fields[i].toString());\n        if (i < this.fields.length - 1)\n            b.append(',');\n    }\n    b.append(\"}\");\n    return b.toString();\n}",
        "summary_tokens": [
            "display",
            "a",
            "string",
            "representation",
            "of",
            "the",
            "schema"
        ]
    },
    {
        "id": 923,
        "code": "public Schema schema() {\n    return this.schema;\n}",
        "summary_tokens": [
            "the",
            "schema",
            "for",
            "this",
            "struct"
        ]
    },
    {
        "id": 924,
        "code": "private Object getFieldOrDefault(BoundField field) {\n    Object value = this.values[field.index];\n    if (value != null)\n        return value;\n    else if (field.def.hasDefaultValue)\n        return field.def.defaultValue;\n    else if (field.def.type.isNullable())\n        return null;\n    else\n        throw new SchemaException(\"Missing value for field '\" + field.def.name + \"' which has no default value.\");\n}",
        "summary_tokens": [
            "return",
            "the",
            "value",
            "of",
            "the",
            "given",
            "pre",
            "validated",
            "field",
            "or",
            "if",
            "the",
            "value",
            "is",
            "missing",
            "return",
            "the",
            "default",
            "value"
        ]
    },
    {
        "id": 925,
        "code": "public Object get(String name) {\n    BoundField field = schema.get(name);\n    if (field == null)\n        throw new SchemaException(\"No such field: \" + name);\n    return getFieldOrDefault(field);\n}",
        "summary_tokens": [
            "get",
            "the",
            "record",
            "value",
            "for",
            "the",
            "field",
            "with",
            "the",
            "given",
            "name",
            "by",
            "doing",
            "a",
            "hash",
            "table",
            "lookup",
            "slower"
        ]
    },
    {
        "id": 926,
        "code": "public boolean hasField(String name) {\n    return schema.get(name) != null;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "struct",
            "contains",
            "a",
            "field"
        ]
    },
    {
        "id": 927,
        "code": "public Struct set(String name, Object value) {\n    BoundField field = this.schema.get(name);\n    if (field == null)\n        throw new SchemaException(\"Unknown field: \" + name);\n    this.values[field.index] = value;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "field",
            "specified",
            "by",
            "the",
            "given",
            "name",
            "to",
            "the",
            "value"
        ]
    },
    {
        "id": 928,
        "code": "public Struct instance(String field) {\n    return instance(schema.get(field));\n}",
        "summary_tokens": [
            "create",
            "a",
            "struct",
            "instance",
            "for",
            "the",
            "given",
            "field",
            "which",
            "must",
            "be",
            "a",
            "container",
            "type",
            "struct",
            "or",
            "array"
        ]
    },
    {
        "id": 929,
        "code": "public void clear() {\n    Arrays.fill(this.values, null);\n}",
        "summary_tokens": [
            "empty",
            "all",
            "the",
            "values",
            "from",
            "this",
            "record"
        ]
    },
    {
        "id": 930,
        "code": "public int sizeOf() {\n    return this.schema.sizeOf(this);\n}",
        "summary_tokens": [
            "get",
            "the",
            "serialized",
            "size",
            "of",
            "this",
            "object"
        ]
    },
    {
        "id": 931,
        "code": "public void writeTo(ByteBuffer buffer) {\n    this.schema.write(buffer, this);\n}",
        "summary_tokens": [
            "write",
            "this",
            "struct",
            "to",
            "a",
            "buffer"
        ]
    },
    {
        "id": 932,
        "code": "private void validateField(BoundField field) {\n    Objects.requireNonNull(field, \"`field` must be non-null\");\n    if (this.schema != field.schema)\n        throw new SchemaException(\"Attempt to access field '\" + field.def.name + \"' from a different schema instance.\");\n    if (field.index > values.length)\n        throw new SchemaException(\"Invalid field index: \" + field.index);\n}",
        "summary_tokens": [
            "ensure",
            "the",
            "user",
            "doesn",
            "t",
            "try",
            "to",
            "access",
            "fields",
            "from",
            "the",
            "wrong",
            "schema"
        ]
    },
    {
        "id": 933,
        "code": "public void validate() {\n    this.schema.validate(this);\n}",
        "summary_tokens": [
            "validate",
            "the",
            "contents",
            "of",
            "this",
            "struct",
            "against",
            "its",
            "schema"
        ]
    },
    {
        "id": 934,
        "code": "public static TaggedFields of(Object... fields) {\n    if (fields.length % 2 != 0) {\n        throw new RuntimeException(\"TaggedFields#of takes an even \" +\n            \"number of parameters.\");\n    }\n    TreeMap<Integer, Field> newFields = new TreeMap<>();\n    for (int i = 0; i < fields.length; i += 2) {\n        Integer tag = (Integer) fields[i];\n        Field field = (Field) fields[i + 1];\n        newFields.put(tag, field);\n    }\n    return new TaggedFields(newFields);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "tagged",
            "fields",
            "object",
            "with",
            "the",
            "given",
            "tags",
            "and",
            "fields"
        ]
    },
    {
        "id": 935,
        "code": "public int numFields() {\n    return this.fields.size();\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "tagged",
            "fields"
        ]
    },
    {
        "id": 936,
        "code": "public boolean isNullable() {\n    return false;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "type",
            "supports",
            "null",
            "values",
            "whether",
            "or",
            "not",
            "null",
            "is",
            "a",
            "valid",
            "value",
            "for",
            "the",
            "type",
            "implementation"
        ]
    },
    {
        "id": 937,
        "code": "public Optional<Type> arrayElementType() {\n    return Optional.empty();\n}",
        "summary_tokens": [
            "if",
            "the",
            "type",
            "is",
            "an",
            "array",
            "return",
            "the",
            "type",
            "of",
            "the",
            "array",
            "elements"
        ]
    },
    {
        "id": 938,
        "code": "public final boolean isArray() {\n    return arrayElementType().isPresent();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "type",
            "is",
            "an",
            "array"
        ]
    },
    {
        "id": 939,
        "code": "public ClientQuotaEntity entity() {\n    return this.entity;\n}",
        "summary_tokens": [
            "the",
            "entity",
            "whose",
            "config",
            "will",
            "be",
            "modified"
        ]
    },
    {
        "id": 940,
        "code": "public Collection<Op> ops() {\n    return this.ops;\n}",
        "summary_tokens": [
            "the",
            "alteration",
            "to",
            "perform"
        ]
    },
    {
        "id": 941,
        "code": "public Map<String, String> entries() {\n    return this.entries;\n}",
        "summary_tokens": [
            "map",
            "of",
            "entity",
            "type",
            "to",
            "its",
            "name"
        ]
    },
    {
        "id": 942,
        "code": "public static ClientQuotaFilter contains(Collection<ClientQuotaFilterComponent> components) {\n    return new ClientQuotaFilter(components, false);\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "quota",
            "filter",
            "that",
            "matches",
            "all",
            "provided",
            "components"
        ]
    },
    {
        "id": 943,
        "code": "public static ClientQuotaFilter containsOnly(Collection<ClientQuotaFilterComponent> components) {\n    return new ClientQuotaFilter(components, true);\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "quota",
            "filter",
            "that",
            "matches",
            "all",
            "provided",
            "components"
        ]
    },
    {
        "id": 944,
        "code": "public static ClientQuotaFilter all() {\n    return new ClientQuotaFilter(Collections.emptyList(), false);\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "quota",
            "filter",
            "that",
            "matches",
            "all",
            "configured",
            "entities"
        ]
    },
    {
        "id": 945,
        "code": "public Collection<ClientQuotaFilterComponent> components() {\n    return this.components;\n}",
        "summary_tokens": [
            "the",
            "filter",
            "s",
            "components"
        ]
    },
    {
        "id": 946,
        "code": "public boolean strict() {\n    return this.strict;\n}",
        "summary_tokens": [
            "whether",
            "the",
            "filter",
            "is",
            "strict",
            "i"
        ]
    },
    {
        "id": 947,
        "code": "public static ClientQuotaFilterComponent ofEntity(String entityType, String entityName) {\n    return new ClientQuotaFilterComponent(entityType, Optional.of(Objects.requireNonNull(entityName)));\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "filter",
            "component",
            "that",
            "exactly",
            "matches",
            "the",
            "provided",
            "entity",
            "name",
            "for",
            "the",
            "entity",
            "type"
        ]
    },
    {
        "id": 948,
        "code": "public static ClientQuotaFilterComponent ofDefaultEntity(String entityType) {\n    return new ClientQuotaFilterComponent(entityType, Optional.empty());\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "filter",
            "component",
            "that",
            "matches",
            "the",
            "built",
            "in",
            "default",
            "entity",
            "name",
            "for",
            "the",
            "entity",
            "type"
        ]
    },
    {
        "id": 949,
        "code": "public static ClientQuotaFilterComponent ofEntityType(String entityType) {\n    return new ClientQuotaFilterComponent(entityType, null);\n}",
        "summary_tokens": [
            "constructs",
            "and",
            "returns",
            "a",
            "filter",
            "component",
            "that",
            "matches",
            "any",
            "specified",
            "name",
            "for",
            "the",
            "entity",
            "type"
        ]
    },
    {
        "id": 950,
        "code": "public String entityType() {\n    return this.entityType;\n}",
        "summary_tokens": [
            "the",
            "component",
            "s",
            "entity",
            "type"
        ]
    },
    {
        "id": 951,
        "code": "public Optional<String> match() {\n    return this.match;\n}",
        "summary_tokens": [
            "the",
            "optional",
            "match",
            "string",
            "where",
            "if",
            "present",
            "the",
            "name",
            "that",
            "s",
            "matched",
            "exactly",
            "if",
            "empty",
            "matches",
            "the",
            "default",
            "name",
            "if",
            "null",
            "matches",
            "any",
            "specified",
            "name"
        ]
    },
    {
        "id": 952,
        "code": "public Iterator<Record> iterator() {\n    return iterator(BufferSupplier.NO_CACHING);\n}",
        "summary_tokens": [
            "get",
            "an",
            "iterator",
            "for",
            "the",
            "nested",
            "entries",
            "contained",
            "within",
            "this",
            "batch"
        ]
    },
    {
        "id": 953,
        "code": "public Iterable<Record> records() {\n    return records;\n}",
        "summary_tokens": [
            "get",
            "an",
            "iterator",
            "over",
            "the",
            "deep",
            "records"
        ]
    },
    {
        "id": 954,
        "code": "public static int estimateSizeInBytesUpperBound(byte magic, CompressionType compressionType, ByteBuffer key,\n                                                ByteBuffer value, Header[] headers) {\n    if (magic >= RecordBatch.MAGIC_VALUE_V2)\n        return DefaultRecordBatch.estimateBatchSizeUpperBound(key, value, headers);\n    else if (compressionType != CompressionType.NONE)\n        return Records.LOG_OVERHEAD + LegacyRecord.recordOverhead(magic) + LegacyRecord.recordSize(magic, key, value);\n    else\n        return Records.LOG_OVERHEAD + LegacyRecord.recordSize(magic, key, value);\n}",
        "summary_tokens": [
            "get",
            "an",
            "upper",
            "bound",
            "estimate",
            "on",
            "the",
            "batch",
            "size",
            "needed",
            "to",
            "hold",
            "a",
            "record",
            "with",
            "the",
            "given",
            "fields"
        ]
    },
    {
        "id": 955,
        "code": "public static int recordBatchHeaderSizeInBytes(byte magic, CompressionType compressionType) {\n    if (magic > RecordBatch.MAGIC_VALUE_V1) {\n        return DefaultRecordBatch.RECORD_BATCH_OVERHEAD;\n    } else if (compressionType != CompressionType.NONE) {\n        return Records.LOG_OVERHEAD + LegacyRecord.recordOverhead(magic);\n    } else {\n        return 0;\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "size",
            "of",
            "the",
            "record",
            "batch",
            "header"
        ]
    },
    {
        "id": 956,
        "code": "Integer nextBatchSize() throws CorruptRecordException {\n    int remaining = buffer.remaining();\n    if (remaining < LOG_OVERHEAD)\n        return null;\n    int recordSize = buffer.getInt(buffer.position() + SIZE_OFFSET);\n        \n    if (recordSize < LegacyRecord.RECORD_OVERHEAD_V0)\n        throw new CorruptRecordException(String.format(\"Record size %d is less than the minimum record overhead (%d)\",\n                recordSize, LegacyRecord.RECORD_OVERHEAD_V0));\n    if (recordSize > maxMessageSize)\n        throw new CorruptRecordException(String.format(\"Record size %d exceeds the largest allowable message size (%d).\",\n                recordSize, maxMessageSize));\n\n    if (remaining < HEADER_SIZE_UP_TO_MAGIC)\n        return null;\n\n    byte magic = buffer.get(buffer.position() + MAGIC_OFFSET);\n    if (magic < 0 || magic > RecordBatch.CURRENT_MAGIC_VALUE)\n        throw new CorruptRecordException(\"Invalid magic found in record: \" + magic);\n\n    return recordSize + LOG_OVERHEAD;\n}",
        "summary_tokens": [
            "validates",
            "the",
            "header",
            "of",
            "the",
            "next",
            "batch",
            "and",
            "returns",
            "batch",
            "size"
        ]
    },
    {
        "id": 957,
        "code": "public static float updateEstimation(String topic, CompressionType type, float observedRatio) {\n    float[] compressionRatioForTopic = getAndCreateEstimationIfAbsent(topic);\n    float currentEstimation = compressionRatioForTopic[type.id];\n    synchronized (compressionRatioForTopic) {\n        if (observedRatio > currentEstimation)\n            compressionRatioForTopic[type.id] = Math.max(currentEstimation + COMPRESSION_RATIO_DETERIORATE_STEP, observedRatio);\n        else if (observedRatio < currentEstimation) {\n            compressionRatioForTopic[type.id] = Math.max(currentEstimation - COMPRESSION_RATIO_IMPROVING_STEP, observedRatio);\n        }\n    }\n    return compressionRatioForTopic[type.id];\n}",
        "summary_tokens": [
            "update",
            "the",
            "compression",
            "ratio",
            "estimation",
            "for",
            "a",
            "topic",
            "and",
            "compression",
            "type"
        ]
    },
    {
        "id": 958,
        "code": "public static float estimation(String topic, CompressionType type) {\n    float[] compressionRatioForTopic = getAndCreateEstimationIfAbsent(topic);\n    return compressionRatioForTopic[type.id];\n}",
        "summary_tokens": [
            "get",
            "the",
            "compression",
            "ratio",
            "estimation",
            "for",
            "a",
            "topic",
            "and",
            "compression",
            "type"
        ]
    },
    {
        "id": 959,
        "code": "public static void resetEstimation(String topic) {\n    float[] compressionRatioForTopic = getAndCreateEstimationIfAbsent(topic);\n    synchronized (compressionRatioForTopic) {\n        for (CompressionType type : CompressionType.values()) {\n            compressionRatioForTopic[type.id] = type.rate;\n        }\n    }\n}",
        "summary_tokens": [
            "reset",
            "the",
            "compression",
            "ratio",
            "estimation",
            "to",
            "the",
            "initial",
            "values",
            "for",
            "a",
            "topic"
        ]
    },
    {
        "id": 960,
        "code": "public static void removeEstimation(String topic) {\n    COMPRESSION_RATIO.remove(topic);\n}",
        "summary_tokens": [
            "remove",
            "the",
            "compression",
            "ratio",
            "estimation",
            "for",
            "a",
            "topic"
        ]
    },
    {
        "id": 961,
        "code": "public static void setEstimation(String topic, CompressionType type, float ratio) {\n    float[] compressionRatioForTopic = getAndCreateEstimationIfAbsent(topic);\n    synchronized (compressionRatioForTopic) {\n        compressionRatioForTopic[type.id] = ratio;\n    }\n}",
        "summary_tokens": [
            "set",
            "the",
            "compression",
            "estimation",
            "for",
            "a",
            "topic",
            "compression",
            "type",
            "combination"
        ]
    },
    {
        "id": 962,
        "code": "public static int writeTo(DataOutputStream out,\n                          int offsetDelta,\n                          long timestampDelta,\n                          ByteBuffer key,\n                          ByteBuffer value,\n                          Header[] headers) throws IOException {\n    int sizeInBytes = sizeOfBodyInBytes(offsetDelta, timestampDelta, key, value, headers);\n    ByteUtils.writeVarint(sizeInBytes, out);\n\n    byte attributes = 0; \n    out.write(attributes);\n\n    ByteUtils.writeVarlong(timestampDelta, out);\n    ByteUtils.writeVarint(offsetDelta, out);\n\n    if (key == null) {\n        ByteUtils.writeVarint(-1, out);\n    } else {\n        int keySize = key.remaining();\n        ByteUtils.writeVarint(keySize, out);\n        Utils.writeTo(out, key, keySize);\n    }\n\n    if (value == null) {\n        ByteUtils.writeVarint(-1, out);\n    } else {\n        int valueSize = value.remaining();\n        ByteUtils.writeVarint(valueSize, out);\n        Utils.writeTo(out, value, valueSize);\n    }\n\n    if (headers == null)\n        throw new IllegalArgumentException(\"Headers cannot be null\");\n\n    ByteUtils.writeVarint(headers.length, out);\n\n    for (Header header : headers) {\n        String headerKey = header.key();\n        if (headerKey == null)\n            throw new IllegalArgumentException(\"Invalid null header key found in headers\");\n\n        byte[] utf8Bytes = Utils.utf8(headerKey);\n        ByteUtils.writeVarint(utf8Bytes.length, out);\n        out.write(utf8Bytes);\n\n        byte[] headerValue = header.value();\n        if (headerValue == null) {\n            ByteUtils.writeVarint(-1, out);\n        } else {\n            ByteUtils.writeVarint(headerValue.length, out);\n            out.write(headerValue);\n        }\n    }\n\n    return ByteUtils.sizeOfVarint(sizeInBytes) + sizeInBytes;\n}",
        "summary_tokens": [
            "write",
            "the",
            "record",
            "to",
            "out",
            "and",
            "return",
            "its",
            "size"
        ]
    },
    {
        "id": 963,
        "code": "public long baseTimestamp() {\n    return buffer.getLong(BASE_TIMESTAMP_OFFSET);\n}",
        "summary_tokens": [
            "gets",
            "the",
            "base",
            "timestamp",
            "of",
            "the",
            "batch",
            "which",
            "is",
            "used",
            "to",
            "calculate",
            "the",
            "record",
            "timestamps",
            "from",
            "the",
            "deltas"
        ]
    },
    {
        "id": 964,
        "code": "static int estimateBatchSizeUpperBound(ByteBuffer key, ByteBuffer value, Header[] headers) {\n    return RECORD_BATCH_OVERHEAD + DefaultRecord.recordSizeUpperBound(key, value, headers);\n}",
        "summary_tokens": [
            "get",
            "an",
            "upper",
            "bound",
            "on",
            "the",
            "size",
            "of",
            "a",
            "batch",
            "with",
            "only",
            "a",
            "single",
            "record",
            "using",
            "a",
            "given",
            "key",
            "and",
            "value"
        ]
    },
    {
        "id": 965,
        "code": "public File file() {\n    return file;\n}",
        "summary_tokens": [
            "get",
            "the",
            "underlying",
            "file"
        ]
    },
    {
        "id": 966,
        "code": "public FileChannel channel() {\n    return channel;\n}",
        "summary_tokens": [
            "get",
            "the",
            "underlying",
            "file",
            "channel"
        ]
    },
    {
        "id": 967,
        "code": "public void readInto(ByteBuffer buffer, int position) throws IOException {\n    Utils.readFully(channel, buffer, position + this.start);\n    buffer.flip();\n}",
        "summary_tokens": [
            "read",
            "log",
            "batches",
            "into",
            "the",
            "given",
            "buffer",
            "until",
            "there",
            "are",
            "no",
            "bytes",
            "remaining",
            "in",
            "the",
            "buffer",
            "or",
            "the",
            "end",
            "of",
            "the",
            "file",
            "is",
            "reached"
        ]
    },
    {
        "id": 968,
        "code": "public FileRecords slice(int position, int size) throws IOException {\n    int availableBytes = availableBytes(position, size);\n    int startPosition = this.start + position;\n    return new FileRecords(file, channel, startPosition, startPosition + availableBytes, true);\n}",
        "summary_tokens": [
            "return",
            "a",
            "slice",
            "of",
            "records",
            "from",
            "this",
            "instance",
            "which",
            "is",
            "a",
            "view",
            "into",
            "this",
            "set",
            "starting",
            "from",
            "the",
            "given",
            "position",
            "and",
            "with",
            "the",
            "given",
            "size",
            "limit"
        ]
    },
    {
        "id": 969,
        "code": "public UnalignedFileRecords sliceUnaligned(int position, int size) {\n    int availableBytes = availableBytes(position, size);\n    return new UnalignedFileRecords(channel, this.start + position, availableBytes);\n}",
        "summary_tokens": [
            "return",
            "a",
            "slice",
            "of",
            "records",
            "from",
            "this",
            "instance",
            "the",
            "difference",
            "with",
            "file",
            "records",
            "slice",
            "int",
            "int",
            "is",
            "that",
            "the",
            "position",
            "is",
            "not",
            "necessarily",
            "on",
            "an",
            "offset",
            "boundary"
        ]
    },
    {
        "id": 970,
        "code": "public int append(MemoryRecords records) throws IOException {\n    if (records.sizeInBytes() > Integer.MAX_VALUE - size.get())\n        throw new IllegalArgumentException(\"Append of size \" + records.sizeInBytes() +\n                \" bytes is too large for segment with current file position at \" + size.get());\n\n    int written = records.writeFullyTo(channel);\n    size.getAndAdd(written);\n    return written;\n}",
        "summary_tokens": [
            "append",
            "a",
            "set",
            "of",
            "records",
            "to",
            "the",
            "file"
        ]
    },
    {
        "id": 971,
        "code": "public void flush() throws IOException {\n    channel.force(true);\n}",
        "summary_tokens": [
            "commit",
            "all",
            "written",
            "data",
            "to",
            "the",
            "physical",
            "disk"
        ]
    },
    {
        "id": 972,
        "code": "public void close() throws IOException {\n    flush();\n    trim();\n    channel.close();\n}",
        "summary_tokens": [
            "close",
            "this",
            "record",
            "set"
        ]
    },
    {
        "id": 973,
        "code": "public void closeHandlers() throws IOException {\n    channel.close();\n}",
        "summary_tokens": [
            "close",
            "file",
            "handlers",
            "used",
            "by",
            "the",
            "file",
            "channel",
            "but",
            "don",
            "t",
            "write",
            "to",
            "disk"
        ]
    },
    {
        "id": 974,
        "code": "public boolean deleteIfExists() throws IOException {\n    Utils.closeQuietly(channel, \"FileChannel\");\n    return Files.deleteIfExists(file.toPath());\n}",
        "summary_tokens": [
            "delete",
            "this",
            "message",
            "set",
            "from",
            "the",
            "filesystem",
            "ioexception",
            "if",
            "deletion",
            "fails",
            "due",
            "to",
            "an",
            "i",
            "o",
            "error",
            "true",
            "if",
            "the",
            "file",
            "was",
            "deleted",
            "by",
            "this",
            "method",
            "false",
            "if",
            "the",
            "file",
            "could",
            "not",
            "be",
            "deleted",
            "because",
            "it",
            "did",
            "not",
            "exist"
        ]
    },
    {
        "id": 975,
        "code": "public void trim() throws IOException {\n    truncateTo(sizeInBytes());\n}",
        "summary_tokens": [
            "trim",
            "file",
            "when",
            "close",
            "or",
            "roll",
            "to",
            "next",
            "file"
        ]
    },
    {
        "id": 976,
        "code": "public void updateParentDir(File parentDir) {\n    this.file = new File(parentDir, file.getName());\n}",
        "summary_tokens": [
            "update",
            "the",
            "parent",
            "directory",
            "to",
            "be",
            "used",
            "with",
            "caution",
            "since",
            "this",
            "does",
            "not",
            "reopen",
            "the",
            "file",
            "channel",
            "parent",
            "dir",
            "the",
            "new",
            "parent",
            "directory"
        ]
    },
    {
        "id": 977,
        "code": "public void renameTo(File f) throws IOException {\n    try {\n        Utils.atomicMoveWithFallback(file.toPath(), f.toPath(), false);\n    } finally {\n        this.file = f;\n    }\n}",
        "summary_tokens": [
            "rename",
            "the",
            "file",
            "that",
            "backs",
            "this",
            "message",
            "set",
            "ioexception",
            "if",
            "rename",
            "fails"
        ]
    },
    {
        "id": 978,
        "code": "public int truncateTo(int targetSize) throws IOException {\n    int originalSize = sizeInBytes();\n    if (targetSize > originalSize || targetSize < 0)\n        throw new KafkaException(\"Attempt to truncate log segment \" + file + \" to \" + targetSize + \" bytes failed, \" +\n                \" size of this log segment is \" + originalSize + \" bytes.\");\n    if (targetSize < (int) channel.size()) {\n        channel.truncate(targetSize);\n        size.set(targetSize);\n    }\n    return originalSize - targetSize;\n}",
        "summary_tokens": [
            "truncate",
            "this",
            "file",
            "message",
            "set",
            "to",
            "the",
            "given",
            "size",
            "in",
            "bytes"
        ]
    },
    {
        "id": 979,
        "code": "public LogOffsetPosition searchForOffsetWithSize(long targetOffset, int startingPosition) {\n    for (FileChannelRecordBatch batch : batchesFrom(startingPosition)) {\n        long offset = batch.lastOffset();\n        if (offset >= targetOffset)\n            return new LogOffsetPosition(offset, batch.position(), batch.sizeInBytes());\n    }\n    return null;\n}",
        "summary_tokens": [
            "search",
            "forward",
            "for",
            "the",
            "file",
            "position",
            "of",
            "the",
            "last",
            "offset",
            "that",
            "is",
            "greater",
            "than",
            "or",
            "equal",
            "to",
            "the",
            "target",
            "offset",
            "and",
            "return",
            "its",
            "physical",
            "position",
            "and",
            "the",
            "size",
            "of",
            "the",
            "message",
            "including",
            "log",
            "overhead",
            "at",
            "the",
            "returned",
            "offset"
        ]
    },
    {
        "id": 980,
        "code": "public TimestampAndOffset searchForTimestamp(long targetTimestamp, int startingPosition, long startingOffset) {\n    for (RecordBatch batch : batchesFrom(startingPosition)) {\n        if (batch.maxTimestamp() >= targetTimestamp) {\n                \n            for (Record record : batch) {\n                long timestamp = record.timestamp();\n                if (timestamp >= targetTimestamp && record.offset() >= startingOffset)\n                    return new TimestampAndOffset(timestamp, record.offset(),\n                            maybeLeaderEpoch(batch.partitionLeaderEpoch()));\n            }\n        }\n    }\n    return null;\n}",
        "summary_tokens": [
            "search",
            "forward",
            "for",
            "the",
            "first",
            "message",
            "that",
            "meets",
            "the",
            "following",
            "requirements",
            "message",
            "s",
            "timestamp",
            "is",
            "greater",
            "than",
            "or",
            "equals",
            "to",
            "the",
            "target",
            "timestamp"
        ]
    },
    {
        "id": 981,
        "code": "public TimestampAndOffset largestTimestampAfter(int startingPosition) {\n    long maxTimestamp = RecordBatch.NO_TIMESTAMP;\n    long offsetOfMaxTimestamp = -1L;\n    int leaderEpochOfMaxTimestamp = RecordBatch.NO_PARTITION_LEADER_EPOCH;\n\n    for (RecordBatch batch : batchesFrom(startingPosition)) {\n        long timestamp = batch.maxTimestamp();\n        if (timestamp > maxTimestamp) {\n            maxTimestamp = timestamp;\n            offsetOfMaxTimestamp = batch.lastOffset();\n            leaderEpochOfMaxTimestamp = batch.partitionLeaderEpoch();\n        }\n    }\n    return new TimestampAndOffset(maxTimestamp, offsetOfMaxTimestamp,\n            maybeLeaderEpoch(leaderEpochOfMaxTimestamp));\n}",
        "summary_tokens": [
            "return",
            "the",
            "largest",
            "timestamp",
            "of",
            "the",
            "messages",
            "after",
            "a",
            "given",
            "position",
            "in",
            "this",
            "file",
            "message",
            "set"
        ]
    },
    {
        "id": 982,
        "code": "public Iterable<FileChannelRecordBatch> batches() {\n    return batches;\n}",
        "summary_tokens": [
            "get",
            "an",
            "iterator",
            "over",
            "the",
            "record",
            "batches",
            "in",
            "the",
            "file"
        ]
    },
    {
        "id": 983,
        "code": "public Iterable<FileChannelRecordBatch> batchesFrom(final int start) {\n    return () -> batchIterator(start);\n}",
        "summary_tokens": [
            "get",
            "an",
            "iterator",
            "over",
            "the",
            "record",
            "batches",
            "in",
            "the",
            "file",
            "starting",
            "at",
            "a",
            "specific",
            "position"
        ]
    },
    {
        "id": 984,
        "code": "private static FileChannel openChannel(File file,\n                                       boolean mutable,\n                                       boolean fileAlreadyExists,\n                                       int initFileSize,\n                                       boolean preallocate) throws IOException {\n    if (mutable) {\n        if (fileAlreadyExists || !preallocate) {\n            return FileChannel.open(file.toPath(), StandardOpenOption.CREATE, StandardOpenOption.READ,\n                    StandardOpenOption.WRITE);\n        } else {\n            RandomAccessFile randomAccessFile = new RandomAccessFile(file, \"rw\");\n            randomAccessFile.setLength(initFileSize);\n            return randomAccessFile.getChannel();\n        }\n    } else {\n        return FileChannel.open(file.toPath());\n    }\n}",
        "summary_tokens": [
            "open",
            "a",
            "channel",
            "for",
            "the",
            "given",
            "file",
            "for",
            "windows",
            "ntfs",
            "and",
            "some",
            "old",
            "linux",
            "file",
            "system",
            "set",
            "preallocate",
            "to",
            "true",
            "and",
            "init",
            "file",
            "size",
            "with",
            "one",
            "value",
            "for",
            "example",
            "0",
            "0",
            "0",
            "can",
            "improve",
            "the",
            "kafka",
            "produce",
            "performance"
        ]
    },
    {
        "id": 985,
        "code": "private static long computeChecksum(byte magic, byte attributes, long timestamp, ByteBuffer key, ByteBuffer value) {\n    CRC32 crc = new CRC32();\n    crc.update(magic);\n    crc.update(attributes);\n    if (magic > RecordBatch.MAGIC_VALUE_V0)\n        Checksums.updateLong(crc, timestamp);\n        \n    if (key == null) {\n        Checksums.updateInt(crc, -1);\n    } else {\n        int size = key.remaining();\n        Checksums.updateInt(crc, size);\n        Checksums.update(crc, key, size);\n    }\n        \n    if (value == null) {\n        Checksums.updateInt(crc, -1);\n    } else {\n        int size = value.remaining();\n        Checksums.updateInt(crc, size);\n        Checksums.update(crc, value, size);\n    }\n    return crc.getValue();\n}",
        "summary_tokens": [
            "compute",
            "the",
            "checksum",
            "of",
            "the",
            "record",
            "from",
            "the",
            "attributes",
            "key",
            "and",
            "value",
            "payloads"
        ]
    },
    {
        "id": 986,
        "code": "public long checksum() {\n    return ByteUtils.readUnsignedInt(buffer, CRC_OFFSET);\n}",
        "summary_tokens": [
            "retrieve",
            "the",
            "previously",
            "computed",
            "crc",
            "for",
            "this",
            "record"
        ]
    },
    {
        "id": 987,
        "code": "public boolean isValid() {\n    return sizeInBytes() >= RECORD_OVERHEAD_V0 && checksum() == computeChecksum();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "crc",
            "stored",
            "with",
            "the",
            "record",
            "matches",
            "the",
            "crc",
            "computed",
            "off",
            "the",
            "record",
            "contents"
        ]
    },
    {
        "id": 988,
        "code": "public void ensureValid() {\n    if (sizeInBytes() < RECORD_OVERHEAD_V0)\n        throw new CorruptRecordException(\"Record is corrupt (crc could not be retrieved as the record is too \"\n                + \"small, size = \" + sizeInBytes() + \")\");\n\n    if (!isValid())\n        throw new CorruptRecordException(\"Record is corrupt (stored crc = \" + checksum()\n                + \", computed crc = \" + computeChecksum() + \")\");\n}",
        "summary_tokens": [
            "throw",
            "an",
            "invalid",
            "record",
            "exception",
            "if",
            "is",
            "valid",
            "is",
            "false",
            "for",
            "this",
            "record"
        ]
    },
    {
        "id": 989,
        "code": "public int sizeInBytes() {\n    return buffer.limit();\n}",
        "summary_tokens": [
            "the",
            "complete",
            "serialized",
            "size",
            "of",
            "this",
            "record",
            "in",
            "bytes",
            "including",
            "crc",
            "header",
            "attributes",
            "etc",
            "but",
            "excluding",
            "the",
            "log",
            "overhead",
            "offset",
            "and",
            "record",
            "size"
        ]
    },
    {
        "id": 990,
        "code": "public int keySize() {\n    if (magic() == RecordBatch.MAGIC_VALUE_V0)\n        return buffer.getInt(KEY_SIZE_OFFSET_V0);\n    else\n        return buffer.getInt(KEY_SIZE_OFFSET_V1);\n}",
        "summary_tokens": [
            "the",
            "length",
            "of",
            "the",
            "key",
            "in",
            "bytes",
            "the",
            "size",
            "in",
            "bytes",
            "of",
            "the",
            "key",
            "0",
            "if",
            "the",
            "key",
            "is",
            "null"
        ]
    },
    {
        "id": 991,
        "code": "public boolean hasKey() {\n    return keySize() >= 0;\n}",
        "summary_tokens": [
            "does",
            "the",
            "record",
            "have",
            "a",
            "key",
            "true",
            "if",
            "so",
            "false",
            "otherwise"
        ]
    },
    {
        "id": 992,
        "code": "private int valueSizeOffset() {\n    if (magic() == RecordBatch.MAGIC_VALUE_V0)\n        return KEY_OFFSET_V0 + Math.max(0, keySize());\n    else\n        return KEY_OFFSET_V1 + Math.max(0, keySize());\n}",
        "summary_tokens": [
            "the",
            "position",
            "where",
            "the",
            "value",
            "size",
            "is",
            "stored"
        ]
    },
    {
        "id": 993,
        "code": "public int valueSize() {\n    return buffer.getInt(valueSizeOffset());\n}",
        "summary_tokens": [
            "the",
            "length",
            "of",
            "the",
            "value",
            "in",
            "bytes",
            "the",
            "size",
            "in",
            "bytes",
            "of",
            "the",
            "value",
            "0",
            "if",
            "the",
            "value",
            "is",
            "null"
        ]
    },
    {
        "id": 994,
        "code": "public boolean hasNullValue() {\n    return valueSize() < 0;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "value",
            "field",
            "of",
            "this",
            "record",
            "is",
            "null"
        ]
    },
    {
        "id": 995,
        "code": "public byte magic() {\n    return buffer.get(MAGIC_OFFSET);\n}",
        "summary_tokens": [
            "the",
            "magic",
            "value",
            "i"
        ]
    },
    {
        "id": 996,
        "code": "public byte attributes() {\n    return buffer.get(ATTRIBUTES_OFFSET);\n}",
        "summary_tokens": [
            "the",
            "attributes",
            "stored",
            "with",
            "this",
            "record",
            "the",
            "attributes"
        ]
    },
    {
        "id": 997,
        "code": "public long timestamp() {\n    if (magic() == RecordBatch.MAGIC_VALUE_V0)\n        return RecordBatch.NO_TIMESTAMP;\n    else {\n            \n        if (wrapperRecordTimestampType == TimestampType.LOG_APPEND_TIME && wrapperRecordTimestamp != null)\n            return wrapperRecordTimestamp;\n            \n        else\n            return buffer.getLong(TIMESTAMP_OFFSET);\n    }\n}",
        "summary_tokens": [
            "when",
            "magic",
            "value",
            "is",
            "greater",
            "than",
            "0",
            "the",
            "timestamp",
            "of",
            "a",
            "record",
            "is",
            "determined",
            "in",
            "the",
            "following",
            "way",
            "0"
        ]
    },
    {
        "id": 998,
        "code": "public TimestampType timestampType() {\n    return timestampType(magic(), wrapperRecordTimestampType, attributes());\n}",
        "summary_tokens": [
            "get",
            "the",
            "timestamp",
            "type",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 999,
        "code": "public CompressionType compressionType() {\n    return CompressionType.forId(buffer.get(ATTRIBUTES_OFFSET) & COMPRESSION_CODEC_MASK);\n}",
        "summary_tokens": [
            "the",
            "compression",
            "type",
            "used",
            "with",
            "this",
            "record"
        ]
    },
    {
        "id": 1000,
        "code": "public ByteBuffer value() {\n    return Utils.sizeDelimited(buffer, valueSizeOffset());\n}",
        "summary_tokens": [
            "a",
            "byte",
            "buffer",
            "containing",
            "the",
            "value",
            "of",
            "this",
            "record",
            "the",
            "value",
            "or",
            "null",
            "if",
            "the",
            "value",
            "for",
            "this",
            "record",
            "is",
            "null"
        ]
    },
    {
        "id": 1001,
        "code": "public ByteBuffer key() {\n    if (magic() == RecordBatch.MAGIC_VALUE_V0)\n        return Utils.sizeDelimited(buffer, KEY_SIZE_OFFSET_V0);\n    else\n        return Utils.sizeDelimited(buffer, KEY_SIZE_OFFSET_V1);\n}",
        "summary_tokens": [
            "a",
            "byte",
            "buffer",
            "containing",
            "the",
            "message",
            "key",
            "the",
            "buffer",
            "or",
            "null",
            "if",
            "the",
            "key",
            "for",
            "this",
            "record",
            "is",
            "null"
        ]
    },
    {
        "id": 1002,
        "code": "public ByteBuffer buffer() {\n    return this.buffer;\n}",
        "summary_tokens": [
            "get",
            "the",
            "underlying",
            "buffer",
            "backing",
            "this",
            "record",
            "instance"
        ]
    },
    {
        "id": 1003,
        "code": "public static LegacyRecord create(byte magic,\n                                  long timestamp,\n                                  byte[] key,\n                                  byte[] value,\n                                  CompressionType compressionType,\n                                  TimestampType timestampType) {\n    int keySize = key == null ? 0 : key.length;\n    int valueSize = value == null ? 0 : value.length;\n    ByteBuffer buffer = ByteBuffer.allocate(recordSize(magic, keySize, valueSize));\n    write(buffer, magic, timestamp, wrapNullable(key), wrapNullable(value), compressionType, timestampType);\n    buffer.rewind();\n    return new LegacyRecord(buffer);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "record",
            "instance"
        ]
    },
    {
        "id": 1004,
        "code": "public static void writeCompressedRecordHeader(ByteBuffer buffer,\n                                               byte magic,\n                                               int recordSize,\n                                               long timestamp,\n                                               CompressionType compressionType,\n                                               TimestampType timestampType) {\n    int recordPosition = buffer.position();\n    int valueSize = recordSize - recordOverhead(magic);\n\n        \n    write(buffer, magic, timestamp, null, null, compressionType, timestampType);\n    buffer.position(recordPosition);\n\n        \n    buffer.putInt(recordPosition + keyOffset(magic), valueSize);\n\n        \n    long crc = crc32(buffer, MAGIC_OFFSET, recordSize - MAGIC_OFFSET);\n    ByteUtils.writeUnsignedInt(buffer, recordPosition + CRC_OFFSET, crc);\n}",
        "summary_tokens": [
            "write",
            "the",
            "header",
            "for",
            "a",
            "compressed",
            "record",
            "set",
            "in",
            "place",
            "i"
        ]
    },
    {
        "id": 1005,
        "code": "public static void write(DataOutputStream out,\n                         byte magic,\n                         long crc,\n                         byte attributes,\n                         long timestamp,\n                         byte[] key,\n                         byte[] value) throws IOException {\n    write(out, magic, crc, attributes, timestamp, wrapNullable(key), wrapNullable(value));\n}",
        "summary_tokens": [
            "write",
            "a",
            "record",
            "using",
            "raw",
            "fields",
            "without",
            "validation"
        ]
    },
    {
        "id": 1006,
        "code": "public int writeFullyTo(GatheringByteChannel channel) throws IOException {\n    buffer.mark();\n    int written = 0;\n    while (written < sizeInBytes())\n        written += channel.write(buffer);\n    buffer.reset();\n    return written;\n}",
        "summary_tokens": [
            "write",
            "all",
            "records",
            "to",
            "the",
            "given",
            "channel",
            "including",
            "partial",
            "records"
        ]
    },
    {
        "id": 1007,
        "code": "public int validBytes() {\n    if (validBytes >= 0)\n        return validBytes;\n\n    int bytes = 0;\n    for (RecordBatch batch : batches())\n        bytes += batch.sizeInBytes();\n\n    this.validBytes = bytes;\n    return bytes;\n}",
        "summary_tokens": [
            "the",
            "total",
            "number",
            "of",
            "bytes",
            "in",
            "this",
            "message",
            "set",
            "not",
            "including",
            "any",
            "partial",
            "trailing",
            "messages"
        ]
    },
    {
        "id": 1008,
        "code": "public Integer firstBatchSize() {\n    if (buffer.remaining() < HEADER_SIZE_UP_TO_MAGIC)\n        return null;\n    return new ByteBufferLogInputStream(buffer, Integer.MAX_VALUE).nextBatchSize();\n}",
        "summary_tokens": [
            "validates",
            "the",
            "header",
            "of",
            "the",
            "first",
            "batch",
            "and",
            "returns",
            "batch",
            "size"
        ]
    },
    {
        "id": 1009,
        "code": "private static FilterResult filterTo(TopicPartition partition, Iterable<MutableRecordBatch> batches,\n                                     RecordFilter filter, ByteBuffer destinationBuffer, int maxRecordBatchSize,\n                                     BufferSupplier decompressionBufferSupplier) {\n    FilterResult filterResult = new FilterResult(destinationBuffer);\n    ByteBufferOutputStream bufferOutputStream = new ByteBufferOutputStream(destinationBuffer);\n    for (MutableRecordBatch batch : batches) {\n        final BatchRetentionResult batchRetentionResult = filter.checkBatchRetention(batch);\n        final boolean containsMarkerForEmptyTxn = batchRetentionResult.containsMarkerForEmptyTxn;\n        final BatchRetention batchRetention = batchRetentionResult.batchRetention;\n\n        filterResult.bytesRead += batch.sizeInBytes();\n\n        if (batchRetention == BatchRetention.DELETE)\n            continue;\n\n            \n            \n            \n            \n        byte batchMagic = batch.magic();\n        List<Record> retainedRecords = new ArrayList<>();\n\n        final BatchFilterResult iterationResult = filterBatch(batch, decompressionBufferSupplier, filterResult, filter,\n                batchMagic, true, retainedRecords);\n        boolean containsTombstones = iterationResult.containsTombstones;\n        boolean writeOriginalBatch = iterationResult.writeOriginalBatch;\n        long maxOffset = iterationResult.maxOffset;\n\n        if (!retainedRecords.isEmpty()) {\n                \n                \n                \n            boolean needToSetDeleteHorizon = batch.magic() >= RecordBatch.MAGIC_VALUE_V2 && (containsTombstones || containsMarkerForEmptyTxn)\n                && !batch.deleteHorizonMs().isPresent();\n            if (writeOriginalBatch && !needToSetDeleteHorizon) {\n                batch.writeTo(bufferOutputStream);\n                filterResult.updateRetainedBatchMetadata(batch, retainedRecords.size(), false);\n            } else {\n                final MemoryRecordsBuilder builder;\n                long deleteHorizonMs;\n                if (needToSetDeleteHorizon)\n                    deleteHorizonMs = filter.currentTime + filter.deleteRetentionMs;\n                else\n                    deleteHorizonMs = batch.deleteHorizonMs().orElse(RecordBatch.NO_TIMESTAMP);\n                builder = buildRetainedRecordsInto(batch, retainedRecords, bufferOutputStream, deleteHorizonMs);\n\n                MemoryRecords records = builder.build();\n                int filteredBatchSize = records.sizeInBytes();\n                if (filteredBatchSize > batch.sizeInBytes() && filteredBatchSize > maxRecordBatchSize)\n                    log.warn(\"Record batch from {} with last offset {} exceeded max record batch size {} after cleaning \" +\n                                    \"(new size is {}). Consumers with version earlier than 0.10.1.0 may need to \" +\n                                    \"increase their fetch sizes.\",\n                            partition, batch.lastOffset(), maxRecordBatchSize, filteredBatchSize);\n\n                MemoryRecordsBuilder.RecordsInfo info = builder.info();\n                filterResult.updateRetainedBatchMetadata(info.maxTimestamp, info.shallowOffsetOfMaxTimestamp,\n                        maxOffset, retainedRecords.size(), filteredBatchSize);\n            }\n        } else if (batchRetention == BatchRetention.RETAIN_EMPTY) {\n            if (batchMagic < RecordBatch.MAGIC_VALUE_V2)\n                throw new IllegalStateException(\"Empty batches are only supported for magic v2 and above\");\n\n            bufferOutputStream.ensureRemaining(DefaultRecordBatch.RECORD_BATCH_OVERHEAD);\n            DefaultRecordBatch.writeEmptyHeader(bufferOutputStream.buffer(), batchMagic, batch.producerId(),\n                    batch.producerEpoch(), batch.baseSequence(), batch.baseOffset(), batch.lastOffset(),\n                    batch.partitionLeaderEpoch(), batch.timestampType(), batch.maxTimestamp(),\n                    batch.isTransactional(), batch.isControlBatch());\n            filterResult.updateRetainedBatchMetadata(batch, 0, true);\n        }\n\n            \n            \n        ByteBuffer outputBuffer = bufferOutputStream.buffer();\n        if (outputBuffer != destinationBuffer) {\n            filterResult.outputBuffer = outputBuffer;\n            return filterResult;\n        }\n    }\n\n    return filterResult;\n}",
        "summary_tokens": [
            "note",
            "this",
            "method",
            "is",
            "also",
            "used",
            "to",
            "convert",
            "the",
            "first",
            "timestamp",
            "of",
            "the",
            "batch",
            "which",
            "is",
            "usually",
            "the",
            "timestamp",
            "of",
            "the",
            "first",
            "record",
            "to",
            "the",
            "delete",
            "horizon",
            "of",
            "the",
            "tombstones",
            "or",
            "txn",
            "markers",
            "which",
            "are",
            "present",
            "in",
            "the",
            "batch"
        ]
    },
    {
        "id": 1010,
        "code": "public ByteBuffer buffer() {\n    return buffer.duplicate();\n}",
        "summary_tokens": [
            "get",
            "the",
            "byte",
            "buffer",
            "that",
            "backs",
            "this",
            "instance",
            "for",
            "reading"
        ]
    },
    {
        "id": 1011,
        "code": "public MemoryRecords build() {\n    if (aborted) {\n        throw new IllegalStateException(\"Attempting to build an aborted record batch\");\n    }\n    close();\n    return builtRecords;\n}",
        "summary_tokens": [
            "close",
            "this",
            "builder",
            "and",
            "return",
            "the",
            "resulting",
            "buffer"
        ]
    },
    {
        "id": 1012,
        "code": "public RecordsInfo info() {\n    if (timestampType == TimestampType.LOG_APPEND_TIME) {\n        long shallowOffsetOfMaxTimestamp;\n            \n        if (compressionType != CompressionType.NONE || magic >= RecordBatch.MAGIC_VALUE_V2)\n            shallowOffsetOfMaxTimestamp = lastOffset;\n        else\n            shallowOffsetOfMaxTimestamp = baseOffset;\n        return new RecordsInfo(logAppendTime, shallowOffsetOfMaxTimestamp);\n    } else if (maxTimestamp == RecordBatch.NO_TIMESTAMP) {\n        return new RecordsInfo(RecordBatch.NO_TIMESTAMP, lastOffset);\n    } else {\n        long shallowOffsetOfMaxTimestamp;\n            \n        if (compressionType != CompressionType.NONE || magic >= RecordBatch.MAGIC_VALUE_V2)\n            shallowOffsetOfMaxTimestamp = lastOffset;\n        else\n            shallowOffsetOfMaxTimestamp = offsetOfMaxTimestamp;\n        return new RecordsInfo(maxTimestamp, shallowOffsetOfMaxTimestamp);\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "max",
            "timestamp",
            "and",
            "its",
            "offset"
        ]
    },
    {
        "id": 1013,
        "code": "public int uncompressedBytesWritten() {\n    return uncompressedRecordsSizeInBytes + batchHeaderSizeInBytes;\n}",
        "summary_tokens": [
            "return",
            "the",
            "sum",
            "of",
            "the",
            "size",
            "of",
            "the",
            "batch",
            "header",
            "always",
            "uncompressed",
            "and",
            "the",
            "records",
            "before",
            "compression"
        ]
    },
    {
        "id": 1014,
        "code": "public void closeForRecordAppends() {\n    if (appendStream != CLOSED_STREAM) {\n        try {\n            appendStream.close();\n        } catch (IOException e) {\n            throw new KafkaException(e);\n        } finally {\n            appendStream = CLOSED_STREAM;\n        }\n    }\n}",
        "summary_tokens": [
            "release",
            "resources",
            "required",
            "for",
            "record",
            "appends",
            "e"
        ]
    },
    {
        "id": 1015,
        "code": "private int writeDefaultBatchHeader() {\n    ensureOpenForRecordBatchWrite();\n    ByteBuffer buffer = bufferStream.buffer();\n    int pos = buffer.position();\n    buffer.position(initialPosition);\n    int size = pos - initialPosition;\n    int writtenCompressed = size - DefaultRecordBatch.RECORD_BATCH_OVERHEAD;\n    int offsetDelta = (int) (lastOffset - baseOffset);\n\n    final long maxTimestamp;\n    if (timestampType == TimestampType.LOG_APPEND_TIME)\n        maxTimestamp = logAppendTime;\n    else\n        maxTimestamp = this.maxTimestamp;\n\n    DefaultRecordBatch.writeHeader(buffer, baseOffset, offsetDelta, size, magic, compressionType, timestampType,\n            baseTimestamp, maxTimestamp, producerId, producerEpoch, baseSequence, isTransactional, isControlBatch,\n            hasDeleteHorizonMs(), partitionLeaderEpoch, numRecords);\n\n    buffer.position(pos);\n    return writtenCompressed;\n}",
        "summary_tokens": [
            "write",
            "the",
            "header",
            "to",
            "the",
            "default",
            "batch"
        ]
    },
    {
        "id": 1016,
        "code": "private int writeLegacyCompressedWrapperHeader() {\n    ensureOpenForRecordBatchWrite();\n    ByteBuffer buffer = bufferStream.buffer();\n    int pos = buffer.position();\n    buffer.position(initialPosition);\n\n    int wrapperSize = pos - initialPosition - Records.LOG_OVERHEAD;\n    int writtenCompressed = wrapperSize - LegacyRecord.recordOverhead(magic);\n    AbstractLegacyRecordBatch.writeHeader(buffer, lastOffset, wrapperSize);\n\n    long timestamp = timestampType == TimestampType.LOG_APPEND_TIME ? logAppendTime : maxTimestamp;\n    LegacyRecord.writeCompressedRecordHeader(buffer, magic, wrapperSize, timestamp, compressionType, timestampType);\n\n    buffer.position(pos);\n    return writtenCompressed;\n}",
        "summary_tokens": [
            "write",
            "the",
            "header",
            "to",
            "the",
            "legacy",
            "batch"
        ]
    },
    {
        "id": 1017,
        "code": "public void appendWithOffset(long offset, LegacyRecord record) {\n    appendWithOffset(offset, record.timestamp(), record.key(), record.value());\n}",
        "summary_tokens": [
            "add",
            "a",
            "record",
            "with",
            "a",
            "given",
            "offset"
        ]
    },
    {
        "id": 1018,
        "code": "public void appendControlRecordWithOffset(long offset, SimpleRecord record) {\n    short typeId = ControlRecordType.parseTypeId(record.key());\n    ControlRecordType type = ControlRecordType.fromTypeId(typeId);\n    if (type == ControlRecordType.UNKNOWN)\n        throw new IllegalArgumentException(\"Cannot append record with unknown control record type \" + typeId);\n\n    appendWithOffset(offset, true, record.timestamp(),\n        record.key(), record.value(), record.headers());\n}",
        "summary_tokens": [
            "append",
            "a",
            "control",
            "record",
            "at",
            "the",
            "given",
            "offset"
        ]
    },
    {
        "id": 1019,
        "code": "public void append(LegacyRecord record) {\n    appendWithOffset(nextSequentialOffset(), record);\n}",
        "summary_tokens": [
            "append",
            "the",
            "record",
            "at",
            "the",
            "next",
            "consecutive",
            "offset"
        ]
    },
    {
        "id": 1020,
        "code": "private void appendControlRecord(long timestamp, ControlRecordType type, ByteBuffer value) {\n    Struct keyStruct = type.recordKey();\n    ByteBuffer key = ByteBuffer.allocate(keyStruct.sizeOf());\n    keyStruct.writeTo(key);\n    key.flip();\n    appendWithOffset(nextSequentialOffset(), true, timestamp, key, value, Record.EMPTY_HEADERS);\n}",
        "summary_tokens": [
            "append",
            "a",
            "control",
            "record",
            "at",
            "the",
            "next",
            "sequential",
            "offset"
        ]
    },
    {
        "id": 1021,
        "code": "public void appendUncheckedWithOffset(long offset, SimpleRecord record) throws IOException {\n    if (magic >= RecordBatch.MAGIC_VALUE_V2) {\n        int offsetDelta = (int) (offset - baseOffset);\n        long timestamp = record.timestamp();\n        if (baseTimestamp == null)\n            baseTimestamp = timestamp;\n\n        int sizeInBytes = DefaultRecord.writeTo(appendStream,\n            offsetDelta,\n            timestamp - baseTimestamp,\n            record.key(),\n            record.value(),\n            record.headers());\n        recordWritten(offset, timestamp, sizeInBytes);\n    } else {\n        LegacyRecord legacyRecord = LegacyRecord.create(magic,\n            record.timestamp(),\n            Utils.toNullableArray(record.key()),\n            Utils.toNullableArray(record.value()));\n        appendUncheckedWithOffset(offset, legacyRecord);\n    }\n}",
        "summary_tokens": [
            "append",
            "a",
            "record",
            "without",
            "doing",
            "offset",
            "magic",
            "validation",
            "this",
            "should",
            "only",
            "be",
            "used",
            "in",
            "testing"
        ]
    },
    {
        "id": 1022,
        "code": "private int estimatedBytesWritten() {\n    if (compressionType == CompressionType.NONE) {\n        return batchHeaderSizeInBytes + uncompressedRecordsSizeInBytes;\n    } else {\n            \n        return batchHeaderSizeInBytes + (int) (uncompressedRecordsSizeInBytes * estimatedCompressionRatio * COMPRESSION_RATE_ESTIMATION_FACTOR);\n    }\n}",
        "summary_tokens": [
            "get",
            "an",
            "estimate",
            "of",
            "the",
            "number",
            "of",
            "bytes",
            "written",
            "based",
            "on",
            "the",
            "estimation",
            "factor",
            "hard",
            "coded",
            "in",
            "compression",
            "type"
        ]
    },
    {
        "id": 1023,
        "code": "public void setEstimatedCompressionRatio(float estimatedCompressionRatio) {\n    this.estimatedCompressionRatio = estimatedCompressionRatio;\n}",
        "summary_tokens": [
            "set",
            "the",
            "estimated",
            "compression",
            "ratio",
            "for",
            "the",
            "memory",
            "records",
            "builder"
        ]
    },
    {
        "id": 1024,
        "code": "public boolean hasRoomFor(long timestamp, ByteBuffer key, ByteBuffer value, Header[] headers) {\n    if (isFull())\n        return false;\n\n        \n    if (numRecords == 0)\n        return true;\n\n    final int recordSize;\n    if (magic < RecordBatch.MAGIC_VALUE_V2) {\n        recordSize = Records.LOG_OVERHEAD + LegacyRecord.recordSize(magic, key, value);\n    } else {\n        int nextOffsetDelta = lastOffset == null ? 0 : (int) (lastOffset - baseOffset + 1);\n        long timestampDelta = baseTimestamp == null ? 0 : timestamp - baseTimestamp;\n        recordSize = DefaultRecord.sizeInBytes(nextOffsetDelta, timestampDelta, key, value, headers);\n    }\n\n        \n    return this.writeLimit >= estimatedBytesWritten() + recordSize;\n}",
        "summary_tokens": [
            "check",
            "if",
            "we",
            "have",
            "room",
            "for",
            "a",
            "new",
            "record",
            "containing",
            "the",
            "given",
            "key",
            "value",
            "pair"
        ]
    },
    {
        "id": 1025,
        "code": "public int estimatedSizeInBytes() {\n    return builtRecords != null ? builtRecords.sizeInBytes() : estimatedBytesWritten();\n}",
        "summary_tokens": [
            "get",
            "an",
            "estimate",
            "of",
            "the",
            "number",
            "of",
            "bytes",
            "written",
            "to",
            "the",
            "underlying",
            "buffer"
        ]
    },
    {
        "id": 1026,
        "code": "public long producerId() {\n    return this.producerId;\n}",
        "summary_tokens": [
            "return",
            "the",
            "producer",
            "id",
            "of",
            "the",
            "record",
            "batches",
            "created",
            "by",
            "this",
            "builder"
        ]
    },
    {
        "id": 1027,
        "code": "public Map<TopicPartition, RecordConversionStats> recordConversionStats() {\n    return recordConversionStats;\n}",
        "summary_tokens": [
            "get",
            "any",
            "statistics",
            "that",
            "were",
            "recorded",
            "as",
            "part",
            "of",
            "executing",
            "this",
            "multi",
            "records",
            "send"
        ]
    },
    {
        "id": 1028,
        "code": "public long temporaryMemoryBytes() {\n    return temporaryMemoryBytes;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "temporary",
            "memory",
            "bytes",
            "allocated",
            "to",
            "process",
            "the",
            "records"
        ]
    },
    {
        "id": 1029,
        "code": "protected static ConvertedRecords<MemoryRecords> downConvert(Iterable<? extends RecordBatch> batches, byte toMagic,\n                                                             long firstOffset, Time time) {\n        \n    List<RecordBatchAndRecords> recordBatchAndRecordsList = new ArrayList<>();\n    int totalSizeEstimate = 0;\n    long startNanos = time.nanoseconds();\n\n    for (RecordBatch batch : batches) {\n        if (toMagic < RecordBatch.MAGIC_VALUE_V2) {\n            if (batch.isControlBatch())\n                continue;\n\n            if (batch.compressionType() == CompressionType.ZSTD)\n                throw new UnsupportedCompressionTypeException(\"Down-conversion of zstandard-compressed batches \" +\n                    \"is not supported\");\n        }\n\n        if (batch.magic() <= toMagic) {\n            totalSizeEstimate += batch.sizeInBytes();\n            recordBatchAndRecordsList.add(new RecordBatchAndRecords(batch, null, null));\n        } else {\n            List<Record> records = new ArrayList<>();\n            for (Record record : batch) {\n                    \n                if (toMagic > RecordBatch.MAGIC_VALUE_V1 || batch.isCompressed() || record.offset() >= firstOffset)\n                    records.add(record);\n            }\n            if (records.isEmpty())\n                continue;\n            final long baseOffset;\n            if (batch.magic() >= RecordBatch.MAGIC_VALUE_V2 && toMagic >= RecordBatch.MAGIC_VALUE_V2)\n                baseOffset = batch.baseOffset();\n            else\n                baseOffset = records.get(0).offset();\n            totalSizeEstimate += AbstractRecords.estimateSizeInBytes(toMagic, baseOffset, batch.compressionType(), records);\n            recordBatchAndRecordsList.add(new RecordBatchAndRecords(batch, records, baseOffset));\n        }\n    }\n\n    ByteBuffer buffer = ByteBuffer.allocate(totalSizeEstimate);\n    long temporaryMemoryBytes = 0;\n    int numRecordsConverted = 0;\n\n    for (RecordBatchAndRecords recordBatchAndRecords : recordBatchAndRecordsList) {\n        temporaryMemoryBytes += recordBatchAndRecords.batch.sizeInBytes();\n        if (recordBatchAndRecords.batch.magic() <= toMagic) {\n            buffer = Utils.ensureCapacity(buffer, buffer.position() + recordBatchAndRecords.batch.sizeInBytes());\n            recordBatchAndRecords.batch.writeTo(buffer);\n        } else {\n            MemoryRecordsBuilder builder = convertRecordBatch(toMagic, buffer, recordBatchAndRecords);\n            buffer = builder.buffer();\n            temporaryMemoryBytes += builder.uncompressedBytesWritten();\n            numRecordsConverted += builder.numRecords();\n        }\n    }\n\n    buffer.flip();\n    RecordConversionStats stats = new RecordConversionStats(temporaryMemoryBytes, numRecordsConverted,\n            time.nanoseconds() - startNanos);\n    return new ConvertedRecords<>(MemoryRecords.readableRecords(buffer), stats);\n}",
        "summary_tokens": [
            "down",
            "convert",
            "batches",
            "to",
            "the",
            "provided",
            "message",
            "format",
            "version"
        ]
    },
    {
        "id": 1030,
        "code": "private static MemoryRecordsBuilder convertRecordBatch(byte magic, ByteBuffer buffer, RecordBatchAndRecords recordBatchAndRecords) {\n    RecordBatch batch = recordBatchAndRecords.batch;\n    final TimestampType timestampType = batch.timestampType();\n    long logAppendTime = timestampType == TimestampType.LOG_APPEND_TIME ? batch.maxTimestamp() : RecordBatch.NO_TIMESTAMP;\n\n    MemoryRecordsBuilder builder = MemoryRecords.builder(buffer, magic, batch.compressionType(),\n            timestampType, recordBatchAndRecords.baseOffset, logAppendTime);\n    for (Record record : recordBatchAndRecords.records) {\n            \n        if (magic > RecordBatch.MAGIC_VALUE_V1)\n            builder.append(record);\n        else\n            builder.appendWithOffset(record.offset(), record.timestamp(), record.key(), record.value());\n    }\n\n    builder.close();\n    return builder;\n}",
        "summary_tokens": [
            "return",
            "a",
            "buffer",
            "containing",
            "the",
            "converted",
            "record",
            "batches"
        ]
    },
    {
        "id": 1031,
        "code": "static Comparator<ReplicaView> comparator() {\n    return Comparator.comparingLong(ReplicaView::logEndOffset)\n        .thenComparing(Comparator.comparingLong(ReplicaView::timeSinceLastCaughtUpMs).reversed())\n        .thenComparing(replicaInfo -> replicaInfo.endpoint().id());\n}",
        "summary_tokens": [
            "comparator",
            "for",
            "replica",
            "view",
            "that",
            "returns",
            "in",
            "the",
            "order",
            "of",
            "most",
            "caught",
            "up"
        ]
    },
    {
        "id": 1032,
        "code": "public short version() {\n    return version;\n}",
        "summary_tokens": [
            "get",
            "the",
            "version",
            "of",
            "this",
            "abstract",
            "request",
            "object"
        ]
    },
    {
        "id": 1033,
        "code": "public final ByteBuffer serializeWithHeader(RequestHeader header) {\n    if (header.apiKey() != apiKey) {\n        throw new IllegalArgumentException(\"Could not build request \" + apiKey + \" with header api key \" + header.apiKey());\n    }\n    if (header.apiVersion() != version) {\n        throw new IllegalArgumentException(\"Could not build request version \" + version + \" with header version \" + header.apiVersion());\n    }\n    return RequestUtils.serialize(header.data(), header.headerVersion(), data(), version);\n}",
        "summary_tokens": [
            "serializes",
            "header",
            "and",
            "body",
            "without",
            "prefixing",
            "with",
            "size",
            "unlike",
            "to",
            "send",
            "which",
            "does",
            "include",
            "a",
            "size",
            "prefix"
        ]
    },
    {
        "id": 1034,
        "code": "public AbstractResponse getErrorResponse(Throwable e) {\n    return getErrorResponse(AbstractResponse.DEFAULT_THROTTLE_TIME, e);\n}",
        "summary_tokens": [
            "get",
            "an",
            "error",
            "response",
            "for",
            "a",
            "request"
        ]
    },
    {
        "id": 1035,
        "code": "public Map<Errors, Integer> errorCounts(Throwable e) {\n    AbstractResponse response = getErrorResponse(0, e);\n    if (response == null)\n        throw new IllegalStateException(\"Error counts could not be obtained for request \" + this);\n    else\n        return response.errorCounts();\n}",
        "summary_tokens": [
            "get",
            "the",
            "error",
            "counts",
            "corresponding",
            "to",
            "an",
            "error",
            "response"
        ]
    },
    {
        "id": 1036,
        "code": "public static RequestAndSize parseRequest(ApiKeys apiKey, short apiVersion, ByteBuffer buffer) {\n    int bufferSize = buffer.remaining();\n    return new RequestAndSize(doParseRequest(apiKey, apiVersion, buffer), bufferSize);\n}",
        "summary_tokens": [
            "factory",
            "method",
            "for",
            "getting",
            "a",
            "request",
            "object",
            "based",
            "on",
            "api",
            "key",
            "id",
            "and",
            "a",
            "version"
        ]
    },
    {
        "id": 1037,
        "code": "final ByteBuffer serializeWithHeader(ResponseHeader header, short version) {\n    return RequestUtils.serialize(header.data(), header.headerVersion(), data(), version);\n}",
        "summary_tokens": [
            "serializes",
            "header",
            "and",
            "body",
            "without",
            "prefixing",
            "with",
            "size",
            "unlike",
            "to",
            "send",
            "which",
            "does",
            "include",
            "a",
            "size",
            "prefix"
        ]
    },
    {
        "id": 1038,
        "code": "public static AbstractResponse parseResponse(ByteBuffer buffer, RequestHeader requestHeader) {\n    ApiKeys apiKey = requestHeader.apiKey();\n    short apiVersion = requestHeader.apiVersion();\n\n    ResponseHeader responseHeader = ResponseHeader.parse(buffer, apiKey.responseHeaderVersion(apiVersion));\n\n    if (requestHeader.correlationId() != responseHeader.correlationId()) {\n        throw new CorrelationIdMismatchException(\"Correlation id for response (\"\n            + responseHeader.correlationId() + \") does not match request (\"\n            + requestHeader.correlationId() + \"), request header: \" + requestHeader,\n            requestHeader.correlationId(), responseHeader.correlationId());\n    }\n\n    return AbstractResponse.parseResponse(apiKey, buffer, apiVersion);\n}",
        "summary_tokens": [
            "parse",
            "a",
            "response",
            "from",
            "the",
            "provided",
            "buffer"
        ]
    },
    {
        "id": 1039,
        "code": "public boolean shouldClientThrottle(short version) {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "whether",
            "or",
            "not",
            "client",
            "should",
            "throttle",
            "upon",
            "receiving",
            "a",
            "response",
            "of",
            "the",
            "specified",
            "version",
            "with",
            "a",
            "non",
            "zero",
            "throttle",
            "time"
        ]
    },
    {
        "id": 1040,
        "code": "public Map<Errors, Integer> errorCounts() {\n    return Collections.singletonMap(Errors.forCode(data.errorCode()), 1);\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "each",
            "type",
            "of",
            "error",
            "in",
            "the",
            "response",
            "including",
            "errors",
            "none",
            "and",
            "top",
            "level",
            "errors",
            "as",
            "well",
            "as",
            "more",
            "specifically",
            "scoped",
            "errors",
            "such",
            "as",
            "topic",
            "or",
            "partition",
            "level",
            "errors"
        ]
    },
    {
        "id": 1041,
        "code": "public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n    return new AlterPartitionResponse(new AlterPartitionResponseData()\n        .setThrottleTimeMs(throttleTimeMs)\n        .setErrorCode(Errors.forException(e).code()));\n}",
        "summary_tokens": [
            "get",
            "an",
            "error",
            "response",
            "for",
            "a",
            "request",
            "with",
            "specified",
            "throttle",
            "time",
            "in",
            "the",
            "response",
            "if",
            "applicable"
        ]
    },
    {
        "id": 1042,
        "code": "public String message() {\n    return message;\n}",
        "summary_tokens": [
            "return",
            "the",
            "optional",
            "error",
            "message",
            "or",
            "null"
        ]
    },
    {
        "id": 1043,
        "code": "public String messageWithFallback() {\n    if (message == null)\n        return error.message();\n    return message;\n}",
        "summary_tokens": [
            "if",
            "message",
            "is",
            "defined",
            "return",
            "it"
        ]
    },
    {
        "id": 1044,
        "code": "public static ApiVersionCollection intersectForwardableApis(\n    final ApiMessageType.ListenerType listenerType,\n    final RecordVersion minRecordVersion,\n    final Map<ApiKeys, ApiVersion> activeControllerApiVersions\n) {\n    ApiVersionCollection apiKeys = new ApiVersionCollection();\n    for (ApiKeys apiKey : ApiKeys.apisForListener(listenerType)) {\n        if (apiKey.minRequiredInterBrokerMagic <= minRecordVersion.value) {\n            ApiVersion brokerApiVersion = toApiVersion(apiKey);\n\n            final ApiVersion finalApiVersion;\n            if (!apiKey.forwardable) {\n                finalApiVersion = brokerApiVersion;\n            } else {\n                Optional<ApiVersion> intersectVersion = intersect(brokerApiVersion,\n                    activeControllerApiVersions.getOrDefault(apiKey, null));\n                if (intersectVersion.isPresent()) {\n                    finalApiVersion = intersectVersion.get();\n                } else {\n                        \n                    continue;\n                }\n            }\n\n            apiKeys.add(finalApiVersion.duplicate());\n        }\n    }\n    return apiKeys;\n}",
        "summary_tokens": [
            "find",
            "the",
            "common",
            "range",
            "of",
            "supported",
            "api",
            "versions",
            "between",
            "the",
            "locally",
            "known",
            "range",
            "and",
            "that",
            "of",
            "another",
            "set"
        ]
    },
    {
        "id": 1045,
        "code": "public static int nextEpoch(int prevEpoch) {\n    if (prevEpoch < 0) {\n            \n        return FINAL_EPOCH;\n    } else if (prevEpoch == Integer.MAX_VALUE) {\n        return 1;\n    } else {\n        return prevEpoch + 1;\n    }\n}",
        "summary_tokens": [
            "returns",
            "the",
            "next",
            "epoch"
        ]
    },
    {
        "id": 1046,
        "code": "public boolean isFull() {\n    return (this.epoch == INITIAL_EPOCH) || (this.epoch == FINAL_EPOCH);\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "a",
            "full",
            "fetch",
            "request"
        ]
    },
    {
        "id": 1047,
        "code": "public FetchMetadata nextCloseExisting() {\n    return new FetchMetadata(sessionId, INITIAL_EPOCH);\n}",
        "summary_tokens": [
            "return",
            "the",
            "metadata",
            "for",
            "the",
            "next",
            "error",
            "response"
        ]
    },
    {
        "id": 1048,
        "code": "public static FetchMetadata newIncremental(int sessionId) {\n    return new FetchMetadata(sessionId, nextEpoch(INITIAL_EPOCH));\n}",
        "summary_tokens": [
            "return",
            "the",
            "metadata",
            "for",
            "the",
            "next",
            "full",
            "fetch",
            "request"
        ]
    },
    {
        "id": 1049,
        "code": "public FetchMetadata nextIncremental() {\n    return new FetchMetadata(sessionId, nextEpoch(epoch));\n}",
        "summary_tokens": [
            "return",
            "the",
            "metadata",
            "for",
            "the",
            "next",
            "incremental",
            "response"
        ]
    },
    {
        "id": 1050,
        "code": "public static int sizeOf(short version,\n                         Iterator<Map.Entry<TopicIdPartition,\n                         FetchResponseData.PartitionData>> partIterator) {\n        \n        \n    FetchResponseData data = toMessage(Errors.NONE, 0, INVALID_SESSION_ID, partIterator);\n    ObjectSerializationCache cache = new ObjectSerializationCache();\n    return 4 + data.size(cache, version);\n}",
        "summary_tokens": [
            "convenience",
            "method",
            "to",
            "find",
            "the",
            "size",
            "of",
            "a",
            "response"
        ]
    },
    {
        "id": 1051,
        "code": "public static int recordsSize(FetchResponseData.PartitionData partition) {\n    return partition.records() == null ? 0 : partition.records().sizeInBytes();\n}",
        "summary_tokens": [
            "the",
            "size",
            "in",
            "bytes",
            "of",
            "the",
            "records"
        ]
    },
    {
        "id": 1052,
        "code": "public static FetchSnapshotRequestData singleton(\n    String clusterId,\n    TopicPartition topicPartition,\n    UnaryOperator<FetchSnapshotRequestData.PartitionSnapshot> operator\n) {\n    FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = operator.apply(\n        new FetchSnapshotRequestData.PartitionSnapshot().setPartition(topicPartition.partition())\n    );\n\n    return new FetchSnapshotRequestData()\n        .setClusterId(clusterId)\n        .setTopics(\n            Collections.singletonList(\n                new FetchSnapshotRequestData.TopicSnapshot()\n                    .setName(topicPartition.topic())\n                    .setPartitions(Collections.singletonList(partitionSnapshot))\n            )\n        );\n}",
        "summary_tokens": [
            "creates",
            "a",
            "fetch",
            "snapshot",
            "request",
            "data",
            "with",
            "a",
            "single",
            "partition",
            "snapshot",
            "for",
            "the",
            "topic",
            "partition"
        ]
    },
    {
        "id": 1053,
        "code": "public static Optional<FetchSnapshotRequestData.PartitionSnapshot> forTopicPartition(\n    FetchSnapshotRequestData data,\n    TopicPartition topicPartition\n) {\n    return data\n        .topics()\n        .stream()\n        .filter(topic -> topic.name().equals(topicPartition.topic()))\n        .flatMap(topic -> topic.partitions().stream())\n        .filter(partition -> partition.partition() == topicPartition.partition())\n        .findAny();\n}",
        "summary_tokens": [
            "finds",
            "the",
            "partition",
            "snapshot",
            "for",
            "a",
            "given",
            "topic",
            "partition"
        ]
    },
    {
        "id": 1054,
        "code": "public static FetchSnapshotResponseData withTopLevelError(Errors error) {\n    return new FetchSnapshotResponseData().setErrorCode(error.code());\n}",
        "summary_tokens": [
            "creates",
            "a",
            "fetch",
            "snapshot",
            "response",
            "data",
            "with",
            "a",
            "top",
            "level",
            "error"
        ]
    },
    {
        "id": 1055,
        "code": "public static FetchSnapshotResponseData singleton(\n    TopicPartition topicPartition,\n    UnaryOperator<FetchSnapshotResponseData.PartitionSnapshot> operator\n) {\n    FetchSnapshotResponseData.PartitionSnapshot partitionSnapshot = operator.apply(\n        new FetchSnapshotResponseData.PartitionSnapshot().setIndex(topicPartition.partition())\n    );\n\n    return new FetchSnapshotResponseData()\n        .setTopics(\n            Collections.singletonList(\n                new FetchSnapshotResponseData.TopicSnapshot()\n                    .setName(topicPartition.topic())\n                    .setPartitions(Collections.singletonList(partitionSnapshot))\n            )\n        );\n}",
        "summary_tokens": [
            "creates",
            "a",
            "fetch",
            "snapshot",
            "response",
            "data",
            "with",
            "a",
            "single",
            "partition",
            "snapshot",
            "for",
            "the",
            "topic",
            "partition"
        ]
    },
    {
        "id": 1056,
        "code": "public static Optional<FetchSnapshotResponseData.PartitionSnapshot> forTopicPartition(\n    FetchSnapshotResponseData data,\n    TopicPartition topicPartition\n) {\n    return data\n        .topics()\n        .stream()\n        .filter(topic -> topic.name().equals(topicPartition.topic()))\n        .flatMap(topic -> topic.partitions().stream())\n        .filter(parition -> parition.index() == topicPartition.partition())\n        .findAny();\n}",
        "summary_tokens": [
            "finds",
            "the",
            "partition",
            "snapshot",
            "for",
            "a",
            "given",
            "topic",
            "partition"
        ]
    },
    {
        "id": 1057,
        "code": "public static void validateGroupInstanceId(String id) {\n    Topic.validate(id, \"Group instance id\", message -> {\n        throw new InvalidConfigurationException(message);\n    });\n}",
        "summary_tokens": [
            "ported",
            "from",
            "class",
            "topic",
            "in",
            "org"
        ]
    },
    {
        "id": 1058,
        "code": "public static String maybeTruncateReason(final String reason) {\n    if (reason.length() > 255) {\n        return reason.substring(0, 255);\n    } else {\n        return reason;\n    }\n}",
        "summary_tokens": [
            "ensures",
            "that",
            "the",
            "provided",
            "reason",
            "remains",
            "within",
            "a",
            "range",
            "of",
            "0",
            "chars"
        ]
    },
    {
        "id": 1059,
        "code": "public static boolean supportsTopicPermission(short latestUsableVersion) {\n    return latestUsableVersion >= 3;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "a",
            "broker",
            "allows",
            "topic",
            "level",
            "permissions",
            "in",
            "order",
            "to",
            "use",
            "the",
            "offset",
            "for",
            "leader",
            "epoch",
            "api"
        ]
    },
    {
        "id": 1060,
        "code": "public ProduceRequestData data() {\n        \n    ProduceRequestData tmp = data;\n    if (tmp == null)\n        throw new IllegalStateException(\"The partition records are no longer available because clearPartitionRecords() has been invoked.\");\n    return tmp;\n}",
        "summary_tokens": [
            "data",
            "or",
            "illegal",
            "state",
            "exception",
            "if",
            "the",
            "data",
            "is",
            "removed",
            "to",
            "prevent",
            "unnecessary",
            "memory",
            "retention"
        ]
    },
    {
        "id": 1061,
        "code": "public Send buildResponseSend(AbstractResponse body) {\n    return body.toSend(header.toResponseHeader(), apiVersion());\n}",
        "summary_tokens": [
            "build",
            "a",
            "send",
            "for",
            "direct",
            "transmission",
            "of",
            "the",
            "provided",
            "response",
            "over",
            "the",
            "network"
        ]
    },
    {
        "id": 1062,
        "code": "public ByteBuffer buildResponseEnvelopePayload(AbstractResponse body) {\n    return body.serializeWithHeader(header.toResponseHeader(), apiVersion());\n}",
        "summary_tokens": [
            "serialize",
            "a",
            "response",
            "into",
            "a",
            "byte",
            "buffer"
        ]
    },
    {
        "id": 1063,
        "code": "static boolean flag(ProduceRequest request, Predicate<RecordBatch> predicate) {\n    for (ProduceRequestData.TopicProduceData tp : request.data().topicData()) {\n        for (ProduceRequestData.PartitionProduceData p : tp.partitionData()) {\n            if (p.records() instanceof Records) {\n                Iterator<? extends RecordBatch> iter = (((Records) p.records())).batchIterator();\n                if (iter.hasNext() && predicate.test(iter.next())) return true;\n            }\n        }\n    }\n    return false;\n}",
        "summary_tokens": [
            "find",
            "a",
            "flag",
            "from",
            "all",
            "records",
            "of",
            "a",
            "produce",
            "request"
        ]
    },
    {
        "id": 1064,
        "code": "public Errors error() {\n    return Errors.forCode(data.errorCode());\n}",
        "summary_tokens": [
            "possible",
            "error",
            "codes",
            "sasl",
            "authentication",
            "failed",
            "0",
            "authentication",
            "failed"
        ]
    },
    {
        "id": 1065,
        "code": "public Iterable<StopReplicaTopicState> topicStates() {\n    if (version() < 1) {\n        Map<String, StopReplicaTopicState> topicStates = new HashMap<>();\n        for (StopReplicaPartitionV0 partition : data.ungroupedPartitions()) {\n            StopReplicaTopicState topicState = topicStates.computeIfAbsent(partition.topicName(),\n                topic -> new StopReplicaTopicState().setTopicName(topic));\n            topicState.partitionStates().add(new StopReplicaPartitionState()\n                .setPartitionIndex(partition.partitionIndex())\n                .setDeletePartition(data.deletePartitions()));\n        }\n        return topicStates.values();\n    } else if (version() < 3) {\n        return () -> new MappedIterator<>(data.topics().iterator(), topic ->\n            new StopReplicaTopicState()\n                .setTopicName(topic.name())\n                .setPartitionStates(topic.partitionIndexes().stream()\n                    .map(partition -> new StopReplicaPartitionState()\n                        .setPartitionIndex(partition)\n                        .setDeletePartition(data.deletePartitions()))\n                    .collect(Collectors.toList())));\n    } else {\n        return data.topicStates();\n    }\n}",
        "summary_tokens": [
            "note",
            "that",
            "this",
            "method",
            "has",
            "allocation",
            "overhead",
            "per",
            "iterated",
            "element",
            "so",
            "callers",
            "should",
            "copy",
            "the",
            "result",
            "into",
            "another",
            "collection",
            "if",
            "they",
            "need",
            "to",
            "iterate",
            "more",
            "than",
            "once"
        ]
    },
    {
        "id": 1066,
        "code": "public boolean areMandatoryProtocolTypeAndNamePresent() {\n    if (version() >= 5)\n        return data.protocolType() != null && data.protocolName() != null;\n    else\n        return true;\n}",
        "summary_tokens": [
            "protocol",
            "type",
            "and",
            "protocol",
            "name",
            "are",
            "mandatory",
            "since",
            "version",
            "0"
        ]
    },
    {
        "id": 1067,
        "code": "public ResourceType resourceType() {\n    return resourceType;\n}",
        "summary_tokens": [
            "return",
            "the",
            "resource",
            "type"
        ]
    },
    {
        "id": 1068,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "return",
            "the",
            "resource",
            "name"
        ]
    },
    {
        "id": 1069,
        "code": "public boolean isUnknown() {\n    return resourceType.isUnknown();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "resource",
            "has",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 1070,
        "code": "public ResourceType resourceType() {\n    return resourceType;\n}",
        "summary_tokens": [
            "the",
            "specific",
            "resource",
            "type",
            "this",
            "pattern",
            "matches"
        ]
    },
    {
        "id": 1071,
        "code": "public PatternType patternType() {\n    return patternType;\n}",
        "summary_tokens": [
            "the",
            "resource",
            "pattern",
            "type"
        ]
    },
    {
        "id": 1072,
        "code": "public ResourcePatternFilter toFilter() {\n    return new ResourcePatternFilter(resourceType, name, patternType);\n}",
        "summary_tokens": [
            "a",
            "filter",
            "which",
            "matches",
            "only",
            "this",
            "pattern"
        ]
    },
    {
        "id": 1073,
        "code": "public boolean isUnknown() {\n    return resourceType.isUnknown() || patternType.isUnknown();\n}",
        "summary_tokens": [
            "true",
            "if",
            "this",
            "resource",
            "has",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 1074,
        "code": "public boolean isUnknown() {\n    return resourceType.isUnknown() || patternType.isUnknown();\n}",
        "summary_tokens": [
            "true",
            "if",
            "this",
            "filter",
            "has",
            "any",
            "unknown",
            "components"
        ]
    },
    {
        "id": 1075,
        "code": "public ResourceType resourceType() {\n    return resourceType;\n}",
        "summary_tokens": [
            "the",
            "specific",
            "resource",
            "type",
            "this",
            "pattern",
            "matches"
        ]
    },
    {
        "id": 1076,
        "code": "public PatternType patternType() {\n    return patternType;\n}",
        "summary_tokens": [
            "the",
            "resource",
            "pattern",
            "type"
        ]
    },
    {
        "id": 1077,
        "code": "public boolean matches(ResourcePattern pattern) {\n    if (!resourceType.equals(ResourceType.ANY) && !resourceType.equals(pattern.resourceType())) {\n        return false;\n    }\n\n    if (!patternType.equals(PatternType.ANY) && !patternType.equals(PatternType.MATCH) && !patternType.equals(pattern.patternType())) {\n        return false;\n    }\n\n    if (name == null) {\n        return true;\n    }\n\n    if (patternType.equals(PatternType.ANY) || patternType.equals(pattern.patternType())) {\n        return name.equals(pattern.name());\n    }\n\n    switch (pattern.patternType()) {\n        case LITERAL:\n            return name.equals(pattern.name()) || pattern.name().equals(WILDCARD_RESOURCE);\n\n        case PREFIXED:\n            return name.startsWith(pattern.name());\n\n        default:\n            throw new IllegalArgumentException(\"Unsupported PatternType: \" + pattern.patternType());\n    }\n}",
        "summary_tokens": [
            "true",
            "if",
            "this",
            "filter",
            "matches",
            "the",
            "given",
            "pattern"
        ]
    },
    {
        "id": 1078,
        "code": "public boolean matchesAtMostOne() {\n    return findIndefiniteField() == null;\n}",
        "summary_tokens": [
            "true",
            "if",
            "this",
            "filter",
            "could",
            "only",
            "match",
            "one",
            "pattern"
        ]
    },
    {
        "id": 1079,
        "code": "public String findIndefiniteField() {\n    if (resourceType == ResourceType.ANY)\n        return \"Resource type is ANY.\";\n    if (resourceType == ResourceType.UNKNOWN)\n        return \"Resource type is UNKNOWN.\";\n    if (name == null)\n        return \"Resource name is NULL.\";\n    if (patternType == PatternType.MATCH)\n        return \"Resource pattern type is MATCH.\";\n    if (patternType == PatternType.UNKNOWN)\n        return \"Resource pattern type is UNKNOWN.\";\n    return null;\n}",
        "summary_tokens": [
            "a",
            "string",
            "describing",
            "any",
            "any",
            "or",
            "unknown",
            "field",
            "or",
            "null",
            "if",
            "there",
            "is",
            "no",
            "such",
            "field"
        ]
    },
    {
        "id": 1080,
        "code": "public static JaasContext loadServerContext(ListenerName listenerName, String mechanism, Map<String, ?> configs) {\n    if (listenerName == null)\n        throw new IllegalArgumentException(\"listenerName should not be null for SERVER\");\n    if (mechanism == null)\n        throw new IllegalArgumentException(\"mechanism should not be null for SERVER\");\n    String listenerContextName = listenerName.value().toLowerCase(Locale.ROOT) + \".\" + GLOBAL_CONTEXT_NAME_SERVER;\n    Password dynamicJaasConfig = (Password) configs.get(mechanism.toLowerCase(Locale.ROOT) + \".\" + SaslConfigs.SASL_JAAS_CONFIG);\n    if (dynamicJaasConfig == null && configs.get(SaslConfigs.SASL_JAAS_CONFIG) != null)\n        LOG.warn(\"Server config {} should be prefixed with SASL mechanism name, ignoring config\", SaslConfigs.SASL_JAAS_CONFIG);\n    return load(Type.SERVER, listenerContextName, GLOBAL_CONTEXT_NAME_SERVER, dynamicJaasConfig);\n}",
        "summary_tokens": [
            "returns",
            "an",
            "instance",
            "of",
            "this",
            "class"
        ]
    },
    {
        "id": 1081,
        "code": "public static JaasContext loadClientContext(Map<String, ?> configs) {\n    Password dynamicJaasConfig = (Password) configs.get(SaslConfigs.SASL_JAAS_CONFIG);\n    return load(JaasContext.Type.CLIENT, null, GLOBAL_CONTEXT_NAME_CLIENT, dynamicJaasConfig);\n}",
        "summary_tokens": [
            "returns",
            "an",
            "instance",
            "of",
            "this",
            "class"
        ]
    },
    {
        "id": 1082,
        "code": "public static String configEntryOption(List<AppConfigurationEntry> configurationEntries, String key, String loginModuleName) {\n    for (AppConfigurationEntry entry : configurationEntries) {\n        if (loginModuleName != null && !loginModuleName.equals(entry.getLoginModuleName()))\n            continue;\n        Object val = entry.getOptions().get(key);\n        if (val != null)\n            return (String) val;\n    }\n    return null;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "configuration",
            "option",
            "for",
            "code",
            "key",
            "code",
            "from",
            "this",
            "context"
        ]
    },
    {
        "id": 1083,
        "code": "public Optional<SSLSession> sslSession() {\n    return sslSession;\n}",
        "summary_tokens": [
            "returns",
            "ssl",
            "session",
            "for",
            "the",
            "connection",
            "if",
            "security",
            "protocol",
            "is",
            "sasl",
            "ssl"
        ]
    },
    {
        "id": 1084,
        "code": "public Map<String, String> map() {\n    return extensionsMap;\n}",
        "summary_tokens": [
            "returns",
            "an",
            "strong",
            "immutable",
            "strong",
            "map",
            "of",
            "the",
            "extension",
            "names",
            "and",
            "their",
            "values"
        ]
    },
    {
        "id": 1085,
        "code": "public static SaslExtensions empty() {\n        \n        \n    return new SaslExtensions(Collections.EMPTY_MAP);\n}",
        "summary_tokens": [
            "creates",
            "an",
            "empty",
            "instance",
            "indicating",
            "no",
            "sasl",
            "extensions"
        ]
    },
    {
        "id": 1086,
        "code": "public final boolean equals(Object o) {\n    return super.equals(o);\n}",
        "summary_tokens": [
            "implements",
            "equals",
            "using",
            "the",
            "reference",
            "comparison",
            "implementation",
            "from",
            "object",
            "equals",
            "object"
        ]
    },
    {
        "id": 1087,
        "code": "public final int hashCode() {\n    return super.hashCode();\n}",
        "summary_tokens": [
            "implements",
            "code",
            "hash",
            "code",
            "code",
            "using",
            "the",
            "native",
            "implementation",
            "from",
            "object",
            "hash",
            "code"
        ]
    },
    {
        "id": 1088,
        "code": "public void extensions(SaslExtensions extensions) {\n    this.extensions = Objects.requireNonNull(extensions, \"extensions must not be null\");\n}",
        "summary_tokens": [
            "sets",
            "the",
            "sasl",
            "extensions",
            "on",
            "this",
            "callback"
        ]
    },
    {
        "id": 1089,
        "code": "default void configure(Map<String, ?> config) {\n\n}",
        "summary_tokens": [
            "configure",
            "method",
            "is",
            "used",
            "to",
            "configure",
            "the",
            "generator",
            "to",
            "create",
            "the",
            "security",
            "provider",
            "config",
            "configuration",
            "parameters",
            "for",
            "initialising",
            "security",
            "provider"
        ]
    },
    {
        "id": 1090,
        "code": "public static LoginManager acquireLoginManager(JaasContext jaasContext, String saslMechanism,\n                                               Class<? extends Login> defaultLoginClass,\n                                               Map<String, ?> configs) throws LoginException {\n    Class<? extends Login> loginClass = configuredClassOrDefault(configs, jaasContext,\n            saslMechanism, SaslConfigs.SASL_LOGIN_CLASS, defaultLoginClass);\n    Class<? extends AuthenticateCallbackHandler> defaultLoginCallbackHandlerClass = OAuthBearerLoginModule.OAUTHBEARER_MECHANISM\n            .equals(saslMechanism) ? OAuthBearerUnsecuredLoginCallbackHandler.class\n                    : AbstractLogin.DefaultLoginCallbackHandler.class;\n    Class<? extends AuthenticateCallbackHandler> loginCallbackClass = configuredClassOrDefault(configs, jaasContext,\n            saslMechanism, SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS, defaultLoginCallbackHandlerClass);\n    synchronized (LoginManager.class) {\n        LoginManager loginManager;\n        Password jaasConfigValue = jaasContext.dynamicJaasConfig();\n        if (jaasConfigValue != null) {\n            LoginMetadata<Password> loginMetadata = new LoginMetadata<>(jaasConfigValue, loginClass, loginCallbackClass);\n            loginManager = DYNAMIC_INSTANCES.get(loginMetadata);\n            if (loginManager == null) {\n                loginManager = new LoginManager(jaasContext, saslMechanism, configs, loginMetadata);\n                DYNAMIC_INSTANCES.put(loginMetadata, loginManager);\n            }\n        } else {\n            LoginMetadata<String> loginMetadata = new LoginMetadata<>(jaasContext.name(), loginClass, loginCallbackClass);\n            loginManager = STATIC_INSTANCES.get(loginMetadata);\n            if (loginManager == null) {\n                loginManager = new LoginManager(jaasContext, saslMechanism, configs, loginMetadata);\n                STATIC_INSTANCES.put(loginMetadata, loginManager);\n            }\n        }\n        SecurityUtils.addConfiguredSecurityProviders(configs);\n        return loginManager.acquire();\n    }\n}",
        "summary_tokens": [
            "returns",
            "an",
            "instance",
            "of",
            "login",
            "manager",
            "and",
            "increases",
            "its",
            "reference",
            "count"
        ]
    },
    {
        "id": 1091,
        "code": "public void release() {\n    synchronized (LoginManager.class) {\n        if (refCount == 0)\n            throw new IllegalStateException(\"release() called on disposed \" + this);\n        else if (refCount == 1) {\n            if (loginMetadata.configInfo instanceof Password) {\n                DYNAMIC_INSTANCES.remove(loginMetadata);\n            } else {\n                STATIC_INSTANCES.remove(loginMetadata);\n            }\n            login.close();\n            loginCallbackHandler.close();\n        }\n        --refCount;\n        LOGGER.trace(\"{} released\", this);\n    }\n}",
        "summary_tokens": [
            "decrease",
            "the",
            "reference",
            "count",
            "for",
            "this",
            "instance",
            "and",
            "release",
            "resources",
            "if",
            "it",
            "reaches",
            "0"
        ]
    },
    {
        "id": 1092,
        "code": "public static boolean isReserved(int correlationId) {\n    return correlationId >= MIN_RESERVED_CORRELATION_ID;\n}",
        "summary_tokens": [
            "true",
            "if",
            "the",
            "correlation",
            "id",
            "is",
            "reserved",
            "for",
            "sasl",
            "request"
        ]
    },
    {
        "id": 1093,
        "code": "public void authenticate() throws IOException {\n    if (netOutBuffer != null && !flushNetOutBufferAndUpdateInterestOps())\n        return;\n\n    switch (saslState) {\n        case SEND_APIVERSIONS_REQUEST:\n                \n            ApiVersionsRequest apiVersionsRequest = new ApiVersionsRequest.Builder().build((short) 0);\n            send(apiVersionsRequest.toSend(nextRequestHeader(ApiKeys.API_VERSIONS, apiVersionsRequest.version())));\n            setSaslState(SaslState.RECEIVE_APIVERSIONS_RESPONSE);\n            break;\n        case RECEIVE_APIVERSIONS_RESPONSE:\n            ApiVersionsResponse apiVersionsResponse = (ApiVersionsResponse) receiveKafkaResponse();\n            if (apiVersionsResponse == null)\n                break;\n            else {\n                setSaslAuthenticateAndHandshakeVersions(apiVersionsResponse);\n                reauthInfo.apiVersionsResponseReceivedFromBroker = apiVersionsResponse;\n                setSaslState(SaslState.SEND_HANDSHAKE_REQUEST);\n                    \n            }\n        case SEND_HANDSHAKE_REQUEST:\n            sendHandshakeRequest(saslHandshakeVersion);\n            setSaslState(SaslState.RECEIVE_HANDSHAKE_RESPONSE);\n            break;\n        case RECEIVE_HANDSHAKE_RESPONSE:\n            SaslHandshakeResponse handshakeResponse = (SaslHandshakeResponse) receiveKafkaResponse();\n            if (handshakeResponse == null)\n                break;\n            else {\n                handleSaslHandshakeResponse(handshakeResponse);\n                setSaslState(SaslState.INITIAL);\n                    \n            }\n        case INITIAL:\n            sendInitialToken();\n            setSaslState(SaslState.INTERMEDIATE);\n            break;\n        case REAUTH_PROCESS_ORIG_APIVERSIONS_RESPONSE:\n            setSaslAuthenticateAndHandshakeVersions(reauthInfo.apiVersionsResponseFromOriginalAuthentication);\n            setSaslState(SaslState.REAUTH_SEND_HANDSHAKE_REQUEST); \n                \n        case REAUTH_SEND_HANDSHAKE_REQUEST:\n            sendHandshakeRequest(saslHandshakeVersion);\n            setSaslState(SaslState.REAUTH_RECEIVE_HANDSHAKE_OR_OTHER_RESPONSE);\n            break;\n        case REAUTH_RECEIVE_HANDSHAKE_OR_OTHER_RESPONSE:\n            handshakeResponse = (SaslHandshakeResponse) receiveKafkaResponse();\n            if (handshakeResponse == null)\n                break;\n            handleSaslHandshakeResponse(handshakeResponse);\n            setSaslState(SaslState.REAUTH_INITIAL); \n                \n        case REAUTH_INITIAL:\n            sendInitialToken();\n            setSaslState(SaslState.INTERMEDIATE);\n            break;\n        case INTERMEDIATE:\n            byte[] serverToken = receiveToken();\n            boolean noResponsesPending = serverToken != null && !sendSaslClientToken(serverToken, false);\n                \n                \n            if (saslClient.isComplete()) {\n                if (saslAuthenticateVersion == DISABLE_KAFKA_SASL_AUTHENTICATE_HEADER || noResponsesPending)\n                    setSaslState(SaslState.COMPLETE);\n                else\n                    setSaslState(SaslState.CLIENT_COMPLETE);\n            }\n            break;\n        case CLIENT_COMPLETE:\n            byte[] serverResponse = receiveToken();\n            if (serverResponse != null)\n                setSaslState(SaslState.COMPLETE);\n            break;\n        case COMPLETE:\n            break;\n        case FAILED:\n                \n            throw new IllegalStateException(\"SASL handshake has already failed\");\n    }\n}",
        "summary_tokens": [
            "sends",
            "an",
            "empty",
            "message",
            "to",
            "the",
            "server",
            "to",
            "initiate",
            "the",
            "authentication",
            "process"
        ]
    },
    {
        "id": 1094,
        "code": "private boolean sendSaslClientToken(byte[] serverToken, boolean isInitial) throws IOException {\n    if (!saslClient.isComplete()) {\n        byte[] saslToken = createSaslToken(serverToken, isInitial);\n        if (saslToken != null) {\n            ByteBuffer tokenBuf = ByteBuffer.wrap(saslToken);\n            Send send;\n            if (saslAuthenticateVersion == DISABLE_KAFKA_SASL_AUTHENTICATE_HEADER) {\n                send = ByteBufferSend.sizePrefixed(tokenBuf);\n            } else {\n                SaslAuthenticateRequestData data = new SaslAuthenticateRequestData()\n                        .setAuthBytes(tokenBuf.array());\n                SaslAuthenticateRequest request = new SaslAuthenticateRequest.Builder(data).build(saslAuthenticateVersion);\n                send = request.toSend(nextRequestHeader(ApiKeys.SASL_AUTHENTICATE, saslAuthenticateVersion));\n            }\n            send(send);\n            return true;\n        }\n    }\n    return false;\n}",
        "summary_tokens": [
            "sends",
            "a",
            "sasl",
            "client",
            "token",
            "to",
            "server",
            "if",
            "required"
        ]
    },
    {
        "id": 1095,
        "code": "public static String firstPrincipal(Subject subject) {\n    Set<Principal> principals = subject.getPrincipals();\n    synchronized (principals) {\n        Iterator<Principal> iterator = principals.iterator();\n        if (iterator.hasNext())\n            return iterator.next().getName();\n        else\n            throw new KafkaException(\"Principal could not be determined from Subject, this may be a transient failure due to Kerberos re-login\");\n    }\n}",
        "summary_tokens": [
            "returns",
            "the",
            "first",
            "principal",
            "from",
            "subject"
        ]
    },
    {
        "id": 1096,
        "code": "public void authenticate() throws IOException {\n    if (saslState != SaslState.REAUTH_PROCESS_HANDSHAKE) {\n        if (netOutBuffer != null && !flushNetOutBufferAndUpdateInterestOps())\n            return;\n\n        if (saslServer != null && saslServer.isComplete()) {\n            setSaslState(SaslState.COMPLETE);\n            return;\n        }\n\n            \n        if (netInBuffer == null) netInBuffer = new NetworkReceive(MAX_RECEIVE_SIZE, connectionId);\n\n        netInBuffer.readFrom(transportLayer);\n        if (!netInBuffer.complete())\n            return;\n        netInBuffer.payload().rewind();\n    }\n    byte[] clientToken = new byte[netInBuffer.payload().remaining()];\n    netInBuffer.payload().get(clientToken, 0, clientToken.length);\n    netInBuffer = null; \n    try {\n        switch (saslState) {\n            case REAUTH_PROCESS_HANDSHAKE:\n            case HANDSHAKE_OR_VERSIONS_REQUEST:\n            case HANDSHAKE_REQUEST:\n                handleKafkaRequest(clientToken);\n                break;\n            case REAUTH_BAD_MECHANISM:\n                throw new SaslAuthenticationException(reauthInfo.badMechanismErrorMessage);\n            case INITIAL_REQUEST:\n                if (handleKafkaRequest(clientToken))\n                    break;\n                    \n                    \n            case AUTHENTICATE:\n                handleSaslToken(clientToken);\n                    \n                    \n                if (saslServer.isComplete())\n                    setSaslState(SaslState.COMPLETE);\n                break;\n            default:\n                break;\n        }\n    } catch (AuthenticationException e) {\n            \n        setSaslState(SaslState.FAILED, e);\n    } catch (Exception e) {\n            \n        saslState = SaslState.FAILED;\n        LOG.debug(\"Failed during {}: {}\", reauthInfo.authenticationOrReauthenticationText(), e.getMessage());\n        throw e;\n    }\n}",
        "summary_tokens": [
            "evaluates",
            "client",
            "responses",
            "via",
            "sasl",
            "server"
        ]
    },
    {
        "id": 1097,
        "code": "private void buildResponseOnAuthenticateFailure(RequestContext context, AbstractResponse response) {\n    authenticationFailureSend = context.buildResponseSend(response);\n}",
        "summary_tokens": [
            "build",
            "a",
            "send",
            "response",
            "on",
            "authenticate",
            "failure"
        ]
    },
    {
        "id": 1098,
        "code": "private void sendAuthenticationFailureResponse() throws IOException {\n    if (authenticationFailureSend == null)\n        return;\n    sendKafkaResponse(authenticationFailureSend);\n    authenticationFailureSend = null;\n}",
        "summary_tokens": [
            "send",
            "any",
            "authentication",
            "failure",
            "response",
            "that",
            "may",
            "have",
            "been",
            "previously",
            "built"
        ]
    },
    {
        "id": 1099,
        "code": "public LoginContext login() throws LoginException {\n\n    this.lastLogin = currentElapsedTime();\n    loginContext = super.login();\n    subject = loginContext.getSubject();\n    isKrbTicket = !subject.getPrivateCredentials(KerberosTicket.class).isEmpty();\n\n    AppConfigurationEntry[] entries = configuration().getAppConfigurationEntry(contextName());\n    if (entries.length == 0) {\n        isUsingTicketCache = false;\n        principal = null;\n    } else {\n            \n        AppConfigurationEntry entry = entries[0];\n        if (entry.getOptions().get(\"useTicketCache\") != null) {\n            String val = (String) entry.getOptions().get(\"useTicketCache\");\n            isUsingTicketCache = val.equals(\"true\");\n        } else\n            isUsingTicketCache = false;\n        if (entry.getOptions().get(\"principal\") != null)\n            principal = (String) entry.getOptions().get(\"principal\");\n        else\n            principal = null;\n    }\n\n    if (!isKrbTicket) {\n        log.debug(\"[Principal={}]: It is not a Kerberos ticket\", principal);\n        t = null;\n            \n        return loginContext;\n    }\n    log.debug(\"[Principal={}]: It is a Kerberos ticket\", principal);\n\n        \n        \n        \n        \n    t = KafkaThread.daemon(String.format(\"kafka-kerberos-refresh-thread-%s\", principal), () -> {\n        log.info(\"[Principal={}]: TGT refresh thread started.\", principal);\n        while (true) {  \n            KerberosTicket tgt = getTGT();\n            long now = currentWallTime();\n            long nextRefresh;\n            Date nextRefreshDate;\n            if (tgt == null) {\n                nextRefresh = now + minTimeBeforeRelogin;\n                nextRefreshDate = new Date(nextRefresh);\n                log.warn(\"[Principal={}]: No TGT found: will try again at {}\", principal, nextRefreshDate);\n            } else {\n                nextRefresh = getRefreshTime(tgt);\n                long expiry = tgt.getEndTime().getTime();\n                Date expiryDate = new Date(expiry);\n                if (isUsingTicketCache && tgt.getRenewTill() != null && tgt.getRenewTill().getTime() < expiry) {\n                    log.warn(\"The TGT cannot be renewed beyond the next expiry date: {}.\" +\n                        \"This process will not be able to authenticate new SASL connections after that \" +\n                        \"time (for example, it will not be able to authenticate a new connection with a Kafka \" +\n                        \"Broker).  Ask your system administrator to either increase the \" +\n                        \"'renew until' time by doing : 'modprinc -maxrenewlife {} ' within \" +\n                        \"kadmin, or instead, to generate a keytab for {}. Because the TGT's \" +\n                        \"expiry cannot be further extended by refreshing, exiting refresh thread now.\",\n                        expiryDate, principal, principal);\n                    return;\n                }\n                    \n                    \n                    \n                    \n                if ((nextRefresh > expiry) || (minTimeBeforeRelogin > expiry - now)) {\n                        \n                    log.info(\"[Principal={}]: Refreshing now because expiry is before next scheduled refresh time.\", principal);\n                    nextRefresh = now;\n                } else {\n                    if (nextRefresh - now < minTimeBeforeRelogin) {\n                            \n                        Date until = new Date(nextRefresh);\n                        Date newUntil = new Date(now + minTimeBeforeRelogin);\n                        log.warn(\"[Principal={}]: TGT refresh thread time adjusted from {} to {} since the former is sooner \" +\n                            \"than the minimum refresh interval ({} seconds) from now.\",\n                            principal, until, newUntil, minTimeBeforeRelogin / 1000);\n                    }\n                    nextRefresh = Math.max(nextRefresh, now + minTimeBeforeRelogin);\n                }\n                nextRefreshDate = new Date(nextRefresh);\n                if (nextRefresh > expiry) {\n                    log.error(\"[Principal={}]: Next refresh: {} is later than expiry {}. This may indicate a clock skew problem.\" +\n                        \"Check that this host and the KDC hosts' clocks are in sync. Exiting refresh thread.\",\n                        principal, nextRefreshDate, expiryDate);\n                    return;\n                }\n            }\n            if (now < nextRefresh) {\n                Date until = new Date(nextRefresh);\n                log.info(\"[Principal={}]: TGT refresh sleeping until: {}\", principal, until);\n                try {\n                    Thread.sleep(nextRefresh - now);\n                } catch (InterruptedException ie) {\n                    log.warn(\"[Principal={}]: TGT renewal thread has been interrupted and will exit.\", principal);\n                    return;\n                }\n            } else {\n                log.error(\"[Principal={}]: NextRefresh: {} is in the past: exiting refresh thread. Check\"\n                    + \" clock sync between this host and KDC - (KDC's clock is likely ahead of this host).\"\n                    + \" Manual intervention will be required for this client to successfully authenticate.\"\n                    + \" Exiting refresh thread.\", principal, nextRefreshDate);\n                return;\n            }\n            if (isUsingTicketCache) {\n                String kinitArgs = \"-R\";\n                int retry = 1;\n                while (retry >= 0) {\n                    try {\n                        log.debug(\"[Principal={}]: Running ticket cache refresh command: {} {}\", principal, kinitCmd, kinitArgs);\n                        Shell.execCommand(kinitCmd, kinitArgs);\n                        break;\n                    } catch (Exception e) {\n                        if (retry > 0) {\n                            log.warn(\"[Principal={}]: Error when trying to renew with TicketCache, but will retry \", principal, e);\n                            --retry;\n                                \n                            try {\n                                Thread.sleep(10 * 1000);\n                            } catch (InterruptedException ie) {\n                                log.error(\"[Principal={}]: Interrupted while renewing TGT, exiting Login thread\", principal);\n                                return;\n                            }\n                        } else {\n                            log.warn(\"[Principal={}]: Could not renew TGT due to problem running shell command: '{} {}'. \" +\n                                \"Exiting refresh thread.\", principal, kinitCmd, kinitArgs, e);\n                            return;\n                        }\n                    }\n                }\n            }\n            try {\n                int retry = 1;\n                while (retry >= 0) {\n                    try {\n                        reLogin();\n                        break;\n                    } catch (LoginException le) {\n                        if (retry > 0) {\n                            log.warn(\"[Principal={}]: Error when trying to re-Login, but will retry \", principal, le);\n                            --retry;\n                                \n                            try {\n                                Thread.sleep(10 * 1000);\n                            } catch (InterruptedException e) {\n                                log.error(\"[Principal={}]: Interrupted during login retry after LoginException:\", principal, le);\n                                throw le;\n                            }\n                        } else {\n                            log.error(\"[Principal={}]: Could not refresh TGT.\", principal, le);\n                        }\n                    }\n                }\n            } catch (LoginException le) {\n                log.error(\"[Principal={}]: Failed to refresh TGT: refresh thread exiting now.\", principal, le);\n                return;\n            }\n        }\n    });\n    t.start();\n    return loginContext;\n}",
        "summary_tokens": [
            "performs",
            "login",
            "for",
            "each",
            "login",
            "module",
            "specified",
            "for",
            "the",
            "login",
            "context",
            "of",
            "this",
            "instance",
            "and",
            "starts",
            "the",
            "thread",
            "used",
            "to",
            "periodically",
            "re",
            "login",
            "to",
            "the",
            "kerberos",
            "ticket",
            "granting",
            "server"
        ]
    },
    {
        "id": 1100,
        "code": "protected void reLogin() throws LoginException {\n    if (!isKrbTicket) {\n        return;\n    }\n    if (loginContext == null) {\n        throw new LoginException(\"Login must be done first\");\n    }\n    if (!hasSufficientTimeElapsed()) {\n        return;\n    }\n    synchronized (KerberosLogin.class) {\n        log.info(\"Initiating logout for {}\", principal);\n            \n        lastLogin = currentElapsedTime();\n            \n            \n            \n            \n        if (subject != null && !subject.getPrincipals().isEmpty()) {\n            logout();\n        }\n            \n            \n        loginContext = new LoginContext(contextName(), subject, null, configuration());\n        log.info(\"Initiating re-login for {}\", principal);\n        login(loginContext);\n    }\n}",
        "summary_tokens": [
            "re",
            "login",
            "a",
            "principal"
        ]
    },
    {
        "id": 1101,
        "code": "public static KerberosName parse(String principalName) {\n    Matcher match = NAME_PARSER.matcher(principalName);\n    if (!match.matches()) {\n        if (principalName.contains(\"@\")) {\n            throw new IllegalArgumentException(\"Malformed Kerberos name: \" + principalName);\n        } else {\n            return new KerberosName(principalName, null, null);\n        }\n    } else {\n        return new KerberosName(match.group(1), match.group(3), match.group(4));\n    }\n}",
        "summary_tokens": [
            "create",
            "a",
            "name",
            "from",
            "the",
            "full",
            "kerberos",
            "principal",
            "name"
        ]
    },
    {
        "id": 1102,
        "code": "public String toString() {\n    StringBuilder result = new StringBuilder();\n    result.append(serviceName);\n    if (hostName != null) {\n        result.append('/');\n        result.append(hostName);\n    }\n    if (realm != null) {\n        result.append('@');\n        result.append(realm);\n    }\n    return result.toString();\n}",
        "summary_tokens": [
            "put",
            "the",
            "name",
            "back",
            "together",
            "from",
            "the",
            "parts"
        ]
    },
    {
        "id": 1103,
        "code": "public String serviceName() {\n    return serviceName;\n}",
        "summary_tokens": [
            "get",
            "the",
            "first",
            "component",
            "of",
            "the",
            "name"
        ]
    },
    {
        "id": 1104,
        "code": "public String hostName() {\n    return hostName;\n}",
        "summary_tokens": [
            "get",
            "the",
            "second",
            "component",
            "of",
            "the",
            "name"
        ]
    },
    {
        "id": 1105,
        "code": "public String realm() {\n    return realm;\n}",
        "summary_tokens": [
            "get",
            "the",
            "realm",
            "of",
            "the",
            "name"
        ]
    },
    {
        "id": 1106,
        "code": "static String replaceParameters(String format,\n                                String[] params) throws BadFormatString {\n    Matcher match = PARAMETER_PATTERN.matcher(format);\n    int start = 0;\n    StringBuilder result = new StringBuilder();\n    while (start < format.length() && match.find(start)) {\n        result.append(match.group(1));\n        String paramNum = match.group(3);\n        if (paramNum != null) {\n            try {\n                int num = Integer.parseInt(paramNum);\n                if (num < 0 || num >= params.length) {\n                    throw new BadFormatString(\"index \" + num + \" from \" + format +\n                            \" is outside of the valid range 0 to \" +\n                            (params.length - 1));\n                }\n                result.append(params[num]);\n            } catch (NumberFormatException nfe) {\n                throw new BadFormatString(\"bad format in username mapping in \" +\n                        paramNum, nfe);\n            }\n\n        }\n        start = match.end();\n    }\n    return result.toString();\n}",
        "summary_tokens": [
            "replace",
            "the",
            "numbered",
            "parameters",
            "of",
            "the",
            "form",
            "n",
            "where",
            "n",
            "is",
            "from",
            "0",
            "to",
            "the",
            "length",
            "of",
            "params",
            "0"
        ]
    },
    {
        "id": 1107,
        "code": "static String replaceSubstitution(String base, Pattern from, String to,\n                                  boolean repeat) {\n    Matcher match = from.matcher(base);\n    if (repeat) {\n        return match.replaceAll(to);\n    } else {\n        return match.replaceFirst(to);\n    }\n}",
        "summary_tokens": [
            "replace",
            "the",
            "matches",
            "of",
            "the",
            "from",
            "pattern",
            "in",
            "the",
            "base",
            "string",
            "with",
            "the",
            "value",
            "of",
            "the",
            "to",
            "string"
        ]
    },
    {
        "id": 1108,
        "code": "String apply(String[] params) throws IOException {\n    String result = null;\n    if (isDefault) {\n        if (defaultRealm.equals(params[0])) {\n            result = params[1];\n        }\n    } else if (params.length - 1 == numOfComponents) {\n        String base = replaceParameters(format, params);\n        if (match == null || match.matcher(base).matches()) {\n            if (fromPattern == null) {\n                result = base;\n            } else {\n                result = replaceSubstitution(base, fromPattern, toPattern,  repeat);\n            }\n        }\n    }\n    if (result != null && NON_SIMPLE_PATTERN.matcher(result).find()) {\n        throw new NoMatchingRule(\"Non-simple name \" + result + \" after auth_to_local rule \" + this);\n    }\n    if (toLowerCase && result != null) {\n        result = result.toLowerCase(Locale.ENGLISH);\n    } else if (toUpperCase && result != null) {\n        result = result.toUpperCase(Locale.ENGLISH);\n    }\n\n    return result;\n}",
        "summary_tokens": [
            "try",
            "to",
            "apply",
            "this",
            "rule",
            "to",
            "the",
            "given",
            "name",
            "represented",
            "as",
            "a",
            "parameter",
            "array"
        ]
    },
    {
        "id": 1109,
        "code": "public String shortName(KerberosName kerberosName) throws IOException {\n    String[] params;\n    if (kerberosName.hostName() == null) {\n            \n        if (kerberosName.realm() == null)\n            return kerberosName.serviceName();\n        params = new String[]{kerberosName.realm(), kerberosName.serviceName()};\n    } else {\n        params = new String[]{kerberosName.realm(), kerberosName.serviceName(), kerberosName.hostName()};\n    }\n    for (KerberosRule r : principalToLocalRules) {\n        String result = r.apply(params);\n        if (result != null)\n            return result;\n    }\n    throw new NoMatchingRule(\"No rules apply to \" + kerberosName + \", rules \" + principalToLocalRules);\n}",
        "summary_tokens": [
            "get",
            "the",
            "translation",
            "of",
            "the",
            "principal",
            "name",
            "into",
            "an",
            "operating",
            "system",
            "user",
            "name"
        ]
    },
    {
        "id": 1110,
        "code": "public OAuthBearerToken token() {\n    return token;\n}",
        "summary_tokens": [
            "oauth",
            "bearer",
            "token",
            "the",
            "oauth",
            "bearer",
            "token",
            "of",
            "the",
            "client"
        ]
    },
    {
        "id": 1111,
        "code": "public SaslExtensions inputExtensions() {\n    return inputExtensions;\n}",
        "summary_tokens": [
            "sasl",
            "extensions",
            "consisting",
            "of",
            "the",
            "unvalidated",
            "extension",
            "names",
            "and",
            "values",
            "that",
            "were",
            "sent",
            "by",
            "the",
            "client"
        ]
    },
    {
        "id": 1112,
        "code": "public Map<String, String> validatedExtensions() {\n    return Collections.unmodifiableMap(validatedExtensions);\n}",
        "summary_tokens": [
            "an",
            "unmodifiable",
            "map",
            "consisting",
            "of",
            "the",
            "validated",
            "and",
            "recognized",
            "by",
            "the",
            "server",
            "extension",
            "names",
            "and",
            "values"
        ]
    },
    {
        "id": 1113,
        "code": "public Map<String, String> invalidExtensions() {\n    return Collections.unmodifiableMap(invalidExtensions);\n}",
        "summary_tokens": [
            "an",
            "immutable",
            "map",
            "consisting",
            "of",
            "the",
            "name",
            "gt",
            "error",
            "messages",
            "of",
            "extensions",
            "which",
            "failed",
            "validation"
        ]
    },
    {
        "id": 1114,
        "code": "public Map<String, String> ignoredExtensions() {\n    return Collections.unmodifiableMap(subtractMap(subtractMap(inputExtensions.map(), invalidExtensions), validatedExtensions));\n}",
        "summary_tokens": [
            "an",
            "immutable",
            "map",
            "consisting",
            "of",
            "the",
            "extensions",
            "that",
            "have",
            "neither",
            "been",
            "validated",
            "nor",
            "invalidated"
        ]
    },
    {
        "id": 1115,
        "code": "public void valid(String extensionName) {\n    if (!inputExtensions.map().containsKey(extensionName))\n        throw new IllegalArgumentException(String.format(\"Extension %s was not found in the original extensions\", extensionName));\n    validatedExtensions.put(extensionName, inputExtensions.map().get(extensionName));\n}",
        "summary_tokens": [
            "validates",
            "a",
            "specific",
            "extension",
            "in",
            "the",
            "original",
            "input",
            "extensions",
            "map",
            "extension",
            "name",
            "the",
            "name",
            "of",
            "the",
            "extension",
            "which",
            "was",
            "validated"
        ]
    },
    {
        "id": 1116,
        "code": "public void error(String invalidExtensionName, String errorMessage) {\n    if (Objects.requireNonNull(invalidExtensionName).isEmpty())\n        throw new IllegalArgumentException(\"extension name must not be empty\");\n    this.invalidExtensions.put(invalidExtensionName, errorMessage);\n}",
        "summary_tokens": [
            "set",
            "the",
            "error",
            "value",
            "for",
            "a",
            "specific",
            "extension",
            "key",
            "value",
            "pair",
            "if",
            "validation",
            "has",
            "failed"
        ]
    },
    {
        "id": 1117,
        "code": "private void identifyExtensions() throws LoginException {\n    SaslExtensionsCallback extensionsCallback = new SaslExtensionsCallback();\n    try {\n        callbackHandler.handle(new Callback[] {extensionsCallback});\n        extensionsRequiringCommit = extensionsCallback.extensions();\n    } catch (IOException e) {\n        log.error(e.getMessage(), e);\n        throw new LoginException(\"An internal error occurred while retrieving SASL extensions from callback handler\");\n    } catch (UnsupportedCallbackException e) {\n        extensionsRequiringCommit = EMPTY_EXTENSIONS;\n        log.debug(\"CallbackHandler {} does not support SASL extensions. No extensions will be added\", callbackHandler.getClass().getName());\n    }\n    if (extensionsRequiringCommit ==  null) {\n        log.error(\"SASL Extensions cannot be null. Check whether your callback handler is explicitly setting them as null.\");\n        throw new LoginException(\"Extensions cannot be null.\");\n    }\n}",
        "summary_tokens": [
            "attaches",
            "sasl",
            "extensions",
            "to",
            "the",
            "subject"
        ]
    },
    {
        "id": 1118,
        "code": "public OAuthBearerToken token() {\n    return token;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "token"
        ]
    },
    {
        "id": 1119,
        "code": "public String errorCode() {\n    return errorCode;\n}",
        "summary_tokens": [
            "return",
            "the",
            "optional",
            "but",
            "always",
            "non",
            "empty",
            "if",
            "not",
            "null",
            "error",
            "code",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1120,
        "code": "public String errorDescription() {\n    return errorDescription;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "error",
            "description",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1121,
        "code": "public String errorUri() {\n    return errorUri;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "error",
            "uri",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1122,
        "code": "public void error(String errorCode, String errorDescription, String errorUri) {\n    if (Objects.requireNonNull(errorCode).isEmpty())\n        throw new IllegalArgumentException(\"error code must not be empty\");\n    this.errorCode = errorCode;\n    this.errorDescription = errorDescription;\n    this.errorUri = errorUri;\n    this.token = null;\n}",
        "summary_tokens": [
            "set",
            "the",
            "error",
            "values",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1123,
        "code": "public String tokenValue() {\n    return tokenValue;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "token",
            "value"
        ]
    },
    {
        "id": 1124,
        "code": "public OAuthBearerToken token() {\n    return token;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "token"
        ]
    },
    {
        "id": 1125,
        "code": "public String errorStatus() {\n    return errorStatus;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "error",
            "status",
            "value",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1126,
        "code": "public String errorScope() {\n    return errorScope;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "error",
            "scope",
            "value",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1127,
        "code": "public String errorOpenIDConfiguration() {\n    return errorOpenIDConfiguration;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "error",
            "openid",
            "configuration",
            "value",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1128,
        "code": "public void error(String errorStatus, String errorScope, String errorOpenIDConfiguration) {\n    if (Objects.requireNonNull(errorStatus).isEmpty())\n        throw new IllegalArgumentException(\"error status must not be empty\");\n    this.errorStatus = errorStatus;\n    this.errorScope = errorScope;\n    this.errorOpenIDConfiguration = errorOpenIDConfiguration;\n    this.token = null;\n}",
        "summary_tokens": [
            "set",
            "the",
            "error",
            "values",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1129,
        "code": "public SaslExtensions extensions() {\n    return saslExtensions;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "extensions"
        ]
    },
    {
        "id": 1130,
        "code": "public String tokenValue() {\n    return tokenValue;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "token",
            "value"
        ]
    },
    {
        "id": 1131,
        "code": "public String authorizationId() {\n    return authorizationId;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "authorization",
            "id"
        ]
    },
    {
        "id": 1132,
        "code": "public static void validateExtensions(SaslExtensions extensions) throws SaslException {\n    if (extensions == null)\n        return;\n    if (extensions.map().containsKey(OAuthBearerClientInitialResponse.AUTH_KEY))\n        throw new SaslException(\"Extension name \" + OAuthBearerClientInitialResponse.AUTH_KEY + \" is invalid\");\n\n    for (Map.Entry<String, String> entry : extensions.map().entrySet()) {\n        String extensionName = entry.getKey();\n        String extensionValue = entry.getValue();\n\n        if (!EXTENSION_KEY_PATTERN.matcher(extensionName).matches())\n            throw new SaslException(\"Extension name \" + extensionName + \" is invalid\");\n        if (!EXTENSION_VALUE_PATTERN.matcher(extensionValue).matches())\n            throw new SaslException(\"Extension value (\" + extensionValue + \") for extension \" + extensionName + \" is invalid\");\n    }\n}",
        "summary_tokens": [
            "validates",
            "that",
            "the",
            "given",
            "extensions",
            "conform",
            "to",
            "the",
            "standard"
        ]
    },
    {
        "id": 1133,
        "code": "private String extensionsMessage() {\n    return Utils.mkString(saslExtensions.map(), \"\", \"\", \"=\", SEPARATOR);\n}",
        "summary_tokens": [
            "converts",
            "the",
            "saslextensions",
            "to",
            "an",
            "oauth",
            "protocol",
            "friendly",
            "string"
        ]
    },
    {
        "id": 1134,
        "code": "public boolean configured() {\n    return configured;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "instance",
            "has",
            "been",
            "configured",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 1135,
        "code": "private static void handleCallback(SaslExtensionsCallback extensionsCallback, Subject subject) {\n    if (subject != null && !subject.getPublicCredentials(SaslExtensions.class).isEmpty()) {\n        SaslExtensions extensions = subject.getPublicCredentials(SaslExtensions.class).iterator().next();\n        extensionsCallback.extensions(extensions);\n    }\n}",
        "summary_tokens": [
            "attaches",
            "the",
            "first",
            "sasl",
            "extensions",
            "found",
            "in",
            "the",
            "public",
            "credentials",
            "of",
            "the",
            "subject"
        ]
    },
    {
        "id": 1136,
        "code": "public byte[] evaluateResponse(byte[] response) throws SaslException, SaslAuthenticationException {\n    if (response.length == 1 && response[0] == OAuthBearerSaslClient.BYTE_CONTROL_A && errorMessage != null) {\n        log.debug(\"Received %x01 response from client after it received our error\");\n        throw new SaslAuthenticationException(errorMessage);\n    }\n    errorMessage = null;\n\n    OAuthBearerClientInitialResponse clientResponse;\n    try {\n        clientResponse = new OAuthBearerClientInitialResponse(response);\n    } catch (SaslException e) {\n        log.debug(e.getMessage());\n        throw e;\n    }\n\n    return process(clientResponse.tokenValue(), clientResponse.authorizationId(), clientResponse.extensions());\n}",
        "summary_tokens": [
            "sasl",
            "authentication",
            "exception",
            "if",
            "access",
            "token",
            "cannot",
            "be",
            "validated",
            "p",
            "b",
            "note",
            "b",
            "this",
            "method",
            "may",
            "throw",
            "sasl",
            "authentication",
            "exception",
            "to",
            "provide",
            "custom",
            "error",
            "messages",
            "to",
            "clients"
        ]
    },
    {
        "id": 1137,
        "code": "public double loginRefreshWindowFactor() {\n    return loginRefreshWindowFactor;\n}",
        "summary_tokens": [
            "background",
            "login",
            "refresh",
            "thread",
            "will",
            "sleep",
            "until",
            "the",
            "specified",
            "window",
            "factor",
            "relative",
            "to",
            "the",
            "credential",
            "s",
            "total",
            "lifetime",
            "has",
            "been",
            "reached",
            "at",
            "which",
            "time",
            "it",
            "will",
            "try",
            "to",
            "refresh",
            "the",
            "credential"
        ]
    },
    {
        "id": 1138,
        "code": "public double loginRefreshWindowJitter() {\n    return loginRefreshWindowJitter;\n}",
        "summary_tokens": [
            "amount",
            "of",
            "random",
            "jitter",
            "added",
            "to",
            "the",
            "background",
            "login",
            "refresh",
            "thread",
            "s",
            "sleep",
            "time"
        ]
    },
    {
        "id": 1139,
        "code": "public short loginRefreshMinPeriodSeconds() {\n    return loginRefreshMinPeriodSeconds;\n}",
        "summary_tokens": [
            "the",
            "desired",
            "minimum",
            "time",
            "between",
            "checks",
            "by",
            "the",
            "background",
            "login",
            "refresh",
            "thread",
            "in",
            "seconds"
        ]
    },
    {
        "id": 1140,
        "code": "public short loginRefreshBufferSeconds() {\n    return loginRefreshBufferSeconds;\n}",
        "summary_tokens": [
            "the",
            "amount",
            "of",
            "buffer",
            "time",
            "before",
            "expiration",
            "to",
            "maintain",
            "when",
            "refreshing"
        ]
    },
    {
        "id": 1141,
        "code": "public boolean loginRefreshReloginAllowedBeforeLogout() {\n    return loginRefreshReloginAllowedBeforeLogout;\n}",
        "summary_tokens": [
            "if",
            "the",
            "login",
            "module",
            "and",
            "sasl",
            "client",
            "implementations",
            "support",
            "multiple",
            "simultaneous",
            "login",
            "contexts",
            "on",
            "a",
            "single",
            "subject",
            "at",
            "the",
            "same",
            "time"
        ]
    },
    {
        "id": 1142,
        "code": "public LoginContext login() throws LoginException {\n    LoginContext tmpLoginContext = loginContextFactory.createLoginContext(this);\n    tmpLoginContext.login();\n    log.info(\"Successfully logged in.\");\n    loginContext = tmpLoginContext;\n    subject = loginContext.getSubject();\n    expiringCredential = expiringCredential();\n    hasExpiringCredential = expiringCredential != null;\n    if (!hasExpiringCredential) {\n            \n        log.debug(\"No Expiring Credential\");\n        principalName = null;\n        refresherThread = null;\n        return loginContext;\n    }\n\n    principalName = expiringCredential.principalName();\n\n        \n    long expireTimeMs = expiringCredential.expireTimeMs();\n    long nowMs = currentMs();\n    if (nowMs > expireTimeMs) {\n        log.error(\n                \"[Principal={}]: Current clock: {} is later than expiry {}. This may indicate a clock skew problem.\"\n                        + \" Check that this host's and remote host's clocks are in sync. Not starting refresh thread.\"\n                        + \" This process is likely unable to authenticate SASL connections (for example, it is unlikely\"\n                        + \" to be able to authenticate a connection with a Kafka Broker).\",\n                principalLogText(), new Date(nowMs), new Date(expireTimeMs));\n        return loginContext;\n    }\n\n    if (log.isDebugEnabled())\n        log.debug(\"[Principal={}]: It is an expiring credential\", principalLogText());\n\n        \n    refresherThread = KafkaThread.daemon(String.format(\"kafka-expiring-relogin-thread-%s\", principalName),\n            new Refresher());\n    refresherThread.start();\n    loginContextFactory.refresherThreadStarted();\n    return loginContext;\n}",
        "summary_tokens": [
            "performs",
            "login",
            "for",
            "each",
            "login",
            "module",
            "specified",
            "for",
            "the",
            "login",
            "context",
            "of",
            "this",
            "instance",
            "and",
            "starts",
            "the",
            "thread",
            "used",
            "to",
            "periodically",
            "re",
            "login"
        ]
    },
    {
        "id": 1143,
        "code": "private Long refreshMs(long relativeToMs) {\n    if (expiringCredential == null) {\n            \n        long retvalNextRefreshMs = relativeToMs + DELAY_SECONDS_BEFORE_NEXT_RETRY_WHEN_RELOGIN_FAILS * 1000L;\n        log.warn(\"[Principal={}]: No Expiring credential found: will try again at {}\", principalLogText(),\n                new Date(retvalNextRefreshMs));\n        return retvalNextRefreshMs;\n    }\n    long expireTimeMs = expiringCredential.expireTimeMs();\n    if (relativeToMs > expireTimeMs) {\n        boolean logoutRequiredBeforeLoggingBackIn = isLogoutRequiredBeforeLoggingBackIn();\n        if (logoutRequiredBeforeLoggingBackIn) {\n            log.error(\n                    \"[Principal={}]: Current clock: {} is later than expiry {}. This may indicate a clock skew problem.\"\n                            + \" Check that this host's and remote host's clocks are in sync. Exiting refresh thread.\",\n                    principalLogText(), new Date(relativeToMs), new Date(expireTimeMs));\n            return null;\n        } else {\n                \n            long retvalNextRefreshMs = relativeToMs + DELAY_SECONDS_BEFORE_NEXT_RETRY_WHEN_RELOGIN_FAILS * 1000L;\n            log.warn(\"[Principal={}]: Expiring credential already expired at {}: will try to refresh again at {}\",\n                    principalLogText(), new Date(expireTimeMs), new Date(retvalNextRefreshMs));\n            return retvalNextRefreshMs;\n        }\n    }\n    Long absoluteLastRefreshTimeMs = expiringCredential.absoluteLastRefreshTimeMs();\n    if (absoluteLastRefreshTimeMs != null && absoluteLastRefreshTimeMs.longValue() < expireTimeMs) {\n        log.warn(\"[Principal={}]: Expiring credential refresh thread exiting because the\"\n                + \" expiring credential's current expiration time ({}) exceeds the latest possible refresh time ({}).\"\n                + \" This process will not be able to authenticate new SASL connections after that\"\n                + \" time (for example, it will not be able to authenticate a new connection with a Kafka Broker).\",\n                principalLogText(), new Date(expireTimeMs), new Date(absoluteLastRefreshTimeMs.longValue()));\n        return null;\n    }\n    Long optionalStartTime = expiringCredential.startTimeMs();\n    long startMs = optionalStartTime != null ? optionalStartTime.longValue() : relativeToMs;\n    log.info(\"[Principal={}]: Expiring credential valid from {} to {}\", expiringCredential.principalName(),\n            new java.util.Date(startMs), new java.util.Date(expireTimeMs));\n\n    double pct = expiringCredentialRefreshConfig.loginRefreshWindowFactor()\n            + (expiringCredentialRefreshConfig.loginRefreshWindowJitter() * RNG.nextDouble());\n        \n    long refreshMinPeriodSeconds = expiringCredentialRefreshConfig.loginRefreshMinPeriodSeconds();\n    long clientRefreshBufferSeconds = expiringCredentialRefreshConfig.loginRefreshBufferSeconds();\n    if (relativeToMs + 1000L * (refreshMinPeriodSeconds + clientRefreshBufferSeconds) > expireTimeMs) {\n        long retvalRefreshMs = relativeToMs + (long) ((expireTimeMs - relativeToMs) * pct);\n        log.warn(\n                \"[Principal={}]: Expiring credential expires at {}, so buffer times of {} and {} seconds\"\n                        + \" at the front and back, respectively, cannot be accommodated.  We will refresh at {}.\",\n                principalLogText(), new Date(expireTimeMs), refreshMinPeriodSeconds, clientRefreshBufferSeconds,\n                new Date(retvalRefreshMs));\n        return retvalRefreshMs;\n    }\n    long proposedRefreshMs = startMs + (long) ((expireTimeMs - startMs) * pct);\n        \n    long beginningOfEndBufferTimeMs = expireTimeMs - clientRefreshBufferSeconds * 1000;\n    if (proposedRefreshMs > beginningOfEndBufferTimeMs) {\n        log.info(\n                \"[Principal={}]: Proposed refresh time of {} extends into the desired buffer time of {} seconds before expiration, so refresh it at the desired buffer begin point, at {}\",\n                expiringCredential.principalName(), new Date(proposedRefreshMs), clientRefreshBufferSeconds,\n                new Date(beginningOfEndBufferTimeMs));\n        return beginningOfEndBufferTimeMs;\n    }\n        \n    long endOfMinRefreshBufferTime = relativeToMs + 1000 * refreshMinPeriodSeconds;\n    if (proposedRefreshMs < endOfMinRefreshBufferTime) {\n        log.info(\n                \"[Principal={}]: Expiring credential re-login thread time adjusted from {} to {} since the former is sooner \"\n                        + \"than the minimum refresh interval ({} seconds from now).\",\n                principalLogText(), new Date(proposedRefreshMs), new Date(endOfMinRefreshBufferTime),\n                refreshMinPeriodSeconds);\n        return endOfMinRefreshBufferTime;\n    }\n        \n    return proposedRefreshMs;\n}",
        "summary_tokens": [
            "determine",
            "when",
            "to",
            "sleep",
            "until",
            "before",
            "performing",
            "a",
            "refresh"
        ]
    },
    {
        "id": 1144,
        "code": "public OAuthBearerValidationResult reason() {\n    return reason;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "reason",
            "for",
            "the",
            "validation",
            "failure"
        ]
    },
    {
        "id": 1145,
        "code": "public static boolean isValidScopeItem(String scopeItem) {\n    return INDIVIDUAL_SCOPE_ITEM_PATTERN.matcher(Objects.requireNonNull(scopeItem)).matches();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "given",
            "value",
            "meets",
            "the",
            "definition",
            "of",
            "a",
            "valid",
            "scope",
            "item",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1146,
        "code": "public static List<String> parseScope(String spaceDelimitedScope) throws OAuthBearerConfigException {\n    List<String> retval = new ArrayList<>();\n    for (String individualScopeItem : Objects.requireNonNull(spaceDelimitedScope).split(\" \")) {\n        if (!individualScopeItem.isEmpty()) {\n            if (!isValidScopeItem(individualScopeItem))\n                throw new OAuthBearerConfigException(String.format(\"Invalid scope value: %s\", individualScopeItem));\n            retval.add(individualScopeItem);\n        }\n    }\n    return Collections.unmodifiableList(retval);\n}",
        "summary_tokens": [
            "convert",
            "a",
            "space",
            "delimited",
            "list",
            "of",
            "scope",
            "values",
            "for",
            "example",
            "code",
            "scope",
            "0",
            "scope",
            "0",
            "code",
            "to",
            "a",
            "list",
            "containing",
            "the",
            "individual",
            "elements",
            "code",
            "scope",
            "0",
            "code",
            "and",
            "code",
            "scope",
            "0",
            "code"
        ]
    },
    {
        "id": 1147,
        "code": "public List<String> splits() {\n    return splits;\n}",
        "summary_tokens": [
            "return",
            "the",
            "0",
            "or",
            "0",
            "dot",
            "separated",
            "sections",
            "of",
            "the",
            "jwt",
            "compact",
            "serialization"
        ]
    },
    {
        "id": 1148,
        "code": "public Map<String, Object> header() {\n    return header;\n}",
        "summary_tokens": [
            "return",
            "the",
            "jose",
            "header",
            "as",
            "a",
            "map"
        ]
    },
    {
        "id": 1149,
        "code": "public Map<String, Object> claims() {\n    return claims;\n}",
        "summary_tokens": [
            "return",
            "the",
            "jwt",
            "claim",
            "set",
            "as",
            "a",
            "map"
        ]
    },
    {
        "id": 1150,
        "code": "public String principalClaimName() {\n    return principalClaimName;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "non",
            "empty",
            "principal",
            "claim",
            "name"
        ]
    },
    {
        "id": 1151,
        "code": "public String scopeClaimName() {\n    return scopeClaimName;\n}",
        "summary_tokens": [
            "return",
            "the",
            "always",
            "non",
            "null",
            "non",
            "empty",
            "scope",
            "claim",
            "name"
        ]
    },
    {
        "id": 1152,
        "code": "public boolean isClaimType(String claimName, Class<?> type) {\n    Object value = rawClaim(claimName);\n    Objects.requireNonNull(type);\n    if (value == null)\n        return false;\n    if (type == String.class && value instanceof String)\n        return true;\n    if (type == Number.class && value instanceof Number)\n        return true;\n    return type == List.class && value instanceof List;\n}",
        "summary_tokens": [
            "indicate",
            "if",
            "the",
            "claim",
            "exists",
            "and",
            "is",
            "the",
            "given",
            "type"
        ]
    },
    {
        "id": 1153,
        "code": "public <T> T claim(String claimName, Class<T> type) throws OAuthBearerIllegalTokenException {\n    Object value = rawClaim(claimName);\n    try {\n        return Objects.requireNonNull(type).cast(value);\n    } catch (ClassCastException e) {\n        throw new OAuthBearerIllegalTokenException(\n                OAuthBearerValidationResult.newFailure(String.format(\"The '%s' claim was not of type %s: %s\",\n                        claimName, type.getSimpleName(), value.getClass().getSimpleName())));\n    }\n}",
        "summary_tokens": [
            "extract",
            "a",
            "claim",
            "of",
            "the",
            "given",
            "type"
        ]
    },
    {
        "id": 1154,
        "code": "public Object rawClaim(String claimName) {\n    return claims().get(Objects.requireNonNull(claimName));\n}",
        "summary_tokens": [
            "extract",
            "a",
            "claim",
            "in",
            "its",
            "raw",
            "form"
        ]
    },
    {
        "id": 1155,
        "code": "public Number expirationTime() throws OAuthBearerIllegalTokenException {\n    return claim(\"exp\", Number.class);\n}",
        "summary_tokens": [
            "return",
            "the",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1156,
        "code": "public Number issuedAt() throws OAuthBearerIllegalTokenException {\n    return claim(\"iat\", Number.class);\n}",
        "summary_tokens": [
            "return",
            "the",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1157,
        "code": "public String subject() throws OAuthBearerIllegalTokenException {\n    return claim(\"sub\", String.class);\n}",
        "summary_tokens": [
            "return",
            "the",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1158,
        "code": "public static Map<String, Object> toMap(String split) throws OAuthBearerIllegalTokenException {\n    Map<String, Object> retval = new HashMap<>();\n    try {\n        byte[] decode = Base64.getDecoder().decode(split);\n        JsonNode jsonNode = new ObjectMapper().readTree(decode);\n        if (jsonNode == null)\n            throw new OAuthBearerIllegalTokenException(OAuthBearerValidationResult.newFailure(\"malformed JSON\"));\n        for (Iterator<Entry<String, JsonNode>> iterator = jsonNode.fields(); iterator.hasNext();) {\n            Entry<String, JsonNode> entry = iterator.next();\n            retval.put(entry.getKey(), convert(entry.getValue()));\n        }\n        return Collections.unmodifiableMap(retval);\n    } catch (IllegalArgumentException e) {\n            \n        throw new OAuthBearerIllegalTokenException(\n                OAuthBearerValidationResult.newFailure(\"malformed Base64 URL encoded value\"));\n    } catch (IOException e) {\n        throw new OAuthBearerIllegalTokenException(OAuthBearerValidationResult.newFailure(\"malformed JSON\"));\n    }\n}",
        "summary_tokens": [
            "decode",
            "the",
            "given",
            "base",
            "0",
            "url",
            "encoded",
            "value",
            "parse",
            "the",
            "resulting",
            "json",
            "as",
            "a",
            "json",
            "object",
            "and",
            "return",
            "the",
            "map",
            "of",
            "member",
            "names",
            "to",
            "their",
            "values",
            "each",
            "value",
            "being",
            "represented",
            "as",
            "either",
            "a",
            "string",
            "a",
            "number",
            "or",
            "a",
            "list",
            "of",
            "strings"
        ]
    },
    {
        "id": 1159,
        "code": "public boolean configured() {\n    return configured;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "instance",
            "has",
            "been",
            "configured",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 1160,
        "code": "private void handleExtensionsCallback(SaslExtensionsCallback callback) {\n    Map<String, String> extensions = new HashMap<>();\n    for (Map.Entry<String, String> configEntry : this.moduleOptions.entrySet()) {\n        String key = configEntry.getKey();\n        if (!key.startsWith(EXTENSION_PREFIX))\n            continue;\n\n        extensions.put(key.substring(EXTENSION_PREFIX.length()), configEntry.getValue());\n    }\n\n    SaslExtensions saslExtensions = new SaslExtensions(extensions);\n    try {\n        OAuthBearerClientInitialResponse.validateExtensions(saslExtensions);\n    } catch (SaslException e) {\n        throw new ConfigException(e.getMessage());\n    }\n\n    callback.extensions(saslExtensions);\n}",
        "summary_tokens": [
            "add",
            "and",
            "validate",
            "all",
            "the",
            "configured",
            "extensions"
        ]
    },
    {
        "id": 1161,
        "code": "public boolean configured() {\n    return configured;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "instance",
            "has",
            "been",
            "configured",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 1162,
        "code": "public static OAuthBearerValidationResult newSuccess() {\n    return new OAuthBearerValidationResult(true, null, null, null);\n}",
        "summary_tokens": [
            "return",
            "an",
            "instance",
            "indicating",
            "success"
        ]
    },
    {
        "id": 1163,
        "code": "public static OAuthBearerValidationResult newFailure(String failureDescription, String failureScope,\n        String failureOpenIdConfig) {\n    return new OAuthBearerValidationResult(false, failureDescription, failureScope, failureOpenIdConfig);\n}",
        "summary_tokens": [
            "return",
            "a",
            "new",
            "validation",
            "failure",
            "instance"
        ]
    },
    {
        "id": 1164,
        "code": "public boolean success() {\n    return success;\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "this",
            "instance",
            "indicates",
            "success",
            "otherwise",
            "false"
        ]
    },
    {
        "id": 1165,
        "code": "public String failureDescription() {\n    return failureDescription;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "descriptive",
            "message",
            "for",
            "the",
            "failure"
        ]
    },
    {
        "id": 1166,
        "code": "public String failureScope() {\n    return failureScope;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "scope",
            "to",
            "be",
            "reported",
            "with",
            "the",
            "failure"
        ]
    },
    {
        "id": 1167,
        "code": "public String failureOpenIdConfig() {\n    return failureOpenIdConfig;\n}",
        "summary_tokens": [
            "return",
            "the",
            "potentially",
            "null",
            "open",
            "id",
            "connect",
            "configuration",
            "to",
            "be",
            "reported",
            "with",
            "the",
            "failure"
        ]
    },
    {
        "id": 1168,
        "code": "public void throwExceptionIfFailed() throws OAuthBearerIllegalTokenException {\n    if (!success())\n        throw new OAuthBearerIllegalTokenException(this);\n}",
        "summary_tokens": [
            "raise",
            "an",
            "exception",
            "if",
            "this",
            "instance",
            "indicates",
            "failure",
            "otherwise",
            "do",
            "nothing"
        ]
    },
    {
        "id": 1169,
        "code": "public static OAuthBearerValidationResult validateClaimForExistenceAndType(OAuthBearerUnsecuredJws jwt,\n        boolean required, String claimName, Class<?>... allowedTypes) {\n    Object rawClaim = Objects.requireNonNull(jwt).rawClaim(Objects.requireNonNull(claimName));\n    if (rawClaim == null)\n        return required\n                ? OAuthBearerValidationResult.newFailure(String.format(\"Required claim missing: %s\", claimName))\n                : OAuthBearerValidationResult.newSuccess();\n    for (Class<?> allowedType : allowedTypes) {\n        if (allowedType != null && allowedType.isAssignableFrom(rawClaim.getClass()))\n            return OAuthBearerValidationResult.newSuccess();\n    }\n    return OAuthBearerValidationResult.newFailure(String.format(\"The %s claim had the incorrect type: %s\",\n            claimName, rawClaim.getClass().getSimpleName()));\n}",
        "summary_tokens": [
            "validate",
            "the",
            "given",
            "claim",
            "for",
            "existence",
            "and",
            "type"
        ]
    },
    {
        "id": 1170,
        "code": "public static OAuthBearerValidationResult validateIssuedAt(OAuthBearerUnsecuredJws jwt, boolean required,\n        long whenCheckTimeMs, int allowableClockSkewMs) throws OAuthBearerConfigException {\n    Number value;\n    try {\n        value = Objects.requireNonNull(jwt).issuedAt();\n    } catch (OAuthBearerIllegalTokenException e) {\n        return e.reason();\n    }\n    boolean exists = value != null;\n    if (!exists)\n        return doesNotExistResult(required, \"iat\");\n    double doubleValue = value.doubleValue();\n    return 1000 * doubleValue > whenCheckTimeMs + confirmNonNegative(allowableClockSkewMs)\n            ? OAuthBearerValidationResult.newFailure(String.format(\n                    \"The Issued At value (%f seconds) was after the indicated time (%d ms) plus allowable clock skew (%d ms)\",\n                    doubleValue, whenCheckTimeMs, allowableClockSkewMs))\n            : OAuthBearerValidationResult.newSuccess();\n}",
        "summary_tokens": [
            "validate",
            "the",
            "iat",
            "issued",
            "at",
            "claim"
        ]
    },
    {
        "id": 1171,
        "code": "public static OAuthBearerValidationResult validateExpirationTime(OAuthBearerUnsecuredJws jwt, long whenCheckTimeMs,\n        int allowableClockSkewMs) throws OAuthBearerConfigException {\n    Number value;\n    try {\n        value = Objects.requireNonNull(jwt).expirationTime();\n    } catch (OAuthBearerIllegalTokenException e) {\n        return e.reason();\n    }\n    boolean exists = value != null;\n    if (!exists)\n        return doesNotExistResult(true, \"exp\");\n    double doubleValue = value.doubleValue();\n    return whenCheckTimeMs - confirmNonNegative(allowableClockSkewMs) >= 1000 * doubleValue\n            ? OAuthBearerValidationResult.newFailure(String.format(\n                    \"The indicated time (%d ms) minus allowable clock skew (%d ms) was on or after the Expiration Time value (%f seconds)\",\n                    whenCheckTimeMs, allowableClockSkewMs, doubleValue))\n            : OAuthBearerValidationResult.newSuccess();\n}",
        "summary_tokens": [
            "validate",
            "the",
            "exp",
            "expiration",
            "time",
            "claim"
        ]
    },
    {
        "id": 1172,
        "code": "public static OAuthBearerValidationResult validateTimeConsistency(OAuthBearerUnsecuredJws jwt) {\n    Number issuedAt;\n    Number expirationTime;\n    try {\n        issuedAt = Objects.requireNonNull(jwt).issuedAt();\n        expirationTime = jwt.expirationTime();\n    } catch (OAuthBearerIllegalTokenException e) {\n        return e.reason();\n    }\n    if (expirationTime != null && issuedAt != null && expirationTime.doubleValue() <= issuedAt.doubleValue())\n        return OAuthBearerValidationResult.newFailure(\n                String.format(\"The Expiration Time time (%f seconds) was not after the Issued At time (%f seconds)\",\n                        expirationTime.doubleValue(), issuedAt.doubleValue()));\n    return OAuthBearerValidationResult.newSuccess();\n}",
        "summary_tokens": [
            "validate",
            "the",
            "iat",
            "issued",
            "at",
            "and",
            "exp",
            "expiration",
            "time",
            "claims",
            "for",
            "internal",
            "consistency"
        ]
    },
    {
        "id": 1173,
        "code": "public static OAuthBearerValidationResult validateScope(OAuthBearerToken token, List<String> requiredScope) {\n    final Set<String> tokenScope = token.scope();\n    if (requiredScope == null || requiredScope.isEmpty())\n        return OAuthBearerValidationResult.newSuccess();\n    for (String requiredScopeElement : requiredScope) {\n        if (!tokenScope.contains(requiredScopeElement))\n            return OAuthBearerValidationResult.newFailure(String.format(\n                    \"The provided scope (%s) was mising a required scope (%s).  All required scope elements: %s\",\n                    String.valueOf(tokenScope), requiredScopeElement, requiredScope.toString()),\n                    requiredScope.toString(), null);\n    }\n    return OAuthBearerValidationResult.newSuccess();\n}",
        "summary_tokens": [
            "validate",
            "the",
            "given",
            "token",
            "s",
            "scope",
            "against",
            "the",
            "required",
            "scope"
        ]
    },
    {
        "id": 1174,
        "code": "default void close() throws IOException {\n        \n}",
        "summary_tokens": [
            "lifecycle",
            "method",
            "to",
            "perform",
            "a",
            "clean",
            "shutdown",
            "of",
            "the",
            "retriever"
        ]
    },
    {
        "id": 1175,
        "code": "public static AccessTokenRetriever create(Map<String, ?> configs, Map<String, Object> jaasConfig) {\n    return create(configs, null, jaasConfig);\n}",
        "summary_tokens": [
            "create",
            "an",
            "access",
            "token",
            "retriever",
            "from",
            "the",
            "given",
            "sasl",
            "and",
            "jaas",
            "configuration"
        ]
    },
    {
        "id": 1176,
        "code": "public String value() {\n    return token;\n}",
        "summary_tokens": [
            "the",
            "code",
            "b",
            "0",
            "token",
            "code",
            "value",
            "as",
            "defined",
            "in",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1177,
        "code": "public Set<String> scope() {\n        \n        \n    return scopes;\n}",
        "summary_tokens": [
            "the",
            "token",
            "s",
            "scope",
            "of",
            "access",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1178,
        "code": "public long lifetimeMs() {\n    return lifetimeMs;\n}",
        "summary_tokens": [
            "the",
            "token",
            "s",
            "lifetime",
            "expressed",
            "as",
            "the",
            "number",
            "of",
            "milliseconds",
            "since",
            "the",
            "epoch",
            "as",
            "per",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1179,
        "code": "public String principalName() {\n    return principalName;\n}",
        "summary_tokens": [
            "the",
            "name",
            "of",
            "the",
            "principal",
            "to",
            "which",
            "this",
            "credential",
            "applies"
        ]
    },
    {
        "id": 1180,
        "code": "public Long startTimeMs() {\n    return startTimeMs;\n}",
        "summary_tokens": [
            "when",
            "the",
            "credential",
            "became",
            "valid",
            "in",
            "terms",
            "of",
            "the",
            "number",
            "of",
            "milliseconds",
            "since",
            "the",
            "epoch",
            "if",
            "known",
            "otherwise",
            "null"
        ]
    },
    {
        "id": 1181,
        "code": "public static Set<String> validateScopes(String scopeClaimName, Collection<String> scopes) throws ValidateException {\n    if (scopes == null)\n        throw new ValidateException(String.format(\"%s value must be non-null\", scopeClaimName));\n\n    Set<String> copy = new HashSet<>();\n\n    for (String scope : scopes) {\n        scope = validateString(scopeClaimName, scope);\n\n        if (copy.contains(scope))\n            throw new ValidateException(String.format(\"%s value must not contain duplicates - %s already present\", scopeClaimName, scope));\n\n        copy.add(scope);\n    }\n\n    return Collections.unmodifiableSet(copy);\n}",
        "summary_tokens": [
            "validates",
            "that",
            "the",
            "scopes",
            "are",
            "valid",
            "where",
            "i",
            "invalid",
            "i",
            "means",
            "i",
            "any",
            "i",
            "of",
            "the",
            "following"
        ]
    },
    {
        "id": 1182,
        "code": "public static long validateExpiration(String claimName, Long claimValue) throws ValidateException {\n    if (claimValue == null)\n        throw new ValidateException(String.format(\"%s value must be non-null\", claimName));\n\n    if (claimValue < 0)\n        throw new ValidateException(String.format(\"%s value must be non-negative; value given was \\\"%s\\\"\", claimName, claimValue));\n\n    return claimValue;\n}",
        "summary_tokens": [
            "validates",
            "that",
            "the",
            "given",
            "lifetime",
            "is",
            "valid",
            "where",
            "i",
            "invalid",
            "i",
            "means",
            "i",
            "any",
            "i",
            "of",
            "the",
            "following"
        ]
    },
    {
        "id": 1183,
        "code": "public static String validateSubject(String claimName, String claimValue) throws ValidateException {\n    return validateString(claimName, claimValue);\n}",
        "summary_tokens": [
            "validates",
            "that",
            "the",
            "given",
            "claim",
            "value",
            "is",
            "valid",
            "where",
            "i",
            "invalid",
            "i",
            "means",
            "i",
            "any",
            "i",
            "of",
            "the",
            "following"
        ]
    },
    {
        "id": 1184,
        "code": "public static Long validateIssuedAt(String claimName, Long claimValue) throws ValidateException {\n    if (claimValue != null && claimValue < 0)\n        throw new ValidateException(String.format(\"%s value must be null or non-negative; value given was \\\"%s\\\"\", claimName, claimValue));\n\n    return claimValue;\n}",
        "summary_tokens": [
            "validates",
            "that",
            "the",
            "given",
            "issued",
            "at",
            "claim",
            "name",
            "is",
            "valid",
            "where",
            "i",
            "invalid",
            "i",
            "means",
            "i",
            "any",
            "i",
            "of",
            "the",
            "following"
        ]
    },
    {
        "id": 1185,
        "code": "public static String validateClaimNameOverride(String name, String value) throws ValidateException {\n    return validateString(name, value);\n}",
        "summary_tokens": [
            "validates",
            "that",
            "the",
            "given",
            "claim",
            "name",
            "override",
            "is",
            "valid",
            "where",
            "i",
            "invalid",
            "i",
            "means",
            "i",
            "any",
            "i",
            "of",
            "the",
            "following"
        ]
    },
    {
        "id": 1186,
        "code": "default void close() throws IOException {\n        \n}",
        "summary_tokens": [
            "lifecycle",
            "method",
            "to",
            "perform",
            "a",
            "clean",
            "shutdown",
            "of",
            "the",
            "verification",
            "key",
            "resolver"
        ]
    },
    {
        "id": 1187,
        "code": "public Path validateFile(String name) {\n    URL url = validateUrl(name);\n    File file;\n\n    try {\n        file = new File(url.toURI().getRawPath()).getAbsoluteFile();\n    } catch (URISyntaxException e) {\n        throw new ConfigException(name, url.toString(), String.format(\"The OAuth configuration option %s contains a URL (%s) that is malformed: %s\", name, url, e.getMessage()));\n    }\n\n    if (!file.exists())\n        throw new ConfigException(name, file, String.format(\"The OAuth configuration option %s contains a file (%s) that doesn't exist\", name, file));\n\n    if (!file.canRead())\n        throw new ConfigException(name, file, String.format(\"The OAuth configuration option %s contains a file (%s) that doesn't have read permission\", name, file));\n\n    if (file.isDirectory())\n        throw new ConfigException(name, file, String.format(\"The OAuth configuration option %s references a directory (%s), not a file\", name, file));\n\n    return file.toPath();\n}",
        "summary_tokens": [
            "validates",
            "that",
            "if",
            "a",
            "value",
            "is",
            "supplied",
            "is",
            "a",
            "file",
            "that"
        ]
    },
    {
        "id": 1188,
        "code": "public Integer validateInteger(String name, boolean isRequired) {\n    Integer value = get(name);\n\n    if (value == null) {\n        if (isRequired)\n            throw new ConfigException(name, null, String.format(\"The OAuth configuration option %s must be non-null\", name));\n        else\n            return null;\n    }\n\n    return value;\n}",
        "summary_tokens": [
            "validates",
            "that",
            "if",
            "a",
            "value",
            "is",
            "supplied",
            "is",
            "a",
            "value",
            "that"
        ]
    },
    {
        "id": 1189,
        "code": "public Long validateLong(String name) {\n    return validateLong(name, true);\n}",
        "summary_tokens": [
            "validates",
            "that",
            "if",
            "a",
            "value",
            "is",
            "supplied",
            "is",
            "a",
            "value",
            "that"
        ]
    },
    {
        "id": 1190,
        "code": "public URL validateUrl(String name) {\n    String value = validateString(name);\n    URL url;\n\n    try {\n        url = new URL(value);\n    } catch (MalformedURLException e) {\n        throw new ConfigException(name, value, String.format(\"The OAuth configuration option %s contains a URL (%s) that is malformed: %s\", name, value, e.getMessage()));\n    }\n\n    String protocol = url.getProtocol();\n\n    if (protocol == null || protocol.trim().isEmpty())\n        throw new ConfigException(name, value, String.format(\"The OAuth configuration option %s contains a URL (%s) that is missing the protocol\", name, value));\n\n    protocol = protocol.toLowerCase(Locale.ROOT);\n\n    if (!(protocol.equals(\"http\") || protocol.equals(\"https\") || protocol.equals(\"file\")))\n        throw new ConfigException(name, value, String.format(\"The OAuth configuration option %s contains a URL (%s) that contains an invalid protocol (%s); only \\\"http\\\", \\\"https\\\", and \\\"file\\\" protocol are supported\", name, value, protocol));\n\n    return url;\n}",
        "summary_tokens": [
            "validates",
            "that",
            "the",
            "configured",
            "url",
            "that"
        ]
    },
    {
        "id": 1191,
        "code": "public String retrieve() throws IOException {\n    String authorizationHeader = formatAuthorizationHeader(clientId, clientSecret);\n    String requestBody = formatRequestBody(scope);\n    Retry<String> retry = new Retry<>(loginRetryBackoffMs, loginRetryBackoffMaxMs);\n    Map<String, String> headers = Collections.singletonMap(AUTHORIZATION_HEADER, authorizationHeader);\n\n    String responseBody;\n\n    try {\n        responseBody = retry.execute(() -> {\n            HttpURLConnection con = null;\n\n            try {\n                con = (HttpURLConnection) new URL(tokenEndpointUrl).openConnection();\n\n                if (sslSocketFactory != null && con instanceof HttpsURLConnection)\n                    ((HttpsURLConnection) con).setSSLSocketFactory(sslSocketFactory);\n\n                return post(con, headers, requestBody, loginConnectTimeoutMs, loginReadTimeoutMs);\n            } catch (IOException e) {\n                throw new ExecutionException(e);\n            } finally {\n                if (con != null)\n                    con.disconnect();\n            }\n        });\n    } catch (ExecutionException e) {\n        if (e.getCause() instanceof IOException)\n            throw (IOException) e.getCause();\n        else\n            throw new KafkaException(e.getCause());\n    }\n\n    return parseAccessToken(responseBody);\n}",
        "summary_tokens": [
            "retrieves",
            "a",
            "jwt",
            "access",
            "token",
            "in",
            "its",
            "serialized",
            "three",
            "part",
            "form"
        ]
    },
    {
        "id": 1192,
        "code": "default void init() throws IOException {\n        \n}",
        "summary_tokens": [
            "lifecycle",
            "method",
            "to",
            "perform",
            "any",
            "one",
            "time",
            "initialization",
            "of",
            "the",
            "retriever"
        ]
    },
    {
        "id": 1193,
        "code": "public OAuthBearerToken validate(String accessToken) throws ValidateException {\n    SerializedJwt serializedJwt = new SerializedJwt(accessToken);\n    Map<String, Object> payload;\n\n    try {\n        payload = OAuthBearerUnsecuredJws.toMap(serializedJwt.getPayload());\n    } catch (OAuthBearerIllegalTokenException e) {\n        throw new ValidateException(String.format(\"Could not validate the access token: %s\", e.getMessage()), e);\n    }\n\n    Object scopeRaw = getClaim(payload, scopeClaimName);\n    Collection<String> scopeRawCollection;\n\n    if (scopeRaw instanceof String)\n        scopeRawCollection = Collections.singletonList((String) scopeRaw);\n    else if (scopeRaw instanceof Collection)\n        scopeRawCollection = (Collection<String>) scopeRaw;\n    else\n        scopeRawCollection = Collections.emptySet();\n\n    Number expirationRaw = (Number) getClaim(payload, EXPIRATION_CLAIM_NAME);\n    String subRaw = (String) getClaim(payload, subClaimName);\n    Number issuedAtRaw = (Number) getClaim(payload, ISSUED_AT_CLAIM_NAME);\n\n    Set<String> scopes = ClaimValidationUtils.validateScopes(scopeClaimName, scopeRawCollection);\n    long expiration = ClaimValidationUtils.validateExpiration(EXPIRATION_CLAIM_NAME,\n        expirationRaw != null ? expirationRaw.longValue() * 1000L : null);\n    String subject = ClaimValidationUtils.validateSubject(subClaimName, subRaw);\n    Long issuedAt = ClaimValidationUtils.validateIssuedAt(ISSUED_AT_CLAIM_NAME,\n        issuedAtRaw != null ? issuedAtRaw.longValue() * 1000L : null);\n\n    OAuthBearerToken token = new BasicOAuthBearerToken(accessToken,\n        scopes,\n        expiration,\n        subject,\n        issuedAt);\n\n    return token;\n}",
        "summary_tokens": [
            "accepts",
            "an",
            "oauth",
            "jwt",
            "access",
            "token",
            "in",
            "base",
            "0",
            "encoded",
            "format",
            "validates",
            "and",
            "returns",
            "an",
            "oauth",
            "bearer",
            "token"
        ]
    },
    {
        "id": 1194,
        "code": "public List<JsonWebKey> getJsonWebKeys() throws JoseException, IOException {\n    if (!isInitialized)\n        throw new IllegalStateException(\"Please call init() first\");\n\n    try {\n        refreshLock.readLock().lock();\n        return jsonWebKeys;\n    } finally {\n        refreshLock.readLock().unlock();\n    }\n}",
        "summary_tokens": [
            "our",
            "implementation",
            "avoids",
            "the",
            "blocking",
            "call",
            "within",
            "https",
            "jwks",
            "refresh",
            "that",
            "is",
            "sometimes",
            "called",
            "internal",
            "to",
            "https",
            "jwks",
            "get",
            "json",
            "web",
            "keys"
        ]
    },
    {
        "id": 1195,
        "code": "private void refresh() {\n    if (!refreshInProgressFlag.compareAndSet(false, true)) {\n        log.debug(\"OAuth JWKS refresh is already in progress; ignoring concurrent refresh\");\n        return;\n    }\n\n    try {\n        log.info(\"OAuth JWKS refresh of {} starting\", httpsJwks.getLocation());\n        Retry<List<JsonWebKey>> retry = new Retry<>(refreshRetryBackoffMs, refreshRetryBackoffMaxMs);\n        List<JsonWebKey> localJWKs = retry.execute(() -> {\n            try {\n                log.debug(\"JWKS validation key calling refresh of {} starting\", httpsJwks.getLocation());\n                    \n                    \n                httpsJwks.refresh();\n                List<JsonWebKey> jwks = httpsJwks.getJsonWebKeys();\n                log.debug(\"JWKS validation key refresh of {} complete\", httpsJwks.getLocation());\n                return jwks;\n            } catch (Exception e) {\n                throw new ExecutionException(e);\n            }\n        });\n\n        try {\n            refreshLock.writeLock().lock();\n\n            for (JsonWebKey jwk : localJWKs)\n                missingKeyIds.remove(jwk.getKeyId());\n\n            jsonWebKeys = Collections.unmodifiableList(localJWKs);\n        } finally {\n            refreshLock.writeLock().unlock();\n        }\n\n        log.info(\"OAuth JWKS refresh of {} complete\", httpsJwks.getLocation());\n    } catch (ExecutionException e) {\n        log.warn(\"OAuth JWKS refresh of {} encountered an error; not updating local JWKS cache\", httpsJwks.getLocation(), e);\n    } finally {\n        refreshInProgressFlag.set(false);\n    }\n}",
        "summary_tokens": [
            "p",
            "code",
            "refresh",
            "code",
            "is",
            "an",
            "internal",
            "method",
            "that",
            "will",
            "refresh",
            "the",
            "jwks",
            "cache",
            "and",
            "is",
            "invoked",
            "in",
            "one",
            "of",
            "two",
            "ways"
        ]
    },
    {
        "id": 1196,
        "code": "public boolean maybeExpediteRefresh(String keyId) {\n    if (keyId.length() > MISSING_KEY_ID_MAX_KEY_LENGTH) {\n            \n            \n            \n            \n            \n            \n            \n            \n        int actualLength = keyId.length();\n        String s = keyId.substring(0, MISSING_KEY_ID_MAX_KEY_LENGTH);\n        String snippet = String.format(\"%s (trimmed to first %s characters out of %s total)\", s, MISSING_KEY_ID_MAX_KEY_LENGTH, actualLength);\n        log.warn(\"Key ID {} was too long to cache\", snippet);\n        return false;\n    } else {\n        try {\n            refreshLock.writeLock().lock();\n\n            Long nextCheckTime = missingKeyIds.get(keyId);\n            long currTime = time.milliseconds();\n            log.debug(\"For key ID {}, nextCheckTime: {}, currTime: {}\", keyId, nextCheckTime, currTime);\n\n            if (nextCheckTime == null || nextCheckTime <= currTime) {\n                    \n                    \n                nextCheckTime = currTime + MISSING_KEY_ID_CACHE_IN_FLIGHT_MS;\n                missingKeyIds.put(keyId, nextCheckTime);\n                executorService.schedule(this::refresh, 0, TimeUnit.MILLISECONDS);\n                return true;\n            } else {\n                return false;\n            }\n        } finally {\n            refreshLock.writeLock().unlock();\n        }\n    }\n}",
        "summary_tokens": [
            "p",
            "code",
            "maybe",
            "expedite",
            "refresh",
            "code",
            "is",
            "a",
            "public",
            "method",
            "that",
            "will",
            "trigger",
            "a",
            "refresh",
            "of",
            "the",
            "jwks",
            "cache",
            "if",
            "all",
            "of",
            "the",
            "following",
            "conditions",
            "are",
            "met"
        ]
    },
    {
        "id": 1197,
        "code": "public String getToken() {\n    return token;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "entire",
            "base",
            "0",
            "encoded",
            "jwt"
        ]
    },
    {
        "id": 1198,
        "code": "public String getHeader() {\n    return header;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "first",
            "section",
            "the",
            "jwt",
            "header",
            "in",
            "its",
            "base",
            "0",
            "encoded",
            "form"
        ]
    },
    {
        "id": 1199,
        "code": "public String getPayload() {\n    return payload;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "second",
            "section",
            "the",
            "jwt",
            "payload",
            "in",
            "its",
            "base",
            "0",
            "encoded",
            "form"
        ]
    },
    {
        "id": 1200,
        "code": "public String getSignature() {\n    return signature;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "third",
            "section",
            "the",
            "jwt",
            "signature",
            "in",
            "its",
            "base",
            "0",
            "encoded",
            "form"
        ]
    },
    {
        "id": 1201,
        "code": "public OAuthBearerToken validate(String accessToken) throws ValidateException {\n    SerializedJwt serializedJwt = new SerializedJwt(accessToken);\n\n    JwtContext jwt;\n\n    try {\n        jwt = jwtConsumer.process(serializedJwt.getToken());\n    } catch (InvalidJwtException e) {\n        throw new ValidateException(String.format(\"Could not validate the access token: %s\", e.getMessage()), e);\n    }\n\n    JwtClaims claims = jwt.getJwtClaims();\n\n    Object scopeRaw = getClaim(() -> claims.getClaimValue(scopeClaimName), scopeClaimName);\n    Collection<String> scopeRawCollection;\n\n    if (scopeRaw instanceof String)\n        scopeRawCollection = Collections.singletonList((String) scopeRaw);\n    else if (scopeRaw instanceof Collection)\n        scopeRawCollection = (Collection<String>) scopeRaw;\n    else\n        scopeRawCollection = Collections.emptySet();\n\n    NumericDate expirationRaw = getClaim(claims::getExpirationTime, ReservedClaimNames.EXPIRATION_TIME);\n    String subRaw = getClaim(() -> claims.getStringClaimValue(subClaimName), subClaimName);\n    NumericDate issuedAtRaw = getClaim(claims::getIssuedAt, ReservedClaimNames.ISSUED_AT);\n\n    Set<String> scopes = ClaimValidationUtils.validateScopes(scopeClaimName, scopeRawCollection);\n    long expiration = ClaimValidationUtils.validateExpiration(ReservedClaimNames.EXPIRATION_TIME,\n        expirationRaw != null ? expirationRaw.getValueInMillis() : null);\n    String sub = ClaimValidationUtils.validateSubject(subClaimName, subRaw);\n    Long issuedAt = ClaimValidationUtils.validateIssuedAt(ReservedClaimNames.ISSUED_AT,\n        issuedAtRaw != null ? issuedAtRaw.getValueInMillis() : null);\n\n    OAuthBearerToken token = new BasicOAuthBearerToken(accessToken,\n        scopes,\n        expiration,\n        sub,\n        issuedAt);\n\n    return token;\n}",
        "summary_tokens": [
            "accepts",
            "an",
            "oauth",
            "jwt",
            "access",
            "token",
            "in",
            "base",
            "0",
            "encoded",
            "format",
            "validates",
            "and",
            "returns",
            "an",
            "oauth",
            "bearer",
            "token"
        ]
    },
    {
        "id": 1202,
        "code": "public static CloseableVerificationKeyResolver create(Map<String, ?> configs,\n    Map<String, Object> jaasConfig) {\n    return create(configs, null, jaasConfig);\n}",
        "summary_tokens": [
            "create",
            "an",
            "access",
            "token",
            "retriever",
            "from",
            "the",
            "given",
            "org"
        ]
    },
    {
        "id": 1203,
        "code": "public char[] password() {\n    return password;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "password",
            "provided",
            "by",
            "the",
            "client",
            "during",
            "sasl",
            "plain",
            "authentication"
        ]
    },
    {
        "id": 1204,
        "code": "public void authenticated(boolean authenticated) {\n    this.authenticated = authenticated;\n}",
        "summary_tokens": [
            "sets",
            "the",
            "authenticated",
            "state"
        ]
    },
    {
        "id": 1205,
        "code": "public byte[] evaluateResponse(byte[] responseBytes) throws SaslAuthenticationException {\n        \n\n    String response = new String(responseBytes, StandardCharsets.UTF_8);\n    List<String> tokens = extractTokens(response);\n    String authorizationIdFromClient = tokens.get(0);\n    String username = tokens.get(1);\n    String password = tokens.get(2);\n\n    if (username.isEmpty()) {\n        throw new SaslAuthenticationException(\"Authentication failed: username not specified\");\n    }\n    if (password.isEmpty()) {\n        throw new SaslAuthenticationException(\"Authentication failed: password not specified\");\n    }\n\n    NameCallback nameCallback = new NameCallback(\"username\", username);\n    PlainAuthenticateCallback authenticateCallback = new PlainAuthenticateCallback(password.toCharArray());\n    try {\n        callbackHandler.handle(new Callback[]{nameCallback, authenticateCallback});\n    } catch (Throwable e) {\n        throw new SaslAuthenticationException(\"Authentication failed: credentials for user could not be verified\", e);\n    }\n    if (!authenticateCallback.authenticated())\n        throw new SaslAuthenticationException(\"Authentication failed: Invalid username or password\");\n    if (!authorizationIdFromClient.isEmpty() && !authorizationIdFromClient.equals(username))\n        throw new SaslAuthenticationException(\"Authentication failed: Client requested an authorization id that is different from username\");\n\n    this.authorizationId = username;\n\n    complete = true;\n    return new byte[0];\n}",
        "summary_tokens": [
            "sasl",
            "authentication",
            "exception",
            "if",
            "username",
            "password",
            "combination",
            "is",
            "invalid",
            "or",
            "if",
            "the",
            "requested",
            "authorization",
            "id",
            "is",
            "not",
            "the",
            "same",
            "as",
            "username"
        ]
    },
    {
        "id": 1206,
        "code": "public byte[] salt() {\n    return salt;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "salt",
            "used",
            "to",
            "process",
            "this",
            "credential",
            "using",
            "the",
            "scram",
            "algorithm"
        ]
    },
    {
        "id": 1207,
        "code": "public byte[] serverKey() {\n    return serverKey;\n}",
        "summary_tokens": [
            "server",
            "key",
            "computed",
            "from",
            "the",
            "client",
            "password",
            "using",
            "the",
            "scram",
            "algorithm"
        ]
    },
    {
        "id": 1208,
        "code": "public byte[] storedKey() {\n    return storedKey;\n}",
        "summary_tokens": [
            "stored",
            "key",
            "computed",
            "from",
            "the",
            "client",
            "password",
            "using",
            "the",
            "scram",
            "algorithm"
        ]
    },
    {
        "id": 1209,
        "code": "public int iterations() {\n    return iterations;\n}",
        "summary_tokens": [
            "number",
            "of",
            "iterations",
            "used",
            "to",
            "process",
            "this",
            "credential",
            "using",
            "the",
            "scram",
            "algorithm"
        ]
    },
    {
        "id": 1210,
        "code": "public ScramCredential scramCredential() {\n    return scramCredential;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "scram",
            "credential",
            "if",
            "set",
            "on",
            "this",
            "instance"
        ]
    },
    {
        "id": 1211,
        "code": "public void extensions(Map<String, String> extensions) {\n    this.extensions = extensions;\n}",
        "summary_tokens": [
            "sets",
            "the",
            "scram",
            "extensions",
            "on",
            "this",
            "callback"
        ]
    },
    {
        "id": 1212,
        "code": "public byte[] evaluateResponse(byte[] response) throws SaslException, SaslAuthenticationException {\n    try {\n        switch (state) {\n            case RECEIVE_CLIENT_FIRST_MESSAGE:\n                this.clientFirstMessage = new ClientFirstMessage(response);\n                this.scramExtensions = clientFirstMessage.extensions();\n                if (!SUPPORTED_EXTENSIONS.containsAll(scramExtensions.map().keySet())) {\n                    log.debug(\"Unsupported extensions will be ignored, supported {}, provided {}\",\n                            SUPPORTED_EXTENSIONS, scramExtensions.map().keySet());\n                }\n                String serverNonce = formatter.secureRandomString();\n                try {\n                    String saslName = clientFirstMessage.saslName();\n                    this.username = ScramFormatter.username(saslName);\n                    NameCallback nameCallback = new NameCallback(\"username\", username);\n                    ScramCredentialCallback credentialCallback;\n                    if (scramExtensions.tokenAuthenticated()) {\n                        DelegationTokenCredentialCallback tokenCallback = new DelegationTokenCredentialCallback();\n                        credentialCallback = tokenCallback;\n                        callbackHandler.handle(new Callback[]{nameCallback, tokenCallback});\n                        if (tokenCallback.tokenOwner() == null)\n                            throw new SaslException(\"Token Authentication failed: Invalid tokenId : \" + username);\n                        this.authorizationId = tokenCallback.tokenOwner();\n                        this.tokenExpiryTimestamp = tokenCallback.tokenExpiryTimestamp();\n                    } else {\n                        credentialCallback = new ScramCredentialCallback();\n                        callbackHandler.handle(new Callback[]{nameCallback, credentialCallback});\n                        this.authorizationId = username;\n                        this.tokenExpiryTimestamp = null;\n                    }\n                    this.scramCredential = credentialCallback.scramCredential();\n                    if (scramCredential == null)\n                        throw new SaslException(\"Authentication failed: Invalid user credentials\");\n                    String authorizationIdFromClient = clientFirstMessage.authorizationId();\n                    if (!authorizationIdFromClient.isEmpty() && !authorizationIdFromClient.equals(username))\n                        throw new SaslAuthenticationException(\"Authentication failed: Client requested an authorization id that is different from username\");\n\n                    if (scramCredential.iterations() < mechanism.minIterations())\n                        throw new SaslException(\"Iterations \" + scramCredential.iterations() +  \" is less than the minimum \" + mechanism.minIterations() + \" for \" + mechanism);\n                    this.serverFirstMessage = new ServerFirstMessage(clientFirstMessage.nonce(),\n                            serverNonce,\n                            scramCredential.salt(),\n                            scramCredential.iterations());\n                    setState(State.RECEIVE_CLIENT_FINAL_MESSAGE);\n                    return serverFirstMessage.toBytes();\n                } catch (SaslException | AuthenticationException e) {\n                    throw e;\n                } catch (Throwable e) {\n                    throw new SaslException(\"Authentication failed: Credentials could not be obtained\", e);\n                }\n\n            case RECEIVE_CLIENT_FINAL_MESSAGE:\n                try {\n                    ClientFinalMessage clientFinalMessage = new ClientFinalMessage(response);\n                    verifyClientProof(clientFinalMessage);\n                    byte[] serverKey = scramCredential.serverKey();\n                    byte[] serverSignature = formatter.serverSignature(serverKey, clientFirstMessage, serverFirstMessage, clientFinalMessage);\n                    ServerFinalMessage serverFinalMessage = new ServerFinalMessage(null, serverSignature);\n                    clearCredentials();\n                    setState(State.COMPLETE);\n                    return serverFinalMessage.toBytes();\n                } catch (InvalidKeyException e) {\n                    throw new SaslException(\"Authentication failed: Invalid client final message\", e);\n                }\n\n            default:\n                throw new IllegalSaslStateException(\"Unexpected challenge in Sasl server state \" + state);\n        }\n    } catch (SaslException | AuthenticationException e) {\n        clearCredentials();\n        setState(State.FAILED);\n        throw e;\n    }\n}",
        "summary_tokens": [
            "sasl",
            "authentication",
            "exception",
            "if",
            "the",
            "requested",
            "authorization",
            "id",
            "is",
            "not",
            "the",
            "same",
            "as",
            "username"
        ]
    },
    {
        "id": 1213,
        "code": "public SSLEngine createSslEngine(String peerHost, int peerPort) {\n    if (sslEngineFactory == null) {\n        throw new IllegalStateException(\"SslFactory has not been configured.\");\n    }\n    if (mode == Mode.SERVER) {\n        return sslEngineFactory.createServerSslEngine(peerHost, peerPort);\n    } else {\n        return sslEngineFactory.createClientSslEngine(peerHost, peerPort, endpointIdentification);\n    }\n}",
        "summary_tokens": [
            "prefer",
            "create",
            "ssl",
            "engine",
            "socket",
            "if",
            "a",
            "socket",
            "instance",
            "is",
            "available"
        ]
    },
    {
        "id": 1214,
        "code": "private String peerHost(Socket socket) {\n    return new InetSocketAddress(socket.getInetAddress(), 0).getHostString();\n}",
        "summary_tokens": [
            "returns",
            "host",
            "ip",
            "address",
            "of",
            "remote",
            "host",
            "without",
            "reverse",
            "dns",
            "lookup",
            "to",
            "be",
            "used",
            "as",
            "the",
            "host",
            "for",
            "creating",
            "ssl",
            "engine"
        ]
    },
    {
        "id": 1215,
        "code": "private static <K, V> void copyMapEntries(Map<K, V> destMap,\n                                          Map<K, ? extends V> srcMap,\n                                          Set<K> keySet) {\n    for (K k : keySet) {\n        copyMapEntry(destMap, srcMap, k);\n    }\n}",
        "summary_tokens": [
            "copy",
            "entries",
            "from",
            "one",
            "map",
            "into",
            "another"
        ]
    },
    {
        "id": 1216,
        "code": "private static <K, V> void copyMapEntry(Map<K, V> destMap,\n                                        Map<K, ? extends V> srcMap,\n                                        K key) {\n    if (srcMap.containsKey(key)) {\n        destMap.put(key, srcMap.get(key));\n    }\n}",
        "summary_tokens": [
            "copy",
            "entry",
            "from",
            "one",
            "map",
            "into",
            "another"
        ]
    },
    {
        "id": 1217,
        "code": "default T deserialize(String topic, Headers headers, byte[] data) {\n    return deserialize(topic, data);\n}",
        "summary_tokens": [
            "deserialize",
            "a",
            "record",
            "value",
            "from",
            "a",
            "byte",
            "array",
            "into",
            "a",
            "value",
            "or",
            "object"
        ]
    },
    {
        "id": 1218,
        "code": "default void configure(Map<String, ?> configs, boolean isKey) {\n        \n}",
        "summary_tokens": [
            "configure",
            "this",
            "class",
            "which",
            "will",
            "configure",
            "the",
            "underlying",
            "serializer",
            "and",
            "deserializer"
        ]
    },
    {
        "id": 1219,
        "code": "",
        "summary_tokens": [
            "close",
            "this",
            "serde",
            "class",
            "which",
            "will",
            "close",
            "the",
            "underlying",
            "serializer",
            "and",
            "deserializer"
        ]
    },
    {
        "id": 1220,
        "code": "static public <T> Serde<T> serdeFrom(final Serializer<T> serializer, final Deserializer<T> deserializer) {\n    if (serializer == null) {\n        throw new IllegalArgumentException(\"serializer must not be null\");\n    }\n    if (deserializer == null) {\n        throw new IllegalArgumentException(\"deserializer must not be null\");\n    }\n\n    return new WrapperSerde<>(serializer, deserializer);\n}",
        "summary_tokens": [
            "construct",
            "a",
            "serde",
            "object",
            "from",
            "separate",
            "serializer",
            "and",
            "deserializer"
        ]
    },
    {
        "id": 1221,
        "code": "static public Serde<Long> Long() {\n    return new LongSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "long",
            "type"
        ]
    },
    {
        "id": 1222,
        "code": "static public Serde<Integer> Integer() {\n    return new IntegerSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "integer",
            "type"
        ]
    },
    {
        "id": 1223,
        "code": "static public Serde<Short> Short() {\n    return new ShortSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "short",
            "type"
        ]
    },
    {
        "id": 1224,
        "code": "static public Serde<Float> Float() {\n    return new FloatSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "float",
            "type"
        ]
    },
    {
        "id": 1225,
        "code": "static public Serde<Double> Double() {\n    return new DoubleSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "double",
            "type"
        ]
    },
    {
        "id": 1226,
        "code": "static public Serde<String> String() {\n    return new StringSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "string",
            "type"
        ]
    },
    {
        "id": 1227,
        "code": "static public Serde<ByteBuffer> ByteBuffer() {\n    return new ByteBufferSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "byte",
            "buffer",
            "type"
        ]
    },
    {
        "id": 1228,
        "code": "static public Serde<Bytes> Bytes() {\n    return new BytesSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "bytes",
            "type"
        ]
    },
    {
        "id": 1229,
        "code": "static public Serde<UUID> UUID() {\n    return new UUIDSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "uuid",
            "type"
        ]
    },
    {
        "id": 1230,
        "code": "static public Serde<byte[]> ByteArray() {\n    return new ByteArraySerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "nullable",
            "byte",
            "type"
        ]
    },
    {
        "id": 1231,
        "code": "static public Serde<Void> Void() {\n    return new VoidSerde();\n}",
        "summary_tokens": [
            "a",
            "serde",
            "for",
            "void",
            "type"
        ]
    },
    {
        "id": 1232,
        "code": "default byte[] serialize(String topic, Headers headers, T data) {\n    return serialize(topic, data);\n}",
        "summary_tokens": [
            "convert",
            "data",
            "into",
            "a",
            "byte",
            "array"
        ]
    },
    {
        "id": 1233,
        "code": "public int initialCapacity() {\n    return initialCapacity;\n}",
        "summary_tokens": [
            "the",
            "capacity",
            "of",
            "the",
            "first",
            "internal",
            "byte",
            "buffer",
            "used",
            "by",
            "this",
            "class"
        ]
    },
    {
        "id": 1234,
        "code": "public void ensureRemaining(int remainingBytesRequired) {\n    if (remainingBytesRequired > buffer.remaining())\n        expandBuffer(remainingBytesRequired);\n}",
        "summary_tokens": [
            "ensure",
            "there",
            "is",
            "enough",
            "space",
            "to",
            "write",
            "some",
            "number",
            "of",
            "bytes",
            "expanding",
            "the",
            "underlying",
            "buffer",
            "if",
            "necessary"
        ]
    },
    {
        "id": 1235,
        "code": "public static void unmap(String resourceDescription, ByteBuffer buffer) throws IOException {\n    if (!buffer.isDirect())\n        throw new IllegalArgumentException(\"Unmapping only works with direct buffers\");\n    if (UNMAP == null)\n        throw UNMAP_NOT_SUPPORTED_EXCEPTION;\n\n    try {\n        UNMAP.invokeExact(buffer);\n    } catch (Throwable throwable) {\n        throw new IOException(\"Unable to unmap the mapped buffer: \" + resourceDescription, throwable);\n    }\n}",
        "summary_tokens": [
            "unmap",
            "the",
            "provided",
            "mapped",
            "or",
            "direct",
            "byte",
            "buffer"
        ]
    },
    {
        "id": 1236,
        "code": "public static long readUnsignedInt(ByteBuffer buffer, int index) {\n    return buffer.getInt(index) & 0xffffffffL;\n}",
        "summary_tokens": [
            "read",
            "an",
            "unsigned",
            "integer",
            "from",
            "the",
            "given",
            "position",
            "without",
            "modifying",
            "the",
            "buffers",
            "position"
        ]
    },
    {
        "id": 1237,
        "code": "public static int readUnsignedIntLE(byte[] buffer, int offset) {\n    return (buffer[offset] << 0 & 0xff)\n            | ((buffer[offset + 1] & 0xff) << 8)\n            | ((buffer[offset + 2] & 0xff) << 16)\n            | ((buffer[offset + 3] & 0xff) << 24);\n}",
        "summary_tokens": [
            "read",
            "an",
            "unsigned",
            "integer",
            "stored",
            "in",
            "little",
            "endian",
            "format",
            "from",
            "a",
            "byte",
            "array",
            "at",
            "a",
            "given",
            "offset"
        ]
    },
    {
        "id": 1238,
        "code": "public static void writeUnsignedInt(ByteBuffer buffer, long value) {\n    buffer.putInt((int) (value & 0xffffffffL));\n}",
        "summary_tokens": [
            "write",
            "the",
            "given",
            "long",
            "value",
            "as",
            "a",
            "0",
            "byte",
            "unsigned",
            "integer"
        ]
    },
    {
        "id": 1239,
        "code": "public static void writeUnsignedIntLE(byte[] buffer, int offset, int value) {\n    buffer[offset] = (byte) value;\n    buffer[offset + 1] = (byte) (value >>> 8);\n    buffer[offset + 2] = (byte) (value >>> 16);\n    buffer[offset + 3]   = (byte) (value >>> 24);\n}",
        "summary_tokens": [
            "write",
            "an",
            "unsigned",
            "integer",
            "in",
            "little",
            "endian",
            "format",
            "to",
            "a",
            "byte",
            "array",
            "at",
            "a",
            "given",
            "offset"
        ]
    },
    {
        "id": 1240,
        "code": "public static int readUnsignedVarint(DataInput in) throws IOException {\n    int value = 0;\n    int i = 0;\n    int b;\n    while (((b = in.readByte()) & 0x80) != 0) {\n        value |= (b & 0x7f) << i;\n        i += 7;\n        if (i > 28)\n            throw illegalVarintException(value);\n    }\n    value |= b << i;\n    return value;\n}",
        "summary_tokens": [
            "read",
            "an",
            "integer",
            "stored",
            "in",
            "variable",
            "length",
            "format",
            "using",
            "unsigned",
            "decoding",
            "from",
            "a",
            "href",
            "http",
            "code"
        ]
    },
    {
        "id": 1241,
        "code": "public static int readVarint(DataInput in) throws IOException {\n    int value = readUnsignedVarint(in);\n    return (value >>> 1) ^ -(value & 1);\n}",
        "summary_tokens": [
            "read",
            "an",
            "integer",
            "stored",
            "in",
            "variable",
            "length",
            "format",
            "using",
            "zig",
            "zag",
            "decoding",
            "from",
            "a",
            "href",
            "http",
            "code"
        ]
    },
    {
        "id": 1242,
        "code": "public static long readVarlong(ByteBuffer buffer)  {\n    long value = 0L;\n    int i = 0;\n    long b;\n    while (((b = buffer.get()) & 0x80) != 0) {\n        value |= (b & 0x7f) << i;\n        i += 7;\n        if (i > 63)\n            throw illegalVarlongException(value);\n    }\n    value |= b << i;\n    return (value >>> 1) ^ -(value & 1);\n}",
        "summary_tokens": [
            "read",
            "a",
            "long",
            "stored",
            "in",
            "variable",
            "length",
            "format",
            "using",
            "zig",
            "zag",
            "decoding",
            "from",
            "a",
            "href",
            "http",
            "code"
        ]
    },
    {
        "id": 1243,
        "code": "public static double readDouble(ByteBuffer buffer) {\n    return buffer.getDouble();\n}",
        "summary_tokens": [
            "read",
            "a",
            "double",
            "precision",
            "0",
            "bit",
            "format",
            "ieee",
            "0",
            "value"
        ]
    },
    {
        "id": 1244,
        "code": "public static void writeUnsignedVarint(int value, DataOutput out) throws IOException {\n    while ((value & 0xffffff80) != 0L) {\n        byte b = (byte) ((value & 0x7f) | 0x80);\n        out.writeByte(b);\n        value >>>= 7;\n    }\n    out.writeByte((byte) value);\n}",
        "summary_tokens": [
            "write",
            "the",
            "given",
            "integer",
            "following",
            "the",
            "variable",
            "length",
            "unsigned",
            "encoding",
            "from",
            "a",
            "href",
            "http",
            "code"
        ]
    },
    {
        "id": 1245,
        "code": "public static void writeVarint(int value, ByteBuffer buffer) {\n    writeUnsignedVarint((value << 1) ^ (value >> 31), buffer);\n}",
        "summary_tokens": [
            "write",
            "the",
            "given",
            "integer",
            "following",
            "the",
            "variable",
            "length",
            "zig",
            "zag",
            "encoding",
            "from",
            "a",
            "href",
            "http",
            "code"
        ]
    },
    {
        "id": 1246,
        "code": "public static void writeVarlong(long value, ByteBuffer buffer) {\n    long v = (value << 1) ^ (value >> 63);\n    while ((v & 0xffffffffffffff80L) != 0L) {\n        byte b = (byte) ((v & 0x7f) | 0x80);\n        buffer.put(b);\n        v >>>= 7;\n    }\n    buffer.put((byte) v);\n}",
        "summary_tokens": [
            "write",
            "the",
            "given",
            "integer",
            "following",
            "the",
            "variable",
            "length",
            "zig",
            "zag",
            "encoding",
            "from",
            "a",
            "href",
            "http",
            "code"
        ]
    },
    {
        "id": 1247,
        "code": "public static void writeDouble(double value, ByteBuffer buffer) {\n    buffer.putDouble(value);\n}",
        "summary_tokens": [
            "write",
            "the",
            "given",
            "double",
            "following",
            "the",
            "double",
            "precision",
            "0",
            "bit",
            "format",
            "ieee",
            "0",
            "value",
            "into",
            "the",
            "buffer"
        ]
    },
    {
        "id": 1248,
        "code": "public static int sizeOfUnsignedVarint(int value) {\n        \n        \n        \n        \n\n        \n\n        \n\n        \n        \n\n    int leadingZeros = Integer.numberOfLeadingZeros(value);\n    int leadingZerosBelow38DividedBy7 = ((38 - leadingZeros) * 0b10010010010010011) >>> 19;\n    return leadingZerosBelow38DividedBy7 + (leadingZeros >>> 5);\n}",
        "summary_tokens": [
            "number",
            "of",
            "bytes",
            "needed",
            "to",
            "encode",
            "an",
            "integer",
            "in",
            "unsigned",
            "variable",
            "length",
            "format"
        ]
    },
    {
        "id": 1249,
        "code": "public static int sizeOfVarint(int value) {\n    return sizeOfUnsignedVarint((value << 1) ^ (value >> 31));\n}",
        "summary_tokens": [
            "number",
            "of",
            "bytes",
            "needed",
            "to",
            "encode",
            "an",
            "integer",
            "in",
            "variable",
            "length",
            "format"
        ]
    },
    {
        "id": 1250,
        "code": "public static int sizeOfVarlong(long value) {\n    long v = (value << 1) ^ (value >> 63);\n\n        \n        \n        \n\n    int leadingZeros = Long.numberOfLeadingZeros(v);\n    int leadingZerosBelow70DividedBy7 = ((70 - leadingZeros) * 0b10010010010010011) >>> 19;\n    return leadingZerosBelow70DividedBy7 + (leadingZeros >>> 6);\n}",
        "summary_tokens": [
            "number",
            "of",
            "bytes",
            "needed",
            "to",
            "encode",
            "a",
            "long",
            "in",
            "variable",
            "length",
            "format"
        ]
    },
    {
        "id": 1251,
        "code": "public byte[] get() {\n    return this.bytes;\n}",
        "summary_tokens": [
            "get",
            "the",
            "data",
            "from",
            "the",
            "bytes"
        ]
    },
    {
        "id": 1252,
        "code": "public int hashCode() {\n    if (hashCode == 0) {\n        hashCode = Arrays.hashCode(bytes);\n    }\n\n    return hashCode;\n}",
        "summary_tokens": [
            "the",
            "hashcode",
            "is",
            "cached",
            "except",
            "for",
            "the",
            "case",
            "where",
            "it",
            "is",
            "computed",
            "as",
            "0",
            "in",
            "which",
            "case",
            "we",
            "compute",
            "the",
            "hashcode",
            "on",
            "every",
            "call"
        ]
    },
    {
        "id": 1253,
        "code": "private static String toString(final byte[] b, int off, int len) {\n    StringBuilder result = new StringBuilder();\n\n    if (b == null)\n        return result.toString();\n\n        \n    if (off >= b.length)\n        return result.toString();\n\n    if (off + len > b.length)\n        len = b.length - off;\n\n    for (int i = off; i < off + len; ++i) {\n        int ch = b[i] & 0xFF;\n        if (ch >= ' ' && ch <= '~' && ch != '\\\\') {\n            result.append((char) ch);\n        } else {\n            result.append(\"\\\\x\");\n            result.append(HEX_CHARS_UPPER[ch / 0x10]);\n            result.append(HEX_CHARS_UPPER[ch % 0x10]);\n        }\n    }\n    return result.toString();\n}",
        "summary_tokens": [
            "write",
            "a",
            "printable",
            "representation",
            "of",
            "a",
            "byte",
            "array"
        ]
    },
    {
        "id": 1254,
        "code": "public static Bytes increment(Bytes input) throws IndexOutOfBoundsException {\n    byte[] inputArr = input.get();\n    byte[] ret = new byte[inputArr.length];\n    int carry = 1;\n    for (int i = inputArr.length - 1; i >= 0; i--) {\n        if (inputArr[i] == (byte) 0xFF && carry == 1) {\n            ret[i] = (byte) 0x00;\n        } else {\n            ret[i] = (byte) (inputArr[i] + carry);\n            carry = 0;\n        }\n    }\n    if (carry == 0) {\n        return wrap(ret);\n    } else {\n        throw new IndexOutOfBoundsException();\n    }\n}",
        "summary_tokens": [
            "increment",
            "the",
            "underlying",
            "byte",
            "array",
            "by",
            "adding",
            "0"
        ]
    },
    {
        "id": 1255,
        "code": "public static void update(Checksum checksum, ByteBuffer buffer, int offset, int length) {\n    if (buffer.hasArray()) {\n        checksum.update(buffer.array(), buffer.position() + buffer.arrayOffset() + offset, length);\n    } else if (BYTE_BUFFER_UPDATE != null && buffer.isDirect()) {\n        final int oldPosition = buffer.position();\n        final int oldLimit = buffer.limit();\n        try {\n                \n            final int start = oldPosition + offset;\n            buffer.limit(start + length);\n            buffer.position(start);\n            BYTE_BUFFER_UPDATE.invokeExact(checksum, buffer);\n        } catch (Throwable t) {\n            handleUpdateThrowable(t);\n        } finally {\n                \n            buffer.limit(oldLimit);\n            buffer.position(oldPosition);\n        }\n    } else {\n            \n        int start = buffer.position() + offset;\n        for (int i = start; i < start + length; i++) {\n            checksum.update(buffer.get(i));\n        }\n    }\n}",
        "summary_tokens": [
            "uses",
            "checksum",
            "update",
            "on",
            "buffer",
            "s",
            "content",
            "starting",
            "from",
            "the",
            "given",
            "offset",
            "by",
            "the",
            "provided",
            "length",
            "without",
            "modifying",
            "its",
            "position",
            "and",
            "limit"
        ]
    },
    {
        "id": 1256,
        "code": "public boolean hasNext() {\n    return true;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "since",
            "the",
            "iteration",
            "will",
            "forever",
            "cycle",
            "through",
            "the",
            "provided",
            "collection"
        ]
    },
    {
        "id": 1257,
        "code": "private T advance() {\n    if (!iterator.hasNext()) {\n        iterator = iterable.iterator();\n    }\n    return iterator.next();\n}",
        "summary_tokens": [
            "return",
            "the",
            "next",
            "value",
            "in",
            "the",
            "iterator",
            "restarting",
            "the",
            "iterator",
            "if",
            "necessary"
        ]
    },
    {
        "id": 1258,
        "code": "public T peek() {\n    return nextValue;\n}",
        "summary_tokens": [
            "peek",
            "at",
            "the",
            "next",
            "value",
            "in",
            "the",
            "iterator"
        ]
    },
    {
        "id": 1259,
        "code": "public static <K, V> Map<K, V> subtractMap(Map<? extends K, ? extends V> minuend, Map<? extends K, ? extends V> subtrahend) {\n    return minuend.entrySet().stream()\n            .filter(entry -> !subtrahend.containsKey(entry.getKey()))\n            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n}",
        "summary_tokens": [
            "given",
            "two",
            "maps",
            "a",
            "b",
            "returns",
            "all",
            "the",
            "key",
            "value",
            "pairs",
            "in",
            "a",
            "whose",
            "keys",
            "are",
            "not",
            "contained",
            "in",
            "b"
        ]
    },
    {
        "id": 1260,
        "code": "public static <T> Map<String, Map<Integer, T>> groupPartitionDataByTopic(Map<TopicPartition, ? extends T> data) {\n    Map<String, Map<Integer, T>> dataByTopic = new HashMap<>();\n    for (Map.Entry<TopicPartition, ? extends T> entry : data.entrySet()) {\n        String topic = entry.getKey().topic();\n        int partition = entry.getKey().partition();\n        Map<Integer, T> topicData = dataByTopic.computeIfAbsent(topic, t -> new HashMap<>());\n        topicData.put(partition, entry.getValue());\n    }\n    return dataByTopic;\n}",
        "summary_tokens": [
            "group",
            "data",
            "by",
            "topic"
        ]
    },
    {
        "id": 1261,
        "code": "public static <T> Map<String, T> groupPartitionsByTopic(\n    Collection<TopicPartition> partitions,\n    Function<String, T> buildGroup,\n    BiConsumer<T, Integer> addToGroup\n) {\n    Map<String, T> dataByTopic = new HashMap<>();\n    for (TopicPartition tp : partitions) {\n        String topic = tp.topic();\n        T topicData = dataByTopic.computeIfAbsent(topic, buildGroup);\n        addToGroup.accept(topicData, tp.partition());\n    }\n    return dataByTopic;\n}",
        "summary_tokens": [
            "group",
            "a",
            "collection",
            "of",
            "partitions",
            "by",
            "topic"
        ]
    },
    {
        "id": 1262,
        "code": "public static <T> Map<String, T> translateDeprecatedConfigs(Map<String, T> configs,\n                                                            Map<String, List<String>> aliasGroups) {\n    Set<String> aliasSet = Stream.concat(\n        aliasGroups.keySet().stream(),\n        aliasGroups.values().stream().flatMap(Collection::stream))\n        .collect(Collectors.toSet());\n\n        \n    Map<String, T> newConfigs = configs.entrySet().stream()\n        .filter(e -> !aliasSet.contains(e.getKey()))\n            \n        .filter(e -> Objects.nonNull(e.getValue()))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    aliasGroups.forEach((target, aliases) -> {\n        List<String> deprecated = aliases.stream()\n            .filter(configs::containsKey)\n            .collect(Collectors.toList());\n\n        if (deprecated.isEmpty()) {\n                \n            if (configs.containsKey(target)) {\n                newConfigs.put(target, configs.get(target));\n            }\n            return;\n        }\n\n        String aliasString = String.join(\", \", deprecated);\n\n        if (configs.containsKey(target)) {\n                \n            log.error(target + \" was configured, as well as the deprecated alias(es) \" +\n                      aliasString + \".  Using the value of \" + target);\n            newConfigs.put(target, configs.get(target));\n        } else if (deprecated.size() > 1) {\n            log.error(\"The configuration keys \" + aliasString + \" are deprecated and may be \" +\n                      \"removed in the future.  Additionally, this configuration is ambigous because \" +\n                      \"these configuration keys are all aliases for \" + target + \".  Please update \" +\n                      \"your configuration to have only \" + target + \" set.\");\n            newConfigs.put(target, configs.get(deprecated.get(0)));\n        } else {\n            log.warn(\"Configuration key \" + deprecated.get(0) + \" is deprecated and may be removed \" +\n                     \"in the future.  Please update your configuration to use \" + target + \" instead.\");\n            newConfigs.put(target, configs.get(deprecated.get(0)));\n        }\n    });\n\n    return newConfigs;\n}",
        "summary_tokens": [
            "translates",
            "deprecated",
            "configurations",
            "into",
            "their",
            "non",
            "deprecated",
            "equivalents"
        ]
    },
    {
        "id": 1263,
        "code": "public static long compute(ByteBuffer buffer, int offset, int size) {\n    Checksum crc = create();\n    Checksums.update(crc, buffer, offset, size);\n    return crc.getValue();\n}",
        "summary_tokens": [
            "compute",
            "the",
            "crc",
            "0",
            "c",
            "castagnoli",
            "of",
            "a",
            "byte",
            "buffer",
            "from",
            "a",
            "given",
            "offset",
            "relative",
            "to",
            "the",
            "buffer",
            "s",
            "current",
            "position"
        ]
    },
    {
        "id": 1264,
        "code": "final public Iterator<E> iterator() {\n    return listIterator(0);\n}",
        "summary_tokens": [
            "returns",
            "an",
            "iterator",
            "that",
            "will",
            "yield",
            "every",
            "element",
            "in",
            "the",
            "set"
        ]
    },
    {
        "id": 1265,
        "code": "final private int findIndexOfEqualElement(Object key) {\n    if (key == null || size == 0) {\n        return INVALID_INDEX;\n    }\n    int slot = slot(elements, key);\n    for (int seen = 0; seen < elements.length; seen++) {\n        Element element = elements[slot];\n        if (element == null) {\n            return INVALID_INDEX;\n        }\n        if (element.elementKeysAreEqual(key)) {\n            return slot;\n        }\n        slot = (slot + 1) % elements.length;\n    }\n    return INVALID_INDEX;\n}",
        "summary_tokens": [
            "find",
            "an",
            "element",
            "matching",
            "an",
            "example",
            "element"
        ]
    },
    {
        "id": 1266,
        "code": "final public E find(E key) {\n    int index = findIndexOfEqualElement(key);\n    if (index == INVALID_INDEX) {\n        return null;\n    }\n    @SuppressWarnings(\"unchecked\")\n    E result = (E) elements[index];\n    return result;\n}",
        "summary_tokens": [
            "an",
            "element",
            "e",
            "in",
            "the",
            "collection",
            "such",
            "that",
            "e"
        ]
    },
    {
        "id": 1267,
        "code": "final public int size() {\n    return size;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "elements",
            "in",
            "the",
            "set"
        ]
    },
    {
        "id": 1268,
        "code": "final public boolean contains(Object key) {\n    return findIndexOfEqualElement(key) != INVALID_INDEX;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "there",
            "is",
            "at",
            "least",
            "one",
            "element",
            "e",
            "in",
            "the",
            "collection",
            "such",
            "that",
            "key"
        ]
    },
    {
        "id": 1269,
        "code": "final public boolean add(E newElement) {\n    if (newElement == null) {\n        return false;\n    }\n    if (newElement.prev() != INVALID_INDEX || newElement.next() != INVALID_INDEX) {\n        return false;\n    }\n    if ((size + 1) >= elements.length / 2) {\n        changeCapacity(calculateCapacity(elements.length));\n    }\n    int slot = addInternal(newElement, elements);\n    if (slot >= 0) {\n        addToListTail(head, elements, slot);\n        size++;\n        return true;\n    }\n    return false;\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "element",
            "to",
            "the",
            "collection"
        ]
    },
    {
        "id": 1270,
        "code": "int addInternal(Element newElement, Element[] addElements) {\n    int slot = slot(addElements, newElement);\n    for (int seen = 0; seen < addElements.length; seen++) {\n        Element element = addElements[slot];\n        if (element == null) {\n            addElements[slot] = newElement;\n            return slot;\n        }\n        if (element.elementKeysAreEqual(newElement)) {\n            return INVALID_INDEX;\n        }\n        slot = (slot + 1) % addElements.length;\n    }\n    throw new RuntimeException(\"Not enough hash table slots to add a new element.\");\n}",
        "summary_tokens": [
            "adds",
            "a",
            "new",
            "element",
            "to",
            "the",
            "appropriate",
            "place",
            "in",
            "the",
            "elements",
            "array"
        ]
    },
    {
        "id": 1271,
        "code": "final public boolean remove(Object key) {\n    int slot = findElementToRemove(key);\n    if (slot == INVALID_INDEX) {\n        return false;\n    }\n    removeElementAtSlot(slot);\n    return true;\n}",
        "summary_tokens": [
            "remove",
            "the",
            "first",
            "element",
            "e",
            "such",
            "that",
            "key"
        ]
    },
    {
        "id": 1272,
        "code": "private boolean removeElementAtSlot(int slot) {\n    size--;\n    removeFromList(head, elements, slot);\n    slot = (slot + 1) % elements.length;\n\n        \n    int endSlot = slot;\n    for (int seen = 0; seen < elements.length; seen++) {\n        Element element = elements[endSlot];\n        if (element == null) {\n            break;\n        }\n        endSlot = (endSlot + 1) % elements.length;\n    }\n\n        \n        \n        \n        \n    while (slot != endSlot) {\n        reseat(slot);\n        slot = (slot + 1) % elements.length;\n    }\n    return true;\n}",
        "summary_tokens": [
            "remove",
            "an",
            "element",
            "in",
            "a",
            "particular",
            "slot"
        ]
    },
    {
        "id": 1273,
        "code": "final public void clear(int expectedNumElements) {\n    if (expectedNumElements == 0) {\n            \n        this.head = HeadElement.EMPTY;\n        this.elements = EMPTY_ELEMENTS;\n        this.size = 0;\n    } else {\n        this.head = new HeadElement();\n        this.elements = new Element[calculateCapacity(expectedNumElements)];\n        this.size = 0;\n    }\n}",
        "summary_tokens": [
            "removes",
            "all",
            "of",
            "the",
            "elements",
            "from",
            "this",
            "set",
            "and",
            "resets",
            "the",
            "set",
            "capacity",
            "based",
            "on",
            "the",
            "provided",
            "expected",
            "number",
            "of",
            "elements"
        ]
    },
    {
        "id": 1274,
        "code": "final public void moveToEnd(E element) {\n    if (element.prev() == INVALID_INDEX || element.next() == INVALID_INDEX) {\n        throw new RuntimeException(\"Element \" + element + \" is not in the collection.\");\n    }\n    Element prevElement = indexToElement(head, elements, element.prev());\n    Element nextElement = indexToElement(head, elements, element.next());\n    int slot = prevElement.next();\n    prevElement.setNext(element.next());\n    nextElement.setPrev(element.prev());\n    addToListTail(head, elements, slot);\n}",
        "summary_tokens": [
            "moves",
            "an",
            "element",
            "which",
            "is",
            "already",
            "in",
            "the",
            "collection",
            "so",
            "that",
            "it",
            "comes",
            "last",
            "in",
            "iteration",
            "order"
        ]
    },
    {
        "id": 1275,
        "code": "public boolean equals(Object o) {\n    if (o == this)\n        return true;\n\n    if (!(o instanceof ImplicitLinkedHashCollection))\n        return false;\n\n    ImplicitLinkedHashCollection<?> ilhs = (ImplicitLinkedHashCollection<?>) o;\n    return this.valuesList().equals(ilhs.valuesList());\n}",
        "summary_tokens": [
            "compares",
            "the",
            "specified",
            "object",
            "with",
            "this",
            "collection",
            "for",
            "equality"
        ]
    },
    {
        "id": 1276,
        "code": "public int hashCode() {\n    return this.valuesList().hashCode();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "hash",
            "code",
            "value",
            "for",
            "this",
            "collection"
        ]
    },
    {
        "id": 1277,
        "code": "public List<E> valuesList() {\n    return new ImplicitLinkedHashCollectionListView();\n}",
        "summary_tokens": [
            "returns",
            "a",
            "list",
            "view",
            "of",
            "the",
            "elements",
            "contained",
            "in",
            "the",
            "collection",
            "ordered",
            "by",
            "order",
            "of",
            "insertion",
            "into",
            "the",
            "collection"
        ]
    },
    {
        "id": 1278,
        "code": "public Set<E> valuesSet() {\n    return new ImplicitLinkedHashCollectionSetView();\n}",
        "summary_tokens": [
            "returns",
            "a",
            "set",
            "view",
            "of",
            "the",
            "elements",
            "contained",
            "in",
            "the",
            "collection"
        ]
    },
    {
        "id": 1279,
        "code": "int addInternal(Element newElement, Element[] addElements) {\n    int slot = slot(addElements, newElement);\n    for (int seen = 0; seen < addElements.length; seen++) {\n        Element element = addElements[slot];\n        if (element == null) {\n            addElements[slot] = newElement;\n            return slot;\n        }\n        if (element == newElement) {\n            return INVALID_INDEX;\n        }\n        slot = (slot + 1) % addElements.length;\n    }\n    throw new RuntimeException(\"Not enough hash table slots to add a new element.\");\n}",
        "summary_tokens": [
            "adds",
            "a",
            "new",
            "element",
            "to",
            "the",
            "appropriate",
            "place",
            "in",
            "the",
            "elements",
            "array"
        ]
    },
    {
        "id": 1280,
        "code": "int findElementToRemove(Object key) {\n    if (key == null || size() == 0) {\n        return INVALID_INDEX;\n    }\n    int slot = slot(elements, key);\n    int bestSlot = INVALID_INDEX;\n    for (int seen = 0; seen < elements.length; seen++) {\n        Element element = elements[slot];\n        if (element == null) {\n            return bestSlot;\n        }\n        if (key == element) {\n            return slot;\n        } else if (element.elementKeysAreEqual(key)) {\n            bestSlot = slot;\n        }\n        slot = (slot + 1) % elements.length;\n    }\n    return INVALID_INDEX;\n}",
        "summary_tokens": [
            "find",
            "an",
            "element",
            "matching",
            "an",
            "example",
            "element"
        ]
    },
    {
        "id": 1281,
        "code": "final public List<E> findAll(E key) {\n    if (key == null || size() == 0) {\n        return Collections.<E>emptyList();\n    }\n    ArrayList<E> results = new ArrayList<>();\n    int slot = slot(elements, key);\n    for (int seen = 0; seen < elements.length; seen++) {\n        Element element = elements[slot];\n        if (element == null) {\n            break;\n        }\n        if (key.elementKeysAreEqual(element)) {\n            @SuppressWarnings(\"unchecked\")\n            E result = (E) elements[slot];\n            results.add(result);\n        }\n        slot = (slot + 1) % elements.length;\n    }\n    return results;\n}",
        "summary_tokens": [
            "returns",
            "all",
            "of",
            "the",
            "elements",
            "e",
            "in",
            "the",
            "collection",
            "such",
            "that",
            "key"
        ]
    },
    {
        "id": 1282,
        "code": "public void register() throws ReflectiveOperationException {\n    Map<String, Object> jvmSignalHandlers = new ConcurrentHashMap<>();\n\n    for (String signal : SIGNALS) {\n        register(signal, jvmSignalHandlers);\n    }\n    log.info(\"Registered signal handlers for \" + String.join(\", \", SIGNALS));\n}",
        "summary_tokens": [
            "register",
            "signal",
            "handler",
            "to",
            "log",
            "termination",
            "due",
            "to",
            "sigterm",
            "sighup",
            "and",
            "sigint",
            "control",
            "c"
        ]
    },
    {
        "id": 1283,
        "code": "public static String sanitize(String name) {\n    String encoded = \"\";\n    try {\n        encoded = URLEncoder.encode(name, StandardCharsets.UTF_8.name());\n        StringBuilder builder = new StringBuilder();\n        for (int i = 0; i < encoded.length(); i++) {\n            char c = encoded.charAt(i);\n            if (c == '*') {         \n                builder.append(\"%2A\");\n            } else if (c == '+') {  \n                builder.append(\"%20\");\n            } else {\n                builder.append(c);\n            }\n        }\n        return builder.toString();\n    } catch (UnsupportedEncodingException e) {\n        throw new KafkaException(e);\n    }\n}",
        "summary_tokens": [
            "sanitize",
            "name",
            "for",
            "safe",
            "use",
            "as",
            "jmx",
            "metric",
            "name",
            "as",
            "well",
            "as",
            "zoo",
            "keeper",
            "node",
            "name",
            "using",
            "url",
            "encoding"
        ]
    },
    {
        "id": 1284,
        "code": "public static String desanitize(String name) {\n    try {\n        return URLDecoder.decode(name, StandardCharsets.UTF_8.name());\n    } catch (UnsupportedEncodingException e) {\n        throw new KafkaException(e);\n    }\n}",
        "summary_tokens": [
            "desanitize",
            "name",
            "that",
            "was",
            "url",
            "encoded",
            "using",
            "sanitize",
            "string"
        ]
    },
    {
        "id": 1285,
        "code": "public static String jmxSanitize(String name) {\n    return MBEAN_PATTERN.matcher(name).matches() ? name : ObjectName.quote(name);\n}",
        "summary_tokens": [
            "quote",
            "name",
            "using",
            "object",
            "name",
            "quote",
            "string",
            "if",
            "name",
            "contains",
            "characters",
            "that",
            "are",
            "not",
            "safe",
            "for",
            "use",
            "in",
            "jmx"
        ]
    },
    {
        "id": 1286,
        "code": "public int exitCode() {\n    return exitCode;\n}",
        "summary_tokens": [
            "get",
            "the",
            "exit",
            "code",
            "the",
            "exit",
            "code",
            "of",
            "the",
            "process"
        ]
    },
    {
        "id": 1287,
        "code": "public Process process() {\n    return process;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "sub",
            "process",
            "executing",
            "the",
            "given",
            "command",
            "process",
            "executing",
            "the",
            "command"
        ]
    },
    {
        "id": 1288,
        "code": "public static String execCommand(String[] cmd, long timeout) throws IOException {\n    ShellCommandExecutor exec = new ShellCommandExecutor(cmd, timeout);\n    exec.execute();\n    return exec.output();\n}",
        "summary_tokens": [
            "static",
            "method",
            "to",
            "execute",
            "a",
            "shell",
            "command"
        ]
    },
    {
        "id": 1289,
        "code": "public static ThreadFactory createThreadFactory(final String pattern,\n                                                final boolean daemon) {\n    return new ThreadFactory() {\n        private final AtomicLong threadEpoch = new AtomicLong(0);\n\n        @Override\n        public Thread newThread(Runnable r) {\n            String threadName;\n            if (pattern.contains(\"%d\")) {\n                threadName = String.format(pattern, threadEpoch.addAndGet(1));\n            } else {\n                threadName = pattern;\n            }\n            Thread thread = new Thread(r, threadName);\n            thread.setDaemon(daemon);\n            return thread;\n        }\n    };\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "thread",
            "factory"
        ]
    },
    {
        "id": 1290,
        "code": "default long hiResClockMs() {\n    return TimeUnit.NANOSECONDS.toMillis(nanoseconds());\n}",
        "summary_tokens": [
            "returns",
            "the",
            "value",
            "returned",
            "by",
            "nanoseconds",
            "converted",
            "into",
            "milliseconds"
        ]
    },
    {
        "id": 1291,
        "code": "default Timer timer(Duration timeout) {\n    return timer(timeout.toMillis());\n}",
        "summary_tokens": [
            "get",
            "a",
            "timer",
            "which",
            "is",
            "bound",
            "to",
            "this",
            "time",
            "instance",
            "and",
            "expires",
            "after",
            "the",
            "given",
            "timeout"
        ]
    },
    {
        "id": 1292,
        "code": "public boolean notExpired() {\n    return !isExpired();\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "timer",
            "has",
            "not",
            "yet",
            "expired"
        ]
    },
    {
        "id": 1293,
        "code": "public void updateAndReset(long timeoutMs) {\n    update();\n    reset(timeoutMs);\n}",
        "summary_tokens": [
            "reset",
            "the",
            "timer",
            "to",
            "the",
            "specific",
            "timeout"
        ]
    },
    {
        "id": 1294,
        "code": "public void reset(long timeoutMs) {\n    if (timeoutMs < 0)\n        throw new IllegalArgumentException(\"Invalid negative timeout \" + timeoutMs);\n\n    this.timeoutMs = timeoutMs;\n    this.startMs = this.currentTimeMs;\n\n    if (currentTimeMs > Long.MAX_VALUE - timeoutMs)\n        this.deadlineMs = Long.MAX_VALUE;\n    else\n        this.deadlineMs = currentTimeMs + timeoutMs;\n}",
        "summary_tokens": [
            "reset",
            "the",
            "timer",
            "using",
            "a",
            "new",
            "timeout"
        ]
    },
    {
        "id": 1295,
        "code": "public void resetDeadline(long deadlineMs) {\n    if (deadlineMs < 0)\n        throw new IllegalArgumentException(\"Invalid negative deadline \" + deadlineMs);\n\n    this.timeoutMs = Math.max(0, deadlineMs - this.currentTimeMs);\n    this.startMs = this.currentTimeMs;\n    this.deadlineMs = deadlineMs;\n}",
        "summary_tokens": [
            "reset",
            "the",
            "timer",
            "s",
            "deadline",
            "directly"
        ]
    },
    {
        "id": 1296,
        "code": "public void update(long currentTimeMs) {\n    this.currentTimeMs = Math.max(currentTimeMs, this.currentTimeMs);\n}",
        "summary_tokens": [
            "update",
            "the",
            "cached",
            "current",
            "time",
            "to",
            "a",
            "specific",
            "value"
        ]
    },
    {
        "id": 1297,
        "code": "public long remainingMs() {\n    return Math.max(0, deadlineMs - currentTimeMs);\n}",
        "summary_tokens": [
            "get",
            "the",
            "remaining",
            "time",
            "in",
            "milliseconds",
            "until",
            "the",
            "timer",
            "expires"
        ]
    },
    {
        "id": 1298,
        "code": "public long currentTimeMs() {\n    return currentTimeMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "time",
            "in",
            "milliseconds"
        ]
    },
    {
        "id": 1299,
        "code": "public long elapsedMs() {\n    return currentTimeMs - startMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "amount",
            "of",
            "time",
            "that",
            "has",
            "elapsed",
            "since",
            "the",
            "timer",
            "began"
        ]
    },
    {
        "id": 1300,
        "code": "public long timeoutMs() {\n    return timeoutMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "timeout",
            "value",
            "specified",
            "through",
            "reset",
            "long",
            "or",
            "reset",
            "deadline",
            "long"
        ]
    },
    {
        "id": 1301,
        "code": "public void sleep(long durationMs) {\n    long sleepDurationMs = Math.min(durationMs, remainingMs());\n    time.sleep(sleepDurationMs);\n    update();\n}",
        "summary_tokens": [
            "sleep",
            "for",
            "the",
            "requested",
            "duration",
            "and",
            "update",
            "the",
            "timer"
        ]
    },
    {
        "id": 1302,
        "code": "public Optional<ApiException> exception() {\n    return exception == null ? Optional.empty() : Optional.of(exception);\n}",
        "summary_tokens": [
            "returns",
            "any",
            "exception",
            "during",
            "create"
        ]
    },
    {
        "id": 1303,
        "code": "public Optional<ApiException> exception() {\n    return exception == null ? Optional.empty() : Optional.of(exception);\n}",
        "summary_tokens": [
            "returns",
            "any",
            "exception",
            "while",
            "attempting",
            "to",
            "match",
            "acl",
            "filter",
            "to",
            "delete",
            "acls"
        ]
    },
    {
        "id": 1304,
        "code": "public Collection<AclBindingDeleteResult> aclBindingDeleteResults() {\n    return aclBindingDeleteResults;\n}",
        "summary_tokens": [
            "returns",
            "delete",
            "result",
            "for",
            "each",
            "matching",
            "acl",
            "binding"
        ]
    },
    {
        "id": 1305,
        "code": "public ResourcePattern resourcePattern() {\n    return resourcePattern;\n}",
        "summary_tokens": [
            "a",
            "non",
            "null",
            "resource",
            "pattern",
            "on",
            "which",
            "this",
            "action",
            "is",
            "being",
            "performed"
        ]
    },
    {
        "id": 1306,
        "code": "public AclOperation operation() {\n    return operation;\n}",
        "summary_tokens": [
            "a",
            "non",
            "null",
            "operation",
            "being",
            "performed"
        ]
    },
    {
        "id": 1307,
        "code": "public boolean logIfAllowed() {\n    return logIfAllowed;\n}",
        "summary_tokens": [
            "indicates",
            "if",
            "audit",
            "logs",
            "tracking",
            "allowed",
            "access",
            "should",
            "include",
            "this",
            "action",
            "if",
            "result",
            "is",
            "allowed"
        ]
    },
    {
        "id": 1308,
        "code": "public boolean logIfDenied() {\n    return logIfDenied;\n}",
        "summary_tokens": [
            "indicates",
            "if",
            "audit",
            "logs",
            "tracking",
            "denied",
            "access",
            "should",
            "include",
            "this",
            "action",
            "if",
            "result",
            "is",
            "denied"
        ]
    },
    {
        "id": 1309,
        "code": "public int resourceReferenceCount() {\n    return resourceReferenceCount;\n}",
        "summary_tokens": [
            "number",
            "of",
            "times",
            "the",
            "resource",
            "being",
            "authorized",
            "is",
            "referenced",
            "within",
            "the",
            "request"
        ]
    },
    {
        "id": 1310,
        "code": "default int aclCount() {\n    return -1;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "number",
            "of",
            "acls",
            "for",
            "the",
            "purpose",
            "of",
            "metrics"
        ]
    },
    {
        "id": 1311,
        "code": "default AuthorizationResult authorizeByResourceType(AuthorizableRequestContext requestContext, AclOperation op, ResourceType resourceType) {\n    SecurityUtils.authorizeByResourceTypeCheckArgs(op, resourceType);\n\n        \n        \n    if (authorize(requestContext, Collections.singletonList(new Action(\n            op, new ResourcePattern(resourceType, \"hardcode\", PatternType.LITERAL),\n            0, true, false)))\n            .get(0) == AuthorizationResult.ALLOWED) {\n        return AuthorizationResult.ALLOWED;\n    }\n\n        \n        \n    ResourcePatternFilter resourceTypeFilter = new ResourcePatternFilter(\n        resourceType, null, PatternType.ANY);\n    AclBindingFilter aclFilter = new AclBindingFilter(\n        resourceTypeFilter, AccessControlEntryFilter.ANY);\n\n    EnumMap<PatternType, Set<String>> denyPatterns =\n        new EnumMap<PatternType, Set<String>>(PatternType.class) {{\n            put(PatternType.LITERAL, new HashSet<>());\n            put(PatternType.PREFIXED, new HashSet<>());\n        }};\n    EnumMap<PatternType, Set<String>> allowPatterns =\n        new EnumMap<PatternType, Set<String>>(PatternType.class) {{\n            put(PatternType.LITERAL, new HashSet<>());\n            put(PatternType.PREFIXED, new HashSet<>());\n        }};\n\n    boolean hasWildCardAllow = false;\n\n    KafkaPrincipal principal = new KafkaPrincipal(\n        requestContext.principal().getPrincipalType(),\n        requestContext.principal().getName());\n    String hostAddr = requestContext.clientAddress().getHostAddress();\n\n    for (AclBinding binding : acls(aclFilter)) {\n        if (!binding.entry().host().equals(hostAddr) && !binding.entry().host().equals(\"*\"))\n            continue;\n\n        if (!SecurityUtils.parseKafkaPrincipal(binding.entry().principal()).equals(principal)\n                && !binding.entry().principal().equals(\"User:*\"))\n            continue;\n\n        if (binding.entry().operation() != op\n                && binding.entry().operation() != AclOperation.ALL)\n            continue;\n\n        if (binding.entry().permissionType() == AclPermissionType.DENY) {\n            switch (binding.pattern().patternType()) {\n                case LITERAL:\n                        \n                    if (binding.pattern().name().equals(ResourcePattern.WILDCARD_RESOURCE))\n                        return AuthorizationResult.DENIED;\n                    denyPatterns.get(PatternType.LITERAL).add(binding.pattern().name());\n                    break;\n                case PREFIXED:\n                    denyPatterns.get(PatternType.PREFIXED).add(binding.pattern().name());\n                    break;\n                default:\n            }\n            continue;\n        }\n\n        if (binding.entry().permissionType() != AclPermissionType.ALLOW)\n            continue;\n\n        switch (binding.pattern().patternType()) {\n            case LITERAL:\n                if (binding.pattern().name().equals(ResourcePattern.WILDCARD_RESOURCE)) {\n                    hasWildCardAllow = true;\n                    continue;\n                }\n                allowPatterns.get(PatternType.LITERAL).add(binding.pattern().name());\n                break;\n            case PREFIXED:\n                allowPatterns.get(PatternType.PREFIXED).add(binding.pattern().name());\n                break;\n            default:\n        }\n    }\n\n    if (hasWildCardAllow) {\n        return AuthorizationResult.ALLOWED;\n    }\n\n        \n        \n    for (Map.Entry<PatternType, Set<String>> entry : allowPatterns.entrySet()) {\n        for (String allowStr : entry.getValue()) {\n            if (entry.getKey() == PatternType.LITERAL\n                    && denyPatterns.get(PatternType.LITERAL).contains(allowStr))\n                continue;\n            StringBuilder sb = new StringBuilder();\n            boolean hasDominatedDeny = false;\n            for (char ch : allowStr.toCharArray()) {\n                sb.append(ch);\n                if (denyPatterns.get(PatternType.PREFIXED).contains(sb.toString())) {\n                    hasDominatedDeny = true;\n                    break;\n                }\n            }\n            if (!hasDominatedDeny)\n                return AuthorizationResult.ALLOWED;\n        }\n    }\n\n    return AuthorizationResult.DENIED;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "caller",
            "is",
            "authorized",
            "to",
            "perform",
            "the",
            "given",
            "acl",
            "operation",
            "on",
            "at",
            "least",
            "one",
            "resource",
            "of",
            "the",
            "given",
            "type"
        ]
    },
    {
        "id": 1312,
        "code": "private static Set<TopicPartition> toSet(TopicPartition... arr) {\n    TreeSet<TopicPartition> set = new TreeSet<>(new Comparator<TopicPartition>() {\n        @Override\n        public int compare(TopicPartition o1, TopicPartition o2) {\n            return o1.toString().compareTo(o2.toString());\n        }\n    });\n    set.addAll(Arrays.asList(arr));\n    return set;\n}",
        "summary_tokens": [
            "create",
            "a",
            "set",
            "of",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 1313,
        "code": "public void testSessionless() {\n    Map<String, Uuid> topicIds = new HashMap<>();\n    Map<Uuid, String> topicNames = new HashMap<>();\n        \n    List<Short> versions = Arrays.asList((short) 12, ApiKeys.FETCH.latestVersion());\n    versions.forEach(version -> {\n        FetchSessionHandler handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n        FetchSessionHandler.Builder builder = handler.newBuilder();\n        addTopicId(topicIds, topicNames, \"foo\", version);\n        Uuid fooId = topicIds.getOrDefault(\"foo\", Uuid.ZERO_UUID);\n        builder.add(new TopicPartition(\"foo\", 0),\n                new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        builder.add(new TopicPartition(\"foo\", 1),\n                new FetchRequest.PartitionData(fooId, 10, 110, 210, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data = builder.build();\n        assertMapsEqual(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 110, 210)),\n                data.toSend(), data.sessionPartitions());\n        assertEquals(INVALID_SESSION_ID, data.metadata().sessionId());\n        assertEquals(INITIAL_EPOCH, data.metadata().epoch());\n\n        FetchResponse resp = FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID,\n            respMap(new RespEntry(\"foo\", 0, fooId, 0, 0),\n                    new RespEntry(\"foo\", 1, fooId, 0, 0)));\n        handler.handleResponse(resp, version);\n\n        FetchSessionHandler.Builder builder2 = handler.newBuilder();\n        builder2.add(new TopicPartition(\"foo\", 0),\n                new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data2 = builder2.build();\n        assertEquals(INVALID_SESSION_ID, data2.metadata().sessionId());\n        assertEquals(INITIAL_EPOCH, data2.metadata().epoch());\n        assertMapsEqual(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200)),\n                data2.toSend(), data2.sessionPartitions());\n    });\n}",
        "summary_tokens": [
            "test",
            "the",
            "handling",
            "of",
            "sessionless",
            "responses"
        ]
    },
    {
        "id": 1314,
        "code": "public void testIncrementals() {\n    Map<String, Uuid> topicIds = new HashMap<>();\n    Map<Uuid, String> topicNames = new HashMap<>();\n        \n    List<Short> versions = Arrays.asList((short) 12, ApiKeys.FETCH.latestVersion());\n    versions.forEach(version -> {\n        FetchSessionHandler handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n        FetchSessionHandler.Builder builder = handler.newBuilder();\n        addTopicId(topicIds, topicNames, \"foo\", version);\n        Uuid fooId = topicIds.getOrDefault(\"foo\", Uuid.ZERO_UUID);\n        TopicPartition foo0 = new TopicPartition(\"foo\", 0);\n        TopicPartition foo1 = new TopicPartition(\"foo\", 1);\n        builder.add(foo0, new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        builder.add(foo1, new FetchRequest.PartitionData(fooId, 10, 110, 210, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data = builder.build();\n        assertMapsEqual(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 110, 210)),\n                data.toSend(), data.sessionPartitions());\n        assertEquals(INVALID_SESSION_ID, data.metadata().sessionId());\n        assertEquals(INITIAL_EPOCH, data.metadata().epoch());\n\n        FetchResponse resp = FetchResponse.of(Errors.NONE, 0, 123,\n            respMap(new RespEntry(\"foo\", 0, fooId, 10, 20),\n                    new RespEntry(\"foo\", 1, fooId, 10, 20)));\n        handler.handleResponse(resp, version);\n\n            \n        FetchSessionHandler.Builder builder2 = handler.newBuilder();\n        addTopicId(topicIds, topicNames, \"bar\", version);\n        Uuid barId = topicIds.getOrDefault(\"bar\", Uuid.ZERO_UUID);\n        TopicPartition bar0 = new TopicPartition(\"bar\", 0);\n        builder2.add(foo0, new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        builder2.add(foo1, new FetchRequest.PartitionData(fooId, 10, 120, 210, Optional.empty()));\n        builder2.add(bar0, new FetchRequest.PartitionData(barId, 20, 200, 200, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data2 = builder2.build();\n        assertFalse(data2.metadata().isFull());\n        assertMapEquals(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 120, 210),\n                new ReqEntry(\"bar\", barId, 0, 20, 200, 200)),\n                data2.sessionPartitions());\n        assertMapEquals(reqMap(new ReqEntry(\"bar\", barId, 0, 20, 200, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 120, 210)),\n                data2.toSend());\n\n        FetchResponse resp2 = FetchResponse.of(Errors.NONE, 0, 123,\n            respMap(new RespEntry(\"foo\", 1, fooId, 20, 20)));\n        handler.handleResponse(resp2, version);\n\n            \n            \n        FetchResponse resp3 = FetchResponse.of(Errors.INVALID_FETCH_SESSION_EPOCH, 0, INVALID_SESSION_ID,\n            respMap());\n        handler.handleResponse(resp3, version);\n\n        FetchSessionHandler.Builder builder4 = handler.newBuilder();\n        builder4.add(foo0, new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        builder4.add(foo1, new FetchRequest.PartitionData(fooId, 10, 120, 210, Optional.empty()));\n        builder4.add(bar0, new FetchRequest.PartitionData(barId, 20, 200, 200, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data4 = builder4.build();\n        assertTrue(data4.metadata().isFull());\n        assertEquals(data2.metadata().sessionId(), data4.metadata().sessionId());\n        assertEquals(INITIAL_EPOCH, data4.metadata().epoch());\n        assertMapsEqual(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 120, 210),\n                new ReqEntry(\"bar\", barId, 0, 20, 200, 200)),\n                data4.sessionPartitions(), data4.toSend());\n    });\n}",
        "summary_tokens": [
            "test",
            "handling",
            "an",
            "incremental",
            "fetch",
            "session"
        ]
    },
    {
        "id": 1315,
        "code": "public void testDoubleBuild() {\n    FetchSessionHandler handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n    FetchSessionHandler.Builder builder = handler.newBuilder();\n    builder.add(new TopicPartition(\"foo\", 0),\n        new FetchRequest.PartitionData(Uuid.randomUuid(), 0, 100, 200, Optional.empty()));\n    builder.build();\n    try {\n        builder.build();\n        fail(\"Expected calling build twice to fail.\");\n    } catch (Throwable t) {\n            \n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "calling",
            "fetch",
            "session",
            "handler",
            "builder",
            "build",
            "twice",
            "fails"
        ]
    },
    {
        "id": 1316,
        "code": "public void testIgnoreLeaderEpochInOlderMetadataResponse() {\n    TopicPartition tp = new TopicPartition(\"topic\", 0);\n\n    MetadataResponsePartition partitionMetadata = new MetadataResponsePartition()\n            .setPartitionIndex(tp.partition())\n            .setLeaderId(5)\n            .setLeaderEpoch(10)\n            .setReplicaNodes(Arrays.asList(1, 2, 3))\n            .setIsrNodes(Arrays.asList(1, 2, 3))\n            .setOfflineReplicas(Collections.emptyList())\n            .setErrorCode(Errors.NONE.code());\n\n    MetadataResponseTopic topicMetadata = new MetadataResponseTopic()\n            .setName(tp.topic())\n            .setErrorCode(Errors.NONE.code())\n            .setPartitions(Collections.singletonList(partitionMetadata))\n            .setIsInternal(false);\n\n    MetadataResponseTopicCollection topics = new MetadataResponseTopicCollection();\n    topics.add(topicMetadata);\n\n    MetadataResponseData data = new MetadataResponseData()\n            .setClusterId(\"clusterId\")\n            .setControllerId(0)\n            .setTopics(topics)\n            .setBrokers(new MetadataResponseBrokerCollection());\n\n    for (short version = ApiKeys.METADATA.oldestVersion(); version < 9; version++) {\n        ByteBuffer buffer = MessageUtil.toByteBuffer(data, version);\n        MetadataResponse response = MetadataResponse.parse(buffer, version);\n        assertFalse(response.hasReliableLeaderEpochs());\n        metadata.updateWithCurrentRequestVersion(response, false, 100);\n        assertTrue(metadata.partitionMetadataIfCurrent(tp).isPresent());\n        MetadataResponse.PartitionMetadata responseMetadata = this.metadata.partitionMetadataIfCurrent(tp).get();\n        assertEquals(Optional.empty(), responseMetadata.leaderEpoch);\n    }\n\n    for (short version = 9; version <= ApiKeys.METADATA.latestVersion(); version++) {\n        ByteBuffer buffer = MessageUtil.toByteBuffer(data, version);\n        MetadataResponse response = MetadataResponse.parse(buffer, version);\n        assertTrue(response.hasReliableLeaderEpochs());\n        metadata.updateWithCurrentRequestVersion(response, false, 100);\n        assertTrue(metadata.partitionMetadataIfCurrent(tp).isPresent());\n        MetadataResponse.PartitionMetadata responseMetadata = metadata.partitionMetadataIfCurrent(tp).get();\n        assertEquals(Optional.of(10), responseMetadata.leaderEpoch);\n    }\n}",
        "summary_tokens": [
            "prior",
            "to",
            "kafka",
            "version",
            "0"
        ]
    },
    {
        "id": 1317,
        "code": "public synchronized void enableBlockingUntilWakeup(int numBlockingWakeups) {\n    this.numBlockingWakeups = numBlockingWakeups;\n}",
        "summary_tokens": [
            "simulate",
            "a",
            "blocking",
            "poll",
            "in",
            "order",
            "to",
            "test",
            "wakeup",
            "behavior"
        ]
    },
    {
        "id": 1318,
        "code": "public void prepareResponse(RequestMatcher matcher, AbstractResponse response, boolean disconnected) {\n    prepareResponseFrom(matcher, response, null, disconnected, false);\n}",
        "summary_tokens": [
            "prepare",
            "a",
            "response",
            "for",
            "a",
            "request",
            "matching",
            "the",
            "provided",
            "matcher"
        ]
    },
    {
        "id": 1319,
        "code": "public void prepareUnsupportedVersionResponse(RequestMatcher matcher) {\n    prepareResponseFrom(matcher, null, null, false, true);\n}",
        "summary_tokens": [
            "raise",
            "an",
            "unsupported",
            "version",
            "error",
            "on",
            "the",
            "next",
            "request",
            "if",
            "it",
            "matches",
            "the",
            "given",
            "matcher"
        ]
    },
    {
        "id": 1320,
        "code": "public static ListPartitionReassignmentsResult listPartitionReassignmentsResult(Throwable t) {\n    KafkaFutureImpl<Map<TopicPartition, PartitionReassignment>> future = new KafkaFutureImpl<>();\n    future.completeExceptionally(t);\n    return new ListPartitionReassignmentsResult(future);\n}",
        "summary_tokens": [
            "helper",
            "to",
            "create",
            "a",
            "list",
            "partition",
            "reassignments",
            "result",
            "instance",
            "for",
            "a",
            "given",
            "throwable"
        ]
    },
    {
        "id": 1321,
        "code": "public static CreateTopicsResult createTopicsResult(String topic, Throwable t) {\n    KafkaFutureImpl<TopicMetadataAndConfig> future = new KafkaFutureImpl<>();\n    future.completeExceptionally(t);\n    return new CreateTopicsResult(Collections.singletonMap(topic, future));\n}",
        "summary_tokens": [
            "helper",
            "to",
            "create",
            "a",
            "create",
            "topics",
            "result",
            "instance",
            "for",
            "a",
            "given",
            "throwable"
        ]
    },
    {
        "id": 1322,
        "code": "public static DeleteTopicsResult deleteTopicsResult(String topic, Throwable t) {\n    KafkaFutureImpl<Void> future = new KafkaFutureImpl<>();\n    future.completeExceptionally(t);\n    return DeleteTopicsResult.ofTopicNames(Collections.singletonMap(topic, future));\n}",
        "summary_tokens": [
            "helper",
            "to",
            "create",
            "a",
            "delete",
            "topics",
            "result",
            "instance",
            "for",
            "a",
            "given",
            "throwable"
        ]
    },
    {
        "id": 1323,
        "code": "public static ListTopicsResult listTopicsResult(String topic) {\n    KafkaFutureImpl<Map<String, TopicListing>> future = new KafkaFutureImpl<>();\n    future.complete(Collections.singletonMap(topic, new TopicListing(topic, Uuid.ZERO_UUID, false)));\n    return new ListTopicsResult(future);\n}",
        "summary_tokens": [
            "helper",
            "to",
            "create",
            "a",
            "list",
            "topics",
            "result",
            "instance",
            "for",
            "a",
            "given",
            "topic"
        ]
    },
    {
        "id": 1324,
        "code": "public static CreatePartitionsResult createPartitionsResult(String topic, Throwable t) {\n    KafkaFutureImpl<Void> future = new KafkaFutureImpl<>();\n    future.completeExceptionally(t);\n    return new CreatePartitionsResult(Collections.singletonMap(topic, future));\n}",
        "summary_tokens": [
            "helper",
            "to",
            "create",
            "a",
            "create",
            "partitions",
            "result",
            "instance",
            "for",
            "a",
            "given",
            "throwable"
        ]
    },
    {
        "id": 1325,
        "code": "public static DescribeTopicsResult describeTopicsResult(String topic, TopicDescription description) {\n    KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n    future.complete(description);\n    return DescribeTopicsResult.ofTopicNames(Collections.singletonMap(topic, future));\n}",
        "summary_tokens": [
            "helper",
            "to",
            "create",
            "a",
            "describe",
            "topics",
            "result",
            "instance",
            "for",
            "a",
            "given",
            "topic"
        ]
    },
    {
        "id": 1326,
        "code": "public static Admin create(Map<String, Object> conf, HostResolver hostResolver) {\n    return KafkaAdminClient.createInternal(new AdminClientConfig(conf, true), null, hostResolver);\n}",
        "summary_tokens": [
            "helper",
            "to",
            "create",
            "a",
            "kafka",
            "admin",
            "client",
            "with",
            "a",
            "custom",
            "host",
            "resolver",
            "accessible",
            "to",
            "tests",
            "outside",
            "this",
            "package"
        ]
    },
    {
        "id": 1327,
        "code": "public void testCloseAdminClientInCallback() throws InterruptedException {\n    MockTime time = new MockTime();\n    AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(time, mockCluster(3, 0));\n\n    final ListTopicsResult result = env.adminClient().listTopics(new ListTopicsOptions().timeoutMs(1000));\n    final KafkaFuture<Collection<TopicListing>> kafkaFuture = result.listings();\n    final Semaphore callbackCalled = new Semaphore(0);\n    kafkaFuture.whenComplete((topicListings, throwable) -> {\n        env.close();\n        callbackCalled.release();\n    });\n\n    time.sleep(2000); \n    callbackCalled.acquire();\n}",
        "summary_tokens": [
            "test",
            "if",
            "admin",
            "client",
            "can",
            "be",
            "closed",
            "in",
            "the",
            "callback",
            "invoked",
            "when",
            "an",
            "api",
            "call",
            "completes"
        ]
    },
    {
        "id": 1328,
        "code": "public void testTimeoutWithoutMetadata() throws Exception {\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(Time.SYSTEM, mockBootstrapCluster(),\n            newStrMap(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"10\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        env.kafkaClient().prepareResponse(prepareCreateTopicsResponse(\"myTopic\", Errors.NONE));\n        KafkaFuture<Void> future = env.adminClient().createTopics(\n                singleton(new NewTopic(\"myTopic\", Collections.singletonMap(0, asList(0, 1, 2)))),\n                new CreateTopicsOptions().timeoutMs(1000)).all();\n        TestUtils.assertFutureError(future, TimeoutException.class);\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "the",
            "client",
            "properly",
            "times",
            "out",
            "when",
            "we",
            "don",
            "t",
            "receive",
            "any",
            "metadata"
        ]
    },
    {
        "id": 1329,
        "code": "public void testPropagatedMetadataFetchException() throws Exception {\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(Time.SYSTEM,\n            mockCluster(3, 0),\n            newStrMap(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:8121\",\n            AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"10\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        env.kafkaClient().createPendingAuthenticationError(env.cluster().nodeById(0),\n                TimeUnit.DAYS.toMillis(1));\n        env.kafkaClient().prepareResponse(prepareCreateTopicsResponse(\"myTopic\", Errors.NONE));\n        KafkaFuture<Void> future = env.adminClient().createTopics(\n            singleton(new NewTopic(\"myTopic\", Collections.singletonMap(0, asList(0, 1, 2)))),\n            new CreateTopicsOptions().timeoutMs(1000)).all();\n        TestUtils.assertFutureError(future, SaslAuthenticationException.class);\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "we",
            "propagate",
            "exceptions",
            "encountered",
            "when",
            "fetching",
            "metadata"
        ]
    },
    {
        "id": 1330,
        "code": "public void testClientSideTimeoutAfterFailureToSend() throws Exception {\n    Cluster cluster = mockCluster(3, 0);\n    CompletableFuture<String> disconnectFuture = new CompletableFuture<>();\n    MockTime time = new MockTime();\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(time, cluster,\n            newStrMap(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"1\",\n                      AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG, \"100000\",\n                      AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, \"1\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        for (Node node : cluster.nodes()) {\n            env.kafkaClient().delayReady(node, 100);\n        }\n\n            \n            \n            \n        CountDownLatch readyLatch = new CountDownLatch(2);\n\n        env.kafkaClient().setDisconnectFuture(disconnectFuture);\n        env.kafkaClient().setReadyCallback(node -> readyLatch.countDown());\n        env.kafkaClient().prepareResponse(prepareMetadataResponse(cluster, Errors.NONE));\n\n        final ListTopicsResult result = env.adminClient().listTopics();\n\n        readyLatch.await(TestUtils.DEFAULT_MAX_WAIT_MS, TimeUnit.MILLISECONDS);\n        log.debug(\"Advancing clock by 25 ms to trigger client-side disconnect.\");\n        time.sleep(25);\n        disconnectFuture.get();\n\n        log.debug(\"Enabling nodes to send requests again.\");\n        for (Node node : cluster.nodes()) {\n            env.kafkaClient().delayReady(node, 0);\n        }\n        time.sleep(5);\n        log.info(\"Waiting for result.\");\n        assertEquals(0, result.listings().get().size());\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "if",
            "the",
            "client",
            "can",
            "obtain",
            "a",
            "node",
            "assignment",
            "but",
            "can",
            "t",
            "send",
            "to",
            "the",
            "given",
            "node",
            "it",
            "will",
            "disconnect",
            "and",
            "try",
            "a",
            "different",
            "node"
        ]
    },
    {
        "id": 1331,
        "code": "public void testClientSideTimeoutAfterFailureToReceiveResponse() throws Exception {\n    Cluster cluster = mockCluster(3, 0);\n    CompletableFuture<String> disconnectFuture = new CompletableFuture<>();\n    MockTime time = new MockTime();\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(time, cluster,\n        newStrMap(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"1\",\n            AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG, \"100000\",\n            AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, \"0\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        env.kafkaClient().setDisconnectFuture(disconnectFuture);\n        final ListTopicsResult result = env.adminClient().listTopics();\n        TestUtils.waitForCondition(() -> {\n            time.sleep(1);\n            return disconnectFuture.isDone();\n        }, 5000, 1, () -> \"Timed out waiting for expected disconnect\");\n        assertFalse(disconnectFuture.isCompletedExceptionally());\n        assertFalse(result.future.isDone());\n        TestUtils.waitForCondition(env.kafkaClient()::hasInFlightRequests,\n            \"Timed out waiting for retry\");\n        env.kafkaClient().respond(prepareMetadataResponse(cluster, Errors.NONE));\n        assertEquals(0, result.listings().get().size());\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "if",
            "the",
            "client",
            "can",
            "send",
            "to",
            "a",
            "node",
            "but",
            "doesn",
            "t",
            "receive",
            "a",
            "response",
            "it",
            "will",
            "disconnect",
            "and",
            "try",
            "a",
            "different",
            "node"
        ]
    },
    {
        "id": 1332,
        "code": "public void verifyValidityAndBalance(Map<String, Subscription> subscriptions,\n                                     Map<String, List<TopicPartition>> assignments,\n                                     Map<String, Integer> partitionsPerTopic) {\n    int rebalances = 0;\n        \n    while (verifyCooperativeValidity(subscriptions, assignments)) {\n\n            \n        for (Map.Entry<String, List<TopicPartition>> entry : assignments.entrySet()) {\n            String consumer = entry.getKey();\n            Subscription oldSubscription = subscriptions.get(consumer);\n            subscriptions.put(consumer, buildSubscription(oldSubscription.topics(), entry.getValue()));\n        }\n\n        assignments.clear();\n        assignments.putAll(assignor.assign(partitionsPerTopic, subscriptions));\n        ++rebalances;\n\n        assertTrue(rebalances <= 4);\n    }\n\n        \n    super.verifyValidityAndBalance(subscriptions, assignments, partitionsPerTopic);\n}",
        "summary_tokens": [
            "the",
            "cooperative",
            "assignor",
            "must",
            "do",
            "some",
            "additional",
            "work",
            "and",
            "verification",
            "of",
            "some",
            "assignments",
            "relative",
            "to",
            "the",
            "eager",
            "assignor",
            "since",
            "it",
            "may",
            "or",
            "may",
            "not",
            "need",
            "to",
            "trigger",
            "a",
            "second",
            "follow",
            "up",
            "rebalance"
        ]
    },
    {
        "id": 1333,
        "code": "public void testSubscriptionChangesWithAutoCommitEnabled() {\n    ConsumerMetadata metadata = createMetadata(subscription);\n    MockClient client = new MockClient(time, metadata);\n\n    Map<String, Integer> tpCounts = new HashMap<>();\n    tpCounts.put(topic, 1);\n    tpCounts.put(topic2, 1);\n    tpCounts.put(topic3, 1);\n    initMetadata(client, tpCounts);\n    Node node = metadata.fetch().nodes().get(0);\n\n    ConsumerPartitionAssignor assignor = new RangeAssignor();\n\n    KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor, true, groupInstanceId);\n\n        \n    consumer.subscribe(Arrays.asList(topic, topic2), getConsumerRebalanceListener(consumer));\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic2));\n    assertTrue(consumer.assignment().isEmpty());\n\n        \n    Node coordinator = prepareRebalance(client, node, assignor, Arrays.asList(tp0, t2p0), null);\n\n    consumer.updateAssignmentMetadataIfNeeded(time.timer(Long.MAX_VALUE));\n    consumer.poll(Duration.ZERO);\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic2));\n    assertEquals(2, consumer.assignment().size());\n    assertTrue(consumer.assignment().contains(tp0) && consumer.assignment().contains(t2p0));\n\n        \n    Map<TopicPartition, FetchInfo> fetches1 = new HashMap<>();\n    fetches1.put(tp0, new FetchInfo(0, 1));\n    fetches1.put(t2p0, new FetchInfo(0, 10));\n    client.respondFrom(fetchResponse(fetches1), node);\n    client.poll(0, time.milliseconds());\n\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1));\n\n        \n    fetches1.put(tp0, new FetchInfo(1, 0));\n    fetches1.put(t2p0, new FetchInfo(10, 0));\n    client.respondFrom(fetchResponse(fetches1), node);\n    client.poll(0, time.milliseconds());\n\n        \n    assertEquals(11, records.count());\n    assertEquals(1L, consumer.position(tp0));\n    assertEquals(10L, consumer.position(t2p0));\n\n        \n    consumer.subscribe(Arrays.asList(topic, topic3), getConsumerRebalanceListener(consumer));\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic3));\n    assertEquals(2, consumer.assignment().size());\n    assertTrue(consumer.assignment().contains(tp0) && consumer.assignment().contains(t2p0));\n\n        \n    Map<TopicPartition, Long> partitionOffsets1 = new HashMap<>();\n    partitionOffsets1.put(tp0, 1L);\n    partitionOffsets1.put(t2p0, 10L);\n    AtomicBoolean commitReceived = prepareOffsetCommitResponse(client, coordinator, partitionOffsets1);\n\n        \n    prepareRebalance(client, node, assignor, Arrays.asList(tp0, t3p0), coordinator);\n\n        \n    Map<TopicPartition, FetchInfo> fetches2 = new HashMap<>();\n    fetches2.put(tp0, new FetchInfo(1, 1));\n    fetches2.put(t3p0, new FetchInfo(0, 100));\n    client.prepareResponse(fetchResponse(fetches2));\n\n    records = consumer.poll(Duration.ofMillis(1));\n\n        \n    assertEquals(101, records.count());\n    assertEquals(2L, consumer.position(tp0));\n    assertEquals(100L, consumer.position(t3p0));\n\n        \n    assertTrue(commitReceived.get());\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic3));\n    assertEquals(2, consumer.assignment().size());\n    assertTrue(consumer.assignment().contains(tp0) && consumer.assignment().contains(t3p0));\n\n    consumer.unsubscribe();\n\n        \n    assertTrue(consumer.subscription().isEmpty());\n    assertTrue(consumer.assignment().isEmpty());\n\n    client.requests().clear();\n    consumer.close();\n}",
        "summary_tokens": [
            "verify",
            "that",
            "when",
            "a",
            "consumer",
            "changes",
            "its",
            "topic",
            "subscription",
            "its",
            "assigned",
            "partitions",
            "do",
            "not",
            "immediately",
            "change",
            "and",
            "the",
            "latest",
            "consumed",
            "offsets",
            "of",
            "its",
            "to",
            "be",
            "revoked",
            "partitions",
            "are",
            "properly",
            "committed",
            "when",
            "auto",
            "commit",
            "is",
            "enabled"
        ]
    },
    {
        "id": 1334,
        "code": "public void testSubscriptionChangesWithAutoCommitDisabled() {\n    ConsumerMetadata metadata = createMetadata(subscription);\n    MockClient client = new MockClient(time, metadata);\n\n    Map<String, Integer> tpCounts = new HashMap<>();\n    tpCounts.put(topic, 1);\n    tpCounts.put(topic2, 1);\n    initMetadata(client, tpCounts);\n    Node node = metadata.fetch().nodes().get(0);\n\n    ConsumerPartitionAssignor assignor = new RangeAssignor();\n\n    KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor, false, groupInstanceId);\n\n    initializeSubscriptionWithSingleTopic(consumer, getConsumerRebalanceListener(consumer));\n\n        \n    prepareRebalance(client, node, assignor, singletonList(tp0), null);\n\n    consumer.updateAssignmentMetadataIfNeeded(time.timer(Long.MAX_VALUE));\n    consumer.poll(Duration.ZERO);\n\n        \n    assertEquals(singleton(topic), consumer.subscription());\n    assertEquals(singleton(tp0), consumer.assignment());\n\n    consumer.poll(Duration.ZERO);\n\n        \n    consumer.subscribe(singleton(topic2), getConsumerRebalanceListener(consumer));\n\n        \n    assertEquals(singleton(topic2), consumer.subscription());\n    assertEquals(singleton(tp0), consumer.assignment());\n\n        \n    for (ClientRequest req: client.requests())\n        assertNotSame(ApiKeys.OFFSET_COMMIT, req.requestBuilder().apiKey());\n\n        \n    consumer.unsubscribe();\n\n        \n    assertEquals(Collections.emptySet(), consumer.subscription());\n    assertEquals(Collections.emptySet(), consumer.assignment());\n\n        \n    for (ClientRequest req: client.requests())\n        assertNotSame(ApiKeys.OFFSET_COMMIT, req.requestBuilder().apiKey());\n\n    client.requests().clear();\n    consumer.close();\n}",
        "summary_tokens": [
            "verify",
            "that",
            "when",
            "a",
            "consumer",
            "changes",
            "its",
            "topic",
            "subscription",
            "its",
            "assigned",
            "partitions",
            "do",
            "not",
            "immediately",
            "change",
            "and",
            "the",
            "consumed",
            "offsets",
            "of",
            "its",
            "to",
            "be",
            "revoked",
            "partitions",
            "are",
            "not",
            "committed",
            "when",
            "auto",
            "commit",
            "is",
            "disabled"
        ]
    },
    {
        "id": 1335,
        "code": "public void testConsumerOwningMinQuotaExpectedMaxQuota() {\n    Map<String, Integer> partitionsPerTopic = new HashMap<>();\n    partitionsPerTopic.put(topic1, 2);\n    partitionsPerTopic.put(topic2, 3);\n\n    List<String> subscribedTopics = topics(topic1, topic2);\n\n    subscriptions.put(consumer1,\n        buildSubscription(subscribedTopics, partitions(tp(topic1, 0), tp(topic2, 1))));\n    subscriptions.put(consumer2,\n        buildSubscription(subscribedTopics, partitions(tp(topic1, 1), tp(topic2, 2))));\n\n    Map<String, List<TopicPartition>> assignment = assignor.assign(partitionsPerTopic, subscriptions);\n    assertEquals(partitions(tp(topic1, 0), tp(topic2, 1), tp(topic2, 0)), assignment.get(consumer1));\n    assertEquals(partitions(tp(topic1, 1), tp(topic2, 2)), assignment.get(consumer2));\n    assertTrue(assignor.partitionsTransferringOwnership.isEmpty());\n\n    verifyValidityAndBalance(subscriptions, assignment, partitionsPerTopic);\n    assertTrue(isFullyBalanced(assignment));\n}",
        "summary_tokens": [
            "this",
            "unit",
            "test",
            "is",
            "testing",
            "consumer",
            "owned",
            "min",
            "quota",
            "partitions",
            "and",
            "expected",
            "to",
            "have",
            "max",
            "quota",
            "partitions",
            "situation"
        ]
    },
    {
        "id": 1336,
        "code": "public void testMaxQuotaConsumerMoreThanNumExpectedMaxCapacityMembers() {\n    Map<String, Integer> partitionsPerTopic = new HashMap<>();\n    partitionsPerTopic.put(topic1, 2);\n    partitionsPerTopic.put(topic2, 2);\n\n    List<String> subscribedTopics = topics(topic1, topic2);\n\n    subscriptions.put(consumer1,\n        buildSubscription(subscribedTopics, partitions(tp(topic1, 0), tp(topic2, 0))));\n    subscriptions.put(consumer2,\n        buildSubscription(subscribedTopics, partitions(tp(topic1, 1), tp(topic2, 1))));\n    subscriptions.put(consumer3, buildSubscription(subscribedTopics, Collections.emptyList()));\n\n    Map<String, List<TopicPartition>> assignment = assignor.assign(partitionsPerTopic, subscriptions);\n    assertEquals(Collections.singletonMap(tp(topic2, 0), consumer3), assignor.partitionsTransferringOwnership);\n\n    verifyValidityAndBalance(subscriptions, assignment, partitionsPerTopic);\n    assertEquals(partitions(tp(topic1, 0)), assignment.get(consumer1));\n    assertEquals(partitions(tp(topic1, 1), tp(topic2, 1)), assignment.get(consumer2));\n    assertEquals(partitions(tp(topic2, 0)), assignment.get(consumer3));\n\n    assertTrue(isFullyBalanced(assignment));\n}",
        "summary_tokens": [
            "this",
            "unit",
            "test",
            "is",
            "testing",
            "consumers",
            "owned",
            "max",
            "quota",
            "partitions",
            "are",
            "more",
            "than",
            "num",
            "expected",
            "max",
            "capacity",
            "members",
            "situation"
        ]
    },
    {
        "id": 1337,
        "code": "public void testAllConsumersAreUnderMinQuota() {\n    Map<String, Integer> partitionsPerTopic = new HashMap<>();\n    partitionsPerTopic.put(topic1, 2);\n    partitionsPerTopic.put(topic2, 3);\n\n    List<String> subscribedTopics = topics(topic1, topic2);\n\n    subscriptions.put(consumer1,\n        buildSubscription(subscribedTopics, partitions(tp(topic1, 0))));\n    subscriptions.put(consumer2,\n        buildSubscription(subscribedTopics, partitions(tp(topic1, 1))));\n    subscriptions.put(consumer3, buildSubscription(subscribedTopics, Collections.emptyList()));\n\n    Map<String, List<TopicPartition>> assignment = assignor.assign(partitionsPerTopic, subscriptions);\n    assertTrue(assignor.partitionsTransferringOwnership.isEmpty());\n\n    verifyValidityAndBalance(subscriptions, assignment, partitionsPerTopic);\n    assertEquals(partitions(tp(topic1, 0), tp(topic2, 1)), assignment.get(consumer1));\n    assertEquals(partitions(tp(topic1, 1), tp(topic2, 2)), assignment.get(consumer2));\n    assertEquals(partitions(tp(topic2, 0)), assignment.get(consumer3));\n\n    assertTrue(isFullyBalanced(assignment));\n}",
        "summary_tokens": [
            "this",
            "unit",
            "test",
            "is",
            "testing",
            "all",
            "consumers",
            "owned",
            "less",
            "than",
            "min",
            "quota",
            "partitions",
            "situation"
        ]
    },
    {
        "id": 1338,
        "code": "public void testPoorRoundRobinAssignmentScenario() {\n    Map<String, Integer> partitionsPerTopic = new HashMap<>();\n    for (int i = 1; i <= 5; i++)\n        partitionsPerTopic.put(String.format(\"topic%d\", i), (i % 2) + 1);\n\n    subscriptions.put(\"consumer1\",\n        new Subscription(topics(\"topic1\", \"topic2\", \"topic3\", \"topic4\", \"topic5\")));\n    subscriptions.put(\"consumer2\",\n        new Subscription(topics(\"topic1\", \"topic3\", \"topic5\")));\n    subscriptions.put(\"consumer3\",\n        new Subscription(topics(\"topic1\", \"topic3\", \"topic5\")));\n    subscriptions.put(\"consumer4\",\n        new Subscription(topics(\"topic1\", \"topic2\", \"topic3\", \"topic4\", \"topic5\")));\n\n    Map<String, List<TopicPartition>> assignment = assignor.assign(partitionsPerTopic, subscriptions);\n    verifyValidityAndBalance(subscriptions, assignment, partitionsPerTopic);\n}",
        "summary_tokens": [
            "this",
            "unit",
            "test",
            "performs",
            "sticky",
            "assignment",
            "for",
            "a",
            "scenario",
            "that",
            "round",
            "robin",
            "assignor",
            "handles",
            "poorly"
        ]
    },
    {
        "id": 1339,
        "code": "protected void verifyValidityAndBalance(Map<String, Subscription> subscriptions,\n                                        Map<String, List<TopicPartition>> assignments,\n                                        Map<String, Integer> partitionsPerTopic) {\n    int size = subscriptions.size();\n    assert size == assignments.size();\n\n    List<String> consumers = Utils.sorted(assignments.keySet());\n\n    for (int i = 0; i < size; ++i) {\n        String consumer = consumers.get(i);\n        List<TopicPartition> partitions = assignments.get(consumer);\n        for (TopicPartition partition: partitions)\n            assertTrue(subscriptions.get(consumer).topics().contains(partition.topic()),\n                \"Error: Partition \" + partition + \"is assigned to c\" + i + \", but it is not subscribed to Topic t\" +\n                partition.topic() + \"\\nSubscriptions: \" + subscriptions + \"\\nAssignments: \" + assignments);\n\n        if (i == size - 1)\n            continue;\n\n        for (int j = i + 1; j < size; ++j) {\n            String otherConsumer = consumers.get(j);\n            List<TopicPartition> otherPartitions = assignments.get(otherConsumer);\n\n            Set<TopicPartition> intersection = new HashSet<>(partitions);\n            intersection.retainAll(otherPartitions);\n            assertTrue(intersection.isEmpty(),\n                \"Error: Consumers c\" + i + \" and c\" + j + \" have common partitions assigned to them: \" + intersection +\n                \"\\nSubscriptions: \" + subscriptions + \"\\nAssignments: \" + assignments);\n\n            int len = partitions.size();\n            int otherLen = otherPartitions.size();\n\n            if (Math.abs(len - otherLen) <= 1)\n                continue;\n\n            Map<String, List<Integer>> map = CollectionUtils.groupPartitionsByTopic(partitions);\n            Map<String, List<Integer>> otherMap = CollectionUtils.groupPartitionsByTopic(otherPartitions);\n\n            int moreLoaded = len > otherLen ? i : j;\n            int lessLoaded = len > otherLen ? j : i;\n\n                \n            for (String topic: map.keySet()) {\n                assertFalse(otherMap.containsKey(topic),\n                    \"Error: Some partitions can be moved from c\" + moreLoaded + \" to c\" + lessLoaded + \" to achieve a better balance\" +\n                    \"\\nc\" + i + \" has \" + len + \" partitions, and c\" + j + \" has \" + otherLen + \" partitions.\" +\n                    \"\\nSubscriptions: \" + subscriptions +\n                    \"\\nAssignments: \" + assignments);\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "the",
            "given",
            "assignment",
            "is",
            "valid",
            "with",
            "respect",
            "to",
            "the",
            "given",
            "subscriptions",
            "validity",
            "requirements",
            "each",
            "consumer",
            "is",
            "subscribed",
            "to",
            "topics",
            "of",
            "all",
            "partitions",
            "assigned",
            "to",
            "it",
            "and",
            "each",
            "partition",
            "is",
            "assigned",
            "to",
            "no",
            "more",
            "than",
            "one",
            "consumer",
            "balance",
            "requirements",
            "the",
            "assignment",
            "is",
            "fully",
            "balanced",
            "the",
            "numbers",
            "of",
            "topic",
            "partitions",
            "assigned",
            "to",
            "consumers",
            "differ",
            "by",
            "at",
            "most",
            "one",
            "or",
            "there",
            "is",
            "no",
            "topic",
            "partition",
            "that",
            "can",
            "be",
            "moved",
            "from",
            "one",
            "consumer",
            "to",
            "another",
            "with",
            "0",
            "fewer",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 1340,
        "code": "public void testRebalanceWithMetadataChange() {\n    final String consumerId = \"leader\";\n    final List<String> topics = Arrays.asList(topic1, topic2);\n    final List<TopicPartition> partitions = Arrays.asList(t1p, t2p);\n    subscriptions.subscribe(toSet(topics), rebalanceListener);\n    client.updateMetadata(RequestTestUtils.metadataUpdateWith(1,\n            Utils.mkMap(Utils.mkEntry(topic1, 1), Utils.mkEntry(topic2, 1))));\n    coordinator.maybeUpdateSubscriptionMetadata();\n\n    client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));\n    coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE));\n\n    Map<String, List<String>> initialSubscription = singletonMap(consumerId, topics);\n    partitionAssignor.prepare(singletonMap(consumerId, partitions));\n\n    client.prepareResponse(joinGroupLeaderResponse(1, consumerId, initialSubscription, Errors.NONE));\n    client.prepareResponse(syncGroupResponse(partitions, Errors.NONE));\n    coordinator.poll(time.timer(Long.MAX_VALUE));\n\n        \n    assertFalse(coordinator.rejoinNeededOrPending());\n    assertEquals(toSet(topics), subscriptions.subscription());\n    assertEquals(toSet(partitions), subscriptions.assignedPartitions());\n    assertEquals(0, rebalanceListener.revokedCount);\n    assertNull(rebalanceListener.revoked);\n    assertEquals(1, rebalanceListener.assignedCount);\n\n        \n    client.updateMetadata(RequestTestUtils.metadataUpdateWith(1, singletonMap(topic1, 1)));\n    coordinator.poll(time.timer(0));\n\n        \n        \n    client.updateMetadata(RequestTestUtils.metadataUpdateWith(1,\n            Utils.mkMap(Utils.mkEntry(topic1, 1), Utils.mkEntry(topic2, 1))));\n    client.respond(joinGroupFollowerResponse(1, consumerId, \"leader\", Errors.NOT_COORDINATOR));\n    client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));\n    coordinator.poll(time.timer(0));\n    assertTrue(coordinator.rejoinNeededOrPending());\n\n    client.respond(request -> {\n        if (!(request instanceof JoinGroupRequest)) {\n            return false;\n        } else {\n            JoinGroupRequest joinRequest = (JoinGroupRequest) request;\n            return consumerId.equals(joinRequest.data().memberId());\n        }\n    }, joinGroupLeaderResponse(2, consumerId, initialSubscription, Errors.NONE));\n    client.prepareResponse(syncGroupResponse(partitions, Errors.NONE));\n    coordinator.poll(time.timer(Long.MAX_VALUE));\n\n    assertFalse(coordinator.rejoinNeededOrPending());\n    Collection<TopicPartition> revoked = getRevoked(partitions, partitions);\n    assertEquals(revoked.isEmpty() ? 0 : 1, rebalanceListener.revokedCount);\n    assertEquals(revoked.isEmpty() ? null : revoked, rebalanceListener.revoked);\n        \n    assertEquals(0, rebalanceListener.lostCount);\n    assertNull(rebalanceListener.lost);\n\n    Collection<TopicPartition> added = getAdded(partitions, partitions);\n    assertEquals(2, rebalanceListener.assignedCount);\n    assertEquals(added.isEmpty() ? Collections.emptySet() : toSet(partitions), rebalanceListener.assigned);\n    assertEquals(toSet(partitions), subscriptions.assignedPartitions());\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "the",
            "consumer",
            "re",
            "joins",
            "after",
            "a",
            "metadata",
            "change"
        ]
    },
    {
        "id": 1341,
        "code": "public void testPendingMemberShouldLeaveGroup() {\n    final String consumerId = \"consumer-id\";\n    subscriptions.subscribe(singleton(topic1), rebalanceListener);\n\n    client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));\n    coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE));\n\n        \n    client.prepareResponse(joinGroupFollowerResponse(-1, consumerId, \"leader-id\", Errors.MEMBER_ID_REQUIRED));\n\n        \n    coordinator.joinGroupIfNeeded(time.timer(0));\n\n    final AtomicBoolean received = new AtomicBoolean(false);\n    client.prepareResponse(body -> {\n        received.set(true);\n        LeaveGroupRequest leaveRequest = (LeaveGroupRequest) body;\n        return validateLeaveGroup(groupId, consumerId, leaveRequest);\n    }, new LeaveGroupResponse(new LeaveGroupResponseData().setErrorCode(Errors.NONE.code())));\n\n    coordinator.maybeLeaveGroup(\"pending member leaves\");\n    assertTrue(received.get());\n}",
        "summary_tokens": [
            "this",
            "test",
            "checks",
            "if",
            "a",
            "consumer",
            "that",
            "has",
            "a",
            "valid",
            "member",
            "id",
            "but",
            "an",
            "invalid",
            "generation",
            "org"
        ]
    },
    {
        "id": 1342,
        "code": "public void testSubscriptionChangeWithAuthorizationFailure() {\n        \n    subscriptions.subscribe(Utils.mkSet(topic1, topic2), rebalanceListener);\n    client.prepareMetadataUpdate(RequestTestUtils.metadataUpdateWith(\"kafka-cluster\", 1,\n            Collections.singletonMap(topic2, Errors.TOPIC_AUTHORIZATION_FAILED), singletonMap(topic1, 1)));\n    assertThrows(TopicAuthorizationException.class, () -> coordinator.poll(time.timer(Long.MAX_VALUE)));\n\n    client.respond(groupCoordinatorResponse(node, Errors.NONE));\n    coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE));\n\n        \n    client.prepareResponse(joinGroupLeaderResponse(0, consumerId, Collections.emptyMap(),\n            Errors.GROUP_AUTHORIZATION_FAILED));\n    assertThrows(GroupAuthorizationException.class, () -> coordinator.poll(time.timer(Long.MAX_VALUE)));\n\n        \n        \n    subscriptions.subscribe(Utils.mkSet(topic1), rebalanceListener);\n    assertEquals(Collections.singleton(topic1), subscriptions.metadataTopics());\n    client.prepareMetadataUpdate(RequestTestUtils.metadataUpdateWith(\"kafka-cluster\", 1,\n            Collections.emptyMap(), singletonMap(topic1, 1)));\n\n    Map<String, List<String>> memberSubscriptions = singletonMap(consumerId, singletonList(topic1));\n    partitionAssignor.prepare(singletonMap(consumerId, singletonList(t1p)));\n    client.prepareResponse(joinGroupLeaderResponse(1, consumerId, memberSubscriptions, Errors.NONE));\n    client.prepareResponse(syncGroupResponse(singletonList(t1p), Errors.NONE));\n    coordinator.poll(time.timer(Long.MAX_VALUE));\n\n    assertEquals(singleton(topic1), subscriptions.subscription());\n    assertEquals(singleton(topic1), subscriptions.metadataTopics());\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "subscription",
            "change",
            "updates",
            "subscription",
            "state",
            "correctly",
            "even",
            "after",
            "join",
            "group",
            "failures",
            "that",
            "don",
            "t",
            "re",
            "invoke",
            "on",
            "join",
            "prepare"
        ]
    },
    {
        "id": 1343,
        "code": "public void testFetchAfterPartitionWithFetchedRecordsIsUnassigned() {\n    buildFetcher(2);\n\n    List<ConsumerRecord<byte[], byte[]>> records;\n    assignFromUser(singleton(tp0));\n    subscriptions.seek(tp0, 1);\n\n        \n    client.prepareResponse(matchesOffset(tidp0, 1), fullFetchResponse(tidp0, this.records, Errors.NONE, 100L, 0));\n\n    assertEquals(1, fetcher.sendFetches());\n    consumerClient.poll(time.timer(0));\n    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> recordsByPartition = fetchedRecords();\n    records = recordsByPartition.get(tp0);\n    assertEquals(2, records.size());\n    assertEquals(3L, subscriptions.position(tp0).offset);\n    assertEquals(1, records.get(0).offset());\n    assertEquals(2, records.get(1).offset());\n\n    assignFromUser(singleton(tp1));\n    client.prepareResponse(matchesOffset(tidp1, 4), fullFetchResponse(tidp1, this.nextRecords, Errors.NONE, 100L, 0));\n    subscriptions.seek(tp1, 4);\n\n    assertEquals(1, fetcher.sendFetches());\n    consumerClient.poll(time.timer(0));\n    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> fetchedRecords = fetchedRecords();\n    assertNull(fetchedRecords.get(tp0));\n    records = fetchedRecords.get(tp1);\n    assertEquals(2, records.size());\n    assertEquals(6L, subscriptions.position(tp1).offset);\n    assertEquals(4, records.get(0).offset());\n    assertEquals(5, records.get(1).offset());\n}",
        "summary_tokens": [
            "test",
            "the",
            "scenario",
            "where",
            "a",
            "partition",
            "with",
            "fetched",
            "but",
            "not",
            "consumed",
            "records",
            "i"
        ]
    },
    {
        "id": 1344,
        "code": "public void testFetchRequestWhenRecordTooLarge() {\n    try {\n        buildFetcher();\n\n        client.setNodeApiVersions(NodeApiVersions.create(ApiKeys.FETCH.id, (short) 2, (short) 2));\n        makeFetchRequestWithIncompleteRecord();\n        try {\n            fetcher.collectFetch();\n            fail(\"RecordTooLargeException should have been raised\");\n        } catch (RecordTooLargeException e) {\n            assertTrue(e.getMessage().startsWith(\"There are some messages at [Partition=Offset]: \"));\n                \n            assertEquals(0, subscriptions.position(tp0).offset);\n        }\n    } finally {\n        client.setNodeApiVersions(NodeApiVersions.create());\n    }\n}",
        "summary_tokens": [
            "test",
            "the",
            "case",
            "where",
            "the",
            "client",
            "makes",
            "a",
            "pre",
            "v",
            "0",
            "fetch",
            "request",
            "but",
            "the",
            "server",
            "replies",
            "with",
            "only",
            "a",
            "partial",
            "request"
        ]
    },
    {
        "id": 1345,
        "code": "public void testFetchRequestInternalError() {\n    buildFetcher();\n    makeFetchRequestWithIncompleteRecord();\n    try {\n        fetcher.collectFetch();\n        fail(\"RecordTooLargeException should have been raised\");\n    } catch (KafkaException e) {\n        assertTrue(e.getMessage().startsWith(\"Failed to make progress reading messages\"));\n            \n        assertEquals(0, subscriptions.position(tp0).offset);\n    }\n}",
        "summary_tokens": [
            "test",
            "the",
            "case",
            "where",
            "the",
            "client",
            "makes",
            "a",
            "post",
            "kip",
            "0",
            "fetch",
            "request",
            "but",
            "the",
            "server",
            "replies",
            "with",
            "only",
            "a",
            "partial",
            "request"
        ]
    },
    {
        "id": 1346,
        "code": "public void testFetchOffsetErrors() {\n    buildFetcher();\n    assignFromUser(singleton(tp0));\n    subscriptions.requestOffsetReset(tp0, OffsetResetStrategy.LATEST);\n\n        \n    client.prepareResponse(listOffsetRequestMatcher(ListOffsetsRequest.LATEST_TIMESTAMP,\n        validLeaderEpoch), listOffsetResponse(Errors.OFFSET_NOT_AVAILABLE, 1L, 5L), false);\n    fetcher.resetOffsetsIfNeeded();\n    consumerClient.pollNoWakeup();\n    assertFalse(subscriptions.hasValidPosition(tp0));\n    assertTrue(subscriptions.isOffsetResetNeeded(tp0));\n    assertFalse(subscriptions.isFetchable(tp0));\n\n        \n    time.sleep(retryBackoffMs);\n    client.prepareResponse(listOffsetRequestMatcher(ListOffsetsRequest.LATEST_TIMESTAMP,\n        validLeaderEpoch), listOffsetResponse(Errors.LEADER_NOT_AVAILABLE, 1L, 5L), false);\n    fetcher.resetOffsetsIfNeeded();\n    consumerClient.pollNoWakeup();\n    assertFalse(subscriptions.hasValidPosition(tp0));\n    assertTrue(subscriptions.isOffsetResetNeeded(tp0));\n    assertFalse(subscriptions.isFetchable(tp0));\n\n        \n    time.sleep(retryBackoffMs);\n    client.prepareResponse(listOffsetRequestMatcher(ListOffsetsRequest.LATEST_TIMESTAMP),\n            listOffsetResponse(Errors.NONE, 1L, 5L), false);\n    fetcher.resetOffsetsIfNeeded();\n    consumerClient.pollNoWakeup();\n    assertTrue(subscriptions.hasValidPosition(tp0));\n    assertFalse(subscriptions.isOffsetResetNeeded(tp0));\n    assertTrue(subscriptions.isFetchable(tp0));\n    assertEquals(subscriptions.position(tp0).offset, 5L);\n}",
        "summary_tokens": [
            "make",
            "sure",
            "the",
            "client",
            "behaves",
            "appropriately",
            "when",
            "receiving",
            "an",
            "exception",
            "for",
            "unavailable",
            "offsets"
        ]
    },
    {
        "id": 1347,
        "code": "private void assertEmptyFetch(String reason) {\n    Fetch<?, ?> fetch = collectFetch();\n    assertEquals(Collections.emptyMap(), fetch.records(), reason);\n    assertFalse(fetch.positionAdvanced(), reason);\n    assertTrue(fetch.isEmpty(), reason);\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "fetcher",
            "collect",
            "fetch",
            "latest",
            "fetch",
            "does",
            "not",
            "contain",
            "any",
            "fetch",
            "records",
            "user",
            "visible",
            "records",
            "did",
            "not",
            "fetch",
            "position",
            "advanced",
            "advance",
            "the",
            "consumer",
            "s",
            "position",
            "and",
            "is",
            "fetch",
            "is",
            "empty",
            "empty"
        ]
    },
    {
        "id": 1348,
        "code": "public void testTimeout() throws Exception {\n    ProduceRequestResult request = new ProduceRequestResult(topicPartition);\n    FutureRecordMetadata future = new FutureRecordMetadata(request, relOffset,\n            RecordBatch.NO_TIMESTAMP, 0, 0, Time.SYSTEM);\n    assertFalse(future.isDone(), \"Request is not completed\");\n    try {\n        future.get(5, TimeUnit.MILLISECONDS);\n        fail(\"Should have thrown exception.\");\n    } catch (TimeoutException e) { \n    }\n\n    request.set(baseOffset, RecordBatch.NO_TIMESTAMP, null);\n    request.done();\n    assertTrue(future.isDone());\n    assertEquals(baseOffset + relOffset, future.get().offset());\n}",
        "summary_tokens": [
            "test",
            "that",
            "waiting",
            "on",
            "a",
            "request",
            "that",
            "never",
            "completes",
            "times",
            "out"
        ]
    },
    {
        "id": 1349,
        "code": "public void testError() throws Exception {\n    FutureRecordMetadata future = new FutureRecordMetadata(asyncRequest(baseOffset, new CorruptRecordException(), 50L),\n            relOffset, RecordBatch.NO_TIMESTAMP, 0, 0, Time.SYSTEM);\n    assertThrows(ExecutionException.class, future::get);\n}",
        "summary_tokens": [
            "test",
            "that",
            "an",
            "asynchronous",
            "request",
            "will",
            "eventually",
            "throw",
            "the",
            "right",
            "exception"
        ]
    },
    {
        "id": 1350,
        "code": "public void testBlocking() throws Exception {\n    FutureRecordMetadata future = new FutureRecordMetadata(asyncRequest(baseOffset, null, 50L),\n            relOffset, RecordBatch.NO_TIMESTAMP, 0, 0, Time.SYSTEM);\n    assertEquals(baseOffset + relOffset, future.get().offset());\n}",
        "summary_tokens": [
            "test",
            "that",
            "an",
            "asynchronous",
            "request",
            "will",
            "eventually",
            "return",
            "the",
            "right",
            "offset"
        ]
    },
    {
        "id": 1351,
        "code": "public void testSimple() throws Exception {\n    long totalMemory = 64 * 1024;\n    int size = 1024;\n    BufferPool pool = new BufferPool(totalMemory, size, metrics, time, metricGroup);\n    ByteBuffer buffer = pool.allocate(size, maxBlockTimeMs);\n    assertEquals(size, buffer.limit(), \"Buffer size should equal requested size.\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"Unallocated memory should have shrunk\");\n    assertEquals(totalMemory - size, pool.availableMemory(), \"Available memory should have shrunk\");\n    buffer.putInt(1);\n    buffer.flip();\n    pool.deallocate(buffer);\n    assertEquals(totalMemory, pool.availableMemory(), \"All memory should be available\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"But now some is on the free list\");\n    buffer = pool.allocate(size, maxBlockTimeMs);\n    assertEquals(0, buffer.position(), \"Recycled buffer should be cleared.\");\n    assertEquals(buffer.capacity(), buffer.limit(), \"Recycled buffer should be cleared.\");\n    pool.deallocate(buffer);\n    assertEquals(totalMemory, pool.availableMemory(), \"All memory should be available\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"Still a single buffer on the free list\");\n    buffer = pool.allocate(2 * size, maxBlockTimeMs);\n    pool.deallocate(buffer);\n    assertEquals(totalMemory, pool.availableMemory(), \"All memory should be available\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"Non-standard size didn't go to the free list.\");\n}",
        "summary_tokens": [
            "test",
            "the",
            "simple",
            "non",
            "blocking",
            "allocation",
            "paths"
        ]
    },
    {
        "id": 1352,
        "code": "public void testCantAllocateMoreMemoryThanWeHave() throws Exception {\n    BufferPool pool = new BufferPool(1024, 512, metrics, time, metricGroup);\n    ByteBuffer buffer = pool.allocate(1024, maxBlockTimeMs);\n    assertEquals(1024, buffer.limit());\n    pool.deallocate(buffer);\n    assertThrows(IllegalArgumentException.class, () -> pool.allocate(1025, maxBlockTimeMs));\n}",
        "summary_tokens": [
            "test",
            "that",
            "we",
            "cannot",
            "try",
            "to",
            "allocate",
            "more",
            "memory",
            "then",
            "we",
            "have",
            "in",
            "the",
            "whole",
            "pool"
        ]
    },
    {
        "id": 1353,
        "code": "public void testDelayedAllocation() throws Exception {\n    BufferPool pool = new BufferPool(5 * 1024, 1024, metrics, time, metricGroup);\n    ByteBuffer buffer = pool.allocate(1024, maxBlockTimeMs);\n    CountDownLatch doDealloc = asyncDeallocate(pool, buffer);\n    CountDownLatch allocation = asyncAllocate(pool, 5 * 1024);\n    assertEquals(1L, allocation.getCount(), \"Allocation shouldn't have happened yet, waiting on memory.\");\n    doDealloc.countDown(); \n    assertTrue(allocation.await(1, TimeUnit.SECONDS), \"Allocation should succeed soon after de-allocation\");\n}",
        "summary_tokens": [
            "test",
            "that",
            "delayed",
            "allocation",
            "blocks"
        ]
    },
    {
        "id": 1354,
        "code": "public void testBufferExhaustedExceptionIsThrown() throws Exception {\n    BufferPool pool = new BufferPool(2, 1, metrics, time, metricGroup);\n    pool.allocate(1, maxBlockTimeMs);\n    assertThrows(BufferExhaustedException.class, () -> pool.allocate(2, maxBlockTimeMs));\n}",
        "summary_tokens": [
            "test",
            "if",
            "buffer",
            "exhausted",
            "exception",
            "is",
            "thrown",
            "when",
            "there",
            "is",
            "not",
            "enough",
            "memory",
            "to",
            "allocate",
            "and",
            "the",
            "elapsed",
            "time",
            "is",
            "greater",
            "than",
            "the",
            "max",
            "specified",
            "block",
            "time"
        ]
    },
    {
        "id": 1355,
        "code": "public void testBlockTimeout() throws Exception {\n    BufferPool pool = new BufferPool(10, 1, metrics, Time.SYSTEM, metricGroup);\n    ByteBuffer buffer1 = pool.allocate(1, maxBlockTimeMs);\n    ByteBuffer buffer2 = pool.allocate(1, maxBlockTimeMs);\n    ByteBuffer buffer3 = pool.allocate(1, maxBlockTimeMs);\n        \n    delayedDeallocate(pool, buffer1, maxBlockTimeMs / 2);\n    delayedDeallocate(pool, buffer2, maxBlockTimeMs);\n        \n    delayedDeallocate(pool, buffer3, maxBlockTimeMs / 2 * 5);\n\n    long beginTimeMs = Time.SYSTEM.milliseconds();\n    try {\n        pool.allocate(10, maxBlockTimeMs);\n        fail(\"The buffer allocated more memory than its maximum value 10\");\n    } catch (BufferExhaustedException e) {\n            \n    }\n        \n    assertTrue(pool.availableMemory() >= 7 && pool.availableMemory() <= 10, \"available memory \" + pool.availableMemory());\n    long durationMs = Time.SYSTEM.milliseconds() - beginTimeMs;\n    assertTrue(durationMs >= maxBlockTimeMs, \"BufferExhaustedException should not throw before maxBlockTimeMs\");\n    assertTrue(durationMs < maxBlockTimeMs + 1000, \"BufferExhaustedException should throw soon after maxBlockTimeMs\");\n}",
        "summary_tokens": [
            "verify",
            "that",
            "a",
            "failed",
            "allocation",
            "attempt",
            "due",
            "to",
            "not",
            "enough",
            "memory",
            "finishes",
            "soon",
            "after",
            "the",
            "max",
            "block",
            "time",
            "ms"
        ]
    },
    {
        "id": 1356,
        "code": "public void testCleanupMemoryAvailabilityWaiterOnBlockTimeout() throws Exception {\n    BufferPool pool = new BufferPool(2, 1, metrics, time, metricGroup);\n    pool.allocate(1, maxBlockTimeMs);\n    try {\n        pool.allocate(2, maxBlockTimeMs);\n        fail(\"The buffer allocated more memory than its maximum value 2\");\n    } catch (BufferExhaustedException e) {\n            \n    }\n    assertEquals(0, pool.queued());\n    assertEquals(1, pool.availableMemory());\n}",
        "summary_tokens": [
            "test",
            "if",
            "the",
            "waiter",
            "that",
            "is",
            "waiting",
            "on",
            "availability",
            "of",
            "more",
            "memory",
            "is",
            "cleaned",
            "up",
            "when",
            "a",
            "timeout",
            "occurs"
        ]
    },
    {
        "id": 1357,
        "code": "public void testCleanupMemoryAvailabilityWaiterOnInterruption() throws Exception {\n    BufferPool pool = new BufferPool(2, 1, metrics, time, metricGroup);\n    long blockTime = 5000;\n    pool.allocate(1, maxBlockTimeMs);\n    Thread t1 = new Thread(new BufferPoolAllocator(pool, blockTime));\n    Thread t2 = new Thread(new BufferPoolAllocator(pool, blockTime));\n        \n    t1.start();\n        \n    Thread.sleep(500);\n    Deque<Condition> waiters = pool.waiters();\n        \n    Condition c1 = waiters.getFirst();\n        \n    t2.start();\n        \n    Thread.sleep(500);\n    t1.interrupt();\n        \n    Thread.sleep(500);\n        \n    Condition c2 = waiters.getLast();\n    t2.interrupt();\n    assertNotEquals(c1, c2);\n    t1.join();\n    t2.join();\n        \n    assertEquals(pool.queued(), 0);\n}",
        "summary_tokens": [
            "test",
            "if",
            "the",
            "waiter",
            "that",
            "is",
            "waiting",
            "on",
            "availability",
            "of",
            "more",
            "memory",
            "is",
            "cleaned",
            "up",
            "when",
            "an",
            "interruption",
            "occurs"
        ]
    },
    {
        "id": 1358,
        "code": "public void testStressfulSituation() throws Exception {\n    int numThreads = 10;\n    final int iterations = 50000;\n    final int poolableSize = 1024;\n    final long totalMemory = numThreads / 2 * poolableSize;\n    final BufferPool pool = new BufferPool(totalMemory, poolableSize, metrics, time, metricGroup);\n    List<StressTestThread> threads = new ArrayList<StressTestThread>();\n    for (int i = 0; i < numThreads; i++)\n        threads.add(new StressTestThread(pool, iterations));\n    for (StressTestThread thread : threads)\n        thread.start();\n    for (StressTestThread thread : threads)\n        thread.join();\n    for (StressTestThread thread : threads)\n        assertTrue(thread.success.get(), \"Thread should have completed all iterations successfully.\");\n    assertEquals(totalMemory, pool.availableMemory());\n}",
        "summary_tokens": [
            "this",
            "test",
            "creates",
            "lots",
            "of",
            "threads",
            "that",
            "hammer",
            "on",
            "the",
            "pool"
        ]
    },
    {
        "id": 1359,
        "code": "public void testBatchExpiration() {\n    long deliveryTimeoutMs = 10240;\n    ProducerBatch batch = new ProducerBatch(new TopicPartition(\"topic\", 1), memoryRecordsBuilder, now);\n        \n    assertFalse(batch.hasReachedDeliveryTimeout(deliveryTimeoutMs, now - 2));\n        \n    assertTrue(batch.hasReachedDeliveryTimeout(deliveryTimeoutMs, now + deliveryTimeoutMs));\n}",
        "summary_tokens": [
            "a",
            "producer",
            "batch",
            "configured",
            "using",
            "a",
            "timestamp",
            "preceding",
            "its",
            "create",
            "time",
            "is",
            "interpreted",
            "correctly",
            "as",
            "not",
            "expired",
            "by",
            "producer",
            "batch",
            "has",
            "reached",
            "delivery",
            "timeout",
            "long",
            "long"
        ]
    },
    {
        "id": 1360,
        "code": "public void testBatchExpirationAfterReenqueue() {\n    ProducerBatch batch = new ProducerBatch(new TopicPartition(\"topic\", 1), memoryRecordsBuilder, now);\n        \n    batch.reenqueued(now);\n        \n    assertFalse(batch.hasReachedDeliveryTimeout(10240, now - 2L));\n}",
        "summary_tokens": [
            "a",
            "producer",
            "batch",
            "configured",
            "using",
            "a",
            "timestamp",
            "preceding",
            "its",
            "create",
            "time",
            "is",
            "interpreted",
            "correctly",
            "as",
            "not",
            "expired",
            "by",
            "producer",
            "batch",
            "has",
            "reached",
            "delivery",
            "timeout",
            "long",
            "long"
        ]
    },
    {
        "id": 1361,
        "code": "private byte[] bytesWithGoodCompression(Random random) {\n    byte[] value = new byte[100];\n    ByteBuffer buffer = ByteBuffer.wrap(value);\n    while (buffer.remaining() > 0)\n        buffer.putInt(random.nextInt(1000));\n    return value;\n}",
        "summary_tokens": [
            "generates",
            "the",
            "compression",
            "ratio",
            "at",
            "about",
            "0"
        ]
    },
    {
        "id": 1362,
        "code": "private byte[] bytesWithPoorCompression(Random random, int size) {\n    byte[] value = new byte[size];\n    random.nextBytes(value);\n    return value;\n}",
        "summary_tokens": [
            "generates",
            "the",
            "compression",
            "ratio",
            "at",
            "about",
            "0"
        ]
    },
    {
        "id": 1363,
        "code": "private int expectedNumAppends(int batchSize) {\n    int size = 0;\n    int offsetDelta = 0;\n    while (true) {\n        int recordSize = DefaultRecord.sizeInBytes(offsetDelta, 0, key.length, value.length,\n            Record.EMPTY_HEADERS);\n        if (size + recordSize > batchSize)\n            return offsetDelta;\n        offsetDelta += 1;\n        size += recordSize;\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "offset",
            "delta"
        ]
    },
    {
        "id": 1364,
        "code": "private int expectedNumAppendsNoKey(int batchSize) {\n    int size = 0;\n    int offsetDelta = 0;\n    while (true) {\n        int recordSize = DefaultRecord.sizeInBytes(offsetDelta, 0, 0, value.length,\n            Record.EMPTY_HEADERS);\n        if (size + recordSize > batchSize)\n            return offsetDelta;\n        offsetDelta += 1;\n        size += recordSize;\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "offset",
            "delta",
            "when",
            "there",
            "is",
            "no",
            "key"
        ]
    },
    {
        "id": 1365,
        "code": "private RecordAccumulator createTestRecordAccumulator(\n    TransactionManager txnManager,\n    int deliveryTimeoutMs,\n    int batchSize,\n    long totalSize,\n    CompressionType type,\n    int lingerMs\n) {\n    long retryBackoffMs = 100L;\n    String metricGrpName = \"producer-metrics\";\n\n    return new RecordAccumulator(\n        logContext,\n        batchSize,\n        type,\n        lingerMs,\n        retryBackoffMs,\n        deliveryTimeoutMs,\n        metrics,\n        metricGrpName,\n        time,\n        new ApiVersions(),\n        txnManager,\n        new BufferPool(totalSize, batchSize, metrics, time, metricGrpName));\n}",
        "summary_tokens": [
            "return",
            "a",
            "test",
            "record",
            "accumulator",
            "instance"
        ]
    },
    {
        "id": 1366,
        "code": "public void testMetadataTopicExpiry() throws Exception {\n    long offset = 0;\n    client.updateMetadata(RequestTestUtils.metadataUpdateWith(1, Collections.singletonMap(\"test\", 2)));\n\n    Future<RecordMetadata> future = appendToAccumulator(tp0);\n    sender.runOnce();\n    assertTrue(metadata.containsTopic(tp0.topic()), \"Topic not added to metadata\");\n    client.updateMetadata(RequestTestUtils.metadataUpdateWith(1, Collections.singletonMap(\"test\", 2)));\n    sender.runOnce();  \n    client.respond(produceResponse(tp0, offset, Errors.NONE, 0));\n    sender.runOnce();\n    assertEquals(0, client.inFlightRequestCount(), \"Request completed.\");\n    assertFalse(client.hasInFlightRequests());\n    assertEquals(0, sender.inFlightBatches(tp0).size());\n    sender.runOnce();\n    assertTrue(future.isDone(), \"Request should be completed\");\n\n    assertTrue(metadata.containsTopic(tp0.topic()), \"Topic not retained in metadata list\");\n    time.sleep(TOPIC_IDLE_MS);\n    client.updateMetadata(RequestTestUtils.metadataUpdateWith(1, Collections.singletonMap(\"test\", 2)));\n    assertFalse(metadata.containsTopic(tp0.topic()), \"Unused topic has not been expired\");\n    future = appendToAccumulator(tp0);\n    sender.runOnce();\n    assertTrue(metadata.containsTopic(tp0.topic()), \"Topic not added to metadata\");\n    client.updateMetadata(RequestTestUtils.metadataUpdateWith(1, Collections.singletonMap(\"test\", 2)));\n    sender.runOnce();  \n    client.respond(produceResponse(tp0, offset + 1, Errors.NONE, 0));\n    sender.runOnce();\n    assertEquals(0, client.inFlightRequestCount(), \"Request completed.\");\n    assertFalse(client.hasInFlightRequests());\n    assertEquals(0, sender.inFlightBatches(tp0).size());\n    sender.runOnce();\n    assertTrue(future.isDone(), \"Request should be completed\");\n}",
        "summary_tokens": [
            "tests",
            "that",
            "topics",
            "are",
            "added",
            "to",
            "the",
            "metadata",
            "list",
            "when",
            "messages",
            "are",
            "available",
            "to",
            "send",
            "and",
            "expired",
            "if",
            "not",
            "used",
            "during",
            "a",
            "metadata",
            "refresh",
            "interval"
        ]
    },
    {
        "id": 1367,
        "code": "public void testInitProducerIdWithMaxInFlightOne() throws Exception {\n    final long producerId = 123456L;\n    createMockClientWithMaxFlightOneMetadataPending();\n\n        \n        \n    TransactionManager transactionManager = new TransactionManager(new LogContext(), \"testInitProducerIdWithPendingMetadataRequest\",\n            60000, 100L, new ApiVersions());\n    setupWithTransactionState(transactionManager, false, null, false);\n    ProducerIdAndEpoch producerIdAndEpoch = new ProducerIdAndEpoch(producerId, (short) 0);\n    transactionManager.initializeTransactions();\n    sender.runOnce();\n\n        \n        \n    MetadataResponse metadataUpdate = RequestTestUtils.metadataUpdateWith(1, Collections.emptyMap());\n    client.respond(metadataUpdate);\n    prepareFindCoordinatorResponse(Errors.NONE, \"testInitProducerIdWithPendingMetadataRequest\");\n    prepareInitProducerResponse(Errors.NONE, producerIdAndEpoch.producerId, producerIdAndEpoch.epoch);\n    waitForProducerId(transactionManager, producerIdAndEpoch);\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "init",
            "producer",
            "id",
            "of",
            "transactional",
            "producer",
            "succeeds",
            "even",
            "if",
            "metadata",
            "requests",
            "are",
            "pending",
            "with",
            "only",
            "one",
            "bootstrap",
            "node",
            "available",
            "and",
            "max",
            "in",
            "flight",
            "0",
            "where",
            "multiple",
            "polls",
            "are",
            "necessary",
            "to",
            "send",
            "requests"
        ]
    },
    {
        "id": 1368,
        "code": "public void testIdempotentInitProducerIdWithMaxInFlightOne() throws Exception {\n    final long producerId = 123456L;\n    createMockClientWithMaxFlightOneMetadataPending();\n\n        \n        \n    TransactionManager transactionManager = createTransactionManager();\n    setupWithTransactionState(transactionManager, false, null, false);\n    ProducerIdAndEpoch producerIdAndEpoch = new ProducerIdAndEpoch(producerId, (short) 0);\n\n        \n        \n    MetadataResponse metadataUpdate = RequestTestUtils.metadataUpdateWith(1, Collections.emptyMap());\n    client.respond(metadataUpdate);\n    sender.runOnce();\n    sender.runOnce();\n    client.respond(initProducerIdResponse(producerIdAndEpoch.producerId, producerIdAndEpoch.epoch, Errors.NONE));\n    waitForProducerId(transactionManager, producerIdAndEpoch);\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "init",
            "producer",
            "id",
            "of",
            "idempotent",
            "producer",
            "succeeds",
            "even",
            "if",
            "metadata",
            "requests",
            "are",
            "pending",
            "with",
            "only",
            "one",
            "bootstrap",
            "node",
            "available",
            "and",
            "max",
            "in",
            "flight",
            "0",
            "where",
            "multiple",
            "polls",
            "are",
            "necessary",
            "to",
            "send",
            "requests"
        ]
    },
    {
        "id": 1369,
        "code": "public void testNodeNotReady() {\n    final long producerId = 123456L;\n    time = new MockTime(10);\n    client = new MockClient(time, metadata);\n\n    TransactionManager transactionManager = new TransactionManager(new LogContext(), \"testNodeNotReady\",\n            60000, 100L, new ApiVersions());\n    setupWithTransactionState(transactionManager, false, null, true);\n    ProducerIdAndEpoch producerIdAndEpoch = new ProducerIdAndEpoch(producerId, (short) 0);\n    transactionManager.initializeTransactions();\n    sender.runOnce();\n\n    Node node = metadata.fetch().nodes().get(0);\n    client.delayReady(node, REQUEST_TIMEOUT + 20);\n    prepareFindCoordinatorResponse(Errors.NONE, \"testNodeNotReady\");\n    sender.runOnce();\n    sender.runOnce();\n    assertNotNull(transactionManager.coordinator(CoordinatorType.TRANSACTION), \"Coordinator not found\");\n\n    client.throttle(node, REQUEST_TIMEOUT + 20);\n    prepareFindCoordinatorResponse(Errors.NONE, \"Coordinator not found\");\n    prepareInitProducerResponse(Errors.NONE, producerIdAndEpoch.producerId, producerIdAndEpoch.epoch);\n    waitForProducerId(transactionManager, producerIdAndEpoch);\n}",
        "summary_tokens": [
            "tests",
            "the",
            "code",
            "path",
            "where",
            "the",
            "target",
            "node",
            "to",
            "send",
            "find",
            "coordinator",
            "or",
            "init",
            "producer",
            "id",
            "is",
            "not",
            "ready"
        ]
    },
    {
        "id": 1370,
        "code": "private void assertIsSuccessful(KafkaFuture<?> future) {\n    assertTrue(future.isDone());\n    assertFalse(future.isCompletedExceptionally());\n    assertFalse(future.isCancelled());\n}",
        "summary_tokens": [
            "asserts",
            "that",
            "the",
            "given",
            "future",
            "is",
            "done",
            "didn",
            "t",
            "fail",
            "and",
            "wasn",
            "t",
            "cancelled"
        ]
    },
    {
        "id": 1371,
        "code": "private void assertIsFailed(KafkaFuture<?> future) {\n    assertTrue(future.isDone());\n    assertFalse(future.isCancelled());\n    assertTrue(future.isCompletedExceptionally());\n}",
        "summary_tokens": [
            "asserts",
            "that",
            "the",
            "given",
            "future",
            "is",
            "done",
            "failed",
            "and",
            "wasn",
            "t",
            "cancelled"
        ]
    },
    {
        "id": 1372,
        "code": "private void assertIsCancelled(KafkaFuture<?> future) {\n    assertTrue(future.isDone());\n    assertTrue(future.isCancelled());\n    assertTrue(future.isCompletedExceptionally());\n    assertThrows(CancellationException.class, () -> future.getNow(null));\n    assertThrows(CancellationException.class, () -> future.get(0, TimeUnit.MILLISECONDS));\n}",
        "summary_tokens": [
            "asserts",
            "that",
            "the",
            "given",
            "future",
            "is",
            "done",
            "didn",
            "t",
            "fail",
            "and",
            "was",
            "cancelled"
        ]
    },
    {
        "id": 1373,
        "code": "public void testAllVersionsHaveSchemas() {\n    for (ApiMessageType type : ApiMessageType.values()) {\n        assertEquals(0, type.lowestSupportedVersion());\n\n        assertEquals(type.requestSchemas().length, type.responseSchemas().length);\n        for (Schema schema : type.requestSchemas())\n            assertNotNull(schema);\n        for (Schema schema : type.responseSchemas())\n            assertNotNull(schema);\n\n        assertEquals(type.highestSupportedVersion() + 1, type.requestSchemas().length);\n    }\n}",
        "summary_tokens": [
            "kafka",
            "currently",
            "supports",
            "direct",
            "upgrades",
            "from",
            "0"
        ]
    },
    {
        "id": 1374,
        "code": "private void testAllMessageRoundTripsBetweenVersions(short startVersion, short endVersion, Message message, Message expected) throws Exception {\n    for (short version = startVersion; version < endVersion; version++) {\n        testMessageRoundTrip(version, message, expected);\n    }\n}",
        "summary_tokens": [
            "start",
            "version",
            "the",
            "version",
            "we",
            "want",
            "to",
            "start",
            "at",
            "inclusive",
            "end",
            "version",
            "the",
            "version",
            "we",
            "want",
            "to",
            "end",
            "at",
            "exclusive"
        ]
    },
    {
        "id": 1375,
        "code": "public void testMessageVersions() {\n    for (ApiKeys apiKey : ApiKeys.values()) {\n        Message message = null;\n        try {\n            message = ApiMessageType.fromApiKey(apiKey.id).newRequest();\n        } catch (UnsupportedVersionException e) {\n            fail(\"No request message spec found for API \" + apiKey);\n        }\n        assertTrue(apiKey.latestVersion() <= message.highestSupportedVersion(),\n            \"Request message spec for \" + apiKey + \" only \" + \"supports versions up to \" +\n            message.highestSupportedVersion());\n        try {\n            message = ApiMessageType.fromApiKey(apiKey.id).newResponse();\n        } catch (UnsupportedVersionException e) {\n            fail(\"No response message spec found for API \" + apiKey);\n        }\n        assertTrue(apiKey.latestVersion() <= message.highestSupportedVersion(),\n            \"Response message spec for \" + apiKey + \" only \" + \"supports versions up to \" +\n            message.highestSupportedVersion());\n    }\n}",
        "summary_tokens": [
            "verify",
            "that",
            "the",
            "json",
            "files",
            "support",
            "the",
            "same",
            "message",
            "versions",
            "as",
            "the",
            "schemas",
            "accessible",
            "through",
            "the",
            "api",
            "key",
            "class"
        ]
    },
    {
        "id": 1376,
        "code": "public void testMyTaggedStruct() {\n        \n    SimpleExampleMessageData.TaggedStruct myStruct =\n        new SimpleExampleMessageData.TaggedStruct().setStructId(\"abc\");\n    testRoundTrip(new SimpleExampleMessageData().setMyTaggedStruct(myStruct),\n        message -> assertEquals(myStruct, message.myTaggedStruct()), (short) 2);\n\n        \n    testRoundTrip(new SimpleExampleMessageData().setMyString(\"abc\"),\n        message -> assertEquals(\"abc\", message.myString()), (short) 1);\n    testRoundTrip(new SimpleExampleMessageData().setMyString(\"abc\"),\n        message -> assertEquals(\"abc\", message.myString()), (short) 2);\n}",
        "summary_tokens": [
            "check",
            "following",
            "cases",
            "0"
        ]
    },
    {
        "id": 1377,
        "code": "public void testSampledStatReturnsNaNWhenNoValuesExist() {\n        \n        \n    Max max = new Max();\n    Min min = new Min();\n    Avg avg = new Avg();\n    long windowMs = 100;\n    int samples = 2;\n    MetricConfig config = new MetricConfig().timeWindow(windowMs, TimeUnit.MILLISECONDS).samples(samples);\n    max.record(config, 50, time.milliseconds());\n    min.record(config, 50, time.milliseconds());\n    avg.record(config, 50, time.milliseconds());\n\n    time.sleep(samples * windowMs);\n\n    assertEquals(Double.NaN, max.measure(config, time.milliseconds()), EPS);\n    assertEquals(Double.NaN, min.measure(config, time.milliseconds()), EPS);\n    assertEquals(Double.NaN, avg.measure(config, time.milliseconds()), EPS);\n}",
        "summary_tokens": [
            "some",
            "implementations",
            "of",
            "sampled",
            "stat",
            "make",
            "sense",
            "to",
            "return",
            "na",
            "n",
            "when",
            "there",
            "are",
            "no",
            "values",
            "set",
            "rather",
            "than",
            "the",
            "initial",
            "value"
        ]
    },
    {
        "id": 1378,
        "code": "public void testSampledStatReturnsInitialValueWhenNoValuesExist() {\n    WindowedCount count = new WindowedCount();\n    WindowedSum sampledTotal = new WindowedSum();\n    long windowMs = 100;\n    int samples = 2;\n    MetricConfig config = new MetricConfig().timeWindow(windowMs, TimeUnit.MILLISECONDS).samples(samples);\n\n    count.record(config, 50, time.milliseconds());\n    sampledTotal.record(config, 50, time.milliseconds());\n\n    time.sleep(samples * windowMs);\n\n    assertEquals(0, count.measure(config, time.milliseconds()), EPS);\n    assertEquals(0.0, sampledTotal.measure(config, time.milliseconds()), EPS);\n}",
        "summary_tokens": [
            "some",
            "implementations",
            "of",
            "sampled",
            "stat",
            "make",
            "sense",
            "to",
            "return",
            "the",
            "initial",
            "value",
            "when",
            "there",
            "are",
            "no",
            "values",
            "set"
        ]
    },
    {
        "id": 1379,
        "code": "public void testConcurrentReadUpdate() throws Exception {\n    final Random random = new Random();\n    final Deque<Sensor> sensors = new ConcurrentLinkedDeque<>();\n    metrics = new Metrics(new MockTime(10));\n    SensorCreator sensorCreator = new SensorCreator(metrics);\n\n    final AtomicBoolean alive = new AtomicBoolean(true);\n    executorService = Executors.newSingleThreadExecutor();\n    executorService.submit(new ConcurrentMetricOperation(alive, \"record\",\n        () -> sensors.forEach(sensor -> sensor.record(random.nextInt(10000)))));\n\n    for (int i = 0; i < 10000; i++) {\n        if (sensors.size() > 5) {\n            Sensor sensor = random.nextBoolean() ? sensors.removeFirst() : sensors.removeLast();\n            metrics.removeSensor(sensor.name());\n        }\n        StatType statType = StatType.forId(random.nextInt(StatType.values().length));\n        sensors.add(sensorCreator.createSensor(statType, i));\n        for (Sensor sensor : sensors) {\n            for (KafkaMetric metric : sensor.metrics()) {\n                assertNotNull(metric.metricValue(), \"Invalid metric value\");\n            }\n        }\n    }\n    alive.set(false);\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "concurrent",
            "sensor",
            "add",
            "remove",
            "updates",
            "and",
            "read",
            "don",
            "t",
            "result",
            "in",
            "errors",
            "or",
            "deadlock"
        ]
    },
    {
        "id": 1380,
        "code": "public void testConcurrentReadUpdateReport() throws Exception {\n\n    class LockingReporter implements MetricsReporter {\n        Map<MetricName, KafkaMetric> activeMetrics = new HashMap<>();\n        @Override\n        public synchronized void init(List<KafkaMetric> metrics) {\n        }\n\n        @Override\n        public synchronized void metricChange(KafkaMetric metric) {\n            activeMetrics.put(metric.metricName(), metric);\n        }\n\n        @Override\n        public synchronized void metricRemoval(KafkaMetric metric) {\n            activeMetrics.remove(metric.metricName(), metric);\n        }\n\n        @Override\n        public synchronized void close() {\n        }\n\n        @Override\n        public void configure(Map<String, ?> configs) {\n        }\n\n        synchronized void processMetrics() {\n            for (KafkaMetric metric : activeMetrics.values()) {\n                assertNotNull(metric.metricValue(), \"Invalid metric value\");\n            }\n        }\n    }\n\n    final LockingReporter reporter = new LockingReporter();\n    this.metrics.close();\n    this.metrics = new Metrics(config, Arrays.asList(reporter), new MockTime(10), true);\n    final Deque<Sensor> sensors = new ConcurrentLinkedDeque<>();\n    SensorCreator sensorCreator = new SensorCreator(metrics);\n\n    final Random random = new Random();\n    final AtomicBoolean alive = new AtomicBoolean(true);\n    executorService = Executors.newFixedThreadPool(3);\n\n    Future<?> writeFuture = executorService.submit(new ConcurrentMetricOperation(alive, \"record\",\n        () -> sensors.forEach(sensor -> sensor.record(random.nextInt(10000)))));\n    Future<?> readFuture = executorService.submit(new ConcurrentMetricOperation(alive, \"read\",\n        () -> sensors.forEach(sensor -> sensor.metrics().forEach(metric ->\n            assertNotNull(metric.metricValue(), \"Invalid metric value\")))));\n    Future<?> reportFuture = executorService.submit(new ConcurrentMetricOperation(alive, \"report\",\n            reporter::processMetrics));\n\n    for (int i = 0; i < 10000; i++) {\n        if (sensors.size() > 10) {\n            Sensor sensor = random.nextBoolean() ? sensors.removeFirst() : sensors.removeLast();\n            metrics.removeSensor(sensor.name());\n        }\n        StatType statType = StatType.forId(random.nextInt(StatType.values().length));\n        sensors.add(sensorCreator.createSensor(statType, i));\n    }\n    assertFalse(readFuture.isDone(), \"Read failed\");\n    assertFalse(writeFuture.isDone(), \"Write failed\");\n    assertFalse(reportFuture.isDone(), \"Report failed\");\n\n    alive.set(false);\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "concurrent",
            "sensor",
            "add",
            "remove",
            "updates",
            "and",
            "read",
            "with",
            "a",
            "metrics",
            "reporter",
            "that",
            "synchronizes",
            "on",
            "every",
            "reporter",
            "method",
            "doesn",
            "t",
            "result",
            "in",
            "errors",
            "or",
            "deadlock"
        ]
    },
    {
        "id": 1381,
        "code": "public void testCheckQuotasInMultiThreads() throws InterruptedException, ExecutionException {\n    final Metrics metrics = new Metrics(new MetricConfig().quota(Quota.upperBound(Double.MAX_VALUE))\n            \n        .timeWindow(1, TimeUnit.MILLISECONDS)\n            \n        .samples(100));\n    final Sensor sensor = metrics.sensor(\"sensor\");\n\n    assertTrue(sensor.add(metrics.metricName(\"test-metric\", \"test-group\"), new Rate()));\n    final int threadCount = 10;\n    final CountDownLatch latch = new CountDownLatch(1);\n    ExecutorService service = Executors.newFixedThreadPool(threadCount);\n    List<Future<Throwable>> workers = new ArrayList<>(threadCount);\n    boolean needShutdown = true;\n    try {\n        for (int i = 0; i != threadCount; ++i) {\n            final int index = i;\n            workers.add(service.submit(new Callable<Throwable>() {\n                @Override\n                public Throwable call() {\n                    try {\n                        assertTrue(latch.await(5, TimeUnit.SECONDS));\n                        for (int j = 0; j != 20; ++j) {\n                            sensor.record(j * index, System.currentTimeMillis() + j, false);\n                            sensor.checkQuotas();\n                        }\n                        return null;\n                    } catch (Throwable e) {\n                        return e;\n                    }\n                }\n            }));\n        }\n        latch.countDown();\n        service.shutdown();\n        assertTrue(service.awaitTermination(10, TimeUnit.SECONDS));\n        needShutdown = false;\n        for (Future<Throwable> callable : workers) {\n            assertTrue(callable.isDone(), \"If this failure happen frequently, we can try to increase the wait time\");\n            assertNull(callable.get(), \"Sensor#checkQuotas SHOULD be thread-safe!\");\n        }\n    } finally {\n        if (needShutdown) {\n            service.shutdownNow();\n        }\n    }\n}",
        "summary_tokens": [
            "the",
            "sensor",
            "check",
            "quotas",
            "should",
            "be",
            "thread",
            "safe",
            "since",
            "the",
            "method",
            "may",
            "be",
            "used",
            "by",
            "many",
            "replica",
            "fetcher",
            "threads"
        ]
    },
    {
        "id": 1382,
        "code": "public void outputChannel(WritableByteChannel channel) {\n    this.outputChannel = new TransferableChannel() {\n\n        @Override\n        public boolean hasPendingWrites() {\n            return false;\n        }\n\n        @Override\n        public long transferFrom(FileChannel fileChannel, long position, long count) throws IOException {\n            return fileChannel.transferTo(position, count, channel);\n        }\n\n        @Override\n        public boolean isOpen() {\n            return channel.isOpen();\n        }\n\n        @Override\n        public void close() throws IOException {\n            channel.close();\n        }\n\n        @Override\n        public int write(ByteBuffer src) throws IOException {\n            return channel.write(src);\n        }\n\n        @Override\n        public long write(ByteBuffer[] srcs, int offset, int length) throws IOException {\n            long result = 0;\n            for (int i = offset; i < offset + length; ++i)\n                result += write(srcs[i]);\n            return result;\n        }\n\n        @Override\n        public long write(ByteBuffer[] srcs) throws IOException {\n            return write(srcs, 0, srcs.length);\n        }\n    };\n}",
        "summary_tokens": [
            "sets",
            "the",
            "output",
            "channel",
            "to",
            "which",
            "messages",
            "received",
            "on",
            "this",
            "server",
            "are",
            "echoed"
        ]
    },
    {
        "id": 1383,
        "code": "public void testClientChannelBuilderWithBrokerConfigs() throws Exception {\n    Map<String, Object> configs = new HashMap<>();\n    CertStores certStores = new CertStores(false, \"client\", \"localhost\");\n    configs.putAll(certStores.getTrustingConfig(certStores));\n    configs.put(SaslConfigs.SASL_KERBEROS_SERVICE_NAME, \"kafka\");\n    configs.putAll(new ConfigDef().withClientSaslSupport().parse(configs));\n    for (Field field : BrokerSecurityConfigs.class.getFields()) {\n        if (field.getName().endsWith(\"_CONFIG\"))\n            configs.put(field.get(BrokerSecurityConfigs.class).toString(), \"somevalue\");\n    }\n\n    SaslChannelBuilder plainBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"PLAIN\");\n    plainBuilder.configure(configs);\n\n    SaslChannelBuilder gssapiBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"GSSAPI\");\n    gssapiBuilder.configure(configs);\n\n    SaslChannelBuilder oauthBearerBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"OAUTHBEARER\");\n    oauthBearerBuilder.configure(configs);\n\n    SaslChannelBuilder scramBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"SCRAM-SHA-256\");\n    scramBuilder.configure(configs);\n\n    SaslChannelBuilder saslSslBuilder = createChannelBuilder(SecurityProtocol.SASL_SSL, \"PLAIN\");\n    saslSslBuilder.configure(configs);\n}",
        "summary_tokens": [
            "verify",
            "that",
            "unparsed",
            "broker",
            "configs",
            "don",
            "t",
            "break",
            "clients"
        ]
    },
    {
        "id": 1384,
        "code": "public void testServerDisconnect() throws Exception {\n    final String node = \"0\";\n\n        \n    blockingConnect(node);\n    assertEquals(\"hello\", blockingRequest(node, \"hello\"));\n\n    KafkaChannel channel = selector.channel(node);\n\n        \n    this.server.closeConnections();\n    TestUtils.waitForCondition(new TestCondition() {\n        @Override\n        public boolean conditionMet() {\n            try {\n                selector.poll(1000L);\n                return selector.disconnected().containsKey(node);\n            } catch (IOException e) {\n                throw new RuntimeException(e);\n            }\n        }\n    }, 5000, \"Failed to observe disconnected node in disconnected set\");\n\n    assertNull(channel.selectionKey().attachment());\n\n        \n    blockingConnect(node);\n    assertEquals(\"hello\", blockingRequest(node, \"hello\"));\n}",
        "summary_tokens": [
            "validate",
            "that",
            "when",
            "the",
            "server",
            "disconnects",
            "a",
            "client",
            "send",
            "ends",
            "up",
            "with",
            "that",
            "node",
            "in",
            "the",
            "disconnected",
            "list"
        ]
    },
    {
        "id": 1385,
        "code": "public void testCantSendWithInProgress() throws Exception {\n    String node = \"0\";\n    blockingConnect(node);\n    selector.send(createSend(node, \"test1\"));\n    try {\n        selector.send(createSend(node, \"test2\"));\n        fail(\"IllegalStateException not thrown when sending a request with one in flight\");\n    } catch (IllegalStateException e) {\n            \n    }\n    selector.poll(0);\n    assertTrue(selector.disconnected().containsKey(node), \"Channel not closed\");\n    assertEquals(ChannelState.FAILED_SEND, selector.disconnected().get(node));\n}",
        "summary_tokens": [
            "sending",
            "a",
            "request",
            "with",
            "one",
            "already",
            "in",
            "flight",
            "should",
            "result",
            "in",
            "an",
            "exception"
        ]
    },
    {
        "id": 1386,
        "code": "public void testSendWithoutConnecting() {\n    assertThrows(IllegalStateException.class, () -> selector.send(createSend(\"0\", \"test\")));\n}",
        "summary_tokens": [
            "sending",
            "a",
            "request",
            "to",
            "a",
            "node",
            "without",
            "an",
            "existing",
            "connection",
            "should",
            "result",
            "in",
            "an",
            "exception"
        ]
    },
    {
        "id": 1387,
        "code": "public void testNoRouteToHost() {\n    assertThrows(IOException.class,\n        () -> selector.connect(\"0\", new InetSocketAddress(\"some.invalid.hostname.foo.bar.local\", server.port), BUFFER_SIZE, BUFFER_SIZE));\n}",
        "summary_tokens": [
            "sending",
            "a",
            "request",
            "to",
            "a",
            "node",
            "with",
            "a",
            "bad",
            "hostname",
            "should",
            "result",
            "in",
            "an",
            "exception",
            "during",
            "connect"
        ]
    },
    {
        "id": 1388,
        "code": "public void testConnectionRefused() throws Exception {\n    String node = \"0\";\n    ServerSocket nonListeningSocket = new ServerSocket(0);\n    int nonListeningPort = nonListeningSocket.getLocalPort();\n    selector.connect(node, new InetSocketAddress(\"localhost\", nonListeningPort), BUFFER_SIZE, BUFFER_SIZE);\n    while (selector.disconnected().containsKey(node)) {\n        assertEquals(ChannelState.NOT_CONNECTED, selector.disconnected().get(node));\n        selector.poll(1000L);\n    }\n    nonListeningSocket.close();\n}",
        "summary_tokens": [
            "sending",
            "a",
            "request",
            "to",
            "a",
            "node",
            "not",
            "listening",
            "on",
            "that",
            "port",
            "should",
            "result",
            "in",
            "disconnection"
        ]
    },
    {
        "id": 1389,
        "code": "public void testNormalOperation() throws Exception {\n    int conns = 5;\n    int reqs = 500;\n\n        \n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port);\n    for (int i = 0; i < conns; i++)\n        connect(Integer.toString(i), addr);\n        \n    Map<String, Integer> requests = new HashMap<>();\n    Map<String, Integer> responses = new HashMap<>();\n    int responseCount = 0;\n    for (int i = 0; i < conns; i++) {\n        String node = Integer.toString(i);\n        selector.send(createSend(node, node + \"-0\"));\n    }\n\n        \n    while (responseCount < conns * reqs) {\n            \n        selector.poll(0L);\n\n        assertEquals(0, selector.disconnected().size(), \"No disconnects should have occurred.\");\n\n            \n        for (NetworkReceive receive : selector.completedReceives()) {\n            String[] pieces = asString(receive).split(\"-\");\n            assertEquals(2, pieces.length, \"Should be in the form 'conn-counter'\");\n            assertEquals(receive.source(), pieces[0], \"Check the source\");\n            assertEquals(0, receive.payload().position(), \"Check that the receive has kindly been rewound\");\n            if (responses.containsKey(receive.source())) {\n                assertEquals((int) responses.get(receive.source()), Integer.parseInt(pieces[1]), \"Check the request counter\");\n                responses.put(receive.source(), responses.get(receive.source()) + 1);\n            } else {\n                assertEquals(0, Integer.parseInt(pieces[1]), \"Check the request counter\");\n                responses.put(receive.source(), 1);\n            }\n            responseCount++;\n        }\n\n            \n        for (NetworkSend send : selector.completedSends()) {\n            String dest = send.destinationId();\n            if (requests.containsKey(dest))\n                requests.put(dest, requests.get(dest) + 1);\n            else\n                requests.put(dest, 1);\n            if (requests.get(dest) < reqs)\n                selector.send(createSend(dest, dest + \"-\" + requests.get(dest)));\n        }\n    }\n    if (channelBuilder instanceof PlaintextChannelBuilder) {\n        assertEquals(0, cipherMetrics(metrics).size());\n    } else {\n        TestUtils.waitForCondition(() -> cipherMetrics(metrics).size() == 1,\n            \"Waiting for cipher metrics to be created.\");\n        assertEquals(Integer.valueOf(5), cipherMetrics(metrics).get(0).metricValue());\n    }\n}",
        "summary_tokens": [
            "send",
            "multiple",
            "requests",
            "to",
            "several",
            "connections",
            "in",
            "parallel"
        ]
    },
    {
        "id": 1390,
        "code": "public void testSendLargeRequest() throws Exception {\n    String node = \"0\";\n    blockingConnect(node);\n    String big = TestUtils.randomString(10 * BUFFER_SIZE);\n    assertEquals(big, blockingRequest(node, big));\n}",
        "summary_tokens": [
            "validate",
            "that",
            "we",
            "can",
            "send",
            "and",
            "receive",
            "a",
            "message",
            "larger",
            "than",
            "the",
            "receive",
            "and",
            "send",
            "buffer",
            "size"
        ]
    },
    {
        "id": 1391,
        "code": "public void testConnectException() throws Exception {\n    Metrics metrics = new Metrics();\n    AtomicBoolean throwIOException = new AtomicBoolean();\n    Selector selector = new ImmediatelyConnectingSelector(CONNECTION_MAX_IDLE_MS, metrics, time, \"MetricGroup\", channelBuilder, new LogContext()) {\n        @Override\n        protected SelectionKey registerChannel(String id, SocketChannel socketChannel, int interestedOps) throws IOException {\n            SelectionKey key = super.registerChannel(id, socketChannel, interestedOps);\n            key.cancel();\n            if (throwIOException.get())\n                throw new IOException(\"Test exception\");\n            return key;\n        }\n    };\n\n    try {\n        verifyImmediatelyConnectedException(selector, \"0\");\n        throwIOException.set(true);\n        verifyImmediatelyConnectedException(selector, \"1\");\n    } finally {\n        selector.close();\n        metrics.close();\n    }\n}",
        "summary_tokens": [
            "verify",
            "that",
            "if",
            "selector",
            "connect",
            "fails",
            "and",
            "throws",
            "an",
            "exception",
            "all",
            "related",
            "objects",
            "are",
            "cleared",
            "immediately",
            "before",
            "the",
            "exception",
            "is",
            "propagated"
        ]
    },
    {
        "id": 1392,
        "code": "public void testExpireClosedConnectionWithPendingReceives() throws Exception {\n    KafkaChannel channel = createConnectionWithPendingReceives(5);\n    server.closeConnections();\n    verifyChannelExpiry(channel);\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "a",
            "muted",
            "connection",
            "closed",
            "by",
            "peer",
            "is",
            "expired",
            "on",
            "idle",
            "timeout",
            "even",
            "if",
            "there",
            "are",
            "pending",
            "receives",
            "on",
            "the",
            "socket"
        ]
    },
    {
        "id": 1393,
        "code": "public void testCloseOldestConnectionWithMultiplePendingReceives() throws Exception {\n    int expectedReceives = 5;\n    KafkaChannel channel = createConnectionWithPendingReceives(expectedReceives);\n    int completedReceives = selector.completedReceives().size();\n\n    while (selector.disconnected().isEmpty()) {\n        time.sleep(CONNECTION_MAX_IDLE_MS + 1_000);\n        selector.poll(completedReceives == expectedReceives ? 0 : 1_000);\n        completedReceives += selector.completedReceives().size();\n    }\n\n    assertEquals(expectedReceives, completedReceives);\n    assertNull(selector.channel(channel.id()), \"Channel not expired\");\n    assertNull(selector.closingChannel(channel.id()), \"Channel not expired\");\n    assertTrue(selector.disconnected().containsKey(channel.id()), \"Disconnect not notified\");\n    assertTrue(selector.completedReceives().isEmpty(), \"Unexpected receive\");\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "sockets",
            "with",
            "incoming",
            "data",
            "available",
            "are",
            "not",
            "expired"
        ]
    },
    {
        "id": 1394,
        "code": "public void testGracefulClose() throws Exception {\n    int maxReceiveCountAfterClose = 0;\n    for (int i = 6; i <= 100 && maxReceiveCountAfterClose < 5; i++) {\n        int receiveCount = 0;\n        KafkaChannel channel = createConnectionWithPendingReceives(i);\n            \n        TestUtils.waitForCondition(() -> {\n            selector.poll(1000);\n            return selector.completedReceives().size() > 0;\n        }, 5000, \"Receive not completed\");\n        server.closeConnections();\n        while (selector.disconnected().isEmpty()) {\n            selector.poll(1);\n            receiveCount += selector.completedReceives().size();\n            assertTrue(selector.completedReceives().size() <= 1, \"Too many completed receives in one poll\");\n        }\n        assertEquals(channel.id(), selector.disconnected().keySet().iterator().next());\n        maxReceiveCountAfterClose = Math.max(maxReceiveCountAfterClose, receiveCount);\n    }\n    assertTrue(maxReceiveCountAfterClose >= 5, \"Too few receives after close: \" + maxReceiveCountAfterClose);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "graceful",
            "close",
            "of",
            "channel",
            "processes",
            "remaining",
            "data",
            "from",
            "socket",
            "read",
            "buffers"
        ]
    },
    {
        "id": 1395,
        "code": "public void testPartialReceiveGracefulClose() throws Exception {\n    String id = \"0\";\n    blockingConnect(id);\n    KafkaChannel channel = selector.channel(id);\n        \n    injectNetworkReceive(channel, 100000);\n    sendNoReceive(channel, 2); \n    selector.poll(1000); \n    assertEquals(0, selector.completedReceives().size());\n    server.closeConnections();\n    TestUtils.waitForCondition(() -> {\n        try {\n            selector.poll(100);\n            return !selector.disconnected().isEmpty();\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }, 10000, \"Channel not disconnected\");\n    assertEquals(1, selector.disconnected().size());\n    assertEquals(channel.id(), selector.disconnected().keySet().iterator().next());\n    assertEquals(0, selector.completedReceives().size());\n}",
        "summary_tokens": [
            "tests",
            "that",
            "graceful",
            "close",
            "is",
            "not",
            "delayed",
            "if",
            "only",
            "part",
            "of",
            "an",
            "incoming",
            "receive",
            "is",
            "available",
            "in",
            "the",
            "socket",
            "buffer"
        ]
    },
    {
        "id": 1396,
        "code": "public void testConnectDisconnectDuringInSinglePoll() throws Exception {\n        \n    KafkaChannel kafkaChannel = mock(KafkaChannel.class);\n    when(kafkaChannel.id()).thenReturn(\"1\");\n    when(kafkaChannel.socketDescription()).thenReturn(\"\");\n    when(kafkaChannel.state()).thenReturn(ChannelState.NOT_CONNECTED);\n    when(kafkaChannel.finishConnect()).thenReturn(true);\n    when(kafkaChannel.isConnected()).thenReturn(true);\n    when(kafkaChannel.ready()).thenReturn(false);\n    doThrow(new IOException()).when(kafkaChannel).prepare();\n\n    SelectionKey selectionKey = mock(SelectionKey.class);\n    when(kafkaChannel.selectionKey()).thenReturn(selectionKey);\n    when(selectionKey.channel()).thenReturn(SocketChannel.open());\n    when(selectionKey.readyOps()).thenReturn(SelectionKey.OP_CONNECT);\n    when(selectionKey.attachment()).thenReturn(kafkaChannel);\n\n    Set<SelectionKey> selectionKeys = Utils.mkSet(selectionKey);\n    selector.pollSelectionKeys(selectionKeys, false, System.nanoTime());\n\n    assertFalse(selector.connected().contains(kafkaChannel.id()));\n    assertTrue(selector.disconnected().containsKey(kafkaChannel.id()));\n\n    verify(kafkaChannel, atLeastOnce()).ready();\n    verify(kafkaChannel).disconnect();\n    verify(kafkaChannel).close();\n    verify(selectionKey).cancel();\n}",
        "summary_tokens": [
            "tests",
            "that",
            "a",
            "connect",
            "and",
            "disconnect",
            "in",
            "a",
            "single",
            "poll",
            "invocation",
            "results",
            "in",
            "the",
            "channel",
            "id",
            "being",
            "in",
            "disconnected",
            "but",
            "not",
            "connected"
        ]
    },
    {
        "id": 1397,
        "code": "public void testChannelCloseWhileProcessingReceives() throws Exception {\n    int numChannels = 4;\n    Map<String, KafkaChannel> channels = TestUtils.fieldValue(selector, Selector.class, \"channels\");\n    Set<SelectionKey> selectionKeys = new HashSet<>();\n    for (int i = 0; i < numChannels; i++) {\n        String id = String.valueOf(i);\n        KafkaChannel channel = mock(KafkaChannel.class);\n        channels.put(id, channel);\n        when(channel.id()).thenReturn(id);\n        when(channel.state()).thenReturn(ChannelState.READY);\n        when(channel.isConnected()).thenReturn(true);\n        when(channel.ready()).thenReturn(true);\n        when(channel.read()).thenReturn(1L);\n\n        SelectionKey selectionKey = mock(SelectionKey.class);\n        when(channel.selectionKey()).thenReturn(selectionKey);\n        when(selectionKey.isValid()).thenReturn(true);\n        when(selectionKey.isReadable()).thenReturn(true);\n        when(selectionKey.readyOps()).thenReturn(SelectionKey.OP_READ);\n        when(selectionKey.attachment())\n                .thenReturn(channel)\n                .thenReturn(null);\n        selectionKeys.add(selectionKey);\n\n        NetworkReceive receive = mock(NetworkReceive.class);\n        when(receive.source()).thenReturn(id);\n        when(receive.size()).thenReturn(10);\n        when(receive.bytesRead()).thenReturn(1);\n        when(receive.payload()).thenReturn(ByteBuffer.allocate(10));\n        when(channel.maybeCompleteReceive()).thenReturn(receive);\n    }\n\n    selector.pollSelectionKeys(selectionKeys, false, System.nanoTime());\n    assertEquals(numChannels, selector.completedReceives().size());\n    Set<KafkaChannel> closed = new HashSet<>();\n    Set<KafkaChannel> notClosed = new HashSet<>();\n    for (NetworkReceive receive : selector.completedReceives()) {\n        KafkaChannel channel = selector.channel(receive.source());\n        assertNotNull(channel);\n        if (closed.size() < 2) {\n            selector.close(channel.id());\n            closed.add(channel);\n        } else\n            notClosed.add(channel);\n    }\n    assertEquals(notClosed, new HashSet<>(selector.channels()));\n    closed.forEach(channel -> assertNull(selector.channel(channel.id())));\n\n    selector.poll(0);\n    assertEquals(0, selector.completedReceives().size());\n}",
        "summary_tokens": [
            "ensure",
            "that",
            "no",
            "errors",
            "are",
            "thrown",
            "if",
            "channels",
            "are",
            "closed",
            "while",
            "processing",
            "multiple",
            "completed",
            "receives"
        ]
    },
    {
        "id": 1398,
        "code": "private KafkaChannel createConnectionWithPendingReceives(int pendingReceives) throws Exception {\n    String id = \"0\";\n    blockingConnect(id);\n    KafkaChannel channel = selector.channel(id);\n    sendNoReceive(channel, pendingReceives);\n    return channel;\n}",
        "summary_tokens": [
            "creates",
            "a",
            "connection",
            "sends",
            "the",
            "specified",
            "number",
            "of",
            "requests",
            "and",
            "returns",
            "without",
            "reading",
            "any",
            "incoming",
            "data"
        ]
    },
    {
        "id": 1399,
        "code": "private void sendNoReceive(KafkaChannel channel, int numRequests) throws Exception {\n    selector.mute(channel.id());\n    for (int i = 0; i < numRequests; i++) {\n        selector.send(createSend(channel.id(), String.valueOf(i)));\n        do {\n            selector.poll(10);\n        } while (selector.completedSends().isEmpty());\n    }\n    selector.unmute(channel.id());\n}",
        "summary_tokens": [
            "sends",
            "the",
            "specified",
            "number",
            "of",
            "requests",
            "and",
            "waits",
            "for",
            "the",
            "requests",
            "to",
            "be",
            "sent"
        ]
    },
    {
        "id": 1400,
        "code": "private void injectNetworkReceive(KafkaChannel channel, int size) throws Exception {\n    NetworkReceive receive = new NetworkReceive();\n    TestUtils.setFieldValue(channel, \"receive\", receive);\n    ByteBuffer sizeBuffer = TestUtils.fieldValue(receive, NetworkReceive.class, \"size\");\n    sizeBuffer.putInt(size);\n    TestUtils.setFieldValue(receive, \"buffer\", ByteBuffer.allocate(size));\n}",
        "summary_tokens": [
            "injects",
            "a",
            "network",
            "receive",
            "for",
            "channel",
            "with",
            "size",
            "buffer",
            "filled",
            "in",
            "with",
            "the",
            "provided",
            "size",
            "and",
            "a",
            "payload",
            "buffer",
            "allocated",
            "with",
            "that",
            "size",
            "but",
            "no",
            "data",
            "in",
            "the",
            "payload",
            "buffer"
        ]
    },
    {
        "id": 1401,
        "code": "protected void connect(String node, InetSocketAddress serverAddr) throws IOException {\n    blockingConnect(node, serverAddr);\n}",
        "summary_tokens": [
            "connects",
            "and",
            "waits",
            "for",
            "handshake",
            "to",
            "complete"
        ]
    },
    {
        "id": 1402,
        "code": "public void testValidEndpointIdentificationSanDns(Args args) throws Exception {\n    createSelector(args);\n    String node = \"0\";\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    createSelector(args.sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n    server.verifyAuthenticationMetrics(1, 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "certificate",
            "with",
            "subject",
            "alt",
            "name",
            "containing",
            "the",
            "valid",
            "hostname",
            "is",
            "accepted",
            "by",
            "a",
            "client",
            "that",
            "connects",
            "using",
            "the",
            "hostname",
            "and",
            "validates",
            "server",
            "endpoint"
        ]
    },
    {
        "id": 1403,
        "code": "public void testValidEndpointIdentificationSanIp(Args args) throws Exception {\n    String node = \"0\";\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).hostAddress(InetAddress.getByName(\"127.0.0.1\")).build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).hostAddress(InetAddress.getByName(\"127.0.0.1\")).build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    createSelector(args.sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"127.0.0.1\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "certificate",
            "with",
            "subject",
            "alt",
            "name",
            "containing",
            "valid",
            "ip",
            "address",
            "is",
            "accepted",
            "by",
            "a",
            "client",
            "that",
            "connects",
            "using",
            "ip",
            "address",
            "and",
            "validates",
            "server",
            "endpoint"
        ]
    },
    {
        "id": 1404,
        "code": "public void testValidEndpointIdentificationCN(Args args) throws Exception {\n    args.serverCertStores = certBuilder(true, \"localhost\", args.useInlinePem).build();\n    args.clientCertStores = certBuilder(false, \"localhost\", args.useInlinePem).build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "certificate",
            "with",
            "cn",
            "containing",
            "valid",
            "hostname",
            "is",
            "accepted",
            "by",
            "a",
            "client",
            "that",
            "connects",
            "using",
            "hostname",
            "and",
            "validates",
            "server",
            "endpoint"
        ]
    },
    {
        "id": 1405,
        "code": "public void testEndpointIdentificationNoReverseLookup(Args args) throws Exception {\n    String node = \"0\";\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    createSelector(args.sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"127.0.0.1\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "hostname",
            "verification",
            "is",
            "performed",
            "on",
            "the",
            "host",
            "name",
            "or",
            "address",
            "specified",
            "by",
            "the",
            "client",
            "without",
            "using",
            "reverse",
            "dns",
            "lookup"
        ]
    },
    {
        "id": 1406,
        "code": "public void testClientEndpointNotValidated(Args args) throws Exception {\n    String node = \"0\";\n\n        \n    args.clientCertStores = certBuilder(false, \"non-existent.com\", args.useInlinePem).build();\n    args.serverCertStores = certBuilder(true, \"localhost\", args.useInlinePem).build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n\n        \n    SslChannelBuilder serverChannelBuilder = new TestSslChannelBuilder(Mode.SERVER) {\n        @Override\n        protected TestSslTransportLayer newTransportLayer(String id, SelectionKey key, SSLEngine sslEngine) throws IOException {\n            SSLParameters sslParams = sslEngine.getSSLParameters();\n            sslParams.setEndpointIdentificationAlgorithm(\"HTTPS\");\n            sslEngine.setSSLParameters(sslParams);\n            return super.newTransportLayer(id, key, sslEngine);\n        }\n    };\n    serverChannelBuilder.configure(args.sslServerConfigs);\n    server = new NioEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL), SecurityProtocol.SSL,\n            new TestSecurityConfig(args.sslServerConfigs), \"localhost\", serverChannelBuilder, null, time);\n    server.start();\n\n    createSelector(args.sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n}",
        "summary_tokens": [
            "according",
            "to",
            "rfc",
            "0",
            "blockquote",
            "typically",
            "the",
            "server",
            "has",
            "no",
            "external",
            "knowledge",
            "of",
            "what",
            "the",
            "client",
            "s",
            "identity",
            "ought",
            "to",
            "be",
            "and",
            "so",
            "checks",
            "other",
            "than",
            "that",
            "the",
            "client",
            "has",
            "a",
            "certificate",
            "chain",
            "rooted",
            "in",
            "an",
            "appropriate",
            "ca",
            "are",
            "not",
            "possible"
        ]
    },
    {
        "id": 1407,
        "code": "public void testInvalidEndpointIdentification(Args args) throws Exception {\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).addHostName(\"notahost\").build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).addHostName(\"localhost\").build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    verifySslConfigsWithHandshakeFailure(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "certificate",
            "with",
            "invalid",
            "host",
            "name",
            "is",
            "not",
            "accepted",
            "by",
            "a",
            "client",
            "that",
            "validates",
            "server",
            "endpoint"
        ]
    },
    {
        "id": 1408,
        "code": "public void testEndpointIdentificationDisabled(Args args) throws Exception {\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).addHostName(\"notahost\").build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).addHostName(\"localhost\").build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n\n        \n    String node = \"1\";\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"\");\n    createSelector(args.sslClientConfigs);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n\n        \n    String node2 = \"2\";\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, null);\n    createSelector(args.sslClientConfigs);\n    selector.connect(node2, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, node2, 100, 10);\n\n        \n    String node3 = \"3\";\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    createSelector(args.sslClientConfigs);\n    selector.connect(node3, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.waitForChannelClose(selector, node3, ChannelState.State.AUTHENTICATION_FAILED);\n    selector.close();\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "certificate",
            "with",
            "invalid",
            "host",
            "name",
            "is",
            "accepted",
            "by",
            "a",
            "client",
            "that",
            "has",
            "disabled",
            "endpoint",
            "validation"
        ]
    },
    {
        "id": 1409,
        "code": "public void testClientAuthenticationRequiredValidProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "accepts",
            "connections",
            "from",
            "clients",
            "with",
            "a",
            "trusted",
            "certificate",
            "when",
            "client",
            "authentication",
            "is",
            "required"
        ]
    },
    {
        "id": 1410,
        "code": "public void testListenerConfigOverride(Args args) throws Exception {\n    String node = \"0\";\n    ListenerName clientListenerName = new ListenerName(\"client\");\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    args.sslServerConfigs.put(clientListenerName.configPrefix() + BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"none\");\n\n        \n    server = createEchoServer(args, SecurityProtocol.SSL);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n\n        \n    createSelector(args.sslClientConfigs);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n    selector.close();\n\n        \n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    createSelector(args.sslClientConfigs);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n    selector.close();\n    server.close();\n\n        \n    server = createEchoServer(args, clientListenerName, SecurityProtocol.SSL);\n    addr = new InetSocketAddress(\"localhost\", server.port());\n\n        \n    createSelector(args.sslClientConfigs);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "disabling",
            "client",
            "authentication",
            "as",
            "a",
            "listener",
            "override",
            "has",
            "the",
            "desired",
            "effect"
        ]
    },
    {
        "id": 1411,
        "code": "public void testClientAuthenticationRequiredUntrustedProvided(Args args) throws Exception {\n    args.sslServerConfigs = args.serverCertStores.getUntrustingConfig();\n    args.sslServerConfigs.putAll(args.sslConfigOverrides);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    verifySslConfigsWithHandshakeFailure(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "does",
            "not",
            "accept",
            "connections",
            "from",
            "clients",
            "with",
            "an",
            "untrusted",
            "certificate",
            "when",
            "client",
            "authentication",
            "is",
            "required"
        ]
    },
    {
        "id": 1412,
        "code": "public void testClientAuthenticationRequiredNotProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    verifySslConfigsWithHandshakeFailure(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "does",
            "not",
            "accept",
            "connections",
            "from",
            "clients",
            "which",
            "don",
            "t",
            "provide",
            "a",
            "certificate",
            "when",
            "client",
            "authentication",
            "is",
            "required"
        ]
    },
    {
        "id": 1413,
        "code": "public void testClientAuthenticationDisabledUntrustedProvided(Args args) throws Exception {\n    args.sslServerConfigs = args.serverCertStores.getUntrustingConfig();\n    args.sslServerConfigs.putAll(args.sslConfigOverrides);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"none\");\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "accepts",
            "connections",
            "from",
            "a",
            "client",
            "configured",
            "with",
            "an",
            "untrusted",
            "certificate",
            "if",
            "client",
            "authentication",
            "is",
            "disabled"
        ]
    },
    {
        "id": 1414,
        "code": "public void testClientAuthenticationDisabledNotProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"none\");\n\n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "accepts",
            "connections",
            "from",
            "a",
            "client",
            "that",
            "does",
            "not",
            "provide",
            "a",
            "certificate",
            "if",
            "client",
            "authentication",
            "is",
            "disabled"
        ]
    },
    {
        "id": 1415,
        "code": "public void testClientAuthenticationRequestedValidProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"requested\");\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "accepts",
            "connections",
            "from",
            "a",
            "client",
            "configured",
            "with",
            "a",
            "valid",
            "certificate",
            "if",
            "client",
            "authentication",
            "is",
            "requested"
        ]
    },
    {
        "id": 1416,
        "code": "public void testClientAuthenticationRequestedNotProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"requested\");\n\n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "server",
            "accepts",
            "connections",
            "from",
            "a",
            "client",
            "that",
            "does",
            "not",
            "provide",
            "a",
            "certificate",
            "if",
            "client",
            "authentication",
            "is",
            "requested",
            "but",
            "not",
            "required"
        ]
    },
    {
        "id": 1417,
        "code": "public void testDsaKeyPair(Args args) throws Exception {\n        \n    assumeTrue(args.tlsProtocol.equals(\"TLSv1.2\"));\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).keyAlgorithm(\"DSA\").build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).keyAlgorithm(\"DSA\").build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "key",
            "pair",
            "created",
            "using",
            "dsa"
        ]
    },
    {
        "id": 1418,
        "code": "public void testECKeyPair(Args args) throws Exception {\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).keyAlgorithm(\"EC\").build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).keyAlgorithm(\"EC\").build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "key",
            "pair",
            "created",
            "using",
            "ec"
        ]
    },
    {
        "id": 1419,
        "code": "public void testPemFiles(Args args) throws Exception {\n    TestSslUtils.convertToPem(args.sslServerConfigs, true, true);\n    TestSslUtils.convertToPem(args.sslClientConfigs, true, true);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "pem",
            "key",
            "store",
            "and",
            "trust",
            "store",
            "files",
            "which",
            "don",
            "t",
            "have",
            "store",
            "passwords"
        ]
    },
    {
        "id": 1420,
        "code": "public void testPemFilesWithoutClientKeyPassword(Args args) throws Exception {\n    boolean useInlinePem = args.useInlinePem;\n    TestSslUtils.convertToPem(args.sslServerConfigs, !useInlinePem, true);\n    TestSslUtils.convertToPem(args.sslClientConfigs, !useInlinePem, false);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "test",
            "with",
            "pem",
            "key",
            "store",
            "files",
            "without",
            "key",
            "password",
            "for",
            "client",
            "key",
            "store"
        ]
    },
    {
        "id": 1421,
        "code": "public void testPemFilesWithoutServerKeyPassword(Args args) throws Exception {\n    TestSslUtils.convertToPem(args.sslServerConfigs, !args.useInlinePem, false);\n    TestSslUtils.convertToPem(args.sslClientConfigs, !args.useInlinePem, true);\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "test",
            "with",
            "pem",
            "key",
            "store",
            "files",
            "without",
            "key",
            "password",
            "for",
            "server",
            "key",
            "store"
        ]
    },
    {
        "id": 1422,
        "code": "public void testInvalidSecureRandomImplementation(Args args) {\n    try (SslChannelBuilder channelBuilder = newClientChannelBuilder()) {\n        args.sslClientConfigs.put(SslConfigs.SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG, \"invalid\");\n        assertThrows(KafkaException.class, () -> channelBuilder.configure(args.sslClientConfigs));\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "an",
            "invalid",
            "secure",
            "random",
            "implementation",
            "cannot",
            "be",
            "configured"
        ]
    },
    {
        "id": 1423,
        "code": "public void testInvalidTruststorePassword(Args args) {\n    try (SslChannelBuilder channelBuilder = newClientChannelBuilder()) {\n        args.sslClientConfigs.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, \"invalid\");\n        assertThrows(KafkaException.class, () -> channelBuilder.configure(args.sslClientConfigs));\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "channels",
            "cannot",
            "be",
            "created",
            "if",
            "truststore",
            "cannot",
            "be",
            "loaded"
        ]
    },
    {
        "id": 1424,
        "code": "public void testInvalidKeystorePassword(Args args) {\n    try (SslChannelBuilder channelBuilder = newClientChannelBuilder()) {\n        args.sslClientConfigs.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, \"invalid\");\n        assertThrows(KafkaException.class, () -> channelBuilder.configure(args.sslClientConfigs));\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "channels",
            "cannot",
            "be",
            "created",
            "if",
            "keystore",
            "cannot",
            "be",
            "loaded"
        ]
    },
    {
        "id": 1425,
        "code": "public void testNullTruststorePassword(Args args) throws Exception {\n    args.sslClientConfigs.remove(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG);\n    args.sslServerConfigs.remove(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG);\n\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "client",
            "connections",
            "can",
            "be",
            "created",
            "to",
            "a",
            "server",
            "if",
            "null",
            "truststore",
            "password",
            "is",
            "used"
        ]
    },
    {
        "id": 1426,
        "code": "public void testInvalidKeyPassword(Args args) throws Exception {\n    args.sslServerConfigs.put(SslConfigs.SSL_KEY_PASSWORD_CONFIG, new Password(\"invalid\"));\n    if (args.useInlinePem) {\n            \n        assertThrows(InvalidConfigurationException.class, () -> createEchoServer(args, SecurityProtocol.SSL));\n        return;\n    }\n    verifySslConfigsWithHandshakeFailure(args);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "client",
            "connections",
            "cannot",
            "be",
            "created",
            "to",
            "a",
            "server",
            "if",
            "key",
            "password",
            "is",
            "invalid"
        ]
    },
    {
        "id": 1427,
        "code": "public void testTlsDefaults(Args args) throws Exception {\n    args.sslServerConfigs = args.serverCertStores.getTrustingConfig(args.clientCertStores);\n    args.sslClientConfigs = args.clientCertStores.getTrustingConfig(args.serverCertStores);\n\n    assertEquals(SslConfigs.DEFAULT_SSL_PROTOCOL, args.sslServerConfigs.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n    assertEquals(SslConfigs.DEFAULT_SSL_PROTOCOL, args.sslClientConfigs.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    createSelector(args.sslClientConfigs);\n\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(\"0\", addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, \"0\", 10, 100);\n    server.verifyAuthenticationMetrics(1, 0);\n    selector.close();\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connection",
            "succeeds",
            "with",
            "the",
            "default",
            "tls",
            "version"
        ]
    },
    {
        "id": 1428,
        "code": "private void checkAuthenticationFailed(Args args, String node, String tlsVersion) throws IOException {\n    args.sslClientConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(tlsVersion));\n    createSelector(args.sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n\n    selector.close();\n}",
        "summary_tokens": [
            "checks",
            "connection",
            "failed",
            "using",
            "the",
            "specified",
            "tls",
            "version"
        ]
    },
    {
        "id": 1429,
        "code": "public void testUnsupportedCiphers(Args args) throws Exception {\n    SSLContext context = SSLContext.getInstance(args.tlsProtocol);\n    context.init(null, null, null);\n    String[] cipherSuites = context.getDefaultSSLParameters().getCipherSuites();\n    args.sslServerConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Arrays.asList(cipherSuites[0]));\n    server = createEchoServer(args, SecurityProtocol.SSL);\n\n    args.sslClientConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Arrays.asList(cipherSuites[1]));\n    createSelector(args.sslClientConfigs);\n\n    checkAuthenticationFailed(args, \"1\", args.tlsProtocol);\n    server.verifyAuthenticationMetrics(0, 1);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connections",
            "cannot",
            "be",
            "made",
            "with",
            "unsupported",
            "tls",
            "cipher",
            "suites"
        ]
    },
    {
        "id": 1430,
        "code": "public void testNetReadBufferResize(Args args) throws Exception {\n    String node = \"0\";\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    createSelector(args.sslClientConfigs, 10, null, null);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 64000, 10);\n}",
        "summary_tokens": [
            "tests",
            "handling",
            "of",
            "buffer",
            "underflow",
            "during",
            "unwrap",
            "when",
            "network",
            "read",
            "buffer",
            "is",
            "smaller",
            "than",
            "ssl",
            "session",
            "packet",
            "buffer",
            "size"
        ]
    },
    {
        "id": 1431,
        "code": "public void testNetWriteBufferResize(Args args) throws Exception {\n    String node = \"0\";\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    createSelector(args.sslClientConfigs, null, 10, null);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 64000, 10);\n}",
        "summary_tokens": [
            "tests",
            "handling",
            "of",
            "buffer",
            "overflow",
            "during",
            "wrap",
            "when",
            "network",
            "write",
            "buffer",
            "is",
            "smaller",
            "than",
            "ssl",
            "session",
            "packet",
            "buffer",
            "size"
        ]
    },
    {
        "id": 1432,
        "code": "public void testApplicationBufferResize(Args args) throws Exception {\n    String node = \"0\";\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    createSelector(args.sslClientConfigs, null, null, 10);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 64000, 10);\n}",
        "summary_tokens": [
            "tests",
            "handling",
            "of",
            "buffer",
            "overflow",
            "during",
            "unwrap",
            "when",
            "application",
            "read",
            "buffer",
            "is",
            "smaller",
            "than",
            "ssl",
            "session",
            "application",
            "buffer",
            "size"
        ]
    },
    {
        "id": 1433,
        "code": "public void testNetworkThreadTimeRecorded(Args args) throws Exception {\n    LogContext logContext = new LogContext();\n    ChannelBuilder channelBuilder = new SslChannelBuilder(Mode.CLIENT, null, false, logContext);\n    channelBuilder.configure(args.sslClientConfigs);\n    try (Selector selector = new Selector(NetworkReceive.UNLIMITED, Selector.NO_IDLE_TIMEOUT_MS, new Metrics(), Time.SYSTEM,\n            \"MetricGroup\", new HashMap<>(), false, true, channelBuilder, MemoryPool.NONE, logContext)) {\n\n        String node = \"0\";\n        server = createEchoServer(args, SecurityProtocol.SSL);\n        InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n        selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n        String message = TestUtils.randomString(1024 * 1024);\n        NetworkTestUtils.waitForChannelReady(selector, node);\n        final KafkaChannel channel = selector.channel(node);\n        assertTrue(channel.getAndResetNetworkThreadTimeNanos() > 0, \"SSL handshake time not recorded\");\n        assertEquals(0, channel.getAndResetNetworkThreadTimeNanos(), \"Time not reset\");\n\n        selector.mute(node);\n        selector.send(new NetworkSend(node, ByteBufferSend.sizePrefixed(ByteBuffer.wrap(message.getBytes()))));\n        while (selector.completedSends().isEmpty()) {\n            selector.poll(100L);\n        }\n        long sendTimeNanos = channel.getAndResetNetworkThreadTimeNanos();\n        assertTrue(sendTimeNanos > 0, \"Send time not recorded: \" + sendTimeNanos);\n        assertEquals(0, channel.getAndResetNetworkThreadTimeNanos(), \"Time not reset\");\n        assertFalse(channel.hasBytesBuffered(), \"Unexpected bytes buffered\");\n        assertEquals(0, selector.completedReceives().size());\n\n        selector.unmute(node);\n            \n        TestUtils.waitForCondition(() -> {\n            try {\n                selector.poll(100L);\n            } catch (IOException e) {\n                return false;\n            }\n            return !selector.completedReceives().isEmpty();\n        }, \"Timed out waiting for a message to receive from echo server\");\n\n        long receiveTimeNanos = channel.getAndResetNetworkThreadTimeNanos();\n        assertTrue(receiveTimeNanos > 0, \"Receive time not recorded: \" + receiveTimeNanos);\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "time",
            "spent",
            "on",
            "the",
            "network",
            "thread",
            "is",
            "accumulated",
            "on",
            "each",
            "channel"
        ]
    },
    {
        "id": 1434,
        "code": "public void testIOExceptionsDuringHandshakeRead(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, FailureAction.THROW_IO_EXCEPTION, FailureAction.NO_OP);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "ioexceptions",
            "from",
            "read",
            "during",
            "ssl",
            "handshake",
            "are",
            "not",
            "treated",
            "as",
            "authentication",
            "failures"
        ]
    },
    {
        "id": 1435,
        "code": "public void testIOExceptionsDuringHandshakeWrite(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, FailureAction.NO_OP, FailureAction.THROW_IO_EXCEPTION);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "ioexceptions",
            "from",
            "write",
            "during",
            "ssl",
            "handshake",
            "are",
            "not",
            "treated",
            "as",
            "authentication",
            "failures"
        ]
    },
    {
        "id": 1436,
        "code": "public void testUngracefulRemoteCloseDuringHandshakeRead(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, server::closeSocketChannels, FailureAction.NO_OP);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "if",
            "the",
            "remote",
            "end",
            "closes",
            "connection",
            "ungracefully",
            "during",
            "ssl",
            "handshake",
            "while",
            "reading",
            "data",
            "the",
            "disconnection",
            "is",
            "not",
            "treated",
            "as",
            "an",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 1437,
        "code": "public void testUngracefulRemoteCloseDuringHandshakeWrite(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, FailureAction.NO_OP, server::closeSocketChannels);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "if",
            "the",
            "remote",
            "end",
            "closes",
            "connection",
            "ungracefully",
            "during",
            "ssl",
            "handshake",
            "while",
            "writing",
            "data",
            "the",
            "disconnection",
            "is",
            "not",
            "treated",
            "as",
            "an",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 1438,
        "code": "public void testGracefulRemoteCloseDuringHandshakeRead(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, FailureAction.NO_OP, server::closeKafkaChannels);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "if",
            "the",
            "remote",
            "end",
            "closes",
            "the",
            "connection",
            "during",
            "ssl",
            "handshake",
            "while",
            "reading",
            "data",
            "the",
            "disconnection",
            "is",
            "not",
            "treated",
            "as",
            "an",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 1439,
        "code": "public void testGracefulRemoteCloseDuringHandshakeWrite(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, server::closeKafkaChannels, FailureAction.NO_OP);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "if",
            "the",
            "remote",
            "end",
            "closes",
            "the",
            "connection",
            "during",
            "ssl",
            "handshake",
            "while",
            "writing",
            "data",
            "the",
            "disconnection",
            "is",
            "not",
            "treated",
            "as",
            "an",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 1440,
        "code": "public void testPeerNotifiedOfHandshakeFailure(Args args) throws Exception {\n    args.sslServerConfigs = args.serverCertStores.getUntrustingConfig();\n    args.sslServerConfigs.putAll(args.sslConfigOverrides);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n\n        \n    for (int i = 0; i < 3; i++) {\n        String node = String.valueOf(i);\n        TestSslChannelBuilder serverChannelBuilder = new TestSslChannelBuilder(Mode.SERVER);\n        serverChannelBuilder.configure(args.sslServerConfigs);\n        serverChannelBuilder.flushDelayCount = i;\n        server = new NioEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n                SecurityProtocol.SSL, new TestSecurityConfig(args.sslServerConfigs),\n                \"localhost\", serverChannelBuilder, null, time);\n        server.start();\n        createSelector(args.sslClientConfigs);\n        InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n        selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n        NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n        server.close();\n        selector.close();\n        serverChannelBuilder.close();\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "handshake",
            "failures",
            "are",
            "propagated",
            "only",
            "after",
            "writes",
            "complete",
            "even",
            "when",
            "there",
            "are",
            "delays",
            "in",
            "writes",
            "to",
            "ensure",
            "that",
            "clients",
            "see",
            "an",
            "authentication",
            "exception",
            "rather",
            "than",
            "a",
            "connection",
            "failure"
        ]
    },
    {
        "id": 1441,
        "code": "public void testInterBrokerSslConfigValidation(Args args) throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SSL;\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    args.sslServerConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    args.sslServerConfigs.putAll(args.serverCertStores.keyStoreProps());\n    args.sslServerConfigs.putAll(args.serverCertStores.trustStoreProps());\n    args.sslClientConfigs.putAll(args.serverCertStores.keyStoreProps());\n    args.sslClientConfigs.putAll(args.serverCertStores.trustStoreProps());\n    TestSecurityConfig config = new TestSecurityConfig(args.sslServerConfigs);\n    ListenerName listenerName = ListenerName.forSecurityProtocol(securityProtocol);\n    ChannelBuilder serverChannelBuilder = ChannelBuilders.serverChannelBuilder(listenerName,\n        true, securityProtocol, config, null, null, time, new LogContext(),\n        defaultApiVersionsSupplier());\n    server = new NioEchoServer(listenerName, securityProtocol, config,\n            \"localhost\", serverChannelBuilder, null, time);\n    server.start();\n\n    this.selector = createSelector(args.sslClientConfigs, null, null, null);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(\"0\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, \"0\", 100, 10);\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "inter",
            "broker",
            "listener",
            "with",
            "validation",
            "of",
            "truststore",
            "against",
            "keystore",
            "works",
            "with",
            "configs",
            "including",
            "mutual",
            "authentication",
            "and",
            "hostname",
            "verification"
        ]
    },
    {
        "id": 1442,
        "code": "public void testInterBrokerSslConfigValidationFailure(Args args) {\n    SecurityProtocol securityProtocol = SecurityProtocol.SSL;\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    TestSecurityConfig config = new TestSecurityConfig(args.sslServerConfigs);\n    ListenerName listenerName = ListenerName.forSecurityProtocol(securityProtocol);\n    assertThrows(KafkaException.class, () -> ChannelBuilders.serverChannelBuilder(\n        listenerName, true, securityProtocol, config,\n        null, null, time, new LogContext(), defaultApiVersionsSupplier()));\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "inter",
            "broker",
            "listener",
            "with",
            "validation",
            "of",
            "truststore",
            "against",
            "keystore",
            "fails",
            "if",
            "certs",
            "from",
            "keystore",
            "are",
            "not",
            "trusted"
        ]
    },
    {
        "id": 1443,
        "code": "public void testServerKeystoreDynamicUpdate(Args args) throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SSL;\n    TestSecurityConfig config = new TestSecurityConfig(args.sslServerConfigs);\n    ListenerName listenerName = ListenerName.forSecurityProtocol(securityProtocol);\n    ChannelBuilder serverChannelBuilder = ChannelBuilders.serverChannelBuilder(listenerName,\n        false, securityProtocol, config, null, null, time, new LogContext(),\n        defaultApiVersionsSupplier());\n    server = new NioEchoServer(listenerName, securityProtocol, config,\n            \"localhost\", serverChannelBuilder, null, time);\n    server.start();\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n\n        \n    String oldNode = \"0\";\n    Selector oldClientSelector = createSelector(args.sslClientConfigs);\n    oldClientSelector.connect(oldNode, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, oldNode, 100, 10);\n\n    CertStores newServerCertStores = certBuilder(true, \"server\", args.useInlinePem).addHostName(\"localhost\").build();\n    Map<String, Object> newKeystoreConfigs = newServerCertStores.keyStoreProps();\n    assertTrue(serverChannelBuilder instanceof ListenerReconfigurable, \"SslChannelBuilder not reconfigurable\");\n    ListenerReconfigurable reconfigurableBuilder = (ListenerReconfigurable) serverChannelBuilder;\n    assertEquals(listenerName, reconfigurableBuilder.listenerName());\n    reconfigurableBuilder.validateReconfiguration(newKeystoreConfigs);\n    reconfigurableBuilder.reconfigure(newKeystoreConfigs);\n\n        \n    oldClientSelector.connect(\"1\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.waitForChannelClose(oldClientSelector, \"1\", ChannelState.State.AUTHENTICATION_FAILED);\n\n        \n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, newServerCertStores);\n    Selector newClientSelector = createSelector(args.sslClientConfigs);\n    newClientSelector.connect(\"2\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(newClientSelector, \"2\", 100, 10);\n\n        \n    NetworkTestUtils.checkClientConnection(oldClientSelector, oldNode, 100, 10);\n\n    CertStores invalidCertStores = certBuilder(true, \"server\", args.useInlinePem).addHostName(\"127.0.0.1\").build();\n    Map<String, Object>  invalidConfigs = args.getTrustingConfig(invalidCertStores, args.clientCertStores);\n    verifyInvalidReconfigure(reconfigurableBuilder, invalidConfigs, \"keystore with different SubjectAltName\");\n\n    Map<String, Object>  missingStoreConfigs = new HashMap<>();\n    missingStoreConfigs.put(SslConfigs.SSL_KEYSTORE_TYPE_CONFIG, \"PKCS12\");\n    missingStoreConfigs.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, \"some.keystore.path\");\n    missingStoreConfigs.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, new Password(\"some.keystore.password\"));\n    missingStoreConfigs.put(SslConfigs.SSL_KEY_PASSWORD_CONFIG, new Password(\"some.key.password\"));\n    verifyInvalidReconfigure(reconfigurableBuilder, missingStoreConfigs, \"keystore not found\");\n\n        \n    newClientSelector.connect(\"3\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(newClientSelector, \"3\", 100, 10);\n}",
        "summary_tokens": [
            "tests",
            "reconfiguration",
            "of",
            "server",
            "keystore"
        ]
    },
    {
        "id": 1444,
        "code": "public void testServerTruststoreDynamicUpdate(Args args) throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SSL;\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    TestSecurityConfig config = new TestSecurityConfig(args.sslServerConfigs);\n    ListenerName listenerName = ListenerName.forSecurityProtocol(securityProtocol);\n    ChannelBuilder serverChannelBuilder = ChannelBuilders.serverChannelBuilder(listenerName,\n        false, securityProtocol, config, null, null, time, new LogContext(),\n        defaultApiVersionsSupplier());\n    server = new NioEchoServer(listenerName, securityProtocol, config,\n            \"localhost\", serverChannelBuilder, null, time);\n    server.start();\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n\n        \n    String oldNode = \"0\";\n    Selector oldClientSelector = createSelector(args.sslClientConfigs);\n    oldClientSelector.connect(oldNode, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, oldNode, 100, 10);\n\n    CertStores newClientCertStores = certBuilder(true, \"client\", args.useInlinePem).addHostName(\"localhost\").build();\n    args.sslClientConfigs = args.getTrustingConfig(newClientCertStores, args.serverCertStores);\n    Map<String, Object> newTruststoreConfigs = newClientCertStores.trustStoreProps();\n    assertTrue(serverChannelBuilder instanceof ListenerReconfigurable, \"SslChannelBuilder not reconfigurable\");\n    ListenerReconfigurable reconfigurableBuilder = (ListenerReconfigurable) serverChannelBuilder;\n    assertEquals(listenerName, reconfigurableBuilder.listenerName());\n    reconfigurableBuilder.validateReconfiguration(newTruststoreConfigs);\n    reconfigurableBuilder.reconfigure(newTruststoreConfigs);\n\n        \n    oldClientSelector.connect(\"1\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.waitForChannelClose(oldClientSelector, \"1\", ChannelState.State.AUTHENTICATION_FAILED);\n\n        \n    Selector newClientSelector = createSelector(args.sslClientConfigs);\n    newClientSelector.connect(\"2\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(newClientSelector, \"2\", 100, 10);\n\n        \n    NetworkTestUtils.checkClientConnection(oldClientSelector, oldNode, 100, 10);\n\n    Map<String, Object>  invalidConfigs = new HashMap<>(newTruststoreConfigs);\n    invalidConfigs.put(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, \"INVALID_TYPE\");\n    verifyInvalidReconfigure(reconfigurableBuilder, invalidConfigs, \"invalid truststore type\");\n\n    Map<String, Object>  missingStoreConfigs = new HashMap<>();\n    missingStoreConfigs.put(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, \"PKCS12\");\n    missingStoreConfigs.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, \"some.truststore.path\");\n    missingStoreConfigs.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, new Password(\"some.truststore.password\"));\n    verifyInvalidReconfigure(reconfigurableBuilder, missingStoreConfigs, \"truststore not found\");\n\n        \n    newClientSelector.connect(\"3\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(newClientSelector, \"3\", 100, 10);\n}",
        "summary_tokens": [
            "tests",
            "reconfiguration",
            "of",
            "server",
            "truststore"
        ]
    },
    {
        "id": 1445,
        "code": "public void testCustomClientSslEngineFactory(Args args) throws Exception {\n    args.sslClientConfigs.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "if",
            "client",
            "can",
            "plugin",
            "customize",
            "ssl"
        ]
    },
    {
        "id": 1446,
        "code": "public void testCustomServerSslEngineFactory(Args args) throws Exception {\n    args.sslServerConfigs.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "if",
            "server",
            "can",
            "plugin",
            "customize",
            "ssl"
        ]
    },
    {
        "id": 1447,
        "code": "public void testCustomClientAndServerSslEngineFactory(Args args) throws Exception {\n    args.sslClientConfigs.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    args.sslServerConfigs.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    verifySslConfigs(args);\n}",
        "summary_tokens": [
            "tests",
            "if",
            "client",
            "and",
            "server",
            "both",
            "can",
            "plugin",
            "customize",
            "ssl"
        ]
    },
    {
        "id": 1448,
        "code": "public void testCiphersSuiteForTls12FailsForTls13() throws Exception {\n    String cipherSuite = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n\n    sslServerConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Collections.singletonList(\"TLSv1.3\"));\n    sslServerConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL, new TestSecurityConfig(sslServerConfigs), null, TIME);\n\n    sslClientConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Collections.singletonList(\"TLSv1.3\"));\n    sslClientConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n\n    checkAuthentiationFailed();\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connections",
            "fails",
            "if",
            "tlsv",
            "0"
        ]
    },
    {
        "id": 1449,
        "code": "public void testCiphersSuiteFailForServerTls12ClientTls13() throws Exception {\n    String tls12CipherSuite = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n    String tls13CipherSuite = \"TLS_AES_128_GCM_SHA256\";\n\n    sslServerConfigs.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLSv1.2\");\n    sslServerConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Collections.singletonList(\"TLSv1.2\"));\n    sslServerConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(tls12CipherSuite));\n    server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL, new TestSecurityConfig(sslServerConfigs), null, TIME);\n\n    sslClientConfigs.put(SslConfigs.SSL_PROTOCOL_CONFIG, \"TLSv1.3\");\n    sslClientConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(tls13CipherSuite));\n\n    checkAuthentiationFailed();\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connections",
            "can",
            "t",
            "be",
            "made",
            "if",
            "server",
            "uses",
            "tlsv",
            "0"
        ]
    },
    {
        "id": 1450,
        "code": "public void testCiphersSuiteForTls13() throws Exception {\n    String cipherSuite = \"TLS_AES_128_GCM_SHA256\";\n\n    sslServerConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL, new TestSecurityConfig(sslServerConfigs), null, TIME);\n\n    sslClientConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    checkAuthenticationSucceed();\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connections",
            "can",
            "be",
            "made",
            "with",
            "tlsv",
            "0"
        ]
    },
    {
        "id": 1451,
        "code": "public void testCiphersSuiteForTls12() throws Exception {\n    String cipherSuite = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n\n    sslServerConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(SslConfigs.DEFAULT_SSL_ENABLED_PROTOCOLS.split(\",\")));\n    sslServerConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL, new TestSecurityConfig(sslServerConfigs), null, TIME);\n\n    sslClientConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(SslConfigs.DEFAULT_SSL_ENABLED_PROTOCOLS.split(\",\")));\n    sslClientConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    checkAuthenticationSucceed();\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connections",
            "can",
            "be",
            "made",
            "with",
            "tlsv",
            "0"
        ]
    },
    {
        "id": 1452,
        "code": "private void checkAuthentiationFailed() throws IOException, InterruptedException {\n    sslClientConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(\"TLSv1.3\"));\n    createSelector(sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(\"0\", addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.waitForChannelClose(selector, \"0\", ChannelState.State.AUTHENTICATION_FAILED);\n    server.verifyAuthenticationMetrics(0, 1);\n}",
        "summary_tokens": [
            "checks",
            "connection",
            "failed",
            "using",
            "the",
            "specified",
            "tls",
            "version"
        ]
    },
    {
        "id": 1453,
        "code": "public void testTlsDefaults(List<String> serverProtocols, List<String> clientProtocols) throws Exception {\n        \n    CertStores serverCertStores = new CertStores(true, \"server\",  \"localhost\");\n    CertStores clientCertStores = new CertStores(false, \"client\", \"localhost\");\n\n    Map<String, Object> sslClientConfigs = getTrustingConfig(clientCertStores, serverCertStores, clientProtocols);\n    Map<String, Object> sslServerConfigs = getTrustingConfig(serverCertStores, clientCertStores, serverProtocols);\n\n    NioEchoServer server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL,\n        new TestSecurityConfig(sslServerConfigs),\n        null,\n        TIME);\n    Selector selector = createClientSelector(sslClientConfigs);\n\n    String node = \"0\";\n    selector.connect(node, new InetSocketAddress(\"localhost\", server.port()), BUFFER_SIZE, BUFFER_SIZE);\n\n    if (isCompatible(serverProtocols, clientProtocols)) {\n        NetworkTestUtils.waitForChannelReady(selector, node);\n\n        int msgSz = 1024 * 1024;\n        String message = TestUtils.randomString(msgSz);\n        selector.send(new NetworkSend(node, ByteBufferSend.sizePrefixed(ByteBuffer.wrap(message.getBytes()))));\n        while (selector.completedReceives().isEmpty()) {\n            selector.poll(100L);\n        }\n        int totalBytes = msgSz + 4; \n        server.waitForMetric(\"incoming-byte\", totalBytes);\n        server.waitForMetric(\"outgoing-byte\", totalBytes);\n        server.waitForMetric(\"request\", 1);\n        server.waitForMetric(\"response\", 1);\n    } else {\n        NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n        server.verifyAuthenticationMetrics(0, 1);\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connection",
            "success",
            "with",
            "the",
            "default",
            "tls",
            "version"
        ]
    },
    {
        "id": 1454,
        "code": "private boolean isCompatible(List<String> serverProtocols, List<String> clientProtocols) {\n    assertNotNull(serverProtocols);\n    assertFalse(serverProtocols.isEmpty());\n    assertNotNull(clientProtocols);\n    assertFalse(clientProtocols.isEmpty());\n\n    return serverProtocols.contains(clientProtocols.get(0)) ||\n        (clientProtocols.get(0).equals(\"TLSv1.3\") && !Collections.disjoint(serverProtocols, clientProtocols));\n}",
        "summary_tokens": [
            "p",
            "the",
            "explanation",
            "of",
            "this",
            "check",
            "in",
            "the",
            "structure",
            "of",
            "the",
            "client",
            "hello",
            "ssl",
            "message"
        ]
    },
    {
        "id": 1455,
        "code": "public void testRenegotiationFails() throws Exception {\n    String node = \"0\";\n        \n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.waitForChannelReady(selector, node);\n\n        \n    selector.send(createSend(node, node + \"-\" + 0));\n    selector.poll(0L);\n    server.renegotiate();\n    selector.send(createSend(node, node + \"-\" + 1));\n    long expiryTime = System.currentTimeMillis() + 2000;\n\n    List<String> disconnected = new ArrayList<>();\n    while (!disconnected.contains(node) && System.currentTimeMillis() < expiryTime) {\n        selector.poll(10);\n        disconnected.addAll(selector.disconnected().keySet());\n    }\n    assertTrue(disconnected.contains(node), \"Renegotiation should cause disconnection\");\n}",
        "summary_tokens": [
            "renegotiation",
            "is",
            "not",
            "supported",
            "when",
            "tls",
            "0"
        ]
    },
    {
        "id": 1456,
        "code": "public void testResponseThrottleTime() {\n    Set<ApiKeys> authenticationKeys = EnumSet.of(ApiKeys.SASL_HANDSHAKE, ApiKeys.SASL_AUTHENTICATE);\n        \n    Set<ApiKeys> clusterActionsWithThrottleTimeMs = EnumSet.of(ApiKeys.ALTER_PARTITION, ApiKeys.ALLOCATE_PRODUCER_IDS, ApiKeys.UPDATE_FEATURES);\n    for (ApiKeys apiKey: ApiKeys.zkBrokerApis()) {\n        Schema responseSchema = apiKey.messageType.responseSchemas()[apiKey.latestVersion()];\n        BoundField throttleTimeField = responseSchema.get(\"throttle_time_ms\");\n        if ((apiKey.clusterAction && !clusterActionsWithThrottleTimeMs.contains(apiKey))\n            || authenticationKeys.contains(apiKey))\n            assertNull(throttleTimeField, \"Unexpected throttle time field: \" + apiKey);\n        else\n            assertNotNull(throttleTimeField, \"Throttle time field missing: \" + apiKey);\n    }\n}",
        "summary_tokens": [
            "all",
            "valid",
            "client",
            "responses",
            "which",
            "may",
            "be",
            "throttled",
            "should",
            "have",
            "a",
            "field",
            "named",
            "throttle",
            "time",
            "ms",
            "to",
            "return",
            "the",
            "throttle",
            "time",
            "to",
            "the",
            "client"
        ]
    },
    {
        "id": 1457,
        "code": "public void testIterateCompressedRecordWithWrapperOffsetZero() {\n    for (byte magic : Arrays.asList(RecordBatch.MAGIC_VALUE_V0, RecordBatch.MAGIC_VALUE_V1)) {\n        SimpleRecord[] simpleRecords = new SimpleRecord[] {\n            new SimpleRecord(1L, \"a\".getBytes(), \"1\".getBytes()),\n            new SimpleRecord(2L, \"b\".getBytes(), \"2\".getBytes()),\n            new SimpleRecord(3L, \"c\".getBytes(), \"3\".getBytes())\n        };\n\n        MemoryRecords records = MemoryRecords.withRecords(magic, 0L,\n                CompressionType.GZIP, TimestampType.CREATE_TIME, simpleRecords);\n\n        ByteBufferLegacyRecordBatch batch = new ByteBufferLegacyRecordBatch(records.buffer());\n        batch.setLastOffset(0L);\n\n        long offset = 0L;\n        for (Record record : batch)\n            assertEquals(offset++, record.offset());\n    }\n}",
        "summary_tokens": [
            "the",
            "wrapper",
            "offset",
            "should",
            "be",
            "0",
            "in",
            "v",
            "0",
            "but",
            "not",
            "in",
            "v",
            "0"
        ]
    },
    {
        "id": 1458,
        "code": "public void testFileSize() throws IOException {\n    assertEquals(fileRecords.channel().size(), fileRecords.sizeInBytes());\n    for (int i = 0; i < 20; i++) {\n        fileRecords.append(MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"abcd\".getBytes())));\n        assertEquals(fileRecords.channel().size(), fileRecords.sizeInBytes());\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "the",
            "cached",
            "size",
            "variable",
            "matches",
            "the",
            "actual",
            "file",
            "size",
            "as",
            "we",
            "append",
            "messages"
        ]
    },
    {
        "id": 1459,
        "code": "public void testIterationOverPartialAndTruncation() throws IOException {\n    testPartialWrite(0, fileRecords);\n    testPartialWrite(2, fileRecords);\n    testPartialWrite(4, fileRecords);\n    testPartialWrite(5, fileRecords);\n    testPartialWrite(6, fileRecords);\n}",
        "summary_tokens": [
            "test",
            "that",
            "adding",
            "invalid",
            "bytes",
            "to",
            "the",
            "end",
            "of",
            "the",
            "log",
            "doesn",
            "t",
            "break",
            "iteration"
        ]
    },
    {
        "id": 1460,
        "code": "public void testIterationDoesntChangePosition() throws IOException {\n    long position = fileRecords.channel().position();\n    Iterator<Record> records = fileRecords.records().iterator();\n    for (byte[] value : values) {\n        assertTrue(records.hasNext());\n        assertEquals(records.next().value(), ByteBuffer.wrap(value));\n    }\n    assertEquals(position, fileRecords.channel().position());\n}",
        "summary_tokens": [
            "iterating",
            "over",
            "the",
            "file",
            "does",
            "file",
            "reads",
            "but",
            "shouldn",
            "t",
            "change",
            "the",
            "position",
            "of",
            "the",
            "underlying",
            "file",
            "channel"
        ]
    },
    {
        "id": 1461,
        "code": "public void testRead() throws IOException {\n    FileRecords read = fileRecords.slice(0, fileRecords.sizeInBytes());\n    assertEquals(fileRecords.sizeInBytes(), read.sizeInBytes());\n    TestUtils.checkEquals(fileRecords.batches(), read.batches());\n\n    List<RecordBatch> items = batches(read);\n    RecordBatch first = items.get(0);\n\n        \n    read = fileRecords.slice(first.sizeInBytes(), fileRecords.sizeInBytes() - first.sizeInBytes());\n    assertEquals(fileRecords.sizeInBytes() - first.sizeInBytes(), read.sizeInBytes());\n    assertEquals(items.subList(1, items.size()), batches(read), \"Read starting from the second message\");\n\n        \n    read = fileRecords.slice(first.sizeInBytes(), fileRecords.sizeInBytes());\n    assertEquals(fileRecords.sizeInBytes() - first.sizeInBytes(), read.sizeInBytes());\n    assertEquals(items.subList(1, items.size()), batches(read), \"Read starting from the second message\");\n\n        \n    read = fileRecords.slice(first.sizeInBytes(), Integer.MAX_VALUE);\n    assertEquals(fileRecords.sizeInBytes() - first.sizeInBytes(), read.sizeInBytes());\n    assertEquals(items.subList(1, items.size()), batches(read), \"Read starting from the second message\");\n\n        \n    read = fileRecords.slice(1, fileRecords.sizeInBytes() - 1)\n            .slice(first.sizeInBytes() - 1, fileRecords.sizeInBytes());\n    assertEquals(fileRecords.sizeInBytes() - first.sizeInBytes(), read.sizeInBytes());\n    assertEquals(items.subList(1, items.size()), batches(read), \"Read starting from the second message\");\n\n        \n    read = fileRecords.slice(1, fileRecords.sizeInBytes() - 1)\n            .slice(first.sizeInBytes() - 1, Integer.MAX_VALUE);\n    assertEquals(fileRecords.sizeInBytes() - first.sizeInBytes(), read.sizeInBytes());\n    assertEquals(items.subList(1, items.size()), batches(read), \"Read starting from the second message\");\n\n        \n    RecordBatch second = items.get(1);\n    read = fileRecords.slice(first.sizeInBytes(), second.sizeInBytes());\n    assertEquals(second.sizeInBytes(), read.sizeInBytes());\n    assertEquals(Collections.singletonList(second), batches(read), \"Read a single message starting from the second message\");\n}",
        "summary_tokens": [
            "test",
            "a",
            "simple",
            "append",
            "and",
            "read"
        ]
    },
    {
        "id": 1462,
        "code": "public void testSearch() throws IOException {\n        \n    SimpleRecord lastMessage = new SimpleRecord(\"test\".getBytes());\n    fileRecords.append(MemoryRecords.withRecords(50L, CompressionType.NONE, lastMessage));\n\n    List<RecordBatch> batches = batches(fileRecords);\n    int position = 0;\n\n    int message1Size = batches.get(0).sizeInBytes();\n    assertEquals(new FileRecords.LogOffsetPosition(0L, position, message1Size),\n        fileRecords.searchForOffsetWithSize(0, 0),\n        \"Should be able to find the first message by its offset\");\n    position += message1Size;\n\n    int message2Size = batches.get(1).sizeInBytes();\n    assertEquals(new FileRecords.LogOffsetPosition(1L, position, message2Size),\n        fileRecords.searchForOffsetWithSize(1, 0),\n        \"Should be able to find second message when starting from 0\");\n    assertEquals(new FileRecords.LogOffsetPosition(1L, position, message2Size),\n        fileRecords.searchForOffsetWithSize(1, position),\n        \"Should be able to find second message starting from its offset\");\n    position += message2Size + batches.get(2).sizeInBytes();\n\n    int message4Size = batches.get(3).sizeInBytes();\n    assertEquals(new FileRecords.LogOffsetPosition(50L, position, message4Size),\n        fileRecords.searchForOffsetWithSize(3, position),\n        \"Should be able to find fourth message from a non-existent offset\");\n    assertEquals(new FileRecords.LogOffsetPosition(50L, position, message4Size),\n        fileRecords.searchForOffsetWithSize(50,  position),\n        \"Should be able to find fourth message by correct offset\");\n}",
        "summary_tokens": [
            "test",
            "the",
            "message",
            "set"
        ]
    },
    {
        "id": 1463,
        "code": "public void testIteratorWithLimits() throws IOException {\n    RecordBatch batch = batches(fileRecords).get(1);\n    int start = fileRecords.searchForOffsetWithSize(1, 0).position;\n    int size = batch.sizeInBytes();\n    FileRecords slice = fileRecords.slice(start, size);\n    assertEquals(Collections.singletonList(batch), batches(slice));\n    FileRecords slice2 = fileRecords.slice(start, size - 1);\n    assertEquals(Collections.emptyList(), batches(slice2));\n}",
        "summary_tokens": [
            "test",
            "that",
            "the",
            "message",
            "set",
            "iterator",
            "obeys",
            "start",
            "and",
            "end",
            "slicing"
        ]
    },
    {
        "id": 1464,
        "code": "public void testTruncate() throws IOException {\n    RecordBatch batch = batches(fileRecords).get(0);\n    int end = fileRecords.searchForOffsetWithSize(1, 0).position;\n    fileRecords.truncateTo(end);\n    assertEquals(Collections.singletonList(batch), batches(fileRecords));\n    assertEquals(batch.sizeInBytes(), fileRecords.sizeInBytes());\n}",
        "summary_tokens": [
            "test",
            "the",
            "truncate",
            "to",
            "method",
            "lops",
            "off",
            "messages",
            "and",
            "appropriately",
            "updates",
            "the",
            "size"
        ]
    },
    {
        "id": 1465,
        "code": "public void testTruncateNotCalledIfSizeIsSameAsTargetSize() throws IOException {\n    FileChannel channelMock = mock(FileChannel.class);\n\n    when(channelMock.size()).thenReturn(42L);\n    when(channelMock.position(42L)).thenReturn(null);\n\n    FileRecords fileRecords = new FileRecords(tempFile(), channelMock, 0, Integer.MAX_VALUE, false);\n    fileRecords.truncateTo(42);\n\n    verify(channelMock, atLeastOnce()).size();\n    verify(channelMock, times(0)).truncate(anyLong());\n}",
        "summary_tokens": [
            "test",
            "that",
            "truncate",
            "to",
            "only",
            "calls",
            "truncate",
            "on",
            "the",
            "file",
            "channel",
            "if",
            "the",
            "size",
            "of",
            "the",
            "file",
            "channel",
            "is",
            "bigger",
            "than",
            "the",
            "target",
            "size"
        ]
    },
    {
        "id": 1466,
        "code": "public void testTruncateNotCalledIfSizeIsBiggerThanTargetSize() throws IOException {\n    FileChannel channelMock = mock(FileChannel.class);\n\n    when(channelMock.size()).thenReturn(42L);\n\n    FileRecords fileRecords = new FileRecords(tempFile(), channelMock, 0, Integer.MAX_VALUE, false);\n\n    try {\n        fileRecords.truncateTo(43);\n        fail(\"Should throw KafkaException\");\n    } catch (KafkaException e) {\n            \n    }\n\n    verify(channelMock, atLeastOnce()).size();\n}",
        "summary_tokens": [
            "expect",
            "a",
            "kafka",
            "exception",
            "if",
            "target",
            "size",
            "is",
            "bigger",
            "than",
            "the",
            "size",
            "of",
            "the",
            "file",
            "records"
        ]
    },
    {
        "id": 1467,
        "code": "public void testTruncateIfSizeIsDifferentToTargetSize() throws IOException {\n    FileChannel channelMock = mock(FileChannel.class);\n\n    when(channelMock.size()).thenReturn(42L);\n    when(channelMock.truncate(anyLong())).thenReturn(channelMock);\n\n    FileRecords fileRecords = new FileRecords(tempFile(), channelMock, 0, Integer.MAX_VALUE, false);\n    fileRecords.truncateTo(23);\n\n    verify(channelMock, atLeastOnce()).size();\n    verify(channelMock).truncate(23);\n}",
        "summary_tokens": [
            "see",
            "test",
            "truncate",
            "not",
            "called",
            "if",
            "size",
            "is",
            "same",
            "as",
            "target",
            "size"
        ]
    },
    {
        "id": 1468,
        "code": "public void testPreallocateTrue() throws IOException {\n    File temp = tempFile();\n    FileRecords fileRecords = FileRecords.open(temp, false, 1024 * 1024, true);\n    long position = fileRecords.channel().position();\n    int size = fileRecords.sizeInBytes();\n    assertEquals(0, position);\n    assertEquals(0, size);\n    assertEquals(1024 * 1024, temp.length());\n}",
        "summary_tokens": [
            "test",
            "the",
            "new",
            "file",
            "records",
            "with",
            "pre",
            "allocate",
            "as",
            "true"
        ]
    },
    {
        "id": 1469,
        "code": "public void testPreallocateFalse() throws IOException {\n    File temp = tempFile();\n    FileRecords set = FileRecords.open(temp, false, 1024 * 1024, false);\n    long position = set.channel().position();\n    int size = set.sizeInBytes();\n    assertEquals(0, position);\n    assertEquals(0, size);\n    assertEquals(0, temp.length());\n}",
        "summary_tokens": [
            "test",
            "the",
            "new",
            "file",
            "records",
            "with",
            "pre",
            "allocate",
            "as",
            "false"
        ]
    },
    {
        "id": 1470,
        "code": "public void testPreallocateClearShutdown() throws IOException {\n    File temp = tempFile();\n    FileRecords fileRecords = FileRecords.open(temp, false, 1024 * 1024, true);\n    append(fileRecords, values);\n\n    int oldPosition = (int) fileRecords.channel().position();\n    int oldSize = fileRecords.sizeInBytes();\n    assertEquals(this.fileRecords.sizeInBytes(), oldPosition);\n    assertEquals(this.fileRecords.sizeInBytes(), oldSize);\n    fileRecords.close();\n\n    File tempReopen = new File(temp.getAbsolutePath());\n    FileRecords setReopen = FileRecords.open(tempReopen, true, 1024 * 1024, true);\n    int position = (int) setReopen.channel().position();\n    int size = setReopen.sizeInBytes();\n\n    assertEquals(oldPosition, position);\n    assertEquals(oldPosition, size);\n    assertEquals(oldPosition, tempReopen.length());\n}",
        "summary_tokens": [
            "test",
            "the",
            "new",
            "file",
            "records",
            "with",
            "pre",
            "allocate",
            "as",
            "true",
            "and",
            "file",
            "has",
            "been",
            "clearly",
            "shut",
            "down",
            "the",
            "file",
            "will",
            "be",
            "truncate",
            "to",
            "end",
            "of",
            "valid",
            "data"
        ]
    },
    {
        "id": 1471,
        "code": "public void testConversionOfCommitMarker() throws IOException {\n    MemoryRecords recordsToConvert = MemoryRecords.withEndTransactionMarker(0, Time.SYSTEM.milliseconds(), RecordBatch.NO_PARTITION_LEADER_EPOCH,\n            1, (short) 1, new EndTransactionMarker(ControlRecordType.COMMIT, 0));\n    MemoryRecords convertedRecords = convertRecords(recordsToConvert, (byte) 1, recordsToConvert.sizeInBytes());\n    ByteBuffer buffer = convertedRecords.buffer();\n\n        \n    buffer.getLong();\n    int sizeOfConvertedRecords = buffer.getInt();\n\n        \n    assertTrue(sizeOfConvertedRecords > buffer.limit());\n    assertFalse(convertedRecords.batchIterator().hasNext());\n}",
        "summary_tokens": [
            "test",
            "the",
            "lazy",
            "down",
            "conversion",
            "path",
            "in",
            "the",
            "presence",
            "of",
            "commit",
            "markers"
        ]
    },
    {
        "id": 1472,
        "code": "public void testConversion(CompressionType compressionType, byte toMagic, boolean overflow) throws IOException {\n    doTestConversion(compressionType, toMagic, overflow);\n}",
        "summary_tokens": [
            "test",
            "the",
            "lazy",
            "down",
            "conversion",
            "path"
        ]
    },
    {
        "id": 1473,
        "code": "public void testChecksum(Args args) {\n    CompressionType compression = args.compression;\n    byte magic = args.magic;\n        \n    if (compression != CompressionType.NONE && compression != CompressionType.LZ4)\n        return;\n\n    SimpleRecord[] records = {\n        new SimpleRecord(283843L, \"key1\".getBytes(), \"value1\".getBytes()),\n        new SimpleRecord(1234L, \"key2\".getBytes(), \"value2\".getBytes())\n    };\n    RecordBatch batch = MemoryRecords.withRecords(magic, compression, records).batches().iterator().next();\n    long expectedChecksum;\n    if (magic == RecordBatch.MAGIC_VALUE_V0) {\n        if (compression == CompressionType.NONE)\n            expectedChecksum = 1978725405L;\n        else\n            expectedChecksum = 66944826L;\n    } else if (magic == RecordBatch.MAGIC_VALUE_V1) {\n        if (compression == CompressionType.NONE)\n            expectedChecksum = 109425508L;\n        else\n            expectedChecksum = 1407303399L;\n    } else {\n        if (compression == CompressionType.NONE)\n            expectedChecksum = 3851219455L;\n        else\n            expectedChecksum = 2745969314L;\n    }\n    assertEquals(expectedChecksum, batch.checksum(), \"Unexpected checksum for magic \" + magic +\n        \" and compression type \" + compression);\n}",
        "summary_tokens": [
            "this",
            "test",
            "verifies",
            "that",
            "the",
            "checksum",
            "returned",
            "for",
            "various",
            "versions",
            "matches",
            "hardcoded",
            "values",
            "to",
            "catch",
            "unintentional",
            "changes",
            "to",
            "how",
            "the",
            "checksum",
            "is",
            "computed"
        ]
    },
    {
        "id": 1474,
        "code": "public void testBaseTimestampToDeleteHorizonConversion(Args args) {\n    int partitionLeaderEpoch = 998;\n    ByteBuffer buffer = ByteBuffer.allocate(2048);\n    MemoryRecordsBuilder builder = MemoryRecords.builder(buffer, args.magic, args.compression, TimestampType.CREATE_TIME,\n            0L, RecordBatch.NO_TIMESTAMP, partitionLeaderEpoch);\n    builder.append(5L, \"0\".getBytes(), \"0\".getBytes());\n    builder.append(10L, \"1\".getBytes(), null);\n    builder.append(15L, \"2\".getBytes(), \"2\".getBytes());\n\n    ByteBuffer filtered = ByteBuffer.allocate(2048);\n    final long deleteHorizon = Integer.MAX_VALUE / 2;\n    final RecordFilter recordFilter = new MemoryRecords.RecordFilter(deleteHorizon - 1, 1) {\n        @Override\n        protected boolean shouldRetainRecord(RecordBatch recordBatch, Record record) {\n            return true;\n        }\n\n        @Override\n        protected BatchRetentionResult checkBatchRetention(RecordBatch batch) {\n            return new BatchRetentionResult(BatchRetention.RETAIN_EMPTY, false);\n        }\n    };\n    builder.build().filterTo(new TopicPartition(\"random\", 0), recordFilter, filtered, Integer.MAX_VALUE, BufferSupplier.NO_CACHING);\n    filtered.flip();\n    MemoryRecords filteredRecords = MemoryRecords.readableRecords(filtered);\n\n    List<MutableRecordBatch> batches = TestUtils.toList(filteredRecords.batches());\n    assertEquals(1, batches.size());\n    assertEquals(OptionalLong.of(deleteHorizon), batches.get(0).deleteHorizonMs());\n\n    CloseableIterator<Record> recordIterator = batches.get(0).streamingIterator(BufferSupplier.create());\n    Record record = recordIterator.next();\n    assertEquals(5L, record.timestamp());\n    record = recordIterator.next();\n    assertEquals(10L, record.timestamp());\n    record = recordIterator.next();\n    assertEquals(15L, record.timestamp());\n    recordIterator.close();\n}",
        "summary_tokens": [
            "this",
            "test",
            "is",
            "used",
            "to",
            "see",
            "if",
            "the",
            "base",
            "timestamp",
            "of",
            "the",
            "batch",
            "has",
            "been",
            "successfully",
            "converted",
            "to",
            "a",
            "delete",
            "horizon",
            "for",
            "the",
            "tombstones",
            "transaction",
            "markers",
            "of",
            "the",
            "batch"
        ]
    },
    {
        "id": 1475,
        "code": "public void testVersionLogic() {\n    for (short version : LEADER_AND_ISR.allVersions()) {\n        List<LeaderAndIsrPartitionState> partitionStates = asList(\n            new LeaderAndIsrPartitionState()\n                .setTopicName(\"topic0\")\n                .setPartitionIndex(0)\n                .setControllerEpoch(2)\n                .setLeader(0)\n                .setLeaderEpoch(10)\n                .setIsr(asList(0, 1))\n                .setPartitionEpoch(10)\n                .setReplicas(asList(0, 1, 2))\n                .setAddingReplicas(asList(3))\n                .setRemovingReplicas(asList(2)),\n            new LeaderAndIsrPartitionState()\n                .setTopicName(\"topic0\")\n                .setPartitionIndex(1)\n                .setControllerEpoch(2)\n                .setLeader(1)\n                .setLeaderEpoch(11)\n                .setIsr(asList(1, 2, 3))\n                .setPartitionEpoch(11)\n                .setReplicas(asList(1, 2, 3))\n                .setAddingReplicas(emptyList())\n                .setRemovingReplicas(emptyList()),\n            new LeaderAndIsrPartitionState()\n                .setTopicName(\"topic1\")\n                .setPartitionIndex(0)\n                .setControllerEpoch(2)\n                .setLeader(2)\n                .setLeaderEpoch(11)\n                .setIsr(asList(2, 3, 4))\n                .setPartitionEpoch(11)\n                .setReplicas(asList(2, 3, 4))\n                .setAddingReplicas(emptyList())\n                .setRemovingReplicas(emptyList())\n        );\n\n        List<Node> liveNodes = asList(\n            new Node(0, \"host0\", 9090),\n            new Node(1, \"host1\", 9091)\n        );\n\n        Map<String, Uuid> topicIds = new HashMap<>();\n        topicIds.put(\"topic0\", Uuid.randomUuid());\n        topicIds.put(\"topic1\", Uuid.randomUuid());\n\n        LeaderAndIsrRequest request = new LeaderAndIsrRequest.Builder(version, 1, 2, 3, partitionStates,\n            topicIds, liveNodes).build();\n\n        List<LeaderAndIsrLiveLeader> liveLeaders = liveNodes.stream().map(n -> new LeaderAndIsrLiveLeader()\n            .setBrokerId(n.id())\n            .setHostName(n.host())\n            .setPort(n.port())).collect(Collectors.toList());\n        assertEquals(new HashSet<>(partitionStates), iterableToSet(request.partitionStates()));\n        assertEquals(liveLeaders, request.liveLeaders());\n        assertEquals(1, request.controllerId());\n        assertEquals(2, request.controllerEpoch());\n        assertEquals(3, request.brokerEpoch());\n\n        ByteBuffer byteBuffer = request.serialize();\n        LeaderAndIsrRequest deserializedRequest = new LeaderAndIsrRequest(new LeaderAndIsrRequestData(\n            new ByteBufferAccessor(byteBuffer), version), version);\n\n            \n            \n        if (version < 3) {\n            partitionStates.get(0)\n                .setAddingReplicas(emptyList())\n                .setRemovingReplicas(emptyList());\n        }\n\n            \n            \n        if (version < 2) {\n            topicIds = new HashMap<>();\n        }\n\n            \n            \n        if (version > 1 && version < 5) {\n            topicIds.put(\"topic0\", Uuid.ZERO_UUID);\n            topicIds.put(\"topic1\", Uuid.ZERO_UUID);\n        }\n\n        assertEquals(new HashSet<>(partitionStates), iterableToSet(deserializedRequest.partitionStates()));\n        assertEquals(topicIds, deserializedRequest.topicIds());\n        assertEquals(liveLeaders, deserializedRequest.liveLeaders());\n        assertEquals(1, request.controllerId());\n        assertEquals(2, request.controllerEpoch());\n        assertEquals(3, request.brokerEpoch());\n    }\n}",
        "summary_tokens": [
            "verifies",
            "the",
            "logic",
            "we",
            "have",
            "in",
            "leader",
            "and",
            "isr",
            "request",
            "to",
            "present",
            "a",
            "unified",
            "interface",
            "across",
            "the",
            "various",
            "versions",
            "works",
            "correctly"
        ]
    },
    {
        "id": 1476,
        "code": "public void testStructBuild() {\n    for (short version : ApiKeys.OFFSET_FETCH.allVersions()) {\n        if (version < 8) {\n            partitionDataMap.put(new TopicPartition(topicTwo, partitionTwo), new PartitionData(\n                offset,\n                leaderEpochTwo,\n                metadata,\n                Errors.GROUP_AUTHORIZATION_FAILED\n            ));\n\n            OffsetFetchResponse latestResponse = new OffsetFetchResponse(throttleTimeMs, Errors.NONE, partitionDataMap);\n            OffsetFetchResponseData data = new OffsetFetchResponseData(\n                new ByteBufferAccessor(latestResponse.serialize(version)), version);\n\n            OffsetFetchResponse oldResponse = new OffsetFetchResponse(data, version);\n\n            if (version <= 1) {\n                assertEquals(Errors.NONE.code(), data.errorCode());\n\n                    \n                assertEquals(Errors.GROUP_AUTHORIZATION_FAILED, oldResponse.error());\n                assertEquals(Utils.mkMap(Utils.mkEntry(Errors.GROUP_AUTHORIZATION_FAILED, 2),\n                    Utils.mkEntry(Errors.TOPIC_AUTHORIZATION_FAILED, 1)),\n                    oldResponse.errorCounts());\n            } else {\n                assertEquals(Errors.NONE.code(), data.errorCode());\n\n                assertEquals(Errors.NONE, oldResponse.error());\n                assertEquals(Utils.mkMap(\n                    Utils.mkEntry(Errors.NONE, 1),\n                    Utils.mkEntry(Errors.GROUP_AUTHORIZATION_FAILED, 1),\n                    Utils.mkEntry(Errors.TOPIC_AUTHORIZATION_FAILED, 1)),\n                    oldResponse.errorCounts());\n            }\n\n            if (version <= 2) {\n                assertEquals(DEFAULT_THROTTLE_TIME, oldResponse.throttleTimeMs());\n            } else {\n                assertEquals(throttleTimeMs, oldResponse.throttleTimeMs());\n            }\n\n            Map<TopicPartition, PartitionData> expectedDataMap = new HashMap<>();\n            for (Map.Entry<TopicPartition, PartitionData> entry : partitionDataMap.entrySet()) {\n                PartitionData partitionData = entry.getValue();\n                expectedDataMap.put(entry.getKey(), new PartitionData(\n                    partitionData.offset,\n                    version <= 4 ? Optional.empty() : partitionData.leaderEpoch,\n                    partitionData.metadata,\n                    partitionData.error\n                ));\n            }\n\n            Map<TopicPartition, PartitionData> responseData = oldResponse.responseDataV0ToV7();\n            assertEquals(expectedDataMap, responseData);\n\n            responseData.forEach((tp, rdata) -> assertTrue(rdata.hasError()));\n        } else {\n            partitionDataMap.put(new TopicPartition(topicTwo, partitionTwo), new PartitionData(\n                offset,\n                leaderEpochTwo,\n                metadata,\n                Errors.GROUP_AUTHORIZATION_FAILED));\n            OffsetFetchResponse latestResponse = new OffsetFetchResponse(\n                throttleTimeMs,\n                Collections.singletonMap(groupOne, Errors.NONE),\n                Collections.singletonMap(groupOne, partitionDataMap));\n            OffsetFetchResponseData data = new OffsetFetchResponseData(\n                new ByteBufferAccessor(latestResponse.serialize(version)), version);\n            OffsetFetchResponse oldResponse = new OffsetFetchResponse(data, version);\n            assertEquals(Errors.NONE.code(), data.groups().get(0).errorCode());\n\n            assertEquals(Errors.NONE, oldResponse.groupLevelError(groupOne));\n            assertEquals(Utils.mkMap(\n                Utils.mkEntry(Errors.NONE, 1),\n                Utils.mkEntry(Errors.GROUP_AUTHORIZATION_FAILED, 1),\n                Utils.mkEntry(Errors.TOPIC_AUTHORIZATION_FAILED, 1)),\n                oldResponse.errorCounts());\n            assertEquals(throttleTimeMs, oldResponse.throttleTimeMs());\n\n            Map<TopicPartition, PartitionData> expectedDataMap = new HashMap<>();\n            for (Map.Entry<TopicPartition, PartitionData> entry : partitionDataMap.entrySet()) {\n                PartitionData partitionData = entry.getValue();\n                expectedDataMap.put(entry.getKey(), new PartitionData(\n                    partitionData.offset,\n                    partitionData.leaderEpoch,\n                    partitionData.metadata,\n                    partitionData.error\n                ));\n            }\n\n            Map<TopicPartition, PartitionData> responseData = oldResponse.partitionDataMap(groupOne);\n            assertEquals(expectedDataMap, responseData);\n\n            responseData.forEach((tp, rdata) -> assertTrue(rdata.hasError()));\n        }\n    }\n}",
        "summary_tokens": [
            "test",
            "behavior",
            "changes",
            "over",
            "the",
            "versions"
        ]
    },
    {
        "id": 1477,
        "code": "public void testErrorCountsIncludesNone() {\n    assertEquals(1, createAddOffsetsToTxnResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createAddPartitionsToTxnResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createAlterClientQuotasResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createAlterConfigsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(2, createAlterPartitionReassignmentsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createAlterReplicaLogDirsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createApiVersionResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createBrokerHeartbeatResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createBrokerRegistrationResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createControlledShutdownResponse().errorCounts().get(Errors.NONE));\n    assertEquals(2, createCreateAclsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createCreatePartitionsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createCreateTokenResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createCreateTopicResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createDeleteAclsResponse(DELETE_ACLS.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createDeleteGroupsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createDeleteTopicsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createDescribeAclsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createDescribeClientQuotasResponse().errorCounts().get(Errors.NONE));\n    assertEquals(2, createDescribeConfigsResponse(DESCRIBE_CONFIGS.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createDescribeGroupResponse().errorCounts().get(Errors.NONE));\n    assertEquals(2, createDescribeLogDirsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createDescribeTokenResponse(DESCRIBE_DELEGATION_TOKEN.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(2, createElectLeadersResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createEndTxnResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createExpireTokenResponse().errorCounts().get(Errors.NONE));\n    assertEquals(3, createFetchResponse(123).errorCounts().get(Errors.NONE));\n    assertEquals(1, createFindCoordinatorResponse(FIND_COORDINATOR.oldestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createFindCoordinatorResponse(FIND_COORDINATOR.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createHeartBeatResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createIncrementalAlterConfigsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createJoinGroupResponse(JOIN_GROUP.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(2, createLeaderAndIsrResponse((short) 4).errorCounts().get(Errors.NONE));\n    assertEquals(2, createLeaderAndIsrResponse((short) 5).errorCounts().get(Errors.NONE));\n    assertEquals(3, createLeaderEpochResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createLeaveGroupResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createListGroupsResponse(LIST_GROUPS.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createListOffsetResponse(LIST_OFFSETS.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createListPartitionReassignmentsResponse().errorCounts().get(Errors.NONE));\n    assertEquals(3, createMetadataResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createOffsetCommitResponse().errorCounts().get(Errors.NONE));\n    assertEquals(2, createOffsetDeleteResponse().errorCounts().get(Errors.NONE));\n    assertEquals(3, createOffsetFetchResponse(OFFSET_FETCH.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createProduceResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createRenewTokenResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createSaslAuthenticateResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createSaslHandshakeResponse().errorCounts().get(Errors.NONE));\n    assertEquals(2, createStopReplicaResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createSyncGroupResponse(SYNC_GROUP.latestVersion()).errorCounts().get(Errors.NONE));\n    assertEquals(1, createTxnOffsetCommitResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createUpdateMetadataResponse().errorCounts().get(Errors.NONE));\n    assertEquals(1, createWriteTxnMarkersResponse().errorCounts().get(Errors.NONE));\n}",
        "summary_tokens": [
            "check",
            "that",
            "all",
            "error",
            "codes",
            "in",
            "the",
            "response",
            "get",
            "included",
            "in",
            "abstract",
            "response",
            "error",
            "counts"
        ]
    },
    {
        "id": 1478,
        "code": "public void testVersionLogic() {\n    String topic0 = \"topic0\";\n    String topic1 = \"topic1\";\n    for (short version : UPDATE_METADATA.allVersions()) {\n        List<UpdateMetadataPartitionState> partitionStates = asList(\n            new UpdateMetadataPartitionState()\n                .setTopicName(topic0)\n                .setPartitionIndex(0)\n                .setControllerEpoch(2)\n                .setLeader(0)\n                .setLeaderEpoch(10)\n                .setIsr(asList(0, 1))\n                .setZkVersion(10)\n                .setReplicas(asList(0, 1, 2))\n                .setOfflineReplicas(asList(2)),\n            new UpdateMetadataPartitionState()\n                .setTopicName(topic0)\n                .setPartitionIndex(1)\n                .setControllerEpoch(2)\n                .setLeader(1)\n                .setLeaderEpoch(11)\n                .setIsr(asList(1, 2, 3))\n                .setZkVersion(11)\n                .setReplicas(asList(1, 2, 3))\n                .setOfflineReplicas(emptyList()),\n            new UpdateMetadataPartitionState()\n                .setTopicName(topic1)\n                .setPartitionIndex(0)\n                .setControllerEpoch(2)\n                .setLeader(2)\n                .setLeaderEpoch(11)\n                .setIsr(asList(2, 3))\n                .setZkVersion(11)\n                .setReplicas(asList(2, 3, 4))\n                .setOfflineReplicas(emptyList())\n        );\n\n        List<UpdateMetadataEndpoint> broker0Endpoints = new ArrayList<>();\n        broker0Endpoints.add(\n            new UpdateMetadataEndpoint()\n                .setHost(\"host0\")\n                .setPort(9090)\n                .setSecurityProtocol(SecurityProtocol.PLAINTEXT.id));\n\n            \n        if (version >= 1) {\n            broker0Endpoints.add(new UpdateMetadataEndpoint()\n                .setHost(\"host0\")\n                .setPort(9091)\n                .setSecurityProtocol(SecurityProtocol.SSL.id));\n        }\n\n            \n        if (version >= 3) {\n            broker0Endpoints.get(0).setListener(\"listener0\");\n            broker0Endpoints.get(1).setListener(\"listener1\");\n        }\n\n        List<UpdateMetadataBroker> liveBrokers = asList(\n            new UpdateMetadataBroker()\n                .setId(0)\n                .setRack(\"rack0\")\n                .setEndpoints(broker0Endpoints),\n            new UpdateMetadataBroker()\n                .setId(1)\n                .setEndpoints(asList(\n                    new UpdateMetadataEndpoint()\n                        .setHost(\"host1\")\n                        .setPort(9090)\n                        .setSecurityProtocol(SecurityProtocol.PLAINTEXT.id)\n                        .setListener(\"PLAINTEXT\")\n                ))\n        );\n\n        Map<String, Uuid> topicIds = new HashMap<>();\n        topicIds.put(topic0, Uuid.randomUuid());\n        topicIds.put(topic1, Uuid.randomUuid());\n\n        UpdateMetadataRequest request = new UpdateMetadataRequest.Builder(version, 1, 2, 3,\n            partitionStates, liveBrokers, topicIds).build();\n\n        assertEquals(new HashSet<>(partitionStates), iterableToSet(request.partitionStates()));\n        assertEquals(liveBrokers, request.liveBrokers());\n        assertEquals(1, request.controllerId());\n        assertEquals(2, request.controllerEpoch());\n        assertEquals(3, request.brokerEpoch());\n\n        ByteBuffer byteBuffer = request.serialize();\n        UpdateMetadataRequest deserializedRequest = new UpdateMetadataRequest(new UpdateMetadataRequestData(\n                new ByteBufferAccessor(byteBuffer), version), version);\n\n            \n\n            \n        if (version < 2) {\n            for (UpdateMetadataBroker liveBroker : liveBrokers)\n                liveBroker.setRack(\"\");\n        }\n\n            \n        if (version < 3) {\n            for (UpdateMetadataBroker liveBroker : liveBrokers) {\n                for (UpdateMetadataEndpoint endpoint : liveBroker.endpoints()) {\n                    SecurityProtocol securityProtocol = SecurityProtocol.forId(endpoint.securityProtocol());\n                    endpoint.setListener(ListenerName.forSecurityProtocol(securityProtocol).value());\n                }\n            }\n        }\n\n            \n        if (version < 4)\n            partitionStates.get(0).setOfflineReplicas(emptyList());\n\n        assertEquals(new HashSet<>(partitionStates), iterableToSet(deserializedRequest.partitionStates()));\n        assertEquals(liveBrokers, deserializedRequest.liveBrokers());\n        assertEquals(1, deserializedRequest.controllerId());\n        assertEquals(2, deserializedRequest.controllerEpoch());\n            \n        if (version >= 5)\n            assertEquals(3, deserializedRequest.brokerEpoch());\n        else\n            assertEquals(-1, deserializedRequest.brokerEpoch());\n\n        long topicIdCount = deserializedRequest.data().topicStates().stream()\n                .map(UpdateMetadataRequestData.UpdateMetadataTopicState::topicId)\n                .filter(topicId -> !Uuid.ZERO_UUID.equals(topicId)).count();\n        if (version >= 7)\n            assertEquals(2, topicIdCount);\n        else\n            assertEquals(0, topicIdCount);\n    }\n}",
        "summary_tokens": [
            "verifies",
            "the",
            "logic",
            "we",
            "have",
            "in",
            "update",
            "metadata",
            "request",
            "to",
            "present",
            "a",
            "unified",
            "interface",
            "across",
            "the",
            "various",
            "versions",
            "works",
            "correctly"
        ]
    },
    {
        "id": 1479,
        "code": "public void testExtensionsWithEqualValuesAreUnique() {\n        \n        \n    assertNotEquals(new SaslExtensions(Collections.singletonMap(\"key\", \"value\")),\n        new SaslExtensions(Collections.singletonMap(\"key\", \"value\")),\n        \"SaslExtensions with unique maps should be unique\");\n\n        \n        \n    assertNotEquals(new SaslExtensions(map),\n        new SaslExtensions(map),\n        \"SaslExtensions with duplicate maps should be unique\");\n\n        \n    assertNotEquals(SaslExtensions.empty(),\n        SaslExtensions.empty(),\n        \"SaslExtensions returned from SaslExtensions.empty() should be unique\");\n}",
        "summary_tokens": [
            "tests",
            "that",
            "even",
            "when",
            "using",
            "the",
            "same",
            "underlying",
            "values",
            "in",
            "the",
            "map",
            "two",
            "sasl",
            "extensions",
            "are",
            "considered",
            "unique"
        ]
    },
    {
        "id": 1480,
        "code": "public void testInvalidPasswordSaslPlain() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", TestJaasConfig.USERNAME, \"invalidpassword\");\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"PLAIN\",\n            \"Authentication failed: Invalid username or password\");\n    server.verifyAuthenticationMetrics(0, 1);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "plain",
            "clients",
            "with",
            "invalid",
            "password",
            "fail",
            "authentication"
        ]
    },
    {
        "id": 1481,
        "code": "public void testInvalidPasswordSaslScram() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Collections.singletonList(\"SCRAM-SHA-256\"));\n    jaasConfig.setClientOptions(\"SCRAM-SHA-256\", TestJaasConfig.USERNAME, \"invalidpassword\");\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"SCRAM-SHA-256\", null);\n    server.verifyAuthenticationMetrics(0, 1);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "scram",
            "clients",
            "with",
            "invalid",
            "password",
            "fail",
            "authentication",
            "with",
            "connection",
            "close",
            "delay",
            "if",
            "configured"
        ]
    },
    {
        "id": 1482,
        "code": "public void testDisabledSaslMechanism() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Collections.singletonList(\"SCRAM-SHA-256\"));\n    jaasConfig.setClientOptions(\"PLAIN\", TestJaasConfig.USERNAME, \"invalidpassword\");\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"SCRAM-SHA-256\", null);\n    server.verifyAuthenticationMetrics(0, 1);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "clients",
            "with",
            "disabled",
            "sasl",
            "mechanism",
            "fail",
            "authentication",
            "with",
            "connection",
            "close",
            "delay",
            "if",
            "configured"
        ]
    },
    {
        "id": 1483,
        "code": "public void testClientConnectionClose() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", TestJaasConfig.USERNAME, \"invalidpassword\");\n\n    server = createEchoServer(securityProtocol);\n    createClientConnection(securityProtocol, node);\n\n    Map<?, ?> delayedClosingChannels = NetworkTestUtils.delayedClosingChannels(server.selector());\n\n        \n    TestUtils.waitForCondition(() -> {\n        poll(selector);\n        return !server.selector().channels().isEmpty();\n    }, \"Timeout waiting for connection\");\n    TestUtils.waitForCondition(() -> {\n        poll(selector);\n        return failedAuthenticationDelayMs == 0 || !delayedClosingChannels.isEmpty();\n    }, \"Timeout waiting for auth failure\");\n\n    selector.close();\n    selector = null;\n\n        \n        \n    TestUtils.waitForCondition(() -> failedAuthenticationDelayMs == 0 || delayedClosingChannels.isEmpty(),\n            \"Timeout waiting for delayed response remove\");\n    TestUtils.waitForCondition(() -> server.selector().channels().isEmpty(),\n            \"Timeout waiting for connection close\");\n\n        \n    TestUtils.waitForCondition(() -> time.milliseconds() > startTimeMs + failedAuthenticationDelayMs + 1,\n            \"Timeout when waiting for auth failure response timeout to elapse\");\n    NetworkTestUtils.completeDelayedChannelClose(server.selector(), time.nanoseconds());\n}",
        "summary_tokens": [
            "tests",
            "client",
            "connection",
            "close",
            "before",
            "response",
            "for",
            "authentication",
            "failure",
            "is",
            "sent"
        ]
    },
    {
        "id": 1484,
        "code": "public void testValidSaslPlainOverSsl() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n\n    server = createEchoServer(securityProtocol);\n    checkAuthenticationAndReauthentication(securityProtocol, node);\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "plain",
            "client",
            "and",
            "server",
            "channels",
            "using",
            "ssl",
            "transport",
            "layer"
        ]
    },
    {
        "id": 1485,
        "code": "public void testValidSaslPlainOverPlaintext() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n\n    server = createEchoServer(securityProtocol);\n    checkAuthenticationAndReauthentication(securityProtocol, node);\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "plain",
            "client",
            "and",
            "server",
            "channels",
            "using",
            "plaintext",
            "transport",
            "layer"
        ]
    },
    {
        "id": 1486,
        "code": "public void testInvalidPasswordSaslPlain() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", TestJaasConfig.USERNAME, \"invalidpassword\");\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"PLAIN\",\n            \"Authentication failed: Invalid username or password\");\n    server.verifyAuthenticationMetrics(0, 1);\n    server.verifyReauthenticationMetrics(0, 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "plain",
            "clients",
            "with",
            "invalid",
            "password",
            "fail",
            "authentication"
        ]
    },
    {
        "id": 1487,
        "code": "public void testInvalidUsernameSaslPlain() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", \"invaliduser\", TestJaasConfig.PASSWORD);\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"PLAIN\",\n            \"Authentication failed: Invalid username or password\");\n    server.verifyAuthenticationMetrics(0, 1);\n    server.verifyReauthenticationMetrics(0, 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "plain",
            "clients",
            "with",
            "invalid",
            "username",
            "fail",
            "authentication"
        ]
    },
    {
        "id": 1488,
        "code": "public void testMissingUsernameSaslPlain() throws Exception {\n    String node = \"0\";\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", null, \"mypassword\");\n\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    server = createEchoServer(securityProtocol);\n    createSelector(securityProtocol, saslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    try {\n        selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n        fail(\"SASL/PLAIN channel created without username\");\n    } catch (IOException e) {\n            \n        assertTrue(selector.channels().isEmpty(), \"Channels not closed\");\n        for (SelectionKey key : selector.keys())\n            assertFalse(key.isValid(), \"Key not cancelled\");\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "plain",
            "clients",
            "without",
            "valid",
            "username",
            "fail",
            "authentication"
        ]
    },
    {
        "id": 1489,
        "code": "public void testMissingPasswordSaslPlain() throws Exception {\n    String node = \"0\";\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", \"myuser\", null);\n\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    server = createEchoServer(securityProtocol);\n    createSelector(securityProtocol, saslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    try {\n        selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n        fail(\"SASL/PLAIN channel created without password\");\n    } catch (IOException e) {\n            \n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "plain",
            "clients",
            "with",
            "missing",
            "password",
            "in",
            "jaas",
            "configuration",
            "fail",
            "authentication"
        ]
    },
    {
        "id": 1490,
        "code": "public void testClientExceptionDoesNotContainSensitiveData() throws Exception {\n    InvalidScramServerCallbackHandler.reset();\n\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Collections.singletonList(\"SCRAM-SHA-256\"));\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, PlainLoginModule.class.getName(), new HashMap<>());\n    String callbackPrefix = ListenerName.forSecurityProtocol(securityProtocol).saslMechanismConfigPrefix(\"SCRAM-SHA-256\");\n    saslServerConfigs.put(callbackPrefix + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            InvalidScramServerCallbackHandler.class.getName());\n    server = createEchoServer(securityProtocol);\n\n    try {\n        InvalidScramServerCallbackHandler.sensitiveException =\n                new IOException(\"Could not connect to password database locahost:8000\");\n        createAndCheckClientAuthenticationFailure(securityProtocol, \"1\", \"SCRAM-SHA-256\", null);\n\n        InvalidScramServerCallbackHandler.sensitiveException =\n                new SaslException(\"Password for existing user \" + TestServerCallbackHandler.USERNAME + \" is invalid\");\n        createAndCheckClientAuthenticationFailure(securityProtocol, \"1\", \"SCRAM-SHA-256\", null);\n\n        InvalidScramServerCallbackHandler.reset();\n        InvalidScramServerCallbackHandler.clientFriendlyException =\n                new SaslAuthenticationException(\"Credential verification failed\");\n        createAndCheckClientAuthenticationFailure(securityProtocol, \"1\", \"SCRAM-SHA-256\",\n                InvalidScramServerCallbackHandler.clientFriendlyException.getMessage());\n    } finally {\n        InvalidScramServerCallbackHandler.reset();\n    }\n}",
        "summary_tokens": [
            "verify",
            "that",
            "messages",
            "from",
            "sasl",
            "exceptions",
            "thrown",
            "in",
            "the",
            "server",
            "during",
            "authentication",
            "are",
            "not",
            "propagated",
            "to",
            "the",
            "client",
            "since",
            "these",
            "may",
            "contain",
            "sensitive",
            "data"
        ]
    },
    {
        "id": 1491,
        "code": "public void testMechanismPluggability() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"DIGEST-MD5\", Arrays.asList(\"DIGEST-MD5\"));\n    configureDigestMd5ServerCallback(securityProtocol);\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnection(securityProtocol, node);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "mechanisms",
            "that",
            "are",
            "not",
            "supported",
            "in",
            "kafka",
            "can",
            "be",
            "plugged",
            "in",
            "without",
            "modifying",
            "kafka",
            "code",
            "if",
            "sasl",
            "client",
            "and",
            "server",
            "providers",
            "are",
            "available"
        ]
    },
    {
        "id": 1492,
        "code": "public void testMultipleServerMechanisms() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"DIGEST-MD5\", Arrays.asList(\"DIGEST-MD5\", \"PLAIN\", \"SCRAM-SHA-256\"));\n    configureDigestMd5ServerCallback(securityProtocol);\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n\n    String node1 = \"1\";\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"PLAIN\");\n    createAndCheckClientConnection(securityProtocol, node1);\n    server.verifyAuthenticationMetrics(1, 0);\n\n    Selector selector2 = null;\n    Selector selector3 = null;\n    try {\n        String node2 = \"2\";\n        saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"DIGEST-MD5\");\n        createSelector(securityProtocol, saslClientConfigs);\n        selector2 = selector;\n        InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n        selector.connect(node2, addr, BUFFER_SIZE, BUFFER_SIZE);\n        NetworkTestUtils.checkClientConnection(selector, node2, 100, 10);\n        selector = null; \n        server.verifyAuthenticationMetrics(2, 0);\n\n        String node3 = \"3\";\n        saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"SCRAM-SHA-256\");\n        createSelector(securityProtocol, saslClientConfigs);\n        selector3 = selector;\n        selector.connect(node3, new InetSocketAddress(\"localhost\", server.port()), BUFFER_SIZE, BUFFER_SIZE);\n        NetworkTestUtils.checkClientConnection(selector, node3, 100, 10);\n        server.verifyAuthenticationMetrics(3, 0);\n            \n            \n        delay((long) (CONNECTIONS_MAX_REAUTH_MS_VALUE * 1.1));\n        server.verifyReauthenticationMetrics(0, 0);\n\n        NetworkTestUtils.checkClientConnection(selector2, node2, 100, 10);\n        server.verifyReauthenticationMetrics(1, 0);\n\n        NetworkTestUtils.checkClientConnection(selector3, node3, 100, 10);\n        server.verifyReauthenticationMetrics(2, 0);\n            \n    } finally {\n        if (selector2 != null)\n            selector2.close();\n        if (selector3 != null)\n            selector3.close();\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "servers",
            "supporting",
            "multiple",
            "sasl",
            "mechanisms",
            "work",
            "with",
            "clients",
            "using",
            "any",
            "of",
            "the",
            "enabled",
            "mechanisms"
        ]
    },
    {
        "id": 1493,
        "code": "public void testValidSaslScramSha256() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"SCRAM-SHA-256\", Arrays.asList(\"SCRAM-SHA-256\"));\n\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n    checkAuthenticationAndReauthentication(securityProtocol, \"0\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "scram",
            "sha",
            "0",
            "client",
            "and",
            "server",
            "channels"
        ]
    },
    {
        "id": 1494,
        "code": "public void testValidSaslScramMechanisms() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"SCRAM-SHA-256\", new ArrayList<>(ScramMechanism.mechanismNames()));\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n\n    for (String mechanism : ScramMechanism.mechanismNames()) {\n        saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, mechanism);\n        createAndCheckClientConnection(securityProtocol, \"node-\" + mechanism);\n    }\n}",
        "summary_tokens": [
            "tests",
            "all",
            "supported",
            "scram",
            "client",
            "and",
            "server",
            "channels"
        ]
    },
    {
        "id": 1495,
        "code": "public void testInvalidPasswordSaslScram() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Arrays.asList(\"SCRAM-SHA-256\"));\n    Map<String, Object> options = new HashMap<>();\n    options.put(\"username\", TestJaasConfig.USERNAME);\n    options.put(\"password\", \"invalidpassword\");\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_CLIENT, ScramLoginModule.class.getName(), options);\n\n    String node = \"0\";\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"SCRAM-SHA-256\", null);\n    server.verifyAuthenticationMetrics(0, 1);\n    server.verifyReauthenticationMetrics(0, 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "scram",
            "clients",
            "fail",
            "authentication",
            "if",
            "password",
            "is",
            "invalid"
        ]
    },
    {
        "id": 1496,
        "code": "public void testUnknownUserSaslScram() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Arrays.asList(\"SCRAM-SHA-256\"));\n    Map<String, Object> options = new HashMap<>();\n    options.put(\"username\", \"unknownUser\");\n    options.put(\"password\", TestJaasConfig.PASSWORD);\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_CLIENT, ScramLoginModule.class.getName(), options);\n\n    String node = \"0\";\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"SCRAM-SHA-256\", null);\n    server.verifyAuthenticationMetrics(0, 1);\n    server.verifyReauthenticationMetrics(0, 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "scram",
            "clients",
            "without",
            "valid",
            "username",
            "fail",
            "authentication"
        ]
    },
    {
        "id": 1497,
        "code": "public void testUserCredentialsUnavailableForScramMechanism() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"SCRAM-SHA-256\", new ArrayList<>(ScramMechanism.mechanismNames()));\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n\n    server.credentialCache().cache(ScramMechanism.SCRAM_SHA_256.mechanismName(), ScramCredential.class).remove(TestJaasConfig.USERNAME);\n    String node = \"1\";\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"SCRAM-SHA-256\");\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"SCRAM-SHA-256\", null);\n    server.verifyAuthenticationMetrics(0, 1);\n\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"SCRAM-SHA-512\");\n    createAndCheckClientConnection(securityProtocol, \"2\");\n    server.verifyAuthenticationMetrics(1, 1);\n    server.verifyReauthenticationMetrics(0, 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "sasl",
            "scram",
            "clients",
            "fail",
            "authentication",
            "if",
            "credentials",
            "are",
            "not",
            "available",
            "for",
            "the",
            "specific",
            "scram",
            "mechanism"
        ]
    },
    {
        "id": 1498,
        "code": "public void testScramUsernameWithSpecialCharacters() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    String username = \"special user= test,scram\";\n    String password = username + \"-password\";\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Arrays.asList(\"SCRAM-SHA-256\"));\n    Map<String, Object> options = new HashMap<>();\n    options.put(\"username\", username);\n    options.put(\"password\", password);\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_CLIENT, ScramLoginModule.class.getName(), options);\n\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(username, password);\n    createAndCheckClientConnection(securityProtocol, \"0\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "scram",
            "with",
            "username",
            "containing",
            "characters",
            "that",
            "need",
            "to",
            "be",
            "encoded"
        ]
    },
    {
        "id": 1499,
        "code": "public void testUnauthenticatedApiVersionsRequestOverPlaintextHandshakeVersion0() throws Exception {\n    testUnauthenticatedApiVersionsRequest(SecurityProtocol.SASL_PLAINTEXT, (short) 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "kafka",
            "api",
            "versions",
            "requests",
            "are",
            "handled",
            "by",
            "the",
            "sasl",
            "server",
            "authenticator",
            "prior",
            "to",
            "sasl",
            "handshake",
            "flow",
            "and",
            "that",
            "subsequent",
            "authentication",
            "succeeds",
            "when",
            "transport",
            "layer",
            "is",
            "plaintext"
        ]
    },
    {
        "id": 1500,
        "code": "public void testUnauthenticatedApiVersionsRequestOverPlaintextHandshakeVersion1() throws Exception {\n    testUnauthenticatedApiVersionsRequest(SecurityProtocol.SASL_PLAINTEXT, (short) 1);\n}",
        "summary_tokens": [
            "see",
            "test",
            "unauthenticated",
            "api",
            "versions",
            "request",
            "over",
            "ssl",
            "handshake",
            "version",
            "0",
            "for",
            "test",
            "scenario"
        ]
    },
    {
        "id": 1501,
        "code": "public void testUnauthenticatedApiVersionsRequestOverSslHandshakeVersion0() throws Exception {\n    testUnauthenticatedApiVersionsRequest(SecurityProtocol.SASL_SSL, (short) 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "kafka",
            "api",
            "versions",
            "requests",
            "are",
            "handled",
            "by",
            "the",
            "sasl",
            "server",
            "authenticator",
            "prior",
            "to",
            "sasl",
            "handshake",
            "flow",
            "and",
            "that",
            "subsequent",
            "authentication",
            "succeeds",
            "when",
            "transport",
            "layer",
            "is",
            "ssl"
        ]
    },
    {
        "id": 1502,
        "code": "public void testUnauthenticatedApiVersionsRequestOverSslHandshakeVersion1() throws Exception {\n    testUnauthenticatedApiVersionsRequest(SecurityProtocol.SASL_SSL, (short) 1);\n}",
        "summary_tokens": [
            "see",
            "test",
            "unauthenticated",
            "api",
            "versions",
            "request",
            "over",
            "plaintext",
            "handshake",
            "version",
            "0",
            "for",
            "test",
            "scenario"
        ]
    },
    {
        "id": 1503,
        "code": "public void testApiVersionsRequestWithServerUnsupportedVersion() throws Exception {\n    short handshakeVersion = ApiKeys.SASL_HANDSHAKE.latestVersion();\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node = \"1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node);\n\n    RequestHeader header = new RequestHeader(new RequestHeaderData().\n            setRequestApiKey(ApiKeys.API_VERSIONS.id).\n            setRequestApiVersion(Short.MAX_VALUE).\n            setClientId(\"someclient\").\n            setCorrelationId(1),\n            (short) 2);\n    ApiVersionsRequest request = new ApiVersionsRequest.Builder().build();\n    selector.send(new NetworkSend(node, request.toSend(header)));\n    ByteBuffer responseBuffer = waitForResponse();\n    ResponseHeader.parse(responseBuffer, ApiKeys.API_VERSIONS.responseHeaderVersion((short) 0));\n    ApiVersionsResponse response = ApiVersionsResponse.parse(responseBuffer, (short) 0);\n    assertEquals(Errors.UNSUPPORTED_VERSION.code(), response.data().errorCode());\n\n    ApiVersion apiVersion = response.data().apiKeys().find(ApiKeys.API_VERSIONS.id);\n    assertNotNull(apiVersion);\n    assertEquals(ApiKeys.API_VERSIONS.id, apiVersion.apiKey());\n    assertEquals(ApiKeys.API_VERSIONS.oldestVersion(), apiVersion.minVersion());\n    assertEquals(ApiKeys.API_VERSIONS.latestVersion(), apiVersion.maxVersion());\n\n        \n    sendVersionRequestReceiveResponse(node);\n\n        \n    sendHandshakeRequestReceiveResponse(node, handshakeVersion);\n    authenticateUsingSaslPlainAndCheckConnection(node, handshakeVersion > 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "unsupported",
            "version",
            "of",
            "api",
            "versions",
            "request",
            "before",
            "sasl",
            "handshake",
            "request",
            "returns",
            "error",
            "response",
            "and",
            "does",
            "not",
            "result",
            "in",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 1504,
        "code": "public void testSaslUnsupportedClientVersions() throws Exception {\n    configureMechanisms(\"SCRAM-SHA-512\", Arrays.asList(\"SCRAM-SHA-512\"));\n\n    server = startServerApiVersionsUnsupportedByClient(SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\");\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n\n    String node = \"0\";\n\n    createClientConnection(SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\", node, true);\n    NetworkTestUtils.checkClientConnection(selector, \"0\", 100, 10);\n}",
        "summary_tokens": [
            "tests",
            "correct",
            "negotiation",
            "of",
            "handshake",
            "and",
            "authenticate",
            "api",
            "versions",
            "by",
            "having",
            "the",
            "server",
            "return",
            "a",
            "higher",
            "version",
            "than",
            "supported",
            "on",
            "the",
            "client"
        ]
    },
    {
        "id": 1505,
        "code": "public void testInvalidApiVersionsRequest() throws Exception {\n    short handshakeVersion = ApiKeys.SASL_HANDSHAKE.latestVersion();\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node = \"1\";\n    short version = ApiKeys.API_VERSIONS.latestVersion();\n    createClientConnection(SecurityProtocol.PLAINTEXT, node);\n    RequestHeader header = new RequestHeader(ApiKeys.API_VERSIONS, version, \"someclient\", 1);\n    ApiVersionsRequest request = new ApiVersionsRequest(new ApiVersionsRequestData().\n            setClientSoftwareName(\"  \").\n            setClientSoftwareVersion(\"   \"), version);\n    selector.send(new NetworkSend(node, request.toSend(header)));\n    ByteBuffer responseBuffer = waitForResponse();\n    ResponseHeader.parse(responseBuffer, ApiKeys.API_VERSIONS.responseHeaderVersion(version));\n    ApiVersionsResponse response =\n        ApiVersionsResponse.parse(responseBuffer, version);\n    assertEquals(Errors.INVALID_REQUEST.code(), response.data().errorCode());\n\n        \n    sendVersionRequestReceiveResponse(node);\n\n        \n    sendHandshakeRequestReceiveResponse(node, handshakeVersion);\n    authenticateUsingSaslPlainAndCheckConnection(node, handshakeVersion > 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "invalid",
            "api",
            "version",
            "request",
            "is",
            "handled",
            "by",
            "the",
            "server",
            "correctly",
            "and",
            "returns",
            "an",
            "invalid",
            "request",
            "error"
        ]
    },
    {
        "id": 1506,
        "code": "public void testValidApiVersionsRequest() throws Exception {\n    short handshakeVersion = ApiKeys.SASL_HANDSHAKE.latestVersion();\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node = \"1\";\n    short version = ApiKeys.API_VERSIONS.latestVersion();\n    createClientConnection(SecurityProtocol.PLAINTEXT, node);\n    RequestHeader header = new RequestHeader(ApiKeys.API_VERSIONS, version, \"someclient\", 1);\n    ApiVersionsRequest request = new ApiVersionsRequest.Builder().build(version);\n    selector.send(new NetworkSend(node, request.toSend(header)));\n    ByteBuffer responseBuffer = waitForResponse();\n    ResponseHeader.parse(responseBuffer, ApiKeys.API_VERSIONS.responseHeaderVersion(version));\n    ApiVersionsResponse response = ApiVersionsResponse.parse(responseBuffer, version);\n    assertEquals(Errors.NONE.code(), response.data().errorCode());\n\n        \n    sendHandshakeRequestReceiveResponse(node, handshakeVersion);\n    authenticateUsingSaslPlainAndCheckConnection(node, handshakeVersion > 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "valid",
            "api",
            "version",
            "request",
            "is",
            "handled",
            "by",
            "the",
            "server",
            "correctly",
            "and",
            "returns",
            "an",
            "none",
            "error"
        ]
    },
    {
        "id": 1507,
        "code": "public void testSaslHandshakeRequestWithUnsupportedVersion() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    SaslHandshakeRequest request = buildSaslHandshakeRequest(\"PLAIN\", ApiKeys.SASL_HANDSHAKE.latestVersion());\n    RequestHeader header = new RequestHeader(ApiKeys.SASL_HANDSHAKE, Short.MAX_VALUE, \"someclient\", 2);\n        \n    selector.send(new NetworkSend(node1, request.toSend(header)));\n        \n        \n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n}",
        "summary_tokens": [
            "tests",
            "that",
            "unsupported",
            "version",
            "of",
            "sasl",
            "handshake",
            "request",
            "returns",
            "error",
            "response",
            "and",
            "fails",
            "authentication"
        ]
    },
    {
        "id": 1508,
        "code": "public void testInvalidSaslPacket() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    sendHandshakeRequestReceiveResponse(node1, (short) 1);\n    Random random = new Random();\n    byte[] bytes = new byte[1024];\n    random.nextBytes(bytes);\n    selector.send(new NetworkSend(node1, ByteBufferSend.sizePrefixed(ByteBuffer.wrap(bytes))));\n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n\n        \n    String node2 = \"invalid2\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node2);\n    random.nextBytes(bytes);\n    selector.send(new NetworkSend(node2, ByteBufferSend.sizePrefixed(ByteBuffer.wrap(bytes))));\n    NetworkTestUtils.waitForChannelClose(selector, node2, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good2\");\n}",
        "summary_tokens": [
            "tests",
            "that",
            "any",
            "invalid",
            "data",
            "during",
            "kafka",
            "sasl",
            "handshake",
            "request",
            "flow",
            "or",
            "the",
            "actual",
            "sasl",
            "authentication",
            "flow",
            "result",
            "in",
            "authentication",
            "failure",
            "and",
            "do",
            "not",
            "cause",
            "any",
            "failures",
            "in",
            "the",
            "server"
        ]
    },
    {
        "id": 1509,
        "code": "public void testInvalidApiVersionsRequestSequence() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    sendHandshakeRequestReceiveResponse(node1, (short) 1);\n\n    ApiVersionsRequest request = createApiVersionsRequestV0();\n    RequestHeader versionsHeader = new RequestHeader(ApiKeys.API_VERSIONS, request.version(), \"someclient\", 2);\n    selector.send(new NetworkSend(node1, request.toSend(versionsHeader)));\n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n}",
        "summary_tokens": [
            "tests",
            "that",
            "api",
            "versions",
            "request",
            "after",
            "kafka",
            "sasl",
            "handshake",
            "request",
            "flow",
            "but",
            "prior",
            "to",
            "actual",
            "sasl",
            "authentication",
            "results",
            "in",
            "authentication",
            "failure"
        ]
    },
    {
        "id": 1510,
        "code": "public void testPacketSizeTooBig() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    sendHandshakeRequestReceiveResponse(node1, (short) 1);\n    ByteBuffer buffer = ByteBuffer.allocate(1024);\n    buffer.putInt(Integer.MAX_VALUE);\n    buffer.put(new byte[buffer.capacity() - 4]);\n    buffer.rewind();\n    selector.send(new NetworkSend(node1, ByteBufferSend.sizePrefixed(buffer)));\n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n\n        \n    String node2 = \"invalid2\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node2);\n    buffer.clear();\n    buffer.putInt(Integer.MAX_VALUE);\n    buffer.put(new byte[buffer.capacity() - 4]);\n    buffer.rewind();\n    selector.send(new NetworkSend(node2, ByteBufferSend.sizePrefixed(buffer)));\n    NetworkTestUtils.waitForChannelClose(selector, node2, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good2\");\n}",
        "summary_tokens": [
            "tests",
            "that",
            "packets",
            "that",
            "are",
            "too",
            "big",
            "during",
            "kafka",
            "sasl",
            "handshake",
            "request",
            "flow",
            "or",
            "the",
            "actual",
            "sasl",
            "authentication",
            "flow",
            "result",
            "in",
            "authentication",
            "failure",
            "and",
            "do",
            "not",
            "cause",
            "any",
            "failures",
            "in",
            "the",
            "server"
        ]
    },
    {
        "id": 1511,
        "code": "public void testDisallowedKafkaRequestsBeforeAuthentication() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    MetadataRequest metadataRequest1 = new MetadataRequest.Builder(Collections.singletonList(\"sometopic\"),\n            true).build();\n    RequestHeader metadataRequestHeader1 = new RequestHeader(ApiKeys.METADATA, metadataRequest1.version(),\n            \"someclient\", 1);\n    selector.send(new NetworkSend(node1, metadataRequest1.toSend(metadataRequestHeader1)));\n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n\n        \n    String node2 = \"invalid2\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node2);\n    sendHandshakeRequestReceiveResponse(node2, (short) 1);\n    MetadataRequest metadataRequest2 = new MetadataRequest.Builder(Collections.singletonList(\"sometopic\"), true).build();\n    RequestHeader metadataRequestHeader2 = new RequestHeader(ApiKeys.METADATA,\n            metadataRequest2.version(), \"someclient\", 2);\n    selector.send(new NetworkSend(node2, metadataRequest2.toSend(metadataRequestHeader2)));\n    NetworkTestUtils.waitForChannelClose(selector, node2, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good2\");\n}",
        "summary_tokens": [
            "tests",
            "that",
            "kafka",
            "requests",
            "that",
            "are",
            "forbidden",
            "until",
            "successful",
            "authentication",
            "result",
            "in",
            "authentication",
            "failure",
            "and",
            "do",
            "not",
            "cause",
            "any",
            "failures",
            "in",
            "the",
            "server"
        ]
    },
    {
        "id": 1512,
        "code": "public void testInvalidLoginModule() throws Exception {\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_CLIENT, \"InvalidLoginModule\", TestJaasConfig.defaultClientOptions());\n\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    server = createEchoServer(securityProtocol);\n    try {\n        createSelector(securityProtocol, saslClientConfigs);\n        fail(\"SASL/PLAIN channel created without valid login module\");\n    } catch (KafkaException e) {\n            \n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "connections",
            "cannot",
            "be",
            "created",
            "if",
            "the",
            "login",
            "module",
            "class",
            "is",
            "unavailable"
        ]
    },
    {
        "id": 1513,
        "code": "public void testClientAuthenticateCallbackHandler() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    saslClientConfigs.put(SaslConfigs.SASL_CLIENT_CALLBACK_HANDLER_CLASS, TestClientCallbackHandler.class.getName());\n    jaasConfig.setClientOptions(\"PLAIN\", \"\", \"\"); \n\n    Map<String, Object> options = new HashMap<>();\n    options.put(\"user_\" + TestClientCallbackHandler.USERNAME, TestClientCallbackHandler.PASSWORD);\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, PlainLoginModule.class.getName(), options);\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnection(securityProtocol, \"good\");\n\n    options.clear();\n    options.put(\"user_\" + TestClientCallbackHandler.USERNAME, \"invalid-password\");\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, PlainLoginModule.class.getName(), options);\n    createAndCheckClientConnectionFailure(securityProtocol, \"invalid\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "client",
            "authentication",
            "callback",
            "handler",
            "override"
        ]
    },
    {
        "id": 1514,
        "code": "public void testServerAuthenticateCallbackHandler() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, PlainLoginModule.class.getName(), new HashMap<String, Object>());\n    String callbackPrefix = ListenerName.forSecurityProtocol(securityProtocol).saslMechanismConfigPrefix(\"PLAIN\");\n    saslServerConfigs.put(callbackPrefix + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            TestServerCallbackHandler.class.getName());\n    server = createEchoServer(securityProtocol);\n\n        \n    jaasConfig.setClientOptions(\"PLAIN\", TestServerCallbackHandler.USERNAME, TestServerCallbackHandler.PASSWORD);\n    createAndCheckClientConnection(securityProtocol, \"good\");\n\n        \n    jaasConfig.setClientOptions(\"PLAIN\", TestJaasConfig.USERNAME, \"invalid-password\");\n    createAndCheckClientConnectionFailure(securityProtocol, \"invalid\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "server",
            "authentication",
            "callback",
            "handler",
            "override"
        ]
    },
    {
        "id": 1515,
        "code": "public void testAuthenticateCallbackHandlerMechanisms() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"DIGEST-MD5\", Arrays.asList(\"DIGEST-MD5\", \"PLAIN\"));\n\n        \n    saslServerConfigs.put(\"plain.\" + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            TestServerCallbackHandler.class);\n    saslServerConfigs.put(\"digest-md5.\" + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            DigestServerCallbackHandler.class);\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnectionFailure(securityProtocol, \"invalid\");\n\n        \n    ListenerName listener = ListenerName.forSecurityProtocol(securityProtocol);\n    saslServerConfigs.remove(\"plain.\" + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS);\n    saslServerConfigs.remove(\"digest-md5.\" + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS);\n    saslServerConfigs.put(listener.saslMechanismConfigPrefix(\"plain\") + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            TestServerCallbackHandler.class);\n    saslServerConfigs.put(listener.saslMechanismConfigPrefix(\"digest-md5\") + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            DigestServerCallbackHandler.class);\n    server = createEchoServer(securityProtocol);\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good-digest-md5\");\n\n        \n    jaasConfig.setClientOptions(\"PLAIN\", TestServerCallbackHandler.USERNAME, TestServerCallbackHandler.PASSWORD);\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"PLAIN\");\n    createAndCheckClientConnection(securityProtocol, \"good-plain\");\n}",
        "summary_tokens": [
            "test",
            "that",
            "callback",
            "handlers",
            "are",
            "only",
            "applied",
            "to",
            "connections",
            "for",
            "the",
            "mechanisms",
            "configured",
            "for",
            "the",
            "handler"
        ]
    },
    {
        "id": 1516,
        "code": "public void testClientLoginOverride() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", \"invaliduser\", \"invalidpassword\");\n    server = createEchoServer(securityProtocol);\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_LOGIN_CLASS, TestLogin.class.getName());\n    createAndCheckClientConnection(securityProtocol, \"1\");\n    assertEquals(1, TestLogin.loginCount.get());\n\n        \n    saslClientConfigs.remove(SaslConfigs.SASL_LOGIN_CLASS);\n    createAndCheckClientConnectionFailure(securityProtocol, \"invalid\");\n    assertEquals(1, TestLogin.loginCount.get());\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "login",
            "class",
            "override"
        ]
    },
    {
        "id": 1517,
        "code": "public void testServerLoginOverride() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    String prefix = ListenerName.forSecurityProtocol(securityProtocol).saslMechanismConfigPrefix(\"PLAIN\");\n    saslServerConfigs.put(prefix + SaslConfigs.SASL_LOGIN_CLASS, TestLogin.class.getName());\n    server = createEchoServer(securityProtocol);\n\n        \n    assertEquals(1, TestLogin.loginCount.get());\n\n    createAndCheckClientConnection(securityProtocol, \"1\");\n    assertEquals(1, TestLogin.loginCount.get());\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "server",
            "login",
            "class",
            "override"
        ]
    },
    {
        "id": 1518,
        "code": "public void testClientLoginCallbackOverride() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_CLIENT, TestPlainLoginModule.class.getName(),\n            Collections.emptyMap());\n    server = createEchoServer(securityProtocol);\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS, TestLoginCallbackHandler.class.getName());\n    createAndCheckClientConnection(securityProtocol, \"1\");\n\n        \n    saslClientConfigs.remove(SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS);\n    try {\n        createClientConnection(securityProtocol, \"invalid\");\n    } catch (Exception e) {\n        assertTrue(e.getCause() instanceof LoginException, \"Unexpected exception \" + e.getCause());\n    }\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "login",
            "callback",
            "class",
            "override"
        ]
    },
    {
        "id": 1519,
        "code": "public void testServerLoginCallbackOverride() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, TestPlainLoginModule.class.getName(),\n            Collections.emptyMap());\n    jaasConfig.setClientOptions(\"PLAIN\", TestServerCallbackHandler.USERNAME, TestServerCallbackHandler.PASSWORD);\n    ListenerName listenerName = ListenerName.forSecurityProtocol(securityProtocol);\n    String prefix = listenerName.saslMechanismConfigPrefix(\"PLAIN\");\n    saslServerConfigs.put(prefix + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            TestServerCallbackHandler.class);\n    Class<?> loginCallback = TestLoginCallbackHandler.class;\n\n    try {\n        createEchoServer(securityProtocol);\n        fail(\"Should have failed to create server with default login handler\");\n    } catch (KafkaException e) {\n            \n    }\n\n    try {\n        saslServerConfigs.put(SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS, loginCallback);\n        createEchoServer(securityProtocol);\n        fail(\"Should have failed to create server with login handler config without listener+mechanism prefix\");\n    } catch (KafkaException e) {\n            \n        saslServerConfigs.remove(SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS);\n    }\n\n    try {\n        saslServerConfigs.put(\"plain.\" + SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS, loginCallback);\n        createEchoServer(securityProtocol);\n        fail(\"Should have failed to create server with login handler config without listener prefix\");\n    } catch (KafkaException e) {\n            \n        saslServerConfigs.remove(\"plain.\" + SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS);\n    }\n\n    try {\n        saslServerConfigs.put(listenerName.configPrefix() + SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS, loginCallback);\n        createEchoServer(securityProtocol);\n        fail(\"Should have failed to create server with login handler config without mechanism prefix\");\n    } catch (KafkaException e) {\n            \n        saslServerConfigs.remove(\"plain.\" + SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS);\n    }\n\n        \n    saslServerConfigs.put(prefix + SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS, loginCallback);\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnection(securityProtocol, \"1\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "server",
            "login",
            "callback",
            "class",
            "override"
        ]
    },
    {
        "id": 1520,
        "code": "public void testDisabledMechanism() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"DIGEST-MD5\"));\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnectionFailure(securityProtocol, node);\n    server.verifyAuthenticationMetrics(0, 1);\n    server.verifyReauthenticationMetrics(0, 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "mechanisms",
            "with",
            "default",
            "implementation",
            "in",
            "kafka",
            "may",
            "be",
            "disabled",
            "in",
            "the",
            "kafka",
            "server",
            "by",
            "removing",
            "from",
            "the",
            "enabled",
            "mechanism",
            "list"
        ]
    },
    {
        "id": 1521,
        "code": "public void testInvalidMechanism() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"INVALID\");\n\n    server = createEchoServer(securityProtocol);\n    try {\n        createAndCheckClientConnectionFailure(securityProtocol, node);\n        fail(\"Did not generate exception prior to creating channel\");\n    } catch (IOException expected) {\n        server.verifyAuthenticationMetrics(0, 0);\n        server.verifyReauthenticationMetrics(0, 0);\n        Throwable underlyingCause = expected.getCause().getCause().getCause();\n        assertEquals(SaslAuthenticationException.class, underlyingCause.getClass());\n        assertEquals(\"Failed to create SaslClient with mechanism INVALID\", underlyingCause.getMessage());\n    } finally {\n        closeClientConnectionIfNecessary();\n    }\n}",
        "summary_tokens": [
            "tests",
            "that",
            "clients",
            "using",
            "invalid",
            "sasl",
            "mechanisms",
            "fail",
            "authentication"
        ]
    },
    {
        "id": 1522,
        "code": "public void testClientDynamicJaasConfiguration() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"PLAIN\");\n    saslServerConfigs.put(BrokerSecurityConfigs.SASL_ENABLED_MECHANISMS_CONFIG, Arrays.asList(\"PLAIN\"));\n    Map<String, Object> serverOptions = new HashMap<>();\n    serverOptions.put(\"user_user1\", \"user1-secret\");\n    serverOptions.put(\"user_user2\", \"user2-secret\");\n    TestJaasConfig staticJaasConfig = new TestJaasConfig();\n    staticJaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, PlainLoginModule.class.getName(),\n            serverOptions);\n    staticJaasConfig.setClientOptions(\"PLAIN\", \"user1\", \"invalidpassword\");\n    Configuration.setConfiguration(staticJaasConfig);\n    server = createEchoServer(securityProtocol);\n\n        \n    createAndCheckClientConnectionFailure(securityProtocol, \"1\");\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_JAAS_CONFIG, TestJaasConfig.jaasConfigProperty(\"PLAIN\", \"user1\", \"user1-secret\"));\n    createAndCheckClientConnection(securityProtocol, \"2\");\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_JAAS_CONFIG, TestJaasConfig.jaasConfigProperty(\"PLAIN\", \"user1\", \"user2-secret\"));\n    createAndCheckClientConnectionFailure(securityProtocol, \"3\");\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_JAAS_CONFIG, TestJaasConfig.jaasConfigProperty(\"PLAIN\", \"user2\", \"user2-secret\"));\n    createAndCheckClientConnection(securityProtocol, \"4\");\n\n        \n    String module1 = TestJaasConfig.jaasConfigProperty(\"PLAIN\", \"user1\", \"user1-secret\").value();\n    String module2 = TestJaasConfig.jaasConfigProperty(\"PLAIN\", \"user2\", \"user2-secret\").value();\n    saslClientConfigs.put(SaslConfigs.SASL_JAAS_CONFIG, new Password(module1 + \" \" + module2));\n    try {\n        createClientConnection(securityProtocol, \"1\");\n        fail(\"Connection created with multiple login modules in sasl.jaas.config\");\n    } catch (IllegalArgumentException e) {\n            \n    }\n}",
        "summary_tokens": [
            "tests",
            "dynamic",
            "jaas",
            "configuration",
            "property",
            "for",
            "sasl",
            "clients"
        ]
    },
    {
        "id": 1523,
        "code": "public void testServerDynamicJaasConfiguration() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"PLAIN\");\n    saslServerConfigs.put(BrokerSecurityConfigs.SASL_ENABLED_MECHANISMS_CONFIG, Arrays.asList(\"PLAIN\"));\n    Map<String, Object> serverOptions = new HashMap<>();\n    serverOptions.put(\"user_user1\", \"user1-secret\");\n    serverOptions.put(\"user_user2\", \"user2-secret\");\n    saslServerConfigs.put(\"listener.name.sasl_ssl.plain.\" + SaslConfigs.SASL_JAAS_CONFIG,\n            TestJaasConfig.jaasConfigProperty(\"PLAIN\", serverOptions));\n    TestJaasConfig staticJaasConfig = new TestJaasConfig();\n    staticJaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, PlainLoginModule.class.getName(),\n            Collections.emptyMap());\n    staticJaasConfig.setClientOptions(\"PLAIN\", \"user1\", \"user1-secret\");\n    Configuration.setConfiguration(staticJaasConfig);\n    server = createEchoServer(securityProtocol);\n\n        \n    createAndCheckClientConnection(securityProtocol, \"1\");\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_JAAS_CONFIG,\n            TestJaasConfig.jaasConfigProperty(\"PLAIN\", \"user2\", \"user2-secret\"));\n    createAndCheckClientConnection(securityProtocol, \"2\");\n}",
        "summary_tokens": [
            "tests",
            "dynamic",
            "jaas",
            "configuration",
            "property",
            "for",
            "sasl",
            "server"
        ]
    },
    {
        "id": 1524,
        "code": "public void oldSaslPlainPlaintextServerWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(false, true, SecurityProtocol.SASL_PLAINTEXT, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "plain",
            "authentication",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1525,
        "code": "public void oldSaslPlainPlaintextClientWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(true, false, SecurityProtocol.SASL_PLAINTEXT, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "plain",
            "authentication",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1526,
        "code": "public void oldSaslScramPlaintextServerWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(false, true, SecurityProtocol.SASL_PLAINTEXT, \"SCRAM-SHA-256\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "scram",
            "authentication",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1527,
        "code": "public void oldSaslScramPlaintextClientWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(true, false, SecurityProtocol.SASL_PLAINTEXT, \"SCRAM-SHA-256\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "scram",
            "authentication",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1528,
        "code": "public void oldSaslPlainSslServerWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(false, true, SecurityProtocol.SASL_SSL, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "plain",
            "authentication",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1529,
        "code": "public void oldSaslPlainSslClientWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(true, false, SecurityProtocol.SASL_SSL, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "plain",
            "authentication",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1530,
        "code": "public void oldSaslScramSslServerWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(false, true, SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "scram",
            "authentication",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1531,
        "code": "public void oldSaslScramSslClientWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(true, false, SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\");\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "scram",
            "authentication",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1532,
        "code": "public void oldSaslPlainPlaintextServerWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(false, true, SecurityProtocol.SASL_PLAINTEXT, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "plain",
            "authentication",
            "failure",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1533,
        "code": "public void oldSaslPlainPlaintextClientWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(true, false, SecurityProtocol.SASL_PLAINTEXT, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "plain",
            "authentication",
            "failure",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1534,
        "code": "public void oldSaslScramPlaintextServerWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(false, true, SecurityProtocol.SASL_PLAINTEXT, \"SCRAM-SHA-256\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "scram",
            "authentication",
            "failure",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1535,
        "code": "public void oldSaslScramPlaintextClientWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(true, false, SecurityProtocol.SASL_PLAINTEXT, \"SCRAM-SHA-256\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "scram",
            "authentication",
            "failure",
            "over",
            "plaintext",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1536,
        "code": "public void oldSaslPlainSslServerWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(false, true, SecurityProtocol.SASL_SSL, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "plain",
            "authentication",
            "failure",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1537,
        "code": "public void oldSaslPlainSslClientWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(true, false, SecurityProtocol.SASL_SSL, \"PLAIN\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "plain",
            "authentication",
            "failure",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1538,
        "code": "public void oldSaslScramSslServerWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(false, true, SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "scram",
            "authentication",
            "failure",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "server",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "client"
        ]
    },
    {
        "id": 1539,
        "code": "public void oldSaslScramSslClientWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(true, false, SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\");\n}",
        "summary_tokens": [
            "tests",
            "sasl",
            "scram",
            "authentication",
            "failure",
            "over",
            "ssl",
            "with",
            "old",
            "version",
            "of",
            "client",
            "that",
            "does",
            "not",
            "support",
            "sasl",
            "authenticate",
            "headers",
            "and",
            "new",
            "version",
            "of",
            "server"
        ]
    },
    {
        "id": 1540,
        "code": "public void testValidSaslOauthBearerMechanism() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"OAUTHBEARER\", Arrays.asList(\"OAUTHBEARER\"));\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnection(securityProtocol, node);\n}",
        "summary_tokens": [
            "tests",
            "oauthbearer",
            "client",
            "and",
            "server",
            "channels"
        ]
    },
    {
        "id": 1541,
        "code": "public void testCannotReauthenticateWithDifferentPrincipal() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    saslClientConfigs.put(SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS,\n            AlternateLoginCallbackHandler.class.getName());\n    configureMechanisms(OAuthBearerLoginModule.OAUTHBEARER_MECHANISM,\n            Arrays.asList(OAuthBearerLoginModule.OAUTHBEARER_MECHANISM));\n    server = createEchoServer(securityProtocol);\n        \n    createClientConnection(securityProtocol, node);\n    checkClientConnection(node);\n        \n    server.verifyAuthenticationMetrics(1, 0);\n    server.verifyReauthenticationMetrics(0, 0);\n        \n    delay(1000L);\n    assertThrows(AssertionFailedError.class, () -> checkClientConnection(node));\n    server.verifyReauthenticationMetrics(0, 1);\n}",
        "summary_tokens": [
            "re",
            "authentication",
            "must",
            "fail",
            "if",
            "principal",
            "changes"
        ]
    },
    {
        "id": 1542,
        "code": "public void testCannotReauthenticateWithDifferentMechanism() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"DIGEST-MD5\", Arrays.asList(\"DIGEST-MD5\", \"PLAIN\"));\n    configureDigestMd5ServerCallback(securityProtocol);\n    server = createEchoServer(securityProtocol);\n\n    String saslMechanism = (String) saslClientConfigs.get(SaslConfigs.SASL_MECHANISM);\n    Map<String, ?> configs = new TestSecurityConfig(saslClientConfigs).values();\n    this.channelBuilder = new AlternateSaslChannelBuilder(Mode.CLIENT,\n            Collections.singletonMap(saslMechanism, JaasContext.loadClientContext(configs)), securityProtocol, null,\n            false, saslMechanism, true, credentialCache, null, time);\n    this.channelBuilder.configure(configs);\n        \n    this.selector = NetworkTestUtils.createSelector(channelBuilder, time);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    checkClientConnection(node);\n        \n    server.verifyAuthenticationMetrics(1, 0);\n    server.verifyReauthenticationMetrics(0, 0);\n        \n    delay((long) (CONNECTIONS_MAX_REAUTH_MS_VALUE * 1.1));\n    assertThrows(AssertionFailedError.class, () -> checkClientConnection(node));\n    server.verifyAuthenticationMetrics(1, 0);\n    server.verifyReauthenticationMetrics(0, 1);\n}",
        "summary_tokens": [
            "re",
            "authentication",
            "must",
            "fail",
            "if",
            "mechanism",
            "changes"
        ]
    },
    {
        "id": 1543,
        "code": "public void testCannotReauthenticateAgainFasterThanOneSecond() throws Exception {\n    String node = \"0\";\n    time = new MockTime();\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(OAuthBearerLoginModule.OAUTHBEARER_MECHANISM,\n            Arrays.asList(OAuthBearerLoginModule.OAUTHBEARER_MECHANISM));\n    server = createEchoServer(securityProtocol);\n    try {\n        createClientConnection(securityProtocol, node);\n        checkClientConnection(node);\n        server.verifyAuthenticationMetrics(1, 0);\n        server.verifyReauthenticationMetrics(0, 0);\n            \n        time.sleep((long) (CONNECTIONS_MAX_REAUTH_MS_VALUE * 1.1));\n        checkClientConnection(node);\n        server.verifyAuthenticationMetrics(1, 0);\n        server.verifyReauthenticationMetrics(1, 0);\n            \n        time.sleep((long) (CONNECTIONS_MAX_REAUTH_MS_VALUE * 1.1));\n        AssertionFailedError exception = assertThrows(AssertionFailedError.class,\n            () -> NetworkTestUtils.checkClientConnection(selector, node, 1, 1));\n        String expectedResponseTextRegex = \"\\\\w-\" + node;\n        String receivedResponseTextRegex = \".*\" + OAuthBearerLoginModule.OAUTHBEARER_MECHANISM;\n        assertTrue(exception.getMessage().matches(\n            \".*<\" + expectedResponseTextRegex + \">.*<\" + receivedResponseTextRegex + \".*?>\"),\n            \"Should have received the SaslHandshakeRequest bytes back since we re-authenticated too quickly, \" +\n            \"but instead we got our generated message echoed back, implying re-auth succeeded when it should not have: \" +\n            exception);\n        server.verifyReauthenticationMetrics(1, 0); \n    } finally {\n        selector.close();\n        selector = null;\n    }\n}",
        "summary_tokens": [
            "second",
            "re",
            "authentication",
            "must",
            "fail",
            "if",
            "it",
            "is",
            "sooner",
            "than",
            "one",
            "second",
            "after",
            "the",
            "first"
        ]
    },
    {
        "id": 1544,
        "code": "public void testRepeatedValidSaslPlainOverSsl() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n        \n    saslServerConfigs.put(BrokerSecurityConfigs.CONNECTIONS_MAX_REAUTH_MS,\n            Double.valueOf(1.1 * 1000L / 0.85).longValue());\n\n    server = createEchoServer(securityProtocol);\n    createClientConnection(securityProtocol, node);\n    checkClientConnection(node);\n    server.verifyAuthenticationMetrics(1, 0);\n    server.verifyReauthenticationMetrics(0, 0);\n    double successfulReauthentications = 0;\n    int desiredNumReauthentications = 5;\n    long startMs = Time.SYSTEM.milliseconds();\n    long timeoutMs = startMs + 1000 * 15; \n    while (successfulReauthentications < desiredNumReauthentications\n            && Time.SYSTEM.milliseconds() < timeoutMs) {\n        checkClientConnection(node);\n        successfulReauthentications = server.metricValue(\"successful-reauthentication-total\");\n    }\n    server.verifyReauthenticationMetrics(desiredNumReauthentications, 0);\n}",
        "summary_tokens": [
            "tests",
            "good",
            "path",
            "sasl",
            "plain",
            "client",
            "and",
            "server",
            "channels",
            "using",
            "ssl",
            "transport",
            "layer"
        ]
    },
    {
        "id": 1545,
        "code": "public void testValidSaslOauthBearerMechanismWithoutServerTokens() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"OAUTHBEARER\");\n    saslServerConfigs.put(BrokerSecurityConfigs.SASL_ENABLED_MECHANISMS_CONFIG, Arrays.asList(\"OAUTHBEARER\"));\n    saslClientConfigs.put(SaslConfigs.SASL_JAAS_CONFIG,\n            TestJaasConfig.jaasConfigProperty(\"OAUTHBEARER\", Collections.singletonMap(\"unsecuredLoginStringClaim_sub\", TestJaasConfig.USERNAME)));\n    saslServerConfigs.put(\"listener.name.sasl_ssl.oauthbearer.\" + SaslConfigs.SASL_JAAS_CONFIG,\n            TestJaasConfig.jaasConfigProperty(\"OAUTHBEARER\", Collections.emptyMap()));\n\n        \n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnection(securityProtocol, node);\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_JAAS_CONFIG,\n            TestJaasConfig.jaasConfigProperty(\"OAUTHBEARER\", Collections.emptyMap()));\n    createAndCheckClientConnectionFailure(securityProtocol, node);\n\n        \n    saslServerConfigs.put(\"listener.name.sasl_ssl.oauthbearer.\" + SaslConfigs.SASL_JAAS_CONFIG,\n            TestJaasConfig.jaasConfigProperty(\"OAUTHBEARER\", Collections.singletonMap(\"unsecuredLoginExtension_test\", \"something\")));\n    try {\n        createEchoServer(securityProtocol);\n        fail(\"Server created with invalid login config containing extensions without a token\");\n    } catch (Throwable e) {\n        assertTrue(e.getCause() instanceof LoginException, \"Unexpected exception \" + Utils.stackTrace(e));\n    }\n}",
        "summary_tokens": [
            "tests",
            "oauthbearer",
            "client",
            "channels",
            "without",
            "tokens",
            "for",
            "the",
            "server"
        ]
    },
    {
        "id": 1546,
        "code": "public void testInsufficientScopeSaslOauthBearerMechanism() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"OAUTHBEARER\", Arrays.asList(\"OAUTHBEARER\"));\n        \n    Map<String, Object> serverJaasConfigOptionsMap = TestJaasConfig.defaultServerOptions(\"OAUTHBEARER\");\n    serverJaasConfigOptionsMap.put(\"unsecuredValidatorRequiredScope\", \"LOGIN_TO_KAFKA\"); \n    jaasConfig.createOrUpdateEntry(\"KafkaServer\",\n            \"org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule\", serverJaasConfigOptionsMap);\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol,\n            \"node-\" + OAuthBearerLoginModule.OAUTHBEARER_MECHANISM, OAuthBearerLoginModule.OAUTHBEARER_MECHANISM,\n            \"{\\\"status\\\":\\\"insufficient_scope\\\", \\\"scope\\\":\\\"[LOGIN_TO_KAFKA]\\\"}\");\n}",
        "summary_tokens": [
            "tests",
            "oauthbearer",
            "fails",
            "the",
            "connection",
            "when",
            "the",
            "client",
            "presents",
            "a",
            "token",
            "with",
            "insufficient",
            "scope"
        ]
    },
    {
        "id": 1547,
        "code": "private void testUnauthenticatedApiVersionsRequest(SecurityProtocol securityProtocol, short saslHandshakeVersion) throws Exception {\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node = \"1\";\n    SecurityProtocol clientProtocol;\n    switch (securityProtocol) {\n        case SASL_PLAINTEXT:\n            clientProtocol = SecurityProtocol.PLAINTEXT;\n            break;\n        case SASL_SSL:\n            clientProtocol = SecurityProtocol.SSL;\n            break;\n        default:\n            throw new IllegalArgumentException(\"Server protocol \" + securityProtocol + \" is not SASL\");\n    }\n    createClientConnection(clientProtocol, node);\n    NetworkTestUtils.waitForChannelReady(selector, node);\n\n        \n    ApiVersionsResponse versionsResponse = sendVersionRequestReceiveResponse(node);\n    assertEquals(ApiKeys.SASL_HANDSHAKE.oldestVersion(), versionsResponse.apiVersion(ApiKeys.SASL_HANDSHAKE.id).minVersion());\n    assertEquals(ApiKeys.SASL_HANDSHAKE.latestVersion(), versionsResponse.apiVersion(ApiKeys.SASL_HANDSHAKE.id).maxVersion());\n    assertEquals(ApiKeys.SASL_AUTHENTICATE.oldestVersion(), versionsResponse.apiVersion(ApiKeys.SASL_AUTHENTICATE.id).minVersion());\n    assertEquals(ApiKeys.SASL_AUTHENTICATE.latestVersion(), versionsResponse.apiVersion(ApiKeys.SASL_AUTHENTICATE.id).maxVersion());\n\n        \n    SaslHandshakeResponse handshakeResponse = sendHandshakeRequestReceiveResponse(node, saslHandshakeVersion);\n    assertEquals(Collections.singletonList(\"PLAIN\"), handshakeResponse.enabledMechanisms());\n\n        \n    authenticateUsingSaslPlainAndCheckConnection(node, saslHandshakeVersion > 0);\n}",
        "summary_tokens": [
            "tests",
            "that",
            "kafka",
            "api",
            "versions",
            "requests",
            "are",
            "handled",
            "by",
            "the",
            "sasl",
            "server",
            "authenticator",
            "prior",
            "to",
            "sasl",
            "handshake",
            "flow",
            "and",
            "that",
            "subsequent",
            "authentication",
            "succeeds",
            "when",
            "transport",
            "layer",
            "is",
            "plaintext",
            "ssl"
        ]
    },
    {
        "id": 1548,
        "code": "public void testUnvalidatedExtensionsAreIgnored() {\n    Map<String, String> extensions = new HashMap<>();\n    extensions.put(\"valid\", \"valid\");\n    extensions.put(\"error\", \"error\");\n    extensions.put(\"nothing\", \"nothing\");\n\n    OAuthBearerExtensionsValidatorCallback callback = new OAuthBearerExtensionsValidatorCallback(TOKEN, new SaslExtensions(extensions));\n    callback.error(\"error\", \"error\");\n    callback.valid(\"valid\");\n\n    assertFalse(callback.validatedExtensions().containsKey(\"nothing\"));\n    assertFalse(callback.invalidExtensions().containsKey(\"nothing\"));\n    assertEquals(\"nothing\", callback.ignoredExtensions().get(\"nothing\"));\n}",
        "summary_tokens": [
            "extensions",
            "that",
            "are",
            "neither",
            "validated",
            "or",
            "invalidated",
            "must",
            "not",
            "be",
            "present",
            "in",
            "either",
            "maps"
        ]
    },
    {
        "id": 1549,
        "code": "private SaslExtensions saslExtensions() {\n    return SaslExtensions.empty();\n}",
        "summary_tokens": [
            "we",
            "don",
            "t",
            "want",
            "to",
            "use",
            "mocks",
            "for",
            "our",
            "tests",
            "as",
            "we",
            "need",
            "to",
            "make",
            "sure",
            "to",
            "test",
            "sasl",
            "extensions",
            "sasl",
            "extensions",
            "equals",
            "object",
            "and",
            "sasl",
            "extensions",
            "hash",
            "code",
            "methods"
        ]
    },
    {
        "id": 1550,
        "code": "public void savesCustomExtensionAsNegotiatedProperty() throws Exception {\n    Map<String, String> customExtensions = new HashMap<>();\n    customExtensions.put(\"firstKey\", \"value1\");\n    customExtensions.put(\"secondKey\", \"value2\");\n\n    byte[] nextChallenge = saslServer\n            .evaluateResponse(clientInitialResponse(null, false, customExtensions));\n\n    assertTrue(nextChallenge.length == 0, \"Next challenge is not empty\");\n    assertEquals(\"value1\", saslServer.getNegotiatedProperty(\"firstKey\"));\n    assertEquals(\"value2\", saslServer.getNegotiatedProperty(\"secondKey\"));\n}",
        "summary_tokens": [
            "sasl",
            "extensions",
            "that",
            "are",
            "validated",
            "by",
            "the",
            "callback",
            "handler",
            "should",
            "be",
            "accessible",
            "through",
            "the",
            "get",
            "negotiated",
            "property",
            "method"
        ]
    },
    {
        "id": 1551,
        "code": "public void unrecognizedExtensionsAreNotSaved() throws Exception {\n    saslServer = new OAuthBearerSaslServer(EXTENSIONS_VALIDATOR_CALLBACK_HANDLER);\n    Map<String, String> customExtensions = new HashMap<>();\n    customExtensions.put(\"firstKey\", \"value1\");\n    customExtensions.put(\"secondKey\", \"value1\");\n    customExtensions.put(\"thirdKey\", \"value1\");\n\n    byte[] nextChallenge = saslServer\n            .evaluateResponse(clientInitialResponse(null, false, customExtensions));\n\n    assertTrue(nextChallenge.length == 0, \"Next challenge is not empty\");\n    assertNull(saslServer.getNegotiatedProperty(\"thirdKey\"), \"Extensions not recognized by the server must be ignored\");\n}",
        "summary_tokens": [
            "sasl",
            "extensions",
            "that",
            "were",
            "not",
            "recognized",
            "neither",
            "validated",
            "nor",
            "invalidated",
            "by",
            "the",
            "callback",
            "handler",
            "must",
            "not",
            "be",
            "accessible",
            "through",
            "the",
            "get",
            "negotiated",
            "property",
            "method"
        ]
    },
    {
        "id": 1552,
        "code": "public void throwsAuthenticationExceptionOnInvalidExtensions() {\n    OAuthBearerUnsecuredValidatorCallbackHandler invalidHandler = new OAuthBearerUnsecuredValidatorCallbackHandler() {\n        @Override\n        public void handle(Callback[] callbacks) throws UnsupportedCallbackException {\n            for (Callback callback : callbacks) {\n                if (callback instanceof OAuthBearerValidatorCallback) {\n                    OAuthBearerValidatorCallback validationCallback = (OAuthBearerValidatorCallback) callback;\n                    validationCallback.token(new OAuthBearerTokenMock());\n                } else if (callback instanceof OAuthBearerExtensionsValidatorCallback) {\n                    OAuthBearerExtensionsValidatorCallback extensionsCallback = (OAuthBearerExtensionsValidatorCallback) callback;\n                    extensionsCallback.error(\"firstKey\", \"is not valid\");\n                    extensionsCallback.error(\"secondKey\", \"is not valid either\");\n                } else\n                    throw new UnsupportedCallbackException(callback);\n            }\n        }\n    };\n    saslServer = new OAuthBearerSaslServer(invalidHandler);\n    Map<String, String> customExtensions = new HashMap<>();\n    customExtensions.put(\"firstKey\", \"value\");\n    customExtensions.put(\"secondKey\", \"value\");\n\n    assertThrows(SaslAuthenticationException.class,\n        () -> saslServer.evaluateResponse(clientInitialResponse(null, false, customExtensions)));\n}",
        "summary_tokens": [
            "if",
            "the",
            "callback",
            "handler",
            "handles",
            "the",
            "oauth",
            "bearer",
            "extensions",
            "validator",
            "callback",
            "and",
            "finds",
            "an",
            "invalid",
            "extension",
            "sasl",
            "server",
            "should",
            "throw",
            "an",
            "authentication",
            "exception"
        ]
    },
    {
        "id": 1553,
        "code": "public void testBasicScheduleRefresh() throws Exception {\n    String keyId = \"abc123\";\n    Time time = new MockTime();\n    HttpsJwks httpsJwks = spyHttpsJwks();\n\n    try (RefreshingHttpsJwks refreshingHttpsJwks = getRefreshingHttpsJwks(time, httpsJwks)) {\n        refreshingHttpsJwks.init();\n        verify(httpsJwks, times(1)).refresh();\n        assertTrue(refreshingHttpsJwks.maybeExpediteRefresh(keyId));\n        verify(httpsJwks, times(1)).refresh();\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "a",
            "key",
            "not",
            "previously",
            "scheduled",
            "for",
            "refresh",
            "will",
            "be",
            "scheduled",
            "without",
            "a",
            "refresh"
        ]
    },
    {
        "id": 1554,
        "code": "public void testMaybeExpediteRefreshNoDelay() throws Exception {\n    String keyId = \"abc123\";\n    Time time = new MockTime();\n    HttpsJwks httpsJwks = spyHttpsJwks();\n\n    try (RefreshingHttpsJwks refreshingHttpsJwks = getRefreshingHttpsJwks(time, httpsJwks)) {\n        refreshingHttpsJwks.init();\n        assertTrue(refreshingHttpsJwks.maybeExpediteRefresh(keyId));\n        assertFalse(refreshingHttpsJwks.maybeExpediteRefresh(keyId));\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "a",
            "key",
            "previously",
            "scheduled",
            "for",
            "refresh",
            "will",
            "b",
            "not",
            "b",
            "be",
            "scheduled",
            "a",
            "second",
            "time",
            "if",
            "it",
            "s",
            "requested",
            "right",
            "away"
        ]
    },
    {
        "id": 1555,
        "code": "public void testMaybeExpediteRefreshDelays() throws Exception {\n    assertMaybeExpediteRefreshWithDelay(MISSING_KEY_ID_CACHE_IN_FLIGHT_MS - 1, false);\n    assertMaybeExpediteRefreshWithDelay(MISSING_KEY_ID_CACHE_IN_FLIGHT_MS, true);\n    assertMaybeExpediteRefreshWithDelay(MISSING_KEY_ID_CACHE_IN_FLIGHT_MS + 1, true);\n}",
        "summary_tokens": [
            "test",
            "that",
            "a",
            "key",
            "previously",
            "scheduled",
            "for",
            "refresh",
            "b",
            "will",
            "b",
            "be",
            "scheduled",
            "a",
            "second",
            "time",
            "if",
            "it",
            "s",
            "requested",
            "after",
            "the",
            "delay"
        ]
    },
    {
        "id": 1556,
        "code": "public void testLongKey() throws Exception {\n    char[] keyIdChars = new char[MISSING_KEY_ID_MAX_KEY_LENGTH + 1];\n    Arrays.fill(keyIdChars, '0');\n    String keyId = new String(keyIdChars);\n\n    Time time = new MockTime();\n    HttpsJwks httpsJwks = spyHttpsJwks();\n\n    try (RefreshingHttpsJwks refreshingHttpsJwks = getRefreshingHttpsJwks(time, httpsJwks)) {\n        refreshingHttpsJwks.init();\n        verify(httpsJwks, times(1)).refresh();\n        assertFalse(refreshingHttpsJwks.maybeExpediteRefresh(keyId));\n        verify(httpsJwks, times(1)).refresh();\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "a",
            "long",
            "key",
            "will",
            "not",
            "be",
            "looked",
            "up",
            "because",
            "the",
            "key",
            "id",
            "is",
            "too",
            "long"
        ]
    },
    {
        "id": 1557,
        "code": "public void testSecondaryRefreshAfterElapsedDelay() throws Exception {\n    String keyId = \"abc123\";\n    Time time = MockTime.SYSTEM;    \n                                        \n    HttpsJwks httpsJwks = spyHttpsJwks();\n\n    try (RefreshingHttpsJwks refreshingHttpsJwks = getRefreshingHttpsJwks(time, httpsJwks)) {\n        refreshingHttpsJwks.init();\n        verify(httpsJwks, times(1)).refresh();\n        assertTrue(refreshingHttpsJwks.maybeExpediteRefresh(keyId));\n        time.sleep(REFRESH_MS + 1);\n        verify(httpsJwks, times(3)).refresh();\n        assertFalse(refreshingHttpsJwks.maybeExpediteRefresh(keyId));\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "if",
            "we",
            "ask",
            "to",
            "load",
            "a",
            "missing",
            "key",
            "and",
            "then",
            "we",
            "wait",
            "past",
            "the",
            "sleep",
            "time",
            "that",
            "it",
            "will",
            "call",
            "refresh",
            "to",
            "load",
            "the",
            "key"
        ]
    },
    {
        "id": 1558,
        "code": "private HttpsJwks spyHttpsJwks() {\n    HttpsJwks httpsJwks = new HttpsJwks(\"https://www.example.com\");\n\n    SimpleResponse simpleResponse = new SimpleResponse() {\n        @Override\n        public int getStatusCode() {\n            return 200;\n        }\n\n        @Override\n        public String getStatusMessage() {\n            return \"OK\";\n        }\n\n        @Override\n        public Collection<String> getHeaderNames() {\n            return Collections.emptyList();\n        }\n\n        @Override\n        public List<String> getHeaderValues(String name) {\n            return Collections.emptyList();\n        }\n\n        @Override\n        public String getBody() {\n            return \"{\\\"keys\\\": []}\";\n        }\n    };\n\n    httpsJwks.setSimpleHttpGet(l -> simpleResponse);\n\n    return Mockito.spy(httpsJwks);\n}",
        "summary_tokens": [
            "we",
            "spy",
            "not",
            "mock",
            "the",
            "https",
            "jwks",
            "instance",
            "because",
            "we",
            "want",
            "to",
            "have",
            "it",
            "partially",
            "mocked",
            "to",
            "determine",
            "if",
            "it",
            "s",
            "calling",
            "its",
            "internal",
            "refresh",
            "method"
        ]
    },
    {
        "id": 1559,
        "code": "public void rfc7677Example() throws Exception {\n    ScramFormatter formatter = new ScramFormatter(ScramMechanism.SCRAM_SHA_256);\n\n    String password = \"pencil\";\n    String c1 = \"n,,n=user,r=rOprNGfwEbeRWgbNEkqO\";\n    String s1 = \"r=rOprNGfwEbeRWgbNEkqO%hvYDpWUa2RaTCAfuxFIlj)hNlF$k0,s=W22ZaJ0SNY7soEsUEjb6gQ==,i=4096\";\n    String c2 = \"c=biws,r=rOprNGfwEbeRWgbNEkqO%hvYDpWUa2RaTCAfuxFIlj)hNlF$k0,p=dHzbZapWIk4jUhN+Ute9ytag9zjfMHgsqmmiz7AndVQ=\";\n    String s2 = \"v=6rriTRBi23WpRR/wtup+mMhUZUn/dB5nLTJRsjl95G4=\";\n    ClientFirstMessage clientFirst = new ClientFirstMessage(ScramFormatter.toBytes(c1));\n    ServerFirstMessage serverFirst = new ServerFirstMessage(ScramFormatter.toBytes(s1));\n    ClientFinalMessage clientFinal = new ClientFinalMessage(ScramFormatter.toBytes(c2));\n    ServerFinalMessage serverFinal = new ServerFinalMessage(ScramFormatter.toBytes(s2));\n\n    String username = clientFirst.saslName();\n    assertEquals(\"user\", username);\n    String clientNonce = clientFirst.nonce();\n    assertEquals(\"rOprNGfwEbeRWgbNEkqO\", clientNonce);\n    String serverNonce = serverFirst.nonce().substring(clientNonce.length());\n    assertEquals(\"%hvYDpWUa2RaTCAfuxFIlj)hNlF$k0\", serverNonce);\n    byte[] salt = serverFirst.salt();\n    assertArrayEquals(Base64.getDecoder().decode(\"W22ZaJ0SNY7soEsUEjb6gQ==\"), salt);\n    int iterations = serverFirst.iterations();\n    assertEquals(4096, iterations);\n    byte[] channelBinding = clientFinal.channelBinding();\n    assertArrayEquals(Base64.getDecoder().decode(\"biws\"), channelBinding);\n    byte[] serverSignature = serverFinal.serverSignature();\n    assertArrayEquals(Base64.getDecoder().decode(\"6rriTRBi23WpRR/wtup+mMhUZUn/dB5nLTJRsjl95G4=\"), serverSignature);\n\n    byte[] saltedPassword = formatter.saltedPassword(password, salt, iterations);\n    byte[] serverKey = formatter.serverKey(saltedPassword);\n    byte[] computedProof = formatter.clientProof(saltedPassword, clientFirst, serverFirst, clientFinal);\n    assertArrayEquals(clientFinal.proof(), computedProof);\n    byte[] computedSignature = formatter.serverSignature(serverKey, clientFirst, serverFirst, clientFinal);\n    assertArrayEquals(serverFinal.serverSignature(), computedSignature);\n\n        \n    assertEquals(4096, ScramMechanism.SCRAM_SHA_256.minIterations());\n}",
        "summary_tokens": [
            "tests",
            "that",
            "the",
            "formatter",
            "implementation",
            "produces",
            "the",
            "same",
            "values",
            "for",
            "the",
            "example",
            "included",
            "in",
            "a",
            "href",
            "https",
            "tools"
        ]
    },
    {
        "id": 1560,
        "code": "public void saslName() throws Exception {\n    String[] usernames = {\"user1\", \"123\", \"1,2\", \"user=A\", \"user==B\", \"user,1\", \"user 1\", \",\", \"=\", \",=\", \"==\"};\n    ScramFormatter formatter = new ScramFormatter(ScramMechanism.SCRAM_SHA_256);\n    for (String username : usernames) {\n        String saslName = ScramFormatter.saslName(username);\n            \n        assertEquals(-1, saslName.indexOf(','));\n            \n        assertEquals(-1, saslName.replace(\"=2C\", \"\").replace(\"=3D\", \"\").indexOf('='));\n        assertEquals(username, ScramFormatter.username(saslName));\n    }\n}",
        "summary_tokens": [
            "tests",
            "encoding",
            "of",
            "username"
        ]
    },
    {
        "id": 1561,
        "code": "public void testClientSpecifiedSslEngineFactoryUsed() throws Exception {\n    File trustStoreFile = TestUtils.tempFile(\"truststore\", \".jks\");\n    Map<String, Object> clientSslConfig = sslConfigsBuilder(Mode.CLIENT)\n            .createNewTrustStore(trustStoreFile)\n            .useClientCert(false)\n            .build();\n    clientSslConfig.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    SslFactory sslFactory = new SslFactory(Mode.CLIENT);\n    sslFactory.configure(clientSslConfig);\n    assertTrue(sslFactory.sslEngineFactory() instanceof TestSslUtils.TestSslEngineFactory,\n        \"SslEngineFactory must be of expected type\");\n}",
        "summary_tokens": [
            "tests",
            "client",
            "side",
            "ssl"
        ]
    },
    {
        "id": 1562,
        "code": "public void testServerSpecifiedSslEngineFactoryUsed() throws Exception {\n    File trustStoreFile = TestUtils.tempFile(\"truststore\", \".jks\");\n    Map<String, Object> serverSslConfig = sslConfigsBuilder(Mode.SERVER)\n            .createNewTrustStore(trustStoreFile)\n            .useClientCert(false)\n            .build();\n    serverSslConfig.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    SslFactory sslFactory = new SslFactory(Mode.SERVER);\n    sslFactory.configure(serverSslConfig);\n    assertTrue(sslFactory.sslEngineFactory() instanceof TestSslUtils.TestSslEngineFactory,\n        \"SslEngineFactory must be of expected type\");\n}",
        "summary_tokens": [
            "tests",
            "server",
            "side",
            "ssl"
        ]
    },
    {
        "id": 1563,
        "code": "public void testUnmap() throws Exception {\n    File file = TestUtils.tempFile();\n    try (FileChannel channel = FileChannel.open(file.toPath())) {\n        MappedByteBuffer map = channel.map(FileChannel.MapMode.READ_ONLY, 0, 0);\n        ByteBufferUnmapper.unmap(file.getAbsolutePath(), map);\n    }\n}",
        "summary_tokens": [
            "checks",
            "that",
            "unmap",
            "doesn",
            "t",
            "throw",
            "exceptions"
        ]
    },
    {
        "id": 1564,
        "code": "public void serverDisconnect(String id) {\n    this.disconnected.put(id, ChannelState.READY);\n    close(id);\n}",
        "summary_tokens": [
            "simulate",
            "a",
            "server",
            "disconnect"
        ]
    },
    {
        "id": 1565,
        "code": "public static X509Certificate generateCertificate(String dn, KeyPair pair,\n                                                  int days, String algorithm)\n    throws  CertificateException {\n    return new CertificateBuilder(days, algorithm).generate(dn, pair);\n}",
        "summary_tokens": [
            "create",
            "a",
            "self",
            "signed",
            "x"
        ]
    },
    {
        "id": 1566,
        "code": "public static void createKeyStore(String filename,\n                                  Password password, Password keyPassword, String alias,\n                                  Key privateKey, Certificate cert) throws GeneralSecurityException, IOException {\n    KeyStore ks = createEmptyKeyStore();\n    ks.setKeyEntry(alias, privateKey, keyPassword.value().toCharArray(),\n            new Certificate[]{cert});\n    saveKeyStore(ks, filename, password);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "keystore",
            "with",
            "a",
            "single",
            "key",
            "and",
            "saves",
            "it",
            "to",
            "a",
            "file"
        ]
    },
    {
        "id": 1567,
        "code": "public static byte[] randomBytes(final int size) {\n    final byte[] bytes = new byte[size];\n    SEEDED_RANDOM.nextBytes(bytes);\n    return bytes;\n}",
        "summary_tokens": [
            "generate",
            "an",
            "array",
            "of",
            "random",
            "bytes"
        ]
    },
    {
        "id": 1568,
        "code": "public static String randomString(final int len) {\n    final StringBuilder b = new StringBuilder();\n    for (int i = 0; i < len; i++)\n        b.append(LETTERS_AND_DIGITS.charAt(SEEDED_RANDOM.nextInt(LETTERS_AND_DIGITS.length())));\n    return b.toString();\n}",
        "summary_tokens": [
            "generate",
            "a",
            "random",
            "string",
            "of",
            "letters",
            "and",
            "digits",
            "of",
            "the",
            "given",
            "length"
        ]
    },
    {
        "id": 1569,
        "code": "public static File tempFile(final String contents) throws IOException {\n    final File file = tempFile();\n    Files.write(file.toPath(), contents.getBytes(StandardCharsets.UTF_8));\n    return file;\n}",
        "summary_tokens": [
            "create",
            "a",
            "file",
            "with",
            "the",
            "given",
            "contents",
            "in",
            "the",
            "default",
            "temporary",
            "file",
            "directory",
            "using",
            "kafka",
            "as",
            "the",
            "prefix",
            "and",
            "tmp",
            "as",
            "the",
            "suffix",
            "to",
            "generate",
            "its",
            "name"
        ]
    },
    {
        "id": 1570,
        "code": "public static File tempDirectory(final Path parent, String prefix) {\n    final File file;\n    prefix = prefix == null ? \"kafka-\" : prefix;\n    try {\n        file = parent == null ?\n            Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile();\n    } catch (final IOException ex) {\n        throw new RuntimeException(\"Failed to create a temp dir\", ex);\n    }\n    file.deleteOnExit();\n\n    Exit.addShutdownHook(\"delete-temp-file-shutdown-hook\", () -> {\n        try {\n            Utils.delete(file);\n        } catch (IOException e) {\n            log.error(\"Error deleting {}\", file.getAbsolutePath(), e);\n        }\n    });\n\n    return file;\n}",
        "summary_tokens": [
            "create",
            "a",
            "temporary",
            "relative",
            "directory",
            "in",
            "the",
            "specified",
            "parent",
            "directory",
            "with",
            "the",
            "given",
            "prefix"
        ]
    },
    {
        "id": 1571,
        "code": "public static Properties consumerConfig(final String bootstrapServers, final Class<?> keyDeserializer, final Class<?> valueDeserializer) {\n    return consumerConfig(bootstrapServers,\n        UUID.randomUUID().toString(),\n        keyDeserializer,\n        valueDeserializer,\n        new Properties());\n}",
        "summary_tokens": [
            "returns",
            "consumer",
            "config",
            "with",
            "random",
            "uuid",
            "for",
            "the",
            "group",
            "id"
        ]
    },
    {
        "id": 1572,
        "code": "public static void waitForCondition(\n    final TestCondition testCondition,\n    final long maxWaitMs,\n    final long pollIntervalMs,\n    Supplier<String> conditionDetailsSupplier\n) throws InterruptedException {\n    retryOnExceptionWithTimeout(maxWaitMs, pollIntervalMs, () -> {\n        String conditionDetailsSupplied = conditionDetailsSupplier != null ? conditionDetailsSupplier.get() : null;\n        String conditionDetails = conditionDetailsSupplied != null ? conditionDetailsSupplied : \"\";\n        assertTrue(testCondition.conditionMet(),\n            \"Condition not met within timeout \" + maxWaitMs + \". \" + conditionDetails);\n    });\n}",
        "summary_tokens": [
            "wait",
            "for",
            "condition",
            "to",
            "be",
            "met",
            "for",
            "at",
            "most",
            "max",
            "wait",
            "ms",
            "with",
            "a",
            "polling",
            "interval",
            "of",
            "poll",
            "interval",
            "ms",
            "and",
            "throw",
            "assertion",
            "failure",
            "otherwise"
        ]
    },
    {
        "id": 1573,
        "code": "public static void retryOnExceptionWithTimeout(final long timeoutMs,\n                                               final long pollIntervalMs,\n                                               final ValuelessCallable runnable) throws InterruptedException {\n    final long expectedEnd = System.currentTimeMillis() + timeoutMs;\n\n    while (true) {\n        try {\n            runnable.call();\n            return;\n        } catch (final NoRetryException e) {\n            throw e;\n        } catch (final AssertionError t) {\n            if (expectedEnd <= System.currentTimeMillis()) {\n                throw t;\n            }\n        } catch (final Exception e) {\n            if (expectedEnd <= System.currentTimeMillis()) {\n                throw new AssertionError(String.format(\"Assertion failed with an exception after %s ms\", timeoutMs), e);\n            }\n        }\n        Thread.sleep(Math.min(pollIntervalMs, timeoutMs));\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "the",
            "given",
            "runnable",
            "to",
            "complete",
            "successfully",
            "i"
        ]
    },
    {
        "id": 1574,
        "code": "public static void isValidClusterId(String clusterId) {\n    assertNotNull(clusterId);\n\n        \n    assertEquals(clusterId.length(), 22);\n\n    Pattern clusterIdPattern = Pattern.compile(\"[a-zA-Z0-9_\\\\-]+\");\n    Matcher matcher = clusterIdPattern.matcher(clusterId);\n    assertTrue(matcher.matches());\n\n        \n    String originalClusterId = String.format(\"%s==\", clusterId.replace(\"_\", \"/\").replace(\"-\", \"+\"));\n    byte[] decodedUuid = Base64.getDecoder().decode(originalClusterId);\n\n        \n    assertEquals(decodedUuid.length, 16);\n\n        \n    try {\n        ByteBuffer uuidBuffer = ByteBuffer.wrap(decodedUuid);\n        new UUID(uuidBuffer.getLong(), uuidBuffer.getLong()).toString();\n    } catch (Exception e) {\n        fail(clusterId + \" cannot be converted back to UUID.\");\n    }\n}",
        "summary_tokens": [
            "checks",
            "if",
            "a",
            "cluster",
            "id",
            "is",
            "valid"
        ]
    },
    {
        "id": 1575,
        "code": "public static <T> void checkEquals(Iterable<T> it1, Iterable<T> it2) {\n    assertEquals(toList(it1), toList(it2));\n}",
        "summary_tokens": [
            "checks",
            "the",
            "two",
            "iterables",
            "for",
            "equality",
            "by",
            "first",
            "converting",
            "both",
            "to",
            "a",
            "list"
        ]
    },
    {
        "id": 1576,
        "code": "public static <T extends Throwable> T assertFutureThrows(Future<?> future, Class<T> exceptionCauseClass) {\n    ExecutionException exception = assertThrows(ExecutionException.class, future::get);\n    assertTrue(exceptionCauseClass.isInstance(exception.getCause()),\n        \"Unexpected exception cause \" + exception.getCause());\n    return exceptionCauseClass.cast(exception.getCause());\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "future",
            "raises",
            "an",
            "expected",
            "exception",
            "cause",
            "type"
        ]
    },
    {
        "id": 1577,
        "code": "public static <T> boolean sameElementsWithOrder(Iterator<T> iterator1,\n                                                Iterator<T> iterator2) {\n    while (iterator1.hasNext()) {\n        if (!iterator2.hasNext()) {\n            return false;\n        }\n\n        if (!Objects.equals(iterator1.next(), iterator2.next())) {\n            return false;\n        }\n    }\n\n    return !iterator2.hasNext();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "both",
            "iterators",
            "have",
            "same",
            "elements",
            "in",
            "the",
            "same",
            "order"
        ]
    },
    {
        "id": 1578,
        "code": "public static <T> boolean sameElementsWithoutOrder(Iterator<T> iterator1,\n                                                   Iterator<T> iterator2) {\n        \n    Set<T> allSegmentsSet = new HashSet<>();\n    iterator1.forEachRemaining(allSegmentsSet::add);\n    Set<T> expectedSegmentsSet = new HashSet<>();\n    iterator2.forEachRemaining(expectedSegmentsSet::add);\n\n    return allSegmentsSet.equals(expectedSegmentsSet);\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "both",
            "the",
            "iterators",
            "have",
            "same",
            "set",
            "of",
            "elements",
            "irrespective",
            "of",
            "order",
            "and",
            "duplicates"
        ]
    },
    {
        "id": 1579,
        "code": "public Headers headers() {\n    return headers;\n}",
        "summary_tokens": [
            "get",
            "the",
            "headers",
            "for",
            "this",
            "record"
        ]
    },
    {
        "id": 1580,
        "code": "public void initialize(ConnectorContext ctx, List<Map<String, String>> taskConfigs) {\n    context = ctx;\n        \n        \n}",
        "summary_tokens": [
            "p",
            "initialize",
            "this",
            "connector",
            "using",
            "the",
            "provided",
            "connector",
            "context",
            "to",
            "notify",
            "the",
            "runtime",
            "of",
            "input",
            "configuration",
            "changes",
            "and",
            "using",
            "the",
            "provided",
            "set",
            "of",
            "task",
            "configurations"
        ]
    },
    {
        "id": 1581,
        "code": "protected ConnectorContext context() {\n    return context;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "context",
            "object",
            "used",
            "to",
            "interact",
            "with",
            "the",
            "kafka",
            "connect",
            "runtime"
        ]
    },
    {
        "id": 1582,
        "code": "public Config validate(Map<String, String> connectorConfigs) {\n    ConfigDef configDef = config();\n    if (null == configDef) {\n        throw new ConnectException(\n            String.format(\"%s.config() must return a ConfigDef that is not null.\", this.getClass().getName())\n        );\n    }\n    List<ConfigValue> configValues = configDef.validate(connectorConfigs);\n    return new Config(configValues);\n}",
        "summary_tokens": [
            "validate",
            "the",
            "connector",
            "configuration",
            "values",
            "against",
            "configuration",
            "definitions"
        ]
    },
    {
        "id": 1583,
        "code": "public Map<String, Object> clientProps() {\n    return clientProps;\n}",
        "summary_tokens": [
            "provides",
            "config",
            "with",
            "prefix",
            "producer"
        ]
    },
    {
        "id": 1584,
        "code": "public ClientType clientType() {\n    return clientType;\n}",
        "summary_tokens": [
            "client",
            "type",
            "producer",
            "for",
            "connector",
            "type",
            "source",
            "client",
            "type",
            "consumer",
            "for",
            "connector",
            "type",
            "sink",
            "client",
            "type",
            "producer",
            "for",
            "dlq",
            "in",
            "connector",
            "type",
            "sink",
            "client",
            "type",
            "admin",
            "for",
            "dlq",
            "topic",
            "creation",
            "in",
            "connector",
            "type",
            "sink"
        ]
    },
    {
        "id": 1585,
        "code": "public String connectorName() {\n    return connectorName;\n}",
        "summary_tokens": [
            "name",
            "of",
            "the",
            "connector",
            "specified",
            "in",
            "the",
            "connector",
            "config"
        ]
    },
    {
        "id": 1586,
        "code": "public ConnectorType connectorType() {\n    return connectorType;\n}",
        "summary_tokens": [
            "type",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1587,
        "code": "public Class<? extends Connector> connectorClass() {\n    return connectorClass;\n}",
        "summary_tokens": [
            "the",
            "class",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1588,
        "code": "public void validateValue(Object value) {\n    validateValue(this, value);\n}",
        "summary_tokens": [
            "validate",
            "that",
            "the",
            "value",
            "can",
            "be",
            "used",
            "for",
            "this",
            "schema",
            "i"
        ]
    },
    {
        "id": 1589,
        "code": "public static SchemaBuilder builder() {\n    return SchemaBuilder.int32()\n            .name(LOGICAL_NAME)\n            .version(1);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "schema",
            "builder",
            "for",
            "a",
            "date"
        ]
    },
    {
        "id": 1590,
        "code": "public static int fromLogical(Schema schema, java.util.Date value) {\n    if (!(LOGICAL_NAME.equals(schema.name())))\n        throw new DataException(\"Requested conversion of Date object but the schema does not match.\");\n    Calendar calendar = Calendar.getInstance(UTC);\n    calendar.setTime(value);\n    if (calendar.get(Calendar.HOUR_OF_DAY) != 0 || calendar.get(Calendar.MINUTE) != 0 ||\n            calendar.get(Calendar.SECOND) != 0 || calendar.get(Calendar.MILLISECOND) != 0) {\n        throw new DataException(\"Kafka Connect Date type should not have any time fields set to non-zero values.\");\n    }\n    long unixMillis = calendar.getTimeInMillis();\n    return (int) (unixMillis / MILLIS_PER_DAY);\n}",
        "summary_tokens": [
            "convert",
            "a",
            "value",
            "from",
            "its",
            "logical",
            "format",
            "date",
            "to",
            "it",
            "s",
            "encoded",
            "format"
        ]
    },
    {
        "id": 1591,
        "code": "public static SchemaBuilder builder(int scale) {\n    return SchemaBuilder.bytes()\n            .name(LOGICAL_NAME)\n            .parameter(SCALE_FIELD, Integer.toString(scale))\n            .version(1);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "schema",
            "builder",
            "for",
            "a",
            "decimal",
            "with",
            "the",
            "given",
            "scale",
            "factor"
        ]
    },
    {
        "id": 1592,
        "code": "public static byte[] fromLogical(Schema schema, BigDecimal value) {\n    int schemaScale = scale(schema);\n    if (value.scale() != schemaScale)\n        throw new DataException(String.format(\n            \"Decimal value has mismatching scale for given Decimal schema. \"\n                + \"Schema has scale %d, value has scale %d.\",\n            schemaScale,\n            value.scale()\n        ));\n    return value.unscaledValue().toByteArray();\n}",
        "summary_tokens": [
            "convert",
            "a",
            "value",
            "from",
            "its",
            "logical",
            "format",
            "big",
            "decimal",
            "to",
            "it",
            "s",
            "encoded",
            "format"
        ]
    },
    {
        "id": 1593,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "this",
            "field"
        ]
    },
    {
        "id": 1594,
        "code": "public int index() {\n    return index;\n}",
        "summary_tokens": [
            "get",
            "the",
            "index",
            "of",
            "this",
            "field",
            "within",
            "the",
            "struct"
        ]
    },
    {
        "id": 1595,
        "code": "public Schema schema() {\n    return schema;\n}",
        "summary_tokens": [
            "get",
            "the",
            "schema",
            "of",
            "this",
            "field",
            "the",
            "schema",
            "of",
            "values",
            "of",
            "this",
            "field"
        ]
    },
    {
        "id": 1596,
        "code": "public SchemaBuilder optional() {\n    checkCanSet(OPTIONAL_FIELD, optional, true);\n    optional = true;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "this",
            "schema",
            "as",
            "optional"
        ]
    },
    {
        "id": 1597,
        "code": "public SchemaBuilder required() {\n    checkCanSet(OPTIONAL_FIELD, optional, false);\n    optional = false;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "this",
            "schema",
            "as",
            "required"
        ]
    },
    {
        "id": 1598,
        "code": "public SchemaBuilder defaultValue(Object value) {\n    checkCanSet(DEFAULT_FIELD, defaultValue, value);\n    checkNotNull(TYPE_FIELD, type, DEFAULT_FIELD);\n    try {\n        ConnectSchema.validateValue(this, value);\n    } catch (DataException e) {\n        throw new SchemaBuilderException(\"Invalid default value\", e);\n    }\n    defaultValue = value;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "default",
            "value",
            "for",
            "this",
            "schema"
        ]
    },
    {
        "id": 1599,
        "code": "public SchemaBuilder name(String name) {\n    checkCanSet(NAME_FIELD, this.name, name);\n    this.name = name;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "name",
            "of",
            "this",
            "schema"
        ]
    },
    {
        "id": 1600,
        "code": "public SchemaBuilder version(Integer version) {\n    checkCanSet(VERSION_FIELD, this.version, version);\n    this.version = version;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "version",
            "of",
            "this",
            "schema"
        ]
    },
    {
        "id": 1601,
        "code": "public SchemaBuilder doc(String doc) {\n    checkCanSet(DOC_FIELD, this.doc, doc);\n    this.doc = doc;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "documentation",
            "for",
            "this",
            "schema"
        ]
    },
    {
        "id": 1602,
        "code": "public SchemaBuilder parameter(String propertyName, String propertyValue) {\n        \n        \n    if (parameters == null)\n        parameters = new LinkedHashMap<>();\n    parameters.put(propertyName, propertyValue);\n    return this;\n}",
        "summary_tokens": [
            "set",
            "a",
            "schema",
            "parameter"
        ]
    },
    {
        "id": 1603,
        "code": "public static SchemaBuilder type(Type type) {\n    return new SchemaBuilder(type);\n}",
        "summary_tokens": [
            "create",
            "a",
            "schema",
            "builder",
            "for",
            "the",
            "specified",
            "type"
        ]
    },
    {
        "id": 1604,
        "code": "public SchemaBuilder field(String fieldName, Schema fieldSchema) {\n    if (type != Type.STRUCT)\n        throw new SchemaBuilderException(\"Cannot create fields on type \" + type);\n    if (null == fieldName || fieldName.isEmpty())\n        throw new SchemaBuilderException(\"fieldName cannot be null.\");\n    if (null == fieldSchema)\n        throw new SchemaBuilderException(\"fieldSchema for field \" + fieldName + \" cannot be null.\");\n    int fieldIndex = fields.size();\n    if (fields.containsKey(fieldName))\n        throw new SchemaBuilderException(\"Cannot create field because of field name duplication \" + fieldName);\n    fields.put(fieldName, new Field(fieldName, fieldIndex, fieldSchema));\n    return this;\n}",
        "summary_tokens": [
            "add",
            "a",
            "field",
            "to",
            "this",
            "struct",
            "schema"
        ]
    },
    {
        "id": 1605,
        "code": "public List<Field> fields() {\n    if (type != Type.STRUCT)\n        throw new DataException(\"Cannot list fields on non-struct type\");\n    return new ArrayList<>(fields.values());\n}",
        "summary_tokens": [
            "get",
            "the",
            "list",
            "of",
            "fields",
            "for",
            "this",
            "schema"
        ]
    },
    {
        "id": 1606,
        "code": "public static SchemaBuilder array(Schema valueSchema) {\n    if (null == valueSchema)\n        throw new SchemaBuilderException(\"valueSchema cannot be null.\");\n    SchemaBuilder builder = new SchemaBuilder(Type.ARRAY);\n    builder.valueSchema = valueSchema;\n    return builder;\n}",
        "summary_tokens": [
            "value",
            "schema",
            "the",
            "schema",
            "for",
            "elements",
            "of",
            "the",
            "array",
            "a",
            "new",
            "schema"
        ]
    },
    {
        "id": 1607,
        "code": "public static SchemaBuilder map(Schema keySchema, Schema valueSchema) {\n    if (null == keySchema)\n        throw new SchemaBuilderException(\"keySchema cannot be null.\");\n    if (null == valueSchema)\n        throw new SchemaBuilderException(\"valueSchema cannot be null.\");\n    SchemaBuilder builder = new SchemaBuilder(Type.MAP);\n    builder.keySchema = keySchema;\n    builder.valueSchema = valueSchema;\n    return builder;\n}",
        "summary_tokens": [
            "key",
            "schema",
            "the",
            "schema",
            "for",
            "keys",
            "in",
            "the",
            "map",
            "value",
            "schema",
            "the",
            "schema",
            "for",
            "values",
            "in",
            "the",
            "map",
            "a",
            "new",
            "schema"
        ]
    },
    {
        "id": 1608,
        "code": "public Schema build() {\n    return new ConnectSchema(type, isOptional(), defaultValue, name, version, doc,\n            parameters == null ? null : Collections.unmodifiableMap(parameters),\n            fields == null ? null : Collections.unmodifiableList(new ArrayList<>(fields.values())), keySchema, valueSchema);\n}",
        "summary_tokens": [
            "build",
            "the",
            "schema",
            "using",
            "the",
            "current",
            "settings",
            "the",
            "schema"
        ]
    },
    {
        "id": 1609,
        "code": "public Schema schema() {\n    return build();\n}",
        "summary_tokens": [
            "return",
            "a",
            "concrete",
            "instance",
            "of",
            "the",
            "schema",
            "specified",
            "by",
            "this",
            "builder",
            "the",
            "schema"
        ]
    },
    {
        "id": 1610,
        "code": "public static Object project(Schema source, Object record, Schema target) throws SchemaProjectorException {\n    checkMaybeCompatible(source, target);\n    if (source.isOptional() && !target.isOptional()) {\n        if (target.defaultValue() != null) {\n            if (record != null) {\n                return projectRequiredSchema(source, record, target);\n            } else {\n                return target.defaultValue();\n            }\n        } else {\n            throw new SchemaProjectorException(\"Writer schema is optional, however, target schema does not provide a default value.\");\n        }\n    } else {\n        if (record != null) {\n            return projectRequiredSchema(source, record, target);\n        } else {\n            return null;\n        }\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "project",
            "a",
            "value",
            "between",
            "compatible",
            "schemas",
            "and",
            "throw",
            "exceptions",
            "when",
            "non",
            "compatible",
            "schemas",
            "are",
            "provided",
            "source",
            "the",
            "schema",
            "used",
            "to",
            "construct",
            "the",
            "record",
            "record",
            "the",
            "value",
            "to",
            "project",
            "from",
            "source",
            "schema",
            "to",
            "target",
            "schema",
            "target",
            "the",
            "schema",
            "to",
            "project",
            "the",
            "record",
            "to",
            "the",
            "projected",
            "value",
            "with",
            "target",
            "schema",
            "schema",
            "projector",
            "exception",
            "if",
            "the",
            "target",
            "schema",
            "is",
            "not",
            "optional",
            "and",
            "does",
            "not",
            "have",
            "a",
            "default",
            "value"
        ]
    },
    {
        "id": 1611,
        "code": "public Schema schema() {\n    return schema;\n}",
        "summary_tokens": [
            "get",
            "the",
            "schema",
            "for",
            "this",
            "struct"
        ]
    },
    {
        "id": 1612,
        "code": "public Object get(Field field) {\n    Object val = values[field.index()];\n    if (val == null && field.schema().defaultValue() != null) {\n        val = field.schema().defaultValue();\n    }\n    return val;\n}",
        "summary_tokens": [
            "get",
            "the",
            "value",
            "of",
            "a",
            "field",
            "returning",
            "the",
            "default",
            "value",
            "if",
            "no",
            "value",
            "has",
            "been",
            "set",
            "yet",
            "and",
            "a",
            "default",
            "value",
            "is",
            "specified",
            "in",
            "the",
            "field",
            "s",
            "schema"
        ]
    },
    {
        "id": 1613,
        "code": "public Object getWithoutDefault(String fieldName) {\n    Field field = lookupField(fieldName);\n    return values[field.index()];\n}",
        "summary_tokens": [
            "get",
            "the",
            "underlying",
            "raw",
            "value",
            "for",
            "the",
            "field",
            "without",
            "accounting",
            "for",
            "default",
            "values"
        ]
    },
    {
        "id": 1614,
        "code": "public Byte getInt8(String fieldName) {\n    return (Byte) getCheckType(fieldName, Schema.Type.INT8);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "byte"
        ]
    },
    {
        "id": 1615,
        "code": "public Short getInt16(String fieldName) {\n    return (Short) getCheckType(fieldName, Schema.Type.INT16);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "short"
        ]
    },
    {
        "id": 1616,
        "code": "public Integer getInt32(String fieldName) {\n    return (Integer) getCheckType(fieldName, Schema.Type.INT32);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "integer"
        ]
    },
    {
        "id": 1617,
        "code": "public Long getInt64(String fieldName) {\n    return (Long) getCheckType(fieldName, Schema.Type.INT64);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "long"
        ]
    },
    {
        "id": 1618,
        "code": "public Float getFloat32(String fieldName) {\n    return (Float) getCheckType(fieldName, Schema.Type.FLOAT32);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "float"
        ]
    },
    {
        "id": 1619,
        "code": "public Double getFloat64(String fieldName) {\n    return (Double) getCheckType(fieldName, Schema.Type.FLOAT64);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "double"
        ]
    },
    {
        "id": 1620,
        "code": "public Boolean getBoolean(String fieldName) {\n    return (Boolean) getCheckType(fieldName, Schema.Type.BOOLEAN);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "boolean"
        ]
    },
    {
        "id": 1621,
        "code": "public String getString(String fieldName) {\n    return (String) getCheckType(fieldName, Schema.Type.STRING);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "string"
        ]
    },
    {
        "id": 1622,
        "code": "public byte[] getBytes(String fieldName) {\n    Object bytes = getCheckType(fieldName, Schema.Type.BYTES);\n    if (bytes instanceof ByteBuffer)\n        return ((ByteBuffer) bytes).array();\n    return (byte[]) bytes;\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "byte"
        ]
    },
    {
        "id": 1623,
        "code": "public <T> List<T> getArray(String fieldName) {\n    return (List<T>) getCheckType(fieldName, Schema.Type.ARRAY);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "list"
        ]
    },
    {
        "id": 1624,
        "code": "public <K, V> Map<K, V> getMap(String fieldName) {\n    return (Map<K, V>) getCheckType(fieldName, Schema.Type.MAP);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "map"
        ]
    },
    {
        "id": 1625,
        "code": "public Struct getStruct(String fieldName) {\n    return (Struct) getCheckType(fieldName, Schema.Type.STRUCT);\n}",
        "summary_tokens": [
            "equivalent",
            "to",
            "calling",
            "get",
            "string",
            "and",
            "casting",
            "the",
            "result",
            "to",
            "a",
            "struct"
        ]
    },
    {
        "id": 1626,
        "code": "public Struct put(Field field, Object value) {\n    if (null == field)\n        throw new DataException(\"field cannot be null.\");\n    ConnectSchema.validateValue(field.name(), field.schema(), value);\n    values[field.index()] = value;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "value",
            "of",
            "a",
            "field"
        ]
    },
    {
        "id": 1627,
        "code": "public void validate() {\n    for (Field field : schema.fields()) {\n        Schema fieldSchema = field.schema();\n        Object value = values[field.index()];\n        if (value == null && (fieldSchema.isOptional() || fieldSchema.defaultValue() != null))\n            continue;\n        ConnectSchema.validateValue(field.name(), fieldSchema, value);\n    }\n}",
        "summary_tokens": [
            "validates",
            "that",
            "this",
            "struct",
            "has",
            "filled",
            "in",
            "all",
            "the",
            "necessary",
            "data",
            "with",
            "valid",
            "values"
        ]
    },
    {
        "id": 1628,
        "code": "public static SchemaBuilder builder() {\n    return SchemaBuilder.int32()\n            .name(LOGICAL_NAME)\n            .version(1);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "schema",
            "builder",
            "for",
            "a",
            "time"
        ]
    },
    {
        "id": 1629,
        "code": "public static int fromLogical(Schema schema, java.util.Date value) {\n    if (!(LOGICAL_NAME.equals(schema.name())))\n        throw new DataException(\"Requested conversion of Time object but the schema does not match.\");\n    Calendar calendar = Calendar.getInstance(UTC);\n    calendar.setTime(value);\n    long unixMillis = calendar.getTimeInMillis();\n    if (unixMillis < 0 || unixMillis > MILLIS_PER_DAY) {\n        throw new DataException(\"Kafka Connect Time type should not have any date fields set to non-zero values.\");\n    }\n    return (int) unixMillis;\n}",
        "summary_tokens": [
            "convert",
            "a",
            "value",
            "from",
            "its",
            "logical",
            "format",
            "time",
            "to",
            "it",
            "s",
            "encoded",
            "format"
        ]
    },
    {
        "id": 1630,
        "code": "public static SchemaBuilder builder() {\n    return SchemaBuilder.int64()\n            .name(LOGICAL_NAME)\n            .version(1);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "schema",
            "builder",
            "for",
            "a",
            "timestamp"
        ]
    },
    {
        "id": 1631,
        "code": "public static long fromLogical(Schema schema, java.util.Date value) {\n    if (!(LOGICAL_NAME.equals(schema.name())))\n        throw new DataException(\"Requested conversion of Timestamp object but the schema does not match.\");\n    return value.getTime();\n}",
        "summary_tokens": [
            "convert",
            "a",
            "value",
            "from",
            "its",
            "logical",
            "format",
            "date",
            "to",
            "it",
            "s",
            "encoded",
            "format"
        ]
    },
    {
        "id": 1632,
        "code": "public static Boolean convertToBoolean(Schema schema, Object value) throws DataException {\n    return (Boolean) convertTo(Schema.OPTIONAL_BOOLEAN_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "boolean",
            "value"
        ]
    },
    {
        "id": 1633,
        "code": "public static Byte convertToByte(Schema schema, Object value) throws DataException {\n    return (Byte) convertTo(Schema.OPTIONAL_INT8_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "int",
            "0",
            "byte",
            "value"
        ]
    },
    {
        "id": 1634,
        "code": "public static Short convertToShort(Schema schema, Object value) throws DataException {\n    return (Short) convertTo(Schema.OPTIONAL_INT16_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "int",
            "0",
            "short",
            "value"
        ]
    },
    {
        "id": 1635,
        "code": "public static Integer convertToInteger(Schema schema, Object value) throws DataException {\n    return (Integer) convertTo(Schema.OPTIONAL_INT32_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "int",
            "0",
            "int",
            "value"
        ]
    },
    {
        "id": 1636,
        "code": "public static Long convertToLong(Schema schema, Object value) throws DataException {\n    return (Long) convertTo(Schema.OPTIONAL_INT64_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "int",
            "0",
            "long",
            "value"
        ]
    },
    {
        "id": 1637,
        "code": "public static Float convertToFloat(Schema schema, Object value) throws DataException {\n    return (Float) convertTo(Schema.OPTIONAL_FLOAT32_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "float",
            "0",
            "float",
            "value"
        ]
    },
    {
        "id": 1638,
        "code": "public static Double convertToDouble(Schema schema, Object value) throws DataException {\n    return (Double) convertTo(Schema.OPTIONAL_FLOAT64_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "float",
            "0",
            "double",
            "value"
        ]
    },
    {
        "id": 1639,
        "code": "public static String convertToString(Schema schema, Object value) {\n    return (String) convertTo(Schema.OPTIONAL_STRING_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "string",
            "value"
        ]
    },
    {
        "id": 1640,
        "code": "public static List<?> convertToList(Schema schema, Object value) {\n    return (List<?>) convertTo(ARRAY_SELECTOR_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "array",
            "value"
        ]
    },
    {
        "id": 1641,
        "code": "public static Map<?, ?> convertToMap(Schema schema, Object value) {\n    return (Map<?, ?>) convertTo(MAP_SELECTOR_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "map",
            "value"
        ]
    },
    {
        "id": 1642,
        "code": "public static Struct convertToStruct(Schema schema, Object value) {\n    return (Struct) convertTo(STRUCT_SELECTOR_SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "type",
            "struct",
            "value"
        ]
    },
    {
        "id": 1643,
        "code": "public static java.util.Date convertToTime(Schema schema, Object value) {\n    return (java.util.Date) convertTo(Time.SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "time",
            "schema",
            "time",
            "value"
        ]
    },
    {
        "id": 1644,
        "code": "public static java.util.Date convertToDate(Schema schema, Object value) {\n    return (java.util.Date) convertTo(Date.SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "date",
            "schema",
            "date",
            "value"
        ]
    },
    {
        "id": 1645,
        "code": "public static java.util.Date convertToTimestamp(Schema schema, Object value) {\n    return (java.util.Date) convertTo(Timestamp.SCHEMA, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "timestamp",
            "schema",
            "timestamp",
            "value"
        ]
    },
    {
        "id": 1646,
        "code": "public static BigDecimal convertToDecimal(Schema schema, Object value, int scale) {\n    return (BigDecimal) convertTo(Decimal.schema(scale), schema, value);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "an",
            "decimal",
            "decimal",
            "value"
        ]
    },
    {
        "id": 1647,
        "code": "public static Schema inferSchema(Object value) {\n    if (value instanceof String) {\n        return Schema.STRING_SCHEMA;\n    }\n    if (value instanceof Boolean) {\n        return Schema.BOOLEAN_SCHEMA;\n    }\n    if (value instanceof Byte) {\n        return Schema.INT8_SCHEMA;\n    }\n    if (value instanceof Short) {\n        return Schema.INT16_SCHEMA;\n    }\n    if (value instanceof Integer) {\n        return Schema.INT32_SCHEMA;\n    }\n    if (value instanceof Long) {\n        return Schema.INT64_SCHEMA;\n    }\n    if (value instanceof Float) {\n        return Schema.FLOAT32_SCHEMA;\n    }\n    if (value instanceof Double) {\n        return Schema.FLOAT64_SCHEMA;\n    }\n    if (value instanceof byte[] || value instanceof ByteBuffer) {\n        return Schema.BYTES_SCHEMA;\n    }\n    if (value instanceof List) {\n        List<?> list = (List<?>) value;\n        if (list.isEmpty()) {\n            return null;\n        }\n        SchemaDetector detector = new SchemaDetector();\n        for (Object element : list) {\n            if (!detector.canDetect(element)) {\n                return null;\n            }\n        }\n        return SchemaBuilder.array(detector.schema()).build();\n    }\n    if (value instanceof Map) {\n        Map<?, ?> map = (Map<?, ?>) value;\n        if (map.isEmpty()) {\n            return null;\n        }\n        SchemaDetector keyDetector = new SchemaDetector();\n        SchemaDetector valueDetector = new SchemaDetector();\n        for (Map.Entry<?, ?> entry : map.entrySet()) {\n            if (!keyDetector.canDetect(entry.getKey()) || !valueDetector.canDetect(entry.getValue())) {\n                return null;\n            }\n        }\n        return SchemaBuilder.map(keyDetector.schema(), valueDetector.schema()).build();\n    }\n    if (value instanceof Struct) {\n        return ((Struct) value).schema();\n    }\n    return null;\n}",
        "summary_tokens": [
            "if",
            "possible",
            "infer",
            "a",
            "schema",
            "for",
            "the",
            "given",
            "value"
        ]
    },
    {
        "id": 1648,
        "code": "public static SchemaAndValue parseString(String value) {\n    if (value == null) {\n        return NULL_SCHEMA_AND_VALUE;\n    }\n    if (value.isEmpty()) {\n        return new SchemaAndValue(Schema.STRING_SCHEMA, value);\n    }\n    Parser parser = new Parser(value);\n    return parse(parser, false);\n}",
        "summary_tokens": [
            "parse",
            "the",
            "specified",
            "string",
            "representation",
            "of",
            "a",
            "value",
            "into",
            "its",
            "schema",
            "and",
            "value"
        ]
    },
    {
        "id": 1649,
        "code": "protected static Object convertTo(Schema toSchema, Schema fromSchema, Object value) throws DataException {\n    if (value == null) {\n        if (toSchema.isOptional()) {\n            return null;\n        }\n        throw new DataException(\"Unable to convert a null value to a schema that requires a value\");\n    }\n    switch (toSchema.type()) {\n        case BYTES:\n            if (Decimal.LOGICAL_NAME.equals(toSchema.name())) {\n                if (value instanceof ByteBuffer) {\n                    value = Utils.toArray((ByteBuffer) value);\n                }\n                if (value instanceof byte[]) {\n                    return Decimal.toLogical(toSchema, (byte[]) value);\n                }\n                if (value instanceof BigDecimal) {\n                    return value;\n                }\n                if (value instanceof Number) {\n                        \n                    double converted = ((Number) value).doubleValue();\n                    return BigDecimal.valueOf(converted);\n                }\n                if (value instanceof String) {\n                    return new BigDecimal(value.toString()).doubleValue();\n                }\n            }\n            if (value instanceof ByteBuffer) {\n                return Utils.toArray((ByteBuffer) value);\n            }\n            if (value instanceof byte[]) {\n                return value;\n            }\n            if (value instanceof BigDecimal) {\n                return Decimal.fromLogical(toSchema, (BigDecimal) value);\n            }\n            break;\n        case STRING:\n            StringBuilder sb = new StringBuilder();\n            append(sb, value, false);\n            return sb.toString();\n        case BOOLEAN:\n            if (value instanceof Boolean) {\n                return value;\n            }\n            if (value instanceof String) {\n                SchemaAndValue parsed = parseString(value.toString());\n                if (parsed.value() instanceof Boolean) {\n                    return parsed.value();\n                }\n            }\n            return asLong(value, fromSchema, null) == 0L ? Boolean.FALSE : Boolean.TRUE;\n        case INT8:\n            if (value instanceof Byte) {\n                return value;\n            }\n            return (byte) asLong(value, fromSchema, null);\n        case INT16:\n            if (value instanceof Short) {\n                return value;\n            }\n            return (short) asLong(value, fromSchema, null);\n        case INT32:\n            if (Date.LOGICAL_NAME.equals(toSchema.name())) {\n                if (value instanceof String) {\n                    SchemaAndValue parsed = parseString(value.toString());\n                    value = parsed.value();\n                }\n                if (value instanceof java.util.Date) {\n                    if (fromSchema != null) {\n                        String fromSchemaName = fromSchema.name();\n                        if (Date.LOGICAL_NAME.equals(fromSchemaName)) {\n                            return value;\n                        }\n                        if (Timestamp.LOGICAL_NAME.equals(fromSchemaName)) {\n                                \n                            long millis = ((java.util.Date) value).getTime();\n                            int days = (int) (millis / MILLIS_PER_DAY); \n                            return Date.toLogical(toSchema, days);\n                        }\n                    } else {\n                            \n                        return value;\n                    }\n                }\n                long numeric = asLong(value, fromSchema, null);\n                return Date.toLogical(toSchema, (int) numeric);\n            }\n            if (Time.LOGICAL_NAME.equals(toSchema.name())) {\n                if (value instanceof String) {\n                    SchemaAndValue parsed = parseString(value.toString());\n                    value = parsed.value();\n                }\n                if (value instanceof java.util.Date) {\n                    if (fromSchema != null) {\n                        String fromSchemaName = fromSchema.name();\n                        if (Time.LOGICAL_NAME.equals(fromSchemaName)) {\n                            return value;\n                        }\n                        if (Timestamp.LOGICAL_NAME.equals(fromSchemaName)) {\n                                \n                            Calendar calendar = Calendar.getInstance(UTC);\n                            calendar.setTime((java.util.Date) value);\n                            calendar.set(Calendar.YEAR, 1970);\n                            calendar.set(Calendar.MONTH, 0); \n                            calendar.set(Calendar.DAY_OF_MONTH, 1);\n                            return Time.toLogical(toSchema, (int) calendar.getTimeInMillis());\n                        }\n                    } else {\n                            \n                        return value;\n                    }\n                }\n                long numeric = asLong(value, fromSchema, null);\n                return Time.toLogical(toSchema, (int) numeric);\n            }\n            if (value instanceof Integer) {\n                return value;\n            }\n            return (int) asLong(value, fromSchema, null);\n        case INT64:\n            if (Timestamp.LOGICAL_NAME.equals(toSchema.name())) {\n                if (value instanceof String) {\n                    SchemaAndValue parsed = parseString(value.toString());\n                    value = parsed.value();\n                }\n                if (value instanceof java.util.Date) {\n                    java.util.Date date = (java.util.Date) value;\n                    if (fromSchema != null) {\n                        String fromSchemaName = fromSchema.name();\n                        if (Date.LOGICAL_NAME.equals(fromSchemaName)) {\n                            int days = Date.fromLogical(fromSchema, date);\n                            long millis = days * MILLIS_PER_DAY;\n                            return Timestamp.toLogical(toSchema, millis);\n                        }\n                        if (Time.LOGICAL_NAME.equals(fromSchemaName)) {\n                            long millis = Time.fromLogical(fromSchema, date);\n                            return Timestamp.toLogical(toSchema, millis);\n                        }\n                        if (Timestamp.LOGICAL_NAME.equals(fromSchemaName)) {\n                            return value;\n                        }\n                    } else {\n                            \n                        return value;\n                    }\n                }\n                long numeric = asLong(value, fromSchema, null);\n                return Timestamp.toLogical(toSchema, numeric);\n            }\n            if (value instanceof Long) {\n                return value;\n            }\n            return asLong(value, fromSchema, null);\n        case FLOAT32:\n            if (value instanceof Float) {\n                return value;\n            }\n            return (float) asDouble(value, fromSchema, null);\n        case FLOAT64:\n            if (value instanceof Double) {\n                return value;\n            }\n            return asDouble(value, fromSchema, null);\n        case ARRAY:\n            if (value instanceof String) {\n                SchemaAndValue schemaAndValue = parseString(value.toString());\n                value = schemaAndValue.value();\n            }\n            if (value instanceof List) {\n                return value;\n            }\n            break;\n        case MAP:\n            if (value instanceof String) {\n                SchemaAndValue schemaAndValue = parseString(value.toString());\n                value = schemaAndValue.value();\n            }\n            if (value instanceof Map) {\n                return value;\n            }\n            break;\n        case STRUCT:\n            if (value instanceof Struct) {\n                return value;\n            }\n    }\n    throw new DataException(\"Unable to convert \" + value + \" (\" + value.getClass() + \") to \" + toSchema);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "value",
            "to",
            "the",
            "desired",
            "type"
        ]
    },
    {
        "id": 1650,
        "code": "protected static long asLong(Object value, Schema fromSchema, Throwable error) {\n    try {\n        if (value instanceof Number) {\n            Number number = (Number) value;\n            return number.longValue();\n        }\n        if (value instanceof String) {\n            return new BigDecimal(value.toString()).longValue();\n        }\n    } catch (NumberFormatException e) {\n        error = e;\n            \n    }\n    if (fromSchema != null) {\n        String schemaName = fromSchema.name();\n        if (value instanceof java.util.Date) {\n            if (Date.LOGICAL_NAME.equals(schemaName)) {\n                return Date.fromLogical(fromSchema, (java.util.Date) value);\n            }\n            if (Time.LOGICAL_NAME.equals(schemaName)) {\n                return Time.fromLogical(fromSchema, (java.util.Date) value);\n            }\n            if (Timestamp.LOGICAL_NAME.equals(schemaName)) {\n                return Timestamp.fromLogical(fromSchema, (java.util.Date) value);\n            }\n        }\n        throw new DataException(\"Unable to convert \" + value + \" (\" + value.getClass() + \") to \" + fromSchema, error);\n    }\n    throw new DataException(\"Unable to convert \" + value + \" (\" + value.getClass() + \") to a number\", error);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "to",
            "the",
            "desired",
            "scalar",
            "value",
            "type"
        ]
    },
    {
        "id": 1651,
        "code": "protected static double asDouble(Object value, Schema schema, Throwable error) {\n    try {\n        if (value instanceof Number) {\n            Number number = (Number) value;\n            return number.doubleValue();\n        }\n        if (value instanceof String) {\n            return new BigDecimal(value.toString()).doubleValue();\n        }\n    } catch (NumberFormatException e) {\n        error = e;\n            \n    }\n    return asLong(value, schema, error);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "specified",
            "value",
            "with",
            "the",
            "desired",
            "floating",
            "point",
            "type"
        ]
    },
    {
        "id": 1652,
        "code": "private void checkKey(String key) {\n    Objects.requireNonNull(key, \"Header key cannot be null\");\n}",
        "summary_tokens": [
            "check",
            "that",
            "the",
            "key",
            "is",
            "not",
            "null"
        ]
    },
    {
        "id": 1653,
        "code": "private void checkSchemaType(Schema schema, Type type) {\n    if (schema.type() != type) {\n        throw new DataException(\"Expecting \" + type + \" but instead found \" + schema.type());\n    }\n}",
        "summary_tokens": [
            "check",
            "the",
            "schema",
            "type",
            "schema",
            "s",
            "type",
            "matches",
            "the",
            "specified",
            "type"
        ]
    },
    {
        "id": 1654,
        "code": "void checkSchemaMatches(SchemaAndValue schemaAndValue) {\n    if (schemaAndValue != null) {\n        Schema schema = schemaAndValue.schema();\n        if (schema == null)\n            return;\n        schema = schema.schema(); \n        Object value = schemaAndValue.value();\n        if (value == null && !schema.isOptional()) {\n            throw new DataException(\"A null value requires an optional schema but was \" + schema);\n        }\n        if (value != null) {\n            switch (schema.type()) {\n                case BYTES:\n                    if (value instanceof ByteBuffer)\n                        return;\n                    if (value instanceof byte[])\n                        return;\n                    if (value instanceof BigDecimal && Decimal.LOGICAL_NAME.equals(schema.name()))\n                        return;\n                    break;\n                case STRING:\n                    if (value instanceof String)\n                        return;\n                    break;\n                case BOOLEAN:\n                    if (value instanceof Boolean)\n                        return;\n                    break;\n                case INT8:\n                    if (value instanceof Byte)\n                        return;\n                    break;\n                case INT16:\n                    if (value instanceof Short)\n                        return;\n                    break;\n                case INT32:\n                    if (value instanceof Integer)\n                        return;\n                    if (value instanceof java.util.Date && Date.LOGICAL_NAME.equals(schema.name()))\n                        return;\n                    if (value instanceof java.util.Date && Time.LOGICAL_NAME.equals(schema.name()))\n                        return;\n                    break;\n                case INT64:\n                    if (value instanceof Long)\n                        return;\n                    if (value instanceof java.util.Date && Timestamp.LOGICAL_NAME.equals(schema.name()))\n                        return;\n                    break;\n                case FLOAT32:\n                    if (value instanceof Float)\n                        return;\n                    break;\n                case FLOAT64:\n                    if (value instanceof Double)\n                        return;\n                    break;\n                case ARRAY:\n                    if (value instanceof List)\n                        return;\n                    break;\n                case MAP:\n                    if (value instanceof Map)\n                        return;\n                    break;\n                case STRUCT:\n                    if (value instanceof Struct)\n                        return;\n                    break;\n            }\n            throw new DataException(\"The value \" + value + \" is not compatible with the schema \" + schema);\n        }\n    }\n}",
        "summary_tokens": [
            "check",
            "that",
            "the",
            "value",
            "and",
            "its",
            "schema",
            "are",
            "compatible"
        ]
    },
    {
        "id": 1655,
        "code": "public String state() {\n    return state;\n}",
        "summary_tokens": [
            "provides",
            "the",
            "current",
            "state",
            "of",
            "the",
            "connector",
            "or",
            "task"
        ]
    },
    {
        "id": 1656,
        "code": "public String workerId() {\n    return workerId;\n}",
        "summary_tokens": [
            "the",
            "identifier",
            "of",
            "the",
            "worker",
            "associated",
            "with",
            "the",
            "connector",
            "or",
            "the",
            "task"
        ]
    },
    {
        "id": 1657,
        "code": "public String traceMessage() {\n    return traceMessage;\n}",
        "summary_tokens": [
            "the",
            "error",
            "message",
            "associated",
            "with",
            "the",
            "connector",
            "or",
            "task"
        ]
    },
    {
        "id": 1658,
        "code": "default Map<String, String> connectorConfig(String connName) {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "lookup",
            "the",
            "current",
            "configuration",
            "of",
            "a",
            "connector"
        ]
    },
    {
        "id": 1659,
        "code": "default ConnectClusterDetails clusterDetails() {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "get",
            "details",
            "about",
            "the",
            "setup",
            "of",
            "the",
            "connect",
            "cluster"
        ]
    },
    {
        "id": 1660,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "provides",
            "the",
            "name",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1661,
        "code": "public ConnectorState connectorState() {\n    return connectorState;\n}",
        "summary_tokens": [
            "provides",
            "the",
            "current",
            "state",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1662,
        "code": "public Map<Integer, TaskState> tasksState() {\n    return tasks;\n}",
        "summary_tokens": [
            "provides",
            "the",
            "current",
            "state",
            "of",
            "the",
            "connector",
            "tasks"
        ]
    },
    {
        "id": 1663,
        "code": "public ConnectorType type() {\n    return type;\n}",
        "summary_tokens": [
            "provides",
            "the",
            "type",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1664,
        "code": "public int taskId() {\n    return taskId;\n}",
        "summary_tokens": [
            "provides",
            "the",
            "id",
            "of",
            "the",
            "task"
        ]
    },
    {
        "id": 1665,
        "code": "public void initialize(SinkTaskContext context) {\n    this.context = context;\n}",
        "summary_tokens": [
            "initialize",
            "the",
            "context",
            "of",
            "this",
            "task"
        ]
    },
    {
        "id": 1666,
        "code": "public void flush(Map<TopicPartition, OffsetAndMetadata> currentOffsets) {\n}",
        "summary_tokens": [
            "flush",
            "all",
            "records",
            "that",
            "have",
            "been",
            "put",
            "collection",
            "for",
            "the",
            "specified",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 1667,
        "code": "public Map<TopicPartition, OffsetAndMetadata> preCommit(Map<TopicPartition, OffsetAndMetadata> currentOffsets) {\n    flush(currentOffsets);\n    return currentOffsets;\n}",
        "summary_tokens": [
            "pre",
            "commit",
            "hook",
            "invoked",
            "prior",
            "to",
            "an",
            "offset",
            "commit"
        ]
    },
    {
        "id": 1668,
        "code": "public void open(Collection<TopicPartition> partitions) {\n    this.onPartitionsAssigned(partitions);\n}",
        "summary_tokens": [
            "the",
            "sink",
            "task",
            "use",
            "this",
            "method",
            "to",
            "create",
            "writers",
            "for",
            "newly",
            "assigned",
            "partitions",
            "in",
            "case",
            "of",
            "partition",
            "rebalance"
        ]
    },
    {
        "id": 1669,
        "code": "public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n}",
        "summary_tokens": [
            "use",
            "open",
            "collection",
            "for",
            "partition",
            "initialization"
        ]
    },
    {
        "id": 1670,
        "code": "public void close(Collection<TopicPartition> partitions) {\n    this.onPartitionsRevoked(partitions);\n}",
        "summary_tokens": [
            "the",
            "sink",
            "task",
            "use",
            "this",
            "method",
            "to",
            "close",
            "writers",
            "for",
            "partitions",
            "that",
            "are",
            "no",
            "longer",
            "assigned",
            "to",
            "the",
            "sink",
            "task"
        ]
    },
    {
        "id": 1671,
        "code": "public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n}",
        "summary_tokens": [
            "use",
            "close",
            "collection",
            "instead",
            "for",
            "partition",
            "cleanup"
        ]
    },
    {
        "id": 1672,
        "code": "default ErrantRecordReporter errantRecordReporter() {\n    return null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "reporter",
            "to",
            "which",
            "the",
            "sink",
            "task",
            "can",
            "report",
            "problematic",
            "or",
            "failed",
            "sink",
            "record",
            "records",
            "passed",
            "to",
            "the",
            "sink",
            "task",
            "put",
            "java"
        ]
    },
    {
        "id": 1673,
        "code": "public ExactlyOnceSupport exactlyOnceSupport(Map<String, String> connectorConfig) {\n    return null;\n}",
        "summary_tokens": [
            "signals",
            "whether",
            "the",
            "connector",
            "supports",
            "exactly",
            "once",
            "delivery",
            "guarantees",
            "with",
            "a",
            "proposed",
            "configuration"
        ]
    },
    {
        "id": 1674,
        "code": "public ConnectorTransactionBoundaries canDefineTransactionBoundaries(Map<String, String> connectorConfig) {\n    return ConnectorTransactionBoundaries.UNSUPPORTED;\n}",
        "summary_tokens": [
            "signals",
            "whether",
            "the",
            "connector",
            "implementation",
            "is",
            "capable",
            "of",
            "defining",
            "the",
            "transaction",
            "boundaries",
            "for",
            "a",
            "connector",
            "with",
            "the",
            "given",
            "configuration"
        ]
    },
    {
        "id": 1675,
        "code": "public void initialize(SourceTaskContext context) {\n    this.context = context;\n}",
        "summary_tokens": [
            "initialize",
            "this",
            "source",
            "task",
            "with",
            "the",
            "specified",
            "context",
            "object"
        ]
    },
    {
        "id": 1676,
        "code": "public void commit() throws InterruptedException {\n        \n}",
        "summary_tokens": [
            "p",
            "commit",
            "the",
            "offsets",
            "up",
            "to",
            "the",
            "offsets",
            "that",
            "have",
            "been",
            "returned",
            "by",
            "poll"
        ]
    },
    {
        "id": 1677,
        "code": "public void commitRecord(SourceRecord record, RecordMetadata metadata)\n        throws InterruptedException {\n        \n    commitRecord(record);\n}",
        "summary_tokens": [
            "p",
            "commit",
            "an",
            "individual",
            "source",
            "record",
            "when",
            "the",
            "callback",
            "from",
            "the",
            "producer",
            "client",
            "is",
            "received"
        ]
    },
    {
        "id": 1678,
        "code": "default TransactionContext transactionContext() {\n    return null;\n}",
        "summary_tokens": [
            "get",
            "a",
            "transaction",
            "context",
            "that",
            "can",
            "be",
            "used",
            "to",
            "define",
            "producer",
            "transaction",
            "boundaries",
            "when",
            "exactly",
            "once",
            "support",
            "is",
            "enabled",
            "for",
            "the",
            "connector"
        ]
    },
    {
        "id": 1679,
        "code": "default byte[] fromConnectData(String topic, Headers headers, Schema schema, Object value) {\n    return fromConnectData(topic, schema, value);\n}",
        "summary_tokens": [
            "convert",
            "a",
            "kafka",
            "connect",
            "data",
            "object",
            "to",
            "a",
            "native",
            "object",
            "for",
            "serialization",
            "potentially",
            "using",
            "the",
            "supplied",
            "topic",
            "and",
            "headers",
            "in",
            "the",
            "record",
            "as",
            "necessary"
        ]
    },
    {
        "id": 1680,
        "code": "default SchemaAndValue toConnectData(String topic, Headers headers, byte[] value) {\n    return toConnectData(topic, value);\n}",
        "summary_tokens": [
            "convert",
            "a",
            "native",
            "object",
            "to",
            "a",
            "kafka",
            "connect",
            "data",
            "object",
            "potentially",
            "using",
            "the",
            "supplied",
            "topic",
            "and",
            "headers",
            "in",
            "the",
            "record",
            "as",
            "necessary"
        ]
    },
    {
        "id": 1681,
        "code": "default ConfigDef config() {\n    return new ConfigDef();\n}",
        "summary_tokens": [
            "configuration",
            "specification",
            "for",
            "this",
            "converter"
        ]
    },
    {
        "id": 1682,
        "code": "public static ConfigDef newConfigDef() {\n    return new ConfigDef().define(TYPE_CONFIG, Type.STRING, ConfigDef.NO_DEFAULT_VALUE,\n                                  in(ConverterType.KEY.getName(), ConverterType.VALUE.getName(), ConverterType.HEADER.getName()),\n                                  Importance.LOW, TYPE_DOC);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "config",
            "def",
            "instance",
            "containing",
            "the",
            "configurations",
            "defined",
            "by",
            "converter",
            "config"
        ]
    },
    {
        "id": 1683,
        "code": "public ConverterType type() {\n    return ConverterType.withName(getString(TYPE_CONFIG));\n}",
        "summary_tokens": [
            "get",
            "the",
            "type",
            "of",
            "converter",
            "as",
            "defined",
            "by",
            "the",
            "type",
            "config",
            "configuration"
        ]
    },
    {
        "id": 1684,
        "code": "public String encoding() {\n    return getString(ENCODING_CONFIG);\n}",
        "summary_tokens": [
            "get",
            "the",
            "string",
            "encoding"
        ]
    },
    {
        "id": 1685,
        "code": "public static <T> List<List<T>> groupPartitions(List<T> elements, int numGroups) {\n    if (numGroups <= 0)\n        throw new IllegalArgumentException(\"Number of groups must be positive.\");\n\n    List<List<T>> result = new ArrayList<>(numGroups);\n\n        \n    int perGroup = elements.size() / numGroups;\n    int leftover = elements.size() - (numGroups * perGroup);\n\n    int assigned = 0;\n    for (int group = 0; group < numGroups; group++) {\n        int numThisGroup = group < leftover ? perGroup + 1 : perGroup;\n        List<T> groupList = new ArrayList<>(numThisGroup);\n        for (int i = 0; i < numThisGroup; i++) {\n            groupList.add(elements.get(assigned));\n            assigned++;\n        }\n        result.add(groupList);\n    }\n\n    return result;\n}",
        "summary_tokens": [
            "given",
            "a",
            "list",
            "of",
            "elements",
            "and",
            "a",
            "target",
            "number",
            "of",
            "groups",
            "generates",
            "list",
            "of",
            "groups",
            "of",
            "elements",
            "to",
            "match",
            "the",
            "target",
            "number",
            "of",
            "groups",
            "spreading",
            "them",
            "evenly",
            "among",
            "the",
            "groups"
        ]
    },
    {
        "id": 1686,
        "code": "public void shouldConvertStringOfListWithOnlyNumericElementTypesIntoListOfLargestNumericType() {\n    int thirdValue = Short.MAX_VALUE + 1;\n    List<?> list = Values.convertToList(Schema.STRING_SCHEMA, \"[1, 2, \" + thirdValue + \"]\");\n    assertEquals(3, list.size());\n    assertEquals(1, ((Number) list.get(0)).intValue());\n    assertEquals(2, ((Number) list.get(1)).intValue());\n    assertEquals(thirdValue, ((Number) list.get(2)).intValue());\n}",
        "summary_tokens": [
            "the",
            "parsed",
            "array",
            "has",
            "byte",
            "values",
            "and",
            "one",
            "int",
            "value",
            "so",
            "we",
            "should",
            "return",
            "list",
            "with",
            "single",
            "unified",
            "type",
            "of",
            "integers"
        ]
    },
    {
        "id": 1687,
        "code": "public void shouldConvertStringOfListWithMixedElementTypesIntoListWithDifferentElementTypes() {\n    String str = \"[1, 2, \\\"three\\\"]\";\n    List<?> list = Values.convertToList(Schema.STRING_SCHEMA, str);\n    assertEquals(3, list.size());\n    assertEquals(1, ((Number) list.get(0)).intValue());\n    assertEquals(2, ((Number) list.get(1)).intValue());\n    assertEquals(\"three\", list.get(2));\n}",
        "summary_tokens": [
            "the",
            "parsed",
            "array",
            "has",
            "byte",
            "values",
            "and",
            "one",
            "int",
            "value",
            "so",
            "we",
            "should",
            "return",
            "list",
            "with",
            "single",
            "unified",
            "type",
            "of",
            "integers"
        ]
    },
    {
        "id": 1688,
        "code": "public void shouldParseStringListWithMultipleElementTypesAndReturnListWithNoSchema() {\n    String str = \"[1, 2, 3, \\\"four\\\"]\";\n    SchemaAndValue result = Values.parseString(str);\n    assertEquals(Type.ARRAY, result.schema().type());\n    assertNull(result.schema().valueSchema());\n    List<?> list = (List<?>) result.value();\n    assertEquals(4, list.size());\n    assertEquals(1, ((Number) list.get(0)).intValue());\n    assertEquals(2, ((Number) list.get(1)).intValue());\n    assertEquals(3, ((Number) list.get(2)).intValue());\n    assertEquals(\"four\", list.get(3));\n}",
        "summary_tokens": [
            "we",
            "parse",
            "into",
            "different",
            "element",
            "types",
            "but",
            "cannot",
            "infer",
            "a",
            "common",
            "element",
            "schema"
        ]
    },
    {
        "id": 1689,
        "code": "public void shouldParseStringListWithExtraDelimitersAndReturnString() {\n    String str = \"[1, 2, 3,,,]\";\n    SchemaAndValue result = Values.parseString(str);\n    assertEquals(Type.STRING, result.schema().type());\n    assertEquals(str, result.value());\n}",
        "summary_tokens": [
            "we",
            "can",
            "t",
            "infer",
            "or",
            "successfully",
            "parse",
            "into",
            "a",
            "different",
            "type",
            "so",
            "this",
            "returns",
            "the",
            "same",
            "string"
        ]
    },
    {
        "id": 1690,
        "code": "public void shouldFailToConvertToListFromStringWithExtraDelimiters() {\n    assertThrows(DataException.class, () -> Values.convertToList(Schema.STRING_SCHEMA, \"[1, 2, 3,,,]\"));\n}",
        "summary_tokens": [
            "this",
            "is",
            "technically",
            "invalid",
            "json",
            "and",
            "we",
            "don",
            "t",
            "want",
            "to",
            "simply",
            "ignore",
            "the",
            "blank",
            "elements"
        ]
    },
    {
        "id": 1691,
        "code": "public void shouldFailToConvertToListFromStringWithNonCommonElementTypeAndBlankElement() {\n    assertThrows(DataException.class, () -> Values.convertToList(Schema.STRING_SCHEMA, \"[1, 2, 3, \\\"four\\\",,,]\"));\n}",
        "summary_tokens": [
            "schema",
            "of",
            "type",
            "array",
            "requires",
            "a",
            "schema",
            "for",
            "the",
            "values",
            "but",
            "connect",
            "has",
            "no",
            "union",
            "or",
            "any",
            "schema",
            "type"
        ]
    },
    {
        "id": 1692,
        "code": "public void shouldFailToParseStringOfMapWithIntValuesWithBlankEntry() {\n    assertThrows(DataException.class,\n        () -> Values.convertToMap(Schema.STRING_SCHEMA, \" { \\\"foo\\\" :  1234567890 ,, \\\"bar\\\" : 0,  \\\"baz\\\" : -987654321 }  \"));\n}",
        "summary_tokens": [
            "this",
            "is",
            "technically",
            "invalid",
            "json",
            "and",
            "we",
            "don",
            "t",
            "want",
            "to",
            "simply",
            "ignore",
            "the",
            "blank",
            "entry"
        ]
    },
    {
        "id": 1693,
        "code": "public void shouldFailToParseStringOfMalformedMap() {\n    assertThrows(DataException.class,\n        () -> Values.convertToMap(Schema.STRING_SCHEMA, \" { \\\"foo\\\" :  1234567890 , \\\"a\\\", \\\"bar\\\" : 0,  \\\"baz\\\" : -987654321 }  \"));\n}",
        "summary_tokens": [
            "this",
            "is",
            "technically",
            "invalid",
            "json",
            "and",
            "we",
            "don",
            "t",
            "want",
            "to",
            "simply",
            "ignore",
            "the",
            "malformed",
            "entry"
        ]
    },
    {
        "id": 1694,
        "code": "public void shouldFailToParseStringOfMapWithIntValuesWithOnlyBlankEntries() {\n    assertThrows(DataException.class, () -> Values.convertToMap(Schema.STRING_SCHEMA, \" { ,,  , , }  \"));\n}",
        "summary_tokens": [
            "this",
            "is",
            "technically",
            "invalid",
            "json",
            "and",
            "we",
            "don",
            "t",
            "want",
            "to",
            "simply",
            "ignore",
            "the",
            "blank",
            "entries"
        ]
    },
    {
        "id": 1695,
        "code": "public void shouldFailToParseStringOfMapWithIntValuesWithBlankEntries() {\n    assertThrows(DataException.class,\n        () -> Values.convertToMap(Schema.STRING_SCHEMA, \" { \\\"foo\\\" :  \\\"1234567890\\\" ,, \\\"bar\\\" : \\\"0\\\",  \\\"baz\\\" : \\\"boz\\\" }  \"));\n}",
        "summary_tokens": [
            "this",
            "is",
            "technically",
            "invalid",
            "json",
            "and",
            "we",
            "don",
            "t",
            "want",
            "to",
            "simply",
            "ignore",
            "the",
            "blank",
            "entry"
        ]
    },
    {
        "id": 1696,
        "code": "private JsonNode convertToJsonWithEnvelope(Schema schema, Object value) {\n    return new JsonSchema.Envelope(asJsonSchema(schema), convertToJson(schema, value)).toJsonNode();\n}",
        "summary_tokens": [
            "convert",
            "this",
            "object",
            "in",
            "org"
        ]
    },
    {
        "id": 1697,
        "code": "private JsonNode convertToJson(Schema schema, Object value) {\n    if (value == null) {\n        if (schema == null) \n            return null;\n        if (schema.defaultValue() != null)\n            return convertToJson(schema, schema.defaultValue());\n        if (schema.isOptional())\n            return JSON_NODE_FACTORY.nullNode();\n        throw new DataException(\"Conversion error: null value for field that is required and has no default value\");\n    }\n\n    if (schema != null && schema.name() != null) {\n        LogicalTypeConverter logicalConverter = LOGICAL_CONVERTERS.get(schema.name());\n        if (logicalConverter != null)\n            return logicalConverter.toJson(schema, value, config);\n    }\n\n    try {\n        final Schema.Type schemaType;\n        if (schema == null) {\n            schemaType = ConnectSchema.schemaType(value.getClass());\n            if (schemaType == null)\n                throw new DataException(\"Java class \" + value.getClass() + \" does not have corresponding schema type.\");\n        } else {\n            schemaType = schema.type();\n        }\n        switch (schemaType) {\n            case INT8:\n                return JSON_NODE_FACTORY.numberNode((Byte) value);\n            case INT16:\n                return JSON_NODE_FACTORY.numberNode((Short) value);\n            case INT32:\n                return JSON_NODE_FACTORY.numberNode((Integer) value);\n            case INT64:\n                return JSON_NODE_FACTORY.numberNode((Long) value);\n            case FLOAT32:\n                return JSON_NODE_FACTORY.numberNode((Float) value);\n            case FLOAT64:\n                return JSON_NODE_FACTORY.numberNode((Double) value);\n            case BOOLEAN:\n                return JSON_NODE_FACTORY.booleanNode((Boolean) value);\n            case STRING:\n                CharSequence charSeq = (CharSequence) value;\n                return JSON_NODE_FACTORY.textNode(charSeq.toString());\n            case BYTES:\n                if (value instanceof byte[])\n                    return JSON_NODE_FACTORY.binaryNode((byte[]) value);\n                else if (value instanceof ByteBuffer)\n                    return JSON_NODE_FACTORY.binaryNode(((ByteBuffer) value).array());\n                else\n                    throw new DataException(\"Invalid type for bytes type: \" + value.getClass());\n            case ARRAY: {\n                Collection<?> collection = (Collection<?>) value;\n                ArrayNode list = JSON_NODE_FACTORY.arrayNode();\n                for (Object elem : collection) {\n                    Schema valueSchema = schema == null ? null : schema.valueSchema();\n                    JsonNode fieldValue = convertToJson(valueSchema, elem);\n                    list.add(fieldValue);\n                }\n                return list;\n            }\n            case MAP: {\n                Map<?, ?> map = (Map<?, ?>) value;\n                    \n                boolean objectMode;\n                if (schema == null) {\n                    objectMode = true;\n                    for (Map.Entry<?, ?> entry : map.entrySet()) {\n                        if (!(entry.getKey() instanceof String)) {\n                            objectMode = false;\n                            break;\n                        }\n                    }\n                } else {\n                    objectMode = schema.keySchema().type() == Schema.Type.STRING;\n                }\n                ObjectNode obj = null;\n                ArrayNode list = null;\n                if (objectMode)\n                    obj = JSON_NODE_FACTORY.objectNode();\n                else\n                    list = JSON_NODE_FACTORY.arrayNode();\n                for (Map.Entry<?, ?> entry : map.entrySet()) {\n                    Schema keySchema = schema == null ? null : schema.keySchema();\n                    Schema valueSchema = schema == null ? null : schema.valueSchema();\n                    JsonNode mapKey = convertToJson(keySchema, entry.getKey());\n                    JsonNode mapValue = convertToJson(valueSchema, entry.getValue());\n\n                    if (objectMode)\n                        obj.set(mapKey.asText(), mapValue);\n                    else\n                        list.add(JSON_NODE_FACTORY.arrayNode().add(mapKey).add(mapValue));\n                }\n                return objectMode ? obj : list;\n            }\n            case STRUCT: {\n                Struct struct = (Struct) value;\n                if (!struct.schema().equals(schema))\n                    throw new DataException(\"Mismatching schema.\");\n                ObjectNode obj = JSON_NODE_FACTORY.objectNode();\n                for (Field field : schema.fields()) {\n                    obj.set(field.name(), convertToJson(field.schema(), struct.get(field)));\n                }\n                return obj;\n            }\n        }\n\n        throw new DataException(\"Couldn't convert \" + value + \" to JSON.\");\n    } catch (ClassCastException e) {\n        String schemaTypeStr = (schema != null) ? schema.type().toString() : \"unknown schema\";\n        throw new DataException(\"Invalid type for \" + schemaTypeStr + \": \" + value.getClass());\n    }\n}",
        "summary_tokens": [
            "convert",
            "this",
            "object",
            "in",
            "the",
            "org"
        ]
    },
    {
        "id": 1698,
        "code": "public boolean schemasEnabled() {\n    return schemasEnabled;\n}",
        "summary_tokens": [
            "return",
            "whether",
            "schemas",
            "are",
            "enabled"
        ]
    },
    {
        "id": 1699,
        "code": "public int schemaCacheSize() {\n    return schemaCacheSize;\n}",
        "summary_tokens": [
            "get",
            "the",
            "cache",
            "size"
        ]
    },
    {
        "id": 1700,
        "code": "public DecimalFormat decimalFormat() {\n    return decimalFormat;\n}",
        "summary_tokens": [
            "get",
            "the",
            "serialization",
            "format",
            "for",
            "decimal",
            "types"
        ]
    },
    {
        "id": 1701,
        "code": "public void emptyBytesToConnect() {\n        \n    Map<String, Boolean> props = Collections.singletonMap(\"schemas.enable\", false);\n    converter.configure(props, true);\n    SchemaAndValue converted = converter.toConnectData(TOPIC, \"\".getBytes());\n    assertEquals(SchemaAndValue.NULL, converted);\n}",
        "summary_tokens": [
            "when",
            "schemas",
            "are",
            "disabled",
            "empty",
            "data",
            "should",
            "be",
            "decoded",
            "to",
            "an",
            "empty",
            "envelope"
        ]
    },
    {
        "id": 1702,
        "code": "public void schemalessWithEmptyFieldValueToConnect() {\n        \n    Map<String, Boolean> props = Collections.singletonMap(\"schemas.enable\", false);\n    converter.configure(props, true);\n    String input = \"{ \\\"a\\\": \\\"\\\", \\\"b\\\": null}\";\n    SchemaAndValue converted = converter.toConnectData(TOPIC, input.getBytes());\n    Map<String, String> expected = new HashMap<>();\n    expected.put(\"a\", \"\");\n    expected.put(\"b\", null);\n    assertEquals(new SchemaAndValue(null, expected), converted);\n}",
        "summary_tokens": [
            "when",
            "schemas",
            "are",
            "disabled",
            "fields",
            "are",
            "mapped",
            "to",
            "connect",
            "maps"
        ]
    },
    {
        "id": 1703,
        "code": "public String formatRemoteTopic(String sourceClusterAlias, String topic) {\n    if (looksLikeHeartbeat(topic)) {\n        return super.formatRemoteTopic(sourceClusterAlias, topic);\n    } else {\n        return topic;\n    }\n}",
        "summary_tokens": [
            "unlike",
            "default",
            "replication",
            "policy",
            "identity",
            "replication",
            "policy",
            "does",
            "not",
            "include",
            "the",
            "source",
            "cluster",
            "alias",
            "in",
            "the",
            "remote",
            "topic",
            "name"
        ]
    },
    {
        "id": 1704,
        "code": "public String topicSource(String topic) {\n    if (looksLikeHeartbeat(topic)) {\n        return super.topicSource(topic);\n    } else {\n        return sourceClusterAlias;\n    }\n}",
        "summary_tokens": [
            "unlike",
            "default",
            "replication",
            "policy",
            "identity",
            "replication",
            "policy",
            "cannot",
            "know",
            "the",
            "source",
            "of",
            "a",
            "remote",
            "topic",
            "based",
            "on",
            "its",
            "name",
            "alone"
        ]
    },
    {
        "id": 1705,
        "code": "public String upstreamTopic(String topic) {\n    if (looksLikeHeartbeat(topic)) {\n        return super.upstreamTopic(topic);\n    } else {\n        return topic;\n    }\n}",
        "summary_tokens": [
            "since",
            "any",
            "topic",
            "may",
            "be",
            "a",
            "remote",
            "topic",
            "this",
            "just",
            "returns",
            "topic"
        ]
    },
    {
        "id": 1706,
        "code": "public ReplicationPolicy replicationPolicy() {\n    return replicationPolicy;\n}",
        "summary_tokens": [
            "get",
            "the",
            "replication",
            "policy",
            "instance",
            "used",
            "to",
            "interpret",
            "remote",
            "topics"
        ]
    },
    {
        "id": 1707,
        "code": "public int replicationHops(String upstreamClusterAlias) throws InterruptedException {\n    return heartbeatTopics().stream()\n        .map(x -> countHopsForTopic(x, upstreamClusterAlias))\n        .filter(x -> x != -1)\n        .mapToInt(x -> x)\n        .min()\n        .orElse(-1);\n}",
        "summary_tokens": [
            "compute",
            "shortest",
            "number",
            "of",
            "hops",
            "from",
            "an",
            "upstream",
            "source",
            "cluster"
        ]
    },
    {
        "id": 1708,
        "code": "public Set<String> heartbeatTopics() throws InterruptedException {\n    return listTopics().stream()\n        .filter(this::isHeartbeatTopic)\n        .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "find",
            "all",
            "heartbeat",
            "topics",
            "on",
            "this",
            "cluster"
        ]
    },
    {
        "id": 1709,
        "code": "public Set<String> checkpointTopics() throws InterruptedException {\n    return listTopics().stream()\n        .filter(this::isCheckpointTopic)\n        .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "find",
            "all",
            "checkpoint",
            "topics",
            "on",
            "this",
            "cluster"
        ]
    },
    {
        "id": 1710,
        "code": "public Set<String> upstreamClusters() throws InterruptedException {\n    return listTopics().stream()\n        .filter(this::isHeartbeatTopic)\n        .flatMap(x -> allSources(x).stream())\n        .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "find",
            "upstream",
            "clusters",
            "which",
            "may",
            "be",
            "multiple",
            "hops",
            "away",
            "based",
            "on",
            "incoming",
            "heartbeats"
        ]
    },
    {
        "id": 1711,
        "code": "public Set<String> remoteTopics(String source) throws InterruptedException {\n    return listTopics().stream()\n        .filter(this::isRemoteTopic)\n        .filter(x -> source.equals(replicationPolicy.topicSource(x)))\n        .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "find",
            "all",
            "remote",
            "topics",
            "that",
            "have",
            "been",
            "replicated",
            "directly",
            "from",
            "the",
            "given",
            "source",
            "cluster"
        ]
    },
    {
        "id": 1712,
        "code": "public Map<TopicPartition, OffsetAndMetadata> remoteConsumerOffsets(String consumerGroupId,\n        String remoteClusterAlias, Duration timeout) {\n    long deadline = System.currentTimeMillis() + timeout.toMillis();\n    Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\n\n    try (KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(consumerConfig,\n            new ByteArrayDeserializer(), new ByteArrayDeserializer())) {\n            \n            \n        String checkpointTopic = replicationPolicy.checkpointsTopic(remoteClusterAlias);\n        List<TopicPartition> checkpointAssignment =\n            Collections.singletonList(new TopicPartition(checkpointTopic, 0));\n        consumer.assign(checkpointAssignment);\n        consumer.seekToBeginning(checkpointAssignment);\n        while (System.currentTimeMillis() < deadline && !endOfStream(consumer, checkpointAssignment)) {\n            ConsumerRecords<byte[], byte[]> records = consumer.poll(timeout);\n            for (ConsumerRecord<byte[], byte[]> record : records) {\n                try {\n                    Checkpoint checkpoint = Checkpoint.deserializeRecord(record);\n                    if (checkpoint.consumerGroupId().equals(consumerGroupId)) {\n                        offsets.put(checkpoint.topicPartition(), checkpoint.offsetAndMetadata());\n                    }\n                } catch (SchemaException e) {\n                    log.info(\"Could not deserialize record. Skipping.\", e);\n                }\n            }\n        }\n        log.info(\"Consumed {} checkpoint records for {} from {}.\", offsets.size(),\n            consumerGroupId, checkpointTopic);\n    }\n    return offsets;\n}",
        "summary_tokens": [
            "translate",
            "a",
            "remote",
            "consumer",
            "group",
            "s",
            "offsets",
            "into",
            "corresponding",
            "local",
            "offsets"
        ]
    },
    {
        "id": 1713,
        "code": "public Map<String, Object> adminConfig() {\n    return clientConfig(ADMIN_CLIENT_PREFIX);\n}",
        "summary_tokens": [
            "sub",
            "config",
            "for",
            "admin",
            "clients"
        ]
    },
    {
        "id": 1714,
        "code": "public Map<String, Object> consumerConfig() {\n    return clientConfig(CONSUMER_CLIENT_PREFIX);\n}",
        "summary_tokens": [
            "sub",
            "config",
            "for",
            "consumer",
            "clients"
        ]
    },
    {
        "id": 1715,
        "code": "public Map<String, Object> producerConfig() {\n    return clientConfig(PRODUCER_CLIENT_PREFIX);\n}",
        "summary_tokens": [
            "sub",
            "config",
            "for",
            "producer",
            "clients"
        ]
    },
    {
        "id": 1716,
        "code": "public static int replicationHops(Map<String, Object> properties, String upstreamClusterAlias)\n        throws InterruptedException, TimeoutException {\n    try (MirrorClient client = new MirrorClient(properties)) {\n        return client.replicationHops(upstreamClusterAlias);\n    }\n}",
        "summary_tokens": [
            "find",
            "shortest",
            "number",
            "of",
            "hops",
            "from",
            "an",
            "upstream",
            "cluster"
        ]
    },
    {
        "id": 1717,
        "code": "public static Set<String> heartbeatTopics(Map<String, Object> properties)\n        throws InterruptedException, TimeoutException {\n    try (MirrorClient client = new MirrorClient(properties)) {\n        return client.heartbeatTopics();\n    }\n}",
        "summary_tokens": [
            "find",
            "all",
            "heartbeat",
            "topics"
        ]
    },
    {
        "id": 1718,
        "code": "public static Set<String> checkpointTopics(Map<String, Object> properties)\n        throws InterruptedException, TimeoutException {\n    try (MirrorClient client = new MirrorClient(properties)) {\n        return client.checkpointTopics();\n    }\n}",
        "summary_tokens": [
            "find",
            "all",
            "checkpoint",
            "topics"
        ]
    },
    {
        "id": 1719,
        "code": "public static Set<String> upstreamClusters(Map<String, Object> properties)\n        throws InterruptedException, TimeoutException {\n    try (MirrorClient client = new MirrorClient(properties)) {\n        return client.upstreamClusters();\n    }\n}",
        "summary_tokens": [
            "find",
            "all",
            "upstream",
            "clusters"
        ]
    },
    {
        "id": 1720,
        "code": "public static Map<TopicPartition, OffsetAndMetadata> translateOffsets(Map<String, Object> properties,\n        String remoteClusterAlias, String consumerGroupId, Duration timeout)\n        throws InterruptedException, TimeoutException {\n    try (MirrorClient client = new MirrorClient(properties)) {\n        return client.remoteConsumerOffsets(consumerGroupId, remoteClusterAlias, timeout);\n    }\n}",
        "summary_tokens": [
            "translate",
            "a",
            "remote",
            "consumer",
            "group",
            "s",
            "offsets",
            "into",
            "corresponding",
            "local",
            "offsets"
        ]
    },
    {
        "id": 1721,
        "code": "default String originalTopic(String topic) {\n    String upstream = upstreamTopic(topic);\n    if (upstream == null || upstream.equals(topic)) {\n        return topic;\n    } else {\n        return originalTopic(upstream);\n    }\n}",
        "summary_tokens": [
            "the",
            "name",
            "of",
            "the",
            "original",
            "source",
            "topic",
            "which",
            "may",
            "have",
            "been",
            "replicated",
            "multiple",
            "hops"
        ]
    },
    {
        "id": 1722,
        "code": "default String heartbeatsTopic() {\n    return \"heartbeats\";\n}",
        "summary_tokens": [
            "returns",
            "heartbeats",
            "topic",
            "name"
        ]
    },
    {
        "id": 1723,
        "code": "default String offsetSyncsTopic(String clusterAlias) {\n    return \"mm2-offset-syncs.\" + clusterAlias + \".internal\";\n}",
        "summary_tokens": [
            "returns",
            "the",
            "offset",
            "syncs",
            "topic",
            "for",
            "given",
            "cluster",
            "alias"
        ]
    },
    {
        "id": 1724,
        "code": "default String checkpointsTopic(String clusterAlias) {\n    return clusterAlias + \".checkpoints.internal\";\n}",
        "summary_tokens": [
            "returns",
            "the",
            "name",
            "checkpoint",
            "topic",
            "for",
            "given",
            "cluster",
            "alias"
        ]
    },
    {
        "id": 1725,
        "code": "default boolean isHeartbeatsTopic(String topic) {\n    return heartbeatsTopic().equals(originalTopic(topic));\n}",
        "summary_tokens": [
            "check",
            "if",
            "topic",
            "is",
            "a",
            "heartbeat",
            "topic",
            "e"
        ]
    },
    {
        "id": 1726,
        "code": "default boolean isCheckpointsTopic(String topic) {\n    return  topic.endsWith(\".checkpoints.internal\");\n}",
        "summary_tokens": [
            "check",
            "if",
            "topic",
            "is",
            "a",
            "checkpoint",
            "topic"
        ]
    },
    {
        "id": 1727,
        "code": "default boolean isMM2InternalTopic(String topic) {\n    return  topic.endsWith(\".internal\");\n}",
        "summary_tokens": [
            "check",
            "topic",
            "is",
            "one",
            "of",
            "mm",
            "0",
            "internal",
            "topic",
            "this",
            "is",
            "used",
            "to",
            "make",
            "sure",
            "the",
            "topic",
            "doesn",
            "t",
            "need",
            "to",
            "be",
            "replicated"
        ]
    },
    {
        "id": 1728,
        "code": "default boolean isInternalTopic(String topic) {\n    boolean isKafkaInternalTopic = topic.startsWith(\"__\") || topic.startsWith(\".\");\n    boolean isDefaultConnectTopic =  topic.endsWith(\"-internal\") ||  topic.endsWith(\".internal\");\n    return isMM2InternalTopic(topic) || isKafkaInternalTopic || isDefaultConnectTopic;\n}",
        "summary_tokens": [
            "internal",
            "topics",
            "are",
            "never",
            "replicated"
        ]
    },
    {
        "id": 1729,
        "code": "public MirrorClientConfig clientConfig(String cluster) {\n    Map<String, String> props = new HashMap<>();\n    props.putAll(originalsStrings());\n    props.putAll(clusterProps(cluster));\n    return new MirrorClientConfig(transform(props));\n}",
        "summary_tokens": [
            "construct",
            "a",
            "mirror",
            "client",
            "config",
            "from",
            "properties",
            "of",
            "the",
            "form",
            "cluster"
        ]
    },
    {
        "id": 1730,
        "code": "public Optional<RestartPlan> buildRestartPlan(RestartRequest request) {\n    String connectorName = request.connectorName();\n    ConnectorStatus connectorStatus = statusBackingStore.get(connectorName);\n    if (connectorStatus == null) {\n        return Optional.empty();\n    }\n\n        \n    AbstractStatus.State connectorState = request.shouldRestartConnector(connectorStatus) ? AbstractStatus.State.RESTARTING : connectorStatus.state();\n    ConnectorStateInfo.ConnectorState connectorInfoState = new ConnectorStateInfo.ConnectorState(\n            connectorState.toString(),\n            connectorStatus.workerId(),\n            connectorStatus.trace()\n    );\n\n        \n    List<ConnectorStateInfo.TaskState> taskStates = statusBackingStore.getAll(connectorName)\n            .stream()\n            .map(taskStatus -> {\n                AbstractStatus.State taskState = request.shouldRestartTask(taskStatus) ? AbstractStatus.State.RESTARTING : taskStatus.state();\n                return new ConnectorStateInfo.TaskState(\n                        taskStatus.id().task(),\n                        taskState.toString(),\n                        taskStatus.workerId(),\n                        taskStatus.trace()\n                );\n            })\n            .collect(Collectors.toList());\n        \n    Map<String, String> conf = rawConfig(connectorName);\n    ConnectorStateInfo stateInfo = new ConnectorStateInfo(\n            connectorName,\n            connectorInfoState,\n            taskStates,\n            conf == null ? ConnectorType.UNKNOWN : connectorTypeForClass(conf.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG))\n    );\n    return Optional.of(new RestartPlan(request, stateInfo));\n}",
        "summary_tokens": [
            "build",
            "the",
            "restart",
            "plan",
            "that",
            "describes",
            "what",
            "should",
            "and",
            "should",
            "not",
            "be",
            "restarted",
            "given",
            "the",
            "restart",
            "request",
            "and",
            "the",
            "current",
            "status",
            "of",
            "the",
            "connector",
            "and",
            "task",
            "instances"
        ]
    },
    {
        "id": 1731,
        "code": "public ConnectorType connectorTypeForClass(String connClass) {\n    return ConnectorType.from(getConnector(connClass).getClass());\n}",
        "summary_tokens": [
            "retrieves",
            "connector",
            "type",
            "for",
            "the",
            "corresponding",
            "connector",
            "class",
            "conn",
            "class",
            "class",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1732,
        "code": "public ConnectorType connectorTypeForConfig(Map<String, String> connConfig) {\n    return connectorTypeForClass(connConfig.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG));\n}",
        "summary_tokens": [
            "retrieves",
            "connector",
            "type",
            "for",
            "the",
            "class",
            "specified",
            "in",
            "the",
            "connector",
            "config",
            "conn",
            "config",
            "the",
            "connector",
            "config",
            "may",
            "not",
            "be",
            "null",
            "the",
            "connector",
            "type",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1733,
        "code": "protected final boolean maybeAddConfigErrors(\n    ConfigInfos configInfos,\n    Callback<Created<ConnectorInfo>> callback\n) {\n    int errors = configInfos.errorCount();\n    boolean hasErrors = errors > 0;\n    if (hasErrors) {\n        StringBuilder messages = new StringBuilder();\n        messages.append(\"Connector configuration is invalid and contains the following \")\n            .append(errors).append(\" error(s):\");\n        for (ConfigInfo configInfo : configInfos.values()) {\n            for (String msg : configInfo.configValue().errors()) {\n                messages.append('\\n').append(msg);\n            }\n        }\n        callback.onCompletion(\n            new BadRequestException(\n                messages.append(\n                    \"\\nYou can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`\"\n                ).toString()\n            ), null\n        );\n    }\n    return hasErrors;\n}",
        "summary_tokens": [
            "checks",
            "a",
            "given",
            "config",
            "infos",
            "for",
            "validation",
            "error",
            "messages",
            "and",
            "adds",
            "an",
            "exception",
            "to",
            "the",
            "given",
            "callback",
            "if",
            "any",
            "were",
            "found"
        ]
    },
    {
        "id": 1734,
        "code": "boolean sendRecords() {\n    int processed = 0;\n    recordBatch(toSend.size());\n    final SourceRecordWriteCounter counter =\n            toSend.size() > 0 ? new SourceRecordWriteCounter(toSend.size(), sourceTaskMetricsGroup) : null;\n    for (final SourceRecord preTransformRecord : toSend) {\n        retryWithToleranceOperator.sourceRecord(preTransformRecord);\n        final SourceRecord record = transformationChain.apply(preTransformRecord);\n        final ProducerRecord<byte[], byte[]> producerRecord = convertTransformedRecord(record);\n        if (producerRecord == null || retryWithToleranceOperator.failed()) {\n            counter.skipRecord();\n            recordDropped(preTransformRecord);\n            continue;\n        }\n\n        log.trace(\"{} Appending record to the topic {} with key {}, value {}\", this, record.topic(), record.key(), record.value());\n        Optional<SubmittedRecords.SubmittedRecord> submittedRecord = prepareToSendRecord(preTransformRecord, producerRecord);\n        try {\n            final String topic = producerRecord.topic();\n            maybeCreateTopic(topic);\n            producer.send(\n                producerRecord,\n                (recordMetadata, e) -> {\n                    if (e != null) {\n                        if (producerClosed) {\n                            log.trace(\"{} failed to send record to {}; this is expected as the producer has already been closed\", AbstractWorkerSourceTask.this, topic, e);\n                        } else {\n                            log.error(\"{} failed to send record to {}: \", AbstractWorkerSourceTask.this, topic, e);\n                        }\n                        log.trace(\"{} Failed record: {}\", AbstractWorkerSourceTask.this, preTransformRecord);\n                        producerSendFailed(false, producerRecord, preTransformRecord, e);\n                        if (retryWithToleranceOperator.getErrorToleranceType() == ToleranceType.ALL) {\n                            counter.skipRecord();\n                            submittedRecord.ifPresent(SubmittedRecords.SubmittedRecord::ack);\n                        }\n                    } else {\n                        counter.completeRecord();\n                        log.trace(\"{} Wrote record successfully: topic {} partition {} offset {}\",\n                                AbstractWorkerSourceTask.this,\n                                recordMetadata.topic(), recordMetadata.partition(),\n                                recordMetadata.offset());\n                        recordSent(preTransformRecord, producerRecord, recordMetadata);\n                        submittedRecord.ifPresent(SubmittedRecords.SubmittedRecord::ack);\n                        if (topicTrackingEnabled) {\n                            recordActiveTopic(producerRecord.topic());\n                        }\n                    }\n                });\n                \n        } catch (RetriableException | org.apache.kafka.common.errors.RetriableException e) {\n            log.warn(\"{} Failed to send record to topic '{}' and partition '{}'. Backing off before retrying: \",\n                    this, producerRecord.topic(), producerRecord.partition(), e);\n            toSend = toSend.subList(processed, toSend.size());\n            submittedRecord.ifPresent(SubmittedRecords.SubmittedRecord::drop);\n            counter.retryRemaining();\n            return false;\n        } catch (ConnectException e) {\n            log.warn(\"{} Failed to send record to topic '{}' and partition '{}' due to an unrecoverable exception: \",\n                    this, producerRecord.topic(), producerRecord.partition(), e);\n            log.trace(\"{} Failed to send {} with unrecoverable exception: \", this, producerRecord, e);\n            throw e;\n        } catch (KafkaException e) {\n            producerSendFailed(true, producerRecord, preTransformRecord, e);\n        }\n        processed++;\n        recordDispatched(preTransformRecord);\n    }\n    toSend = null;\n    return true;\n}",
        "summary_tokens": [
            "try",
            "to",
            "send",
            "a",
            "batch",
            "of",
            "records"
        ]
    },
    {
        "id": 1735,
        "code": "protected ProducerRecord<byte[], byte[]> convertTransformedRecord(SourceRecord record) {\n    if (record == null) {\n        return null;\n    }\n\n    RecordHeaders headers = retryWithToleranceOperator.execute(() -> convertHeaderFor(record), Stage.HEADER_CONVERTER, headerConverter.getClass());\n\n    byte[] key = retryWithToleranceOperator.execute(() -> keyConverter.fromConnectData(record.topic(), headers, record.keySchema(), record.key()),\n            Stage.KEY_CONVERTER, keyConverter.getClass());\n\n    byte[] value = retryWithToleranceOperator.execute(() -> valueConverter.fromConnectData(record.topic(), headers, record.valueSchema(), record.value()),\n            Stage.VALUE_CONVERTER, valueConverter.getClass());\n\n    if (retryWithToleranceOperator.failed()) {\n        return null;\n    }\n\n    return new ProducerRecord<>(record.topic(), record.kafkaPartition(),\n            ConnectUtils.checkAndConvertTimestamp(record.timestamp()), key, value, headers);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "source",
            "record",
            "into",
            "a",
            "producer",
            "record"
        ]
    },
    {
        "id": 1736,
        "code": "public String workerId() {\n    return workerId;\n}",
        "summary_tokens": [
            "get",
            "the",
            "worker",
            "identifier"
        ]
    },
    {
        "id": 1737,
        "code": "public Metrics metrics() {\n    return metrics;\n}",
        "summary_tokens": [
            "get",
            "the",
            "metrics",
            "kafka",
            "metrics",
            "that",
            "are",
            "managed",
            "by",
            "this",
            "object",
            "and",
            "that",
            "should",
            "be",
            "used",
            "to",
            "add",
            "sensors",
            "and",
            "individual",
            "metrics"
        ]
    },
    {
        "id": 1738,
        "code": "public ConnectMetricsRegistry registry() {\n    return registry;\n}",
        "summary_tokens": [
            "get",
            "the",
            "registry",
            "of",
            "metric",
            "names"
        ]
    },
    {
        "id": 1739,
        "code": "public MetricGroup group(String groupName, String... tagKeyValues) {\n    MetricGroupId groupId = groupId(groupName, tagKeyValues);\n    MetricGroup group = groupsByName.get(groupId);\n    if (group == null) {\n        group = new MetricGroup(groupId);\n        MetricGroup previous = groupsByName.putIfAbsent(groupId, group);\n        if (previous != null)\n            group = previous;\n    }\n    return group;\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "a",
            "metric",
            "group",
            "with",
            "the",
            "specified",
            "group",
            "name",
            "and",
            "the",
            "given",
            "tags"
        ]
    },
    {
        "id": 1740,
        "code": "public void stop() {\n    metrics.close();\n    LOG.debug(\"Unregistering Connect metrics with JMX for worker '{}'\", workerId);\n    AppInfoParser.unregisterAppInfo(JMX_PREFIX, workerId, metrics);\n}",
        "summary_tokens": [
            "stop",
            "and",
            "unregister",
            "the",
            "metrics",
            "from",
            "any",
            "reporters"
        ]
    },
    {
        "id": 1741,
        "code": "public static void main(String[] args) {\n    ConnectMetricsRegistry metrics = new ConnectMetricsRegistry();\n    System.out.println(Metrics.toHtmlTable(JMX_PREFIX, metrics.getAllTemplates()));\n}",
        "summary_tokens": [
            "utility",
            "to",
            "generate",
            "the",
            "documentation",
            "for",
            "the",
            "connect",
            "metrics"
        ]
    },
    {
        "id": 1742,
        "code": "public <R extends ConnectRecord<R>> List<Transformation<R>> transformations() {\n    final List<String> transformAliases = getList(TRANSFORMS_CONFIG);\n\n    final List<Transformation<R>> transformations = new ArrayList<>(transformAliases.size());\n    for (String alias : transformAliases) {\n        final String prefix = TRANSFORMS_CONFIG + \".\" + alias + \".\";\n\n        try {\n            @SuppressWarnings(\"unchecked\")\n            final Transformation<R> transformation = Utils.newInstance(getClass(prefix + \"type\"), Transformation.class);\n            Map<String, Object> configs = originalsWithPrefix(prefix);\n            Object predicateAlias = configs.remove(PredicatedTransformation.PREDICATE_CONFIG);\n            Object negate = configs.remove(PredicatedTransformation.NEGATE_CONFIG);\n            transformation.configure(configs);\n            if (predicateAlias != null) {\n                String predicatePrefix = PREDICATES_PREFIX + predicateAlias + \".\";\n                @SuppressWarnings(\"unchecked\")\n                Predicate<R> predicate = Utils.newInstance(getClass(predicatePrefix + \"type\"), Predicate.class);\n                predicate.configure(originalsWithPrefix(predicatePrefix));\n                transformations.add(new PredicatedTransformation<>(predicate, negate == null ? false : Boolean.parseBoolean(negate.toString()), transformation));\n            } else {\n                transformations.add(transformation);\n            }\n        } catch (Exception e) {\n            throw new ConnectException(e);\n        }\n    }\n\n    return transformations;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "initialized",
            "list",
            "of",
            "transformation",
            "which",
            "are",
            "specified",
            "in",
            "transforms",
            "config"
        ]
    },
    {
        "id": 1743,
        "code": "public static ConfigDef enrich(Plugins plugins, ConfigDef baseConfigDef, Map<String, String> props, boolean requireFullConfig) {\n    ConfigDef newDef = new ConfigDef(baseConfigDef);\n    new EnrichablePlugin<Transformation<?>>(\"Transformation\", TRANSFORMS_CONFIG, TRANSFORMS_GROUP, (Class) Transformation.class,\n            props, requireFullConfig) {\n        @SuppressWarnings(\"rawtypes\")\n        @Override\n        protected Set<PluginDesc<Transformation<?>>> plugins() {\n            return plugins.transformations();\n        }\n\n        @Override\n        protected ConfigDef initialConfigDef() {\n                \n            return super.initialConfigDef()\n                    .define(PredicatedTransformation.PREDICATE_CONFIG, Type.STRING, \"\", Importance.MEDIUM,\n                            \"The alias of a predicate used to determine whether to apply this transformation.\")\n                    .define(PredicatedTransformation.NEGATE_CONFIG, Type.BOOLEAN, false, Importance.MEDIUM,\n                            \"Whether the configured predicate should be negated.\");\n        }\n\n        @Override\n        protected Stream<Map.Entry<String, ConfigDef.ConfigKey>> configDefsForClass(String typeConfig) {\n            return super.configDefsForClass(typeConfig)\n                .filter(entry -> {\n                        \n                    if (PredicatedTransformation.PREDICATE_CONFIG.equals(entry.getKey())\n                            || PredicatedTransformation.NEGATE_CONFIG.equals(entry.getKey())) {\n                        log.warn(\"Transformer config {} is masked by implicit config of that name\",\n                                entry.getKey());\n                        return false;\n                    } else {\n                        return true;\n                    }\n                });\n        }\n\n        @Override\n        protected ConfigDef config(Transformation<?> transformation) {\n            return transformation.config();\n        }\n\n        @Override\n        protected void validateProps(String prefix) {\n            String prefixedNegate = prefix + PredicatedTransformation.NEGATE_CONFIG;\n            String prefixedPredicate = prefix + PredicatedTransformation.PREDICATE_CONFIG;\n            if (props.containsKey(prefixedNegate) &&\n                    !props.containsKey(prefixedPredicate)) {\n                throw new ConfigException(\"Config '\" + prefixedNegate + \"' was provided \" +\n                        \"but there is no config '\" + prefixedPredicate + \"' defining a predicate to be negated.\");\n            }\n        }\n    }.enrich(newDef);\n\n    new EnrichablePlugin<Predicate<?>>(\"Predicate\", PREDICATES_CONFIG, PREDICATES_GROUP,\n            (Class) Predicate.class, props, requireFullConfig) {\n        @Override\n        protected Set<PluginDesc<Predicate<?>>> plugins() {\n            return plugins.predicates();\n        }\n\n        @Override\n        protected ConfigDef config(Predicate<?> predicate) {\n            return predicate.config();\n        }\n    }.enrich(newDef);\n    return newDef;\n}",
        "summary_tokens": [
            "returns",
            "an",
            "enriched",
            "config",
            "def",
            "building",
            "upon",
            "the",
            "config",
            "def",
            "using",
            "the",
            "current",
            "configuration",
            "specified",
            "in",
            "props",
            "as",
            "an",
            "input"
        ]
    },
    {
        "id": 1744,
        "code": "default void validateConnectorConfig(Map<String, String> connectorConfig, Callback<ConfigInfos> callback, boolean doLog) {\n    validateConnectorConfig(connectorConfig, callback);\n}",
        "summary_tokens": [
            "validate",
            "the",
            "provided",
            "connector",
            "config",
            "values",
            "against",
            "the",
            "configuration",
            "definition"
        ]
    },
    {
        "id": 1745,
        "code": "public ConsumerRecord<byte[], byte[]> originalRecord() {\n    return originalRecord;\n}",
        "summary_tokens": [
            "return",
            "the",
            "original",
            "consumer",
            "record",
            "that",
            "this",
            "sink",
            "record",
            "represents"
        ]
    },
    {
        "id": 1746,
        "code": "public String connectorName() {\n    return request.connectorName();\n}",
        "summary_tokens": [
            "get",
            "the",
            "connector",
            "name"
        ]
    },
    {
        "id": 1747,
        "code": "public RestartRequest restartRequest() {\n    return request;\n}",
        "summary_tokens": [
            "get",
            "the",
            "original",
            "restart",
            "request"
        ]
    },
    {
        "id": 1748,
        "code": "public ConnectorStateInfo restartConnectorStateInfo() {\n    return stateInfo;\n}",
        "summary_tokens": [
            "get",
            "the",
            "connector",
            "state",
            "info",
            "that",
            "reflects",
            "the",
            "current",
            "state",
            "of",
            "the",
            "connector",
            "em",
            "except",
            "em",
            "with",
            "the",
            "status",
            "set",
            "to",
            "abstract",
            "status"
        ]
    },
    {
        "id": 1749,
        "code": "public Collection<ConnectorTaskId> taskIdsToRestart() {\n    return idsToRestart;\n}",
        "summary_tokens": [
            "get",
            "the",
            "immutable",
            "collection",
            "of",
            "connector",
            "task",
            "id",
            "for",
            "all",
            "tasks",
            "to",
            "be",
            "restarted",
            "based",
            "upon",
            "the",
            "restart",
            "request",
            "restart",
            "request"
        ]
    },
    {
        "id": 1750,
        "code": "public boolean shouldRestartConnector() {\n    return isRestarting(stateInfo.connector());\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "the",
            "connector",
            "instance",
            "is",
            "to",
            "be",
            "restarted",
            "based",
            "upon",
            "the",
            "restart",
            "request",
            "restart",
            "request"
        ]
    },
    {
        "id": 1751,
        "code": "public boolean shouldRestartTasks() {\n    return !taskIdsToRestart().isEmpty();\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "at",
            "least",
            "one",
            "task",
            "instance",
            "is",
            "to",
            "be",
            "restarted",
            "based",
            "upon",
            "the",
            "restart",
            "request",
            "restart",
            "request"
        ]
    },
    {
        "id": 1752,
        "code": "public int restartTaskCount() {\n    return taskIdsToRestart().size();\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "connector",
            "tasks",
            "that",
            "are",
            "to",
            "be",
            "restarted",
            "based",
            "upon",
            "the",
            "restart",
            "request",
            "restart",
            "request"
        ]
    },
    {
        "id": 1753,
        "code": "public int totalTaskCount() {\n    return stateInfo.tasks().size();\n}",
        "summary_tokens": [
            "get",
            "the",
            "total",
            "number",
            "of",
            "tasks",
            "in",
            "the",
            "connector"
        ]
    },
    {
        "id": 1754,
        "code": "public String connectorName() {\n    return connectorName;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1755,
        "code": "public boolean onlyFailed() {\n    return onlyFailed;\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "only",
            "failed",
            "instances",
            "be",
            "restarted"
        ]
    },
    {
        "id": 1756,
        "code": "public boolean includeTasks() {\n    return includeTasks;\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "task",
            "instances",
            "should",
            "also",
            "be",
            "restarted",
            "in",
            "addition",
            "to",
            "the",
            "connector",
            "instance"
        ]
    },
    {
        "id": 1757,
        "code": "public boolean shouldRestartConnector(ConnectorStatus status) {\n    return !onlyFailed || status.state() == AbstractStatus.State.FAILED;\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "the",
            "connector",
            "with",
            "the",
            "given",
            "status",
            "is",
            "to",
            "be",
            "restarted"
        ]
    },
    {
        "id": 1758,
        "code": "public boolean forceRestartConnectorOnly() {\n    return !onlyFailed() && !includeTasks();\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "only",
            "the",
            "connector",
            "instance",
            "is",
            "to",
            "be",
            "restarted",
            "even",
            "if",
            "not",
            "failed"
        ]
    },
    {
        "id": 1759,
        "code": "public boolean shouldRestartTask(TaskStatus status) {\n    return includeTasks && (!onlyFailed || status.state() == AbstractStatus.State.FAILED);\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "the",
            "task",
            "instance",
            "with",
            "the",
            "given",
            "status",
            "is",
            "to",
            "be",
            "restarted"
        ]
    },
    {
        "id": 1760,
        "code": "public SecretKey key() {\n    return key;\n}",
        "summary_tokens": [
            "get",
            "the",
            "cryptographic",
            "key",
            "to",
            "use",
            "for",
            "request",
            "validation"
        ]
    },
    {
        "id": 1761,
        "code": "public long creationTimestamp() {\n    return creationTimestamp;\n}",
        "summary_tokens": [
            "get",
            "the",
            "time",
            "at",
            "which",
            "the",
            "key",
            "was",
            "generated"
        ]
    },
    {
        "id": 1762,
        "code": "public static void validate(Map<String, String> props) {\n    final boolean hasTopicsConfig = hasTopicsConfig(props);\n    final boolean hasTopicsRegexConfig = hasTopicsRegexConfig(props);\n    final boolean hasDlqTopicConfig = hasDlqTopicConfig(props);\n\n    if (hasTopicsConfig && hasTopicsRegexConfig) {\n        throw new ConfigException(SinkTask.TOPICS_CONFIG + \" and \" + SinkTask.TOPICS_REGEX_CONFIG +\n            \" are mutually exclusive options, but both are set.\");\n    }\n\n    if (!hasTopicsConfig && !hasTopicsRegexConfig) {\n        throw new ConfigException(\"Must configure one of \" +\n            SinkTask.TOPICS_CONFIG + \" or \" + SinkTask.TOPICS_REGEX_CONFIG);\n    }\n\n    if (hasDlqTopicConfig) {\n        String dlqTopic = props.get(DLQ_TOPIC_NAME_CONFIG).trim();\n        if (hasTopicsConfig) {\n            List<String> topics = parseTopicsList(props);\n            if (topics.contains(dlqTopic)) {\n                throw new ConfigException(String.format(\"The DLQ topic '%s' may not be included in the list of \"\n                        + \"topics ('%s=%s') consumed by the connector\", dlqTopic, SinkTask.TOPICS_REGEX_CONFIG, topics));\n            }\n        }\n        if (hasTopicsRegexConfig) {\n            String topicsRegexStr = props.get(SinkTask.TOPICS_REGEX_CONFIG);\n            Pattern pattern = Pattern.compile(topicsRegexStr);\n            if (pattern.matcher(dlqTopic).matches()) {\n                throw new ConfigException(String.format(\"The DLQ topic '%s' may not be included in the regex matching the \"\n                        + \"topics ('%s=%s') consumed by the connector\", dlqTopic, SinkTask.TOPICS_REGEX_CONFIG, topicsRegexStr));\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "throw",
            "an",
            "exception",
            "if",
            "the",
            "passed",
            "in",
            "properties",
            "do",
            "not",
            "constitute",
            "a",
            "valid",
            "sink"
        ]
    },
    {
        "id": 1763,
        "code": "public static ConfigDef enrich(ConfigDef baseConfigDef, Map<String, String> props, AbstractConfig defaultGroupConfig) {\n    List<Object> topicCreationGroups = new ArrayList<>();\n    Object aliases = ConfigDef.parseType(TOPIC_CREATION_GROUPS_CONFIG, props.get(TOPIC_CREATION_GROUPS_CONFIG), ConfigDef.Type.LIST);\n    if (aliases instanceof List) {\n        topicCreationGroups.addAll((List<?>) aliases);\n    }\n\n        \n    if (topicCreationGroups.contains(DEFAULT_TOPIC_CREATION_GROUP)) {\n        log.warn(\"'{}' topic creation group always exists and does not need to be listed explicitly\",\n            DEFAULT_TOPIC_CREATION_GROUP);\n        topicCreationGroups.removeAll(Collections.singleton(DEFAULT_TOPIC_CREATION_GROUP));\n    }\n\n    ConfigDef newDef = new ConfigDef(baseConfigDef);\n    String defaultGroupPrefix = TOPIC_CREATION_PREFIX + DEFAULT_TOPIC_CREATION_GROUP + \".\";\n    short defaultGroupReplicationFactor = defaultGroupConfig.getShort(defaultGroupPrefix + REPLICATION_FACTOR_CONFIG);\n    int defaultGroupPartitions = defaultGroupConfig.getInt(defaultGroupPrefix + PARTITIONS_CONFIG);\n    topicCreationGroups.stream().distinct().forEach(group -> {\n        if (!(group instanceof String)) {\n            throw new ConfigException(\"Item in \" + TOPIC_CREATION_GROUPS_CONFIG + \" property is not of type String\");\n        }\n        String alias = (String) group;\n        String prefix = TOPIC_CREATION_PREFIX + alias + \".\";\n        String configGroup = TOPIC_CREATION_GROUP + \": \" + alias;\n        newDef.embed(prefix, configGroup, 0,\n                TopicCreationConfig.configDef(configGroup, defaultGroupReplicationFactor, defaultGroupPartitions));\n    });\n    return newDef;\n}",
        "summary_tokens": [
            "returns",
            "an",
            "enriched",
            "config",
            "def",
            "building",
            "upon",
            "the",
            "config",
            "def",
            "using",
            "the",
            "current",
            "configuration",
            "specified",
            "in",
            "props",
            "as",
            "an",
            "input"
        ]
    },
    {
        "id": 1764,
        "code": "public boolean usesTopicCreation() {\n    return enrichedSourceConfig != null;\n}",
        "summary_tokens": [
            "returns",
            "whether",
            "this",
            "configuration",
            "uses",
            "topic",
            "creation",
            "properties"
        ]
    },
    {
        "id": 1765,
        "code": "public synchronized void changeState(State newState, long now) {\n        \n    lastState.set(lastState.get().newState(newState, now));\n}",
        "summary_tokens": [
            "change",
            "the",
            "current",
            "state"
        ]
    },
    {
        "id": 1766,
        "code": "public double durationRatio(State ratioState, long now) {\n    return lastState.get().durationRatio(ratioState, now);\n}",
        "summary_tokens": [
            "calculate",
            "the",
            "ratio",
            "of",
            "time",
            "spent",
            "in",
            "the",
            "specified",
            "state"
        ]
    },
    {
        "id": 1767,
        "code": "public State currentState() {\n    return lastState.get().state;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "state"
        ]
    },
    {
        "id": 1768,
        "code": "public SubmittedRecord submit(SourceRecord record) {\n    return submit((Map<String, Object>) record.sourcePartition(), (Map<String, Object>) record.sourceOffset());\n}",
        "summary_tokens": [
            "enqueue",
            "a",
            "new",
            "source",
            "record",
            "before",
            "dispatching",
            "it",
            "to",
            "a",
            "producer"
        ]
    },
    {
        "id": 1769,
        "code": "public CommittableOffsets committableOffsets() {\n    Map<Map<String, Object>, Map<String, Object>> offsets = new HashMap<>();\n    int totalCommittableMessages = 0;\n    int totalUncommittableMessages = 0;\n    int largestDequeSize = 0;\n    Map<String, Object> largestDequePartition = null;\n    for (Map.Entry<Map<String, Object>, Deque<SubmittedRecord>> entry : records.entrySet()) {\n        Map<String, Object> partition = entry.getKey();\n        Deque<SubmittedRecord> queuedRecords = entry.getValue();\n        int initialDequeSize = queuedRecords.size();\n        if (canCommitHead(queuedRecords)) {\n            Map<String, Object> offset = committableOffset(queuedRecords);\n            offsets.put(partition, offset);\n        }\n        int uncommittableMessages = queuedRecords.size();\n        int committableMessages = initialDequeSize - uncommittableMessages;\n        totalCommittableMessages += committableMessages;\n        totalUncommittableMessages += uncommittableMessages;\n        if (uncommittableMessages > largestDequeSize) {\n            largestDequeSize = uncommittableMessages;\n            largestDequePartition = partition;\n        }\n    }\n        \n    records.values().removeIf(Deque::isEmpty);\n    return new CommittableOffsets(offsets, totalCommittableMessages, totalUncommittableMessages, records.size(), largestDequeSize, largestDequePartition);\n}",
        "summary_tokens": [
            "clear",
            "out",
            "any",
            "acknowledged",
            "records",
            "at",
            "the",
            "head",
            "of",
            "the",
            "deques",
            "and",
            "return",
            "a",
            "committable",
            "offsets",
            "snapshot",
            "of",
            "the",
            "offsets",
            "and",
            "offset",
            "metadata",
            "accrued",
            "between",
            "the",
            "last",
            "time",
            "this",
            "method",
            "was",
            "invoked",
            "and",
            "now"
        ]
    },
    {
        "id": 1770,
        "code": "public boolean awaitAllMessages(long timeout, TimeUnit timeUnit) {\n        \n        \n    CountDownLatch messageDrainLatch;\n    synchronized (this) {\n        messageDrainLatch = new CountDownLatch(numUnackedMessages);\n        this.messageDrainLatch = messageDrainLatch;\n    }\n    try {\n        return messageDrainLatch.await(timeout, timeUnit);\n    } catch (InterruptedException e) {\n        return false;\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "all",
            "currently",
            "in",
            "flight",
            "messages",
            "to",
            "be",
            "acknowledged",
            "up",
            "to",
            "the",
            "requested",
            "timeout"
        ]
    },
    {
        "id": 1771,
        "code": "public String topic() {\n    return topic;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "the",
            "topic"
        ]
    },
    {
        "id": 1772,
        "code": "public String connector() {\n    return connector;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "the",
            "connector"
        ]
    },
    {
        "id": 1773,
        "code": "public int task() {\n    return task;\n}",
        "summary_tokens": [
            "get",
            "the",
            "id",
            "of",
            "the",
            "task",
            "that",
            "stored",
            "the",
            "topic",
            "status"
        ]
    },
    {
        "id": 1774,
        "code": "public long discoverTimestamp() {\n    return discoverTimestamp;\n}",
        "summary_tokens": [
            "get",
            "a",
            "timestamp",
            "that",
            "represents",
            "when",
            "this",
            "topic",
            "was",
            "discovered",
            "as",
            "being",
            "actively",
            "used",
            "by",
            "this",
            "connector"
        ]
    },
    {
        "id": 1775,
        "code": "public void startConnector(\n        String connName,\n        Map<String, String> connProps,\n        CloseableConnectorContext ctx,\n        ConnectorStatus.Listener statusListener,\n        TargetState initialState,\n        Callback<TargetState> onConnectorStateChange\n) {\n    final ConnectorStatus.Listener connectorStatusListener = workerMetricsGroup.wrapStatusListener(statusListener);\n    try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n        if (connectors.containsKey(connName)) {\n            onConnectorStateChange.onCompletion(\n                    new ConnectException(\"Connector with name \" + connName + \" already exists\"),\n                    null);\n            return;\n        }\n\n        final WorkerConnector workerConnector;\n        ClassLoader savedLoader = plugins.currentThreadLoader();\n        try {\n                \n                \n                \n            final String connClass = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n            ClassLoader connectorLoader = plugins.delegatingLoader().connectorLoader(connClass);\n            savedLoader = Plugins.compareAndSwapLoaders(connectorLoader);\n\n            log.info(\"Creating connector {} of type {}\", connName, connClass);\n            final Connector connector = plugins.newConnector(connClass);\n            final ConnectorConfig connConfig;\n            final CloseableOffsetStorageReader offsetReader;\n            final ConnectorOffsetBackingStore offsetStore;\n            if (ConnectUtils.isSinkConnector(connector)) {\n                connConfig = new SinkConnectorConfig(plugins, connProps);\n                offsetReader = null;\n                offsetStore = null;\n            } else {\n                SourceConnectorConfig sourceConfig = new SourceConnectorConfig(plugins, connProps, config.topicCreationEnable());\n                connConfig = sourceConfig;\n\n                    \n                offsetStore = config.exactlyOnceSourceEnabled()\n                        ? offsetStoreForExactlyOnceSourceConnector(sourceConfig, connName, connector)\n                        : offsetStoreForRegularSourceConnector(sourceConfig, connName, connector);\n                offsetStore.configure(config);\n                offsetReader = new OffsetStorageReaderImpl(offsetStore, connName, internalKeyConverter, internalValueConverter);\n            }\n            workerConnector = new WorkerConnector(\n                    connName, connector, connConfig, ctx, metrics, connectorStatusListener, offsetReader, offsetStore, connectorLoader);\n            log.info(\"Instantiated connector {} with version {} of type {}\", connName, connector.version(), connector.getClass());\n            workerConnector.transitionTo(initialState, onConnectorStateChange);\n            Plugins.compareAndSwapLoaders(savedLoader);\n        } catch (Throwable t) {\n            log.error(\"Failed to start connector {}\", connName, t);\n                \n                \n            Plugins.compareAndSwapLoaders(savedLoader);\n            connectorStatusListener.onFailure(connName, t);\n            onConnectorStateChange.onCompletion(t, null);\n            return;\n        }\n\n        WorkerConnector existing = connectors.putIfAbsent(connName, workerConnector);\n        if (existing != null) {\n            onConnectorStateChange.onCompletion(\n                    new ConnectException(\"Connector with name \" + connName + \" already exists\"),\n                    null);\n                \n                \n            return;\n        }\n\n        executor.submit(workerConnector);\n\n        log.info(\"Finished creating connector {}\", connName);\n    }\n}",
        "summary_tokens": [
            "start",
            "a",
            "connector",
            "managed",
            "by",
            "this",
            "worker"
        ]
    },
    {
        "id": 1776,
        "code": "public boolean isSinkConnector(String connName) {\n    WorkerConnector workerConnector = connectors.get(connName);\n    if (workerConnector == null)\n        throw new ConnectException(\"Connector \" + connName + \" not found in this worker.\");\n\n    ClassLoader savedLoader = plugins.currentThreadLoader();\n    try {\n        savedLoader = Plugins.compareAndSwapLoaders(workerConnector.loader());\n        return workerConnector.isSinkConnector();\n    } finally {\n        Plugins.compareAndSwapLoaders(savedLoader);\n    }\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "connector",
            "associated",
            "with",
            "this",
            "worker",
            "is",
            "a",
            "sink",
            "connector"
        ]
    },
    {
        "id": 1777,
        "code": "public List<Map<String, String>> connectorTaskConfigs(String connName, ConnectorConfig connConfig) {\n    List<Map<String, String>> result = new ArrayList<>();\n    try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n        log.trace(\"Reconfiguring connector tasks for {}\", connName);\n\n        WorkerConnector workerConnector = connectors.get(connName);\n        if (workerConnector == null)\n            throw new ConnectException(\"Connector \" + connName + \" not found in this worker.\");\n\n        int maxTasks = connConfig.getInt(ConnectorConfig.TASKS_MAX_CONFIG);\n        Map<String, String> connOriginals = connConfig.originalsStrings();\n\n        Connector connector = workerConnector.connector();\n        ClassLoader savedLoader = plugins.currentThreadLoader();\n        try {\n            savedLoader = Plugins.compareAndSwapLoaders(workerConnector.loader());\n            String taskClassName = connector.taskClass().getName();\n            for (Map<String, String> taskProps : connector.taskConfigs(maxTasks)) {\n                    \n                Map<String, String> taskConfig = new HashMap<>(taskProps);\n                taskConfig.put(TaskConfig.TASK_CLASS_CONFIG, taskClassName);\n                if (connOriginals.containsKey(SinkTask.TOPICS_CONFIG)) {\n                    taskConfig.put(SinkTask.TOPICS_CONFIG, connOriginals.get(SinkTask.TOPICS_CONFIG));\n                }\n                if (connOriginals.containsKey(SinkTask.TOPICS_REGEX_CONFIG)) {\n                    taskConfig.put(SinkTask.TOPICS_REGEX_CONFIG, connOriginals.get(SinkTask.TOPICS_REGEX_CONFIG));\n                }\n                result.add(taskConfig);\n            }\n        } finally {\n            Plugins.compareAndSwapLoaders(savedLoader);\n        }\n    }\n\n    return result;\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "updated",
            "task",
            "properties",
            "for",
            "the",
            "tasks",
            "of",
            "this",
            "connector"
        ]
    },
    {
        "id": 1778,
        "code": "private void stopConnector(String connName) {\n    try (LoggingContext loggingContext = LoggingContext.forConnector(connName)) {\n        WorkerConnector workerConnector = connectors.get(connName);\n        log.info(\"Stopping connector {}\", connName);\n\n        if (workerConnector == null) {\n            log.warn(\"Ignoring stop request for unowned connector {}\", connName);\n            return;\n        }\n\n        ClassLoader savedLoader = plugins.currentThreadLoader();\n        try {\n            savedLoader = Plugins.compareAndSwapLoaders(workerConnector.loader());\n            workerConnector.shutdown();\n        } finally {\n            Plugins.compareAndSwapLoaders(savedLoader);\n        }\n    }\n}",
        "summary_tokens": [
            "stop",
            "a",
            "connector",
            "managed",
            "by",
            "this",
            "worker"
        ]
    },
    {
        "id": 1779,
        "code": "public void stopAndAwaitConnectors(Collection<String> ids) {\n    stopConnectors(ids);\n    awaitStopConnectors(ids);\n}",
        "summary_tokens": [
            "stop",
            "asynchronously",
            "a",
            "collection",
            "of",
            "connectors",
            "that",
            "belong",
            "to",
            "this",
            "worker",
            "and",
            "await",
            "their",
            "termination"
        ]
    },
    {
        "id": 1780,
        "code": "public void stopAndAwaitConnector(String connName) {\n    stopConnector(connName);\n    awaitStopConnectors(Collections.singletonList(connName));\n}",
        "summary_tokens": [
            "stop",
            "a",
            "connector",
            "that",
            "belongs",
            "to",
            "this",
            "worker",
            "and",
            "await",
            "its",
            "termination"
        ]
    },
    {
        "id": 1781,
        "code": "public Set<String> connectorNames() {\n    return connectors.keySet();\n}",
        "summary_tokens": [
            "get",
            "the",
            "ids",
            "of",
            "the",
            "connectors",
            "currently",
            "running",
            "in",
            "this",
            "worker"
        ]
    },
    {
        "id": 1782,
        "code": "public boolean isRunning(String connName) {\n    WorkerConnector workerConnector = connectors.get(connName);\n    return workerConnector != null && workerConnector.isRunning();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "a",
            "connector",
            "with",
            "the",
            "given",
            "name",
            "is",
            "managed",
            "by",
            "this",
            "worker",
            "and",
            "is",
            "currently",
            "running"
        ]
    },
    {
        "id": 1783,
        "code": "public boolean startSinkTask(\n        ConnectorTaskId id,\n        ClusterConfigState configState,\n        Map<String, String> connProps,\n        Map<String, String> taskProps,\n        TaskStatus.Listener statusListener,\n        TargetState initialState\n) {\n    return startTask(id, connProps, taskProps, statusListener,\n            new SinkTaskBuilder(id, configState, statusListener, initialState));\n}",
        "summary_tokens": [
            "start",
            "a",
            "sink",
            "task",
            "managed",
            "by",
            "this",
            "worker"
        ]
    },
    {
        "id": 1784,
        "code": "public boolean startSourceTask(\n        ConnectorTaskId id,\n        ClusterConfigState configState,\n        Map<String, String> connProps,\n        Map<String, String> taskProps,\n        TaskStatus.Listener statusListener,\n        TargetState initialState\n) {\n    return startTask(id, connProps, taskProps, statusListener,\n            new SourceTaskBuilder(id, configState, statusListener, initialState));\n}",
        "summary_tokens": [
            "start",
            "a",
            "source",
            "task",
            "managed",
            "by",
            "this",
            "worker",
            "using",
            "older",
            "behavior",
            "that",
            "does",
            "not",
            "provide",
            "exactly",
            "once",
            "support"
        ]
    },
    {
        "id": 1785,
        "code": "public boolean startExactlyOnceSourceTask(\n        ConnectorTaskId id,\n        ClusterConfigState configState,\n        Map<String, String> connProps,\n        Map<String, String> taskProps,\n        TaskStatus.Listener statusListener,\n        TargetState initialState,\n        Runnable preProducerCheck,\n        Runnable postProducerCheck\n) {\n    return startTask(id, connProps, taskProps, statusListener,\n            new ExactlyOnceSourceTaskBuilder(id, configState, statusListener, initialState, preProducerCheck, postProducerCheck));\n}",
        "summary_tokens": [
            "start",
            "a",
            "source",
            "task",
            "with",
            "exactly",
            "once",
            "support",
            "managed",
            "by",
            "this",
            "worker"
        ]
    },
    {
        "id": 1786,
        "code": "private boolean startTask(\n        ConnectorTaskId id,\n        Map<String, String> connProps,\n        Map<String, String> taskProps,\n        TaskStatus.Listener statusListener,\n        TaskBuilder taskBuilder\n) {\n    final WorkerTask workerTask;\n    final TaskStatus.Listener taskStatusListener = workerMetricsGroup.wrapStatusListener(statusListener);\n    try (LoggingContext loggingContext = LoggingContext.forTask(id)) {\n        log.info(\"Creating task {}\", id);\n\n        if (tasks.containsKey(id))\n            throw new ConnectException(\"Task already exists in this worker: \" + id);\n\n        connectorStatusMetricsGroup.recordTaskAdded(id);\n        ClassLoader savedLoader = plugins.currentThreadLoader();\n        try {\n            String connType = connProps.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG);\n            ClassLoader connectorLoader = plugins.delegatingLoader().connectorLoader(connType);\n            savedLoader = Plugins.compareAndSwapLoaders(connectorLoader);\n            final ConnectorConfig connConfig = new ConnectorConfig(plugins, connProps);\n            final TaskConfig taskConfig = new TaskConfig(taskProps);\n            final Class<? extends Task> taskClass = taskConfig.getClass(TaskConfig.TASK_CLASS_CONFIG).asSubclass(Task.class);\n            final Task task = plugins.newTask(taskClass);\n            log.info(\"Instantiated task {} with version {} of type {}\", id, task.version(), taskClass.getName());\n\n                \n                \n                \n                \n            Converter keyConverter = plugins.newConverter(connConfig, WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, ClassLoaderUsage\n                                                                                                                       .CURRENT_CLASSLOADER);\n            Converter valueConverter = plugins.newConverter(connConfig, WorkerConfig.VALUE_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.CURRENT_CLASSLOADER);\n            HeaderConverter headerConverter = plugins.newHeaderConverter(connConfig, WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,\n                                                                         ClassLoaderUsage.CURRENT_CLASSLOADER);\n            if (keyConverter == null) {\n                keyConverter = plugins.newConverter(config, WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS);\n                log.info(\"Set up the key converter {} for task {} using the worker config\", keyConverter.getClass(), id);\n            } else {\n                log.info(\"Set up the key converter {} for task {} using the connector config\", keyConverter.getClass(), id);\n            }\n            if (valueConverter == null) {\n                valueConverter = plugins.newConverter(config, WorkerConfig.VALUE_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS);\n                log.info(\"Set up the value converter {} for task {} using the worker config\", valueConverter.getClass(), id);\n            } else {\n                log.info(\"Set up the value converter {} for task {} using the connector config\", valueConverter.getClass(), id);\n            }\n            if (headerConverter == null) {\n                headerConverter = plugins.newHeaderConverter(config, WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, ClassLoaderUsage\n                                                                                                                         .PLUGINS);\n                log.info(\"Set up the header converter {} for task {} using the worker config\", headerConverter.getClass(), id);\n            } else {\n                log.info(\"Set up the header converter {} for task {} using the connector config\", headerConverter.getClass(), id);\n            }\n\n            workerTask = taskBuilder\n                    .withTask(task)\n                    .withConnectorConfig(connConfig)\n                    .withKeyConverter(keyConverter)\n                    .withValueConverter(valueConverter)\n                    .withHeaderConverter(headerConverter)\n                    .withClassloader(connectorLoader)\n                    .build();\n\n            workerTask.initialize(taskConfig);\n            Plugins.compareAndSwapLoaders(savedLoader);\n        } catch (Throwable t) {\n            log.error(\"Failed to start task {}\", id, t);\n                \n                \n            Plugins.compareAndSwapLoaders(savedLoader);\n            connectorStatusMetricsGroup.recordTaskRemoved(id);\n            taskStatusListener.onFailure(id, t);\n            return false;\n        }\n\n        WorkerTask existing = tasks.putIfAbsent(id, workerTask);\n        if (existing != null)\n            throw new ConnectException(\"Task already exists in this worker: \" + id);\n\n        executor.submit(workerTask);\n        if (workerTask instanceof WorkerSourceTask) {\n            sourceTaskOffsetCommitter.ifPresent(committer -> committer.schedule(id, (WorkerSourceTask) workerTask));\n        }\n        return true;\n    }\n}",
        "summary_tokens": [
            "start",
            "a",
            "task",
            "managed",
            "by",
            "this",
            "worker"
        ]
    },
    {
        "id": 1787,
        "code": "public KafkaFuture<Void> fenceZombies(String connName, int numTasks, Map<String, String> connProps) {\n    return fenceZombies(connName, numTasks, connProps, Admin::create);\n}",
        "summary_tokens": [
            "using",
            "the",
            "admin",
            "principal",
            "for",
            "this",
            "connector",
            "perform",
            "a",
            "round",
            "of",
            "zombie",
            "fencing",
            "that",
            "disables",
            "transactional",
            "producers",
            "for",
            "the",
            "specified",
            "number",
            "of",
            "source",
            "tasks",
            "from",
            "sending",
            "any",
            "more",
            "records"
        ]
    },
    {
        "id": 1788,
        "code": "public static String taskTransactionalId(String groupId, String connector, int taskId) {\n    return String.format(\"%s-%s-%d\", groupId, connector, taskId);\n}",
        "summary_tokens": [
            "the",
            "producer",
            "config",
            "transactional",
            "id",
            "config",
            "transactional",
            "id",
            "to",
            "use",
            "for",
            "a",
            "task",
            "that",
            "writes",
            "records",
            "and",
            "or",
            "offsets",
            "in",
            "a",
            "transaction"
        ]
    },
    {
        "id": 1789,
        "code": "public void stopAndAwaitTasks(Collection<ConnectorTaskId> ids) {\n    stopTasks(ids);\n    awaitStopTasks(ids);\n}",
        "summary_tokens": [
            "stop",
            "asynchronously",
            "a",
            "collection",
            "of",
            "tasks",
            "that",
            "belong",
            "to",
            "this",
            "worker",
            "and",
            "await",
            "their",
            "termination"
        ]
    },
    {
        "id": 1790,
        "code": "public void stopAndAwaitTask(ConnectorTaskId taskId) {\n    stopTask(taskId);\n    awaitStopTasks(Collections.singletonList(taskId));\n}",
        "summary_tokens": [
            "stop",
            "a",
            "task",
            "that",
            "belongs",
            "to",
            "this",
            "worker",
            "and",
            "await",
            "its",
            "termination"
        ]
    },
    {
        "id": 1791,
        "code": "public Set<ConnectorTaskId> taskIds() {\n    return tasks.keySet();\n}",
        "summary_tokens": [
            "get",
            "the",
            "ids",
            "of",
            "the",
            "tasks",
            "currently",
            "running",
            "in",
            "this",
            "worker"
        ]
    },
    {
        "id": 1792,
        "code": "public boolean isTopicCreationEnabled() {\n    return config.topicCreationEnable();\n}",
        "summary_tokens": [
            "returns",
            "whether",
            "this",
            "worker",
            "is",
            "configured",
            "to",
            "allow",
            "source",
            "connectors",
            "to",
            "create",
            "the",
            "topics",
            "that",
            "they",
            "use",
            "with",
            "custom",
            "configurations",
            "if",
            "these",
            "topics",
            "don",
            "t",
            "already",
            "exist"
        ]
    },
    {
        "id": 1793,
        "code": "public ConnectMetrics metrics() {\n    return metrics;\n}",
        "summary_tokens": [
            "get",
            "the",
            "connect",
            "metrics",
            "that",
            "uses",
            "kafka",
            "metrics",
            "and",
            "manages",
            "the",
            "jmx",
            "reporter"
        ]
    },
    {
        "id": 1794,
        "code": "private boolean sameOffsetTopicAsWorker(String offsetsTopic, Map<String, Object> producerProps) {\n        \n        \n        \n        \n        \n        \n        \n    Set<String> workerBootstrapServers = new HashSet<>(config.getList(BOOTSTRAP_SERVERS_CONFIG));\n    Set<String> producerBootstrapServers = new HashSet<>();\n    try {\n        String rawBootstrapServers = producerProps.getOrDefault(BOOTSTRAP_SERVERS_CONFIG, \"\").toString();\n        @SuppressWarnings(\"unchecked\")\n        List<String> parsedBootstrapServers = (List<String>) ConfigDef.parseType(BOOTSTRAP_SERVERS_CONFIG, rawBootstrapServers, ConfigDef.Type.LIST);\n        producerBootstrapServers.addAll(parsedBootstrapServers);\n    } catch (Exception e) {\n            \n        throw new ConnectException(\"Failed to parse bootstrap servers property in producer config\", e);\n    }\n    return offsetsTopic.equals(config.offsetsTopic())\n            && workerBootstrapServers.equals(producerBootstrapServers);\n}",
        "summary_tokens": [
            "gives",
            "a",
            "best",
            "effort",
            "guess",
            "for",
            "whether",
            "the",
            "given",
            "offsets",
            "topic",
            "is",
            "the",
            "same",
            "topic",
            "as",
            "the",
            "worker",
            "global",
            "offsets",
            "topic"
        ]
    },
    {
        "id": 1795,
        "code": "protected static ConfigDef baseConfigDef() {\n    return new ConfigDef()\n            .define(BOOTSTRAP_SERVERS_CONFIG, Type.LIST, BOOTSTRAP_SERVERS_DEFAULT,\n                    Importance.HIGH, BOOTSTRAP_SERVERS_DOC)\n            .define(CLIENT_DNS_LOOKUP_CONFIG,\n                    Type.STRING,\n                    ClientDnsLookup.USE_ALL_DNS_IPS.toString(),\n                    in(ClientDnsLookup.USE_ALL_DNS_IPS.toString(),\n                       ClientDnsLookup.RESOLVE_CANONICAL_BOOTSTRAP_SERVERS_ONLY.toString()),\n                    Importance.MEDIUM,\n                    CLIENT_DNS_LOOKUP_DOC)\n            .define(KEY_CONVERTER_CLASS_CONFIG, Type.CLASS,\n                    Importance.HIGH, KEY_CONVERTER_CLASS_DOC)\n            .define(VALUE_CONVERTER_CLASS_CONFIG, Type.CLASS,\n                    Importance.HIGH, VALUE_CONVERTER_CLASS_DOC)\n            .define(TASK_SHUTDOWN_GRACEFUL_TIMEOUT_MS_CONFIG, Type.LONG,\n                    TASK_SHUTDOWN_GRACEFUL_TIMEOUT_MS_DEFAULT, Importance.LOW,\n                    TASK_SHUTDOWN_GRACEFUL_TIMEOUT_MS_DOC)\n            .define(OFFSET_COMMIT_INTERVAL_MS_CONFIG, Type.LONG, OFFSET_COMMIT_INTERVAL_MS_DEFAULT,\n                    Importance.LOW, OFFSET_COMMIT_INTERVAL_MS_DOC)\n            .define(OFFSET_COMMIT_TIMEOUT_MS_CONFIG, Type.LONG, OFFSET_COMMIT_TIMEOUT_MS_DEFAULT,\n                    Importance.LOW, OFFSET_COMMIT_TIMEOUT_MS_DOC)\n            .define(LISTENERS_CONFIG, Type.LIST, LISTENERS_DEFAULT, new ListenersValidator(), Importance.LOW, LISTENERS_DOC)\n            .define(REST_ADVERTISED_HOST_NAME_CONFIG, Type.STRING,  null, Importance.LOW, REST_ADVERTISED_HOST_NAME_DOC)\n            .define(REST_ADVERTISED_PORT_CONFIG, Type.INT,  null, Importance.LOW, REST_ADVERTISED_PORT_DOC)\n            .define(REST_ADVERTISED_LISTENER_CONFIG, Type.STRING,  null, Importance.LOW, REST_ADVERTISED_LISTENER_DOC)\n            .define(ACCESS_CONTROL_ALLOW_ORIGIN_CONFIG, Type.STRING,\n                    ACCESS_CONTROL_ALLOW_ORIGIN_DEFAULT, Importance.LOW,\n                    ACCESS_CONTROL_ALLOW_ORIGIN_DOC)\n            .define(ACCESS_CONTROL_ALLOW_METHODS_CONFIG, Type.STRING,\n                    ACCESS_CONTROL_ALLOW_METHODS_DEFAULT, Importance.LOW,\n                    ACCESS_CONTROL_ALLOW_METHODS_DOC)\n            .define(PLUGIN_PATH_CONFIG,\n                    Type.LIST,\n                    null,\n                    Importance.LOW,\n                    PLUGIN_PATH_DOC)\n            .define(METRICS_SAMPLE_WINDOW_MS_CONFIG, Type.LONG,\n                    30000, atLeast(0), Importance.LOW,\n                    CommonClientConfigs.METRICS_SAMPLE_WINDOW_MS_DOC)\n            .define(METRICS_NUM_SAMPLES_CONFIG, Type.INT,\n                    2, atLeast(1), Importance.LOW,\n                    CommonClientConfigs.METRICS_NUM_SAMPLES_DOC)\n            .define(METRICS_RECORDING_LEVEL_CONFIG, Type.STRING,\n                    Sensor.RecordingLevel.INFO.toString(),\n                    in(Sensor.RecordingLevel.INFO.toString(), Sensor.RecordingLevel.DEBUG.toString()),\n                    Importance.LOW,\n                    CommonClientConfigs.METRICS_RECORDING_LEVEL_DOC)\n            .define(METRIC_REPORTER_CLASSES_CONFIG, Type.LIST,\n                    \"\", Importance.LOW,\n                    CommonClientConfigs.METRIC_REPORTER_CLASSES_DOC)\n            .define(AUTO_INCLUDE_JMX_REPORTER_CONFIG,\n                    Type.BOOLEAN,\n                    true,\n                    Importance.LOW,\n                    CommonClientConfigs.AUTO_INCLUDE_JMX_REPORTER_DOC)\n            .define(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG,\n                    ConfigDef.Type.STRING, SslClientAuth.NONE.toString(), in(Utils.enumOptions(SslClientAuth.class)), ConfigDef.Importance.LOW, BrokerSecurityConfigs.SSL_CLIENT_AUTH_DOC)\n            .define(HEADER_CONVERTER_CLASS_CONFIG, Type.CLASS,\n                    HEADER_CONVERTER_CLASS_DEFAULT,\n                    Importance.LOW, HEADER_CONVERTER_CLASS_DOC)\n            .define(CONFIG_PROVIDERS_CONFIG, Type.LIST,\n                    Collections.emptyList(),\n                    Importance.LOW, CONFIG_PROVIDERS_DOC)\n            .define(REST_EXTENSION_CLASSES_CONFIG, Type.LIST, \"\",\n                    Importance.LOW, REST_EXTENSION_CLASSES_DOC)\n            .define(ADMIN_LISTENERS_CONFIG, Type.LIST, null,\n                    new AdminListenersValidator(), Importance.LOW, ADMIN_LISTENERS_DOC)\n            .define(CONNECTOR_CLIENT_POLICY_CLASS_CONFIG, Type.STRING, CONNECTOR_CLIENT_POLICY_CLASS_DEFAULT,\n                    Importance.MEDIUM, CONNECTOR_CLIENT_POLICY_CLASS_DOC)\n            .define(TOPIC_TRACKING_ENABLE_CONFIG, Type.BOOLEAN, TOPIC_TRACKING_ENABLE_DEFAULT,\n                    Importance.LOW, TOPIC_TRACKING_ENABLE_DOC)\n            .define(TOPIC_TRACKING_ALLOW_RESET_CONFIG, Type.BOOLEAN, TOPIC_TRACKING_ALLOW_RESET_DEFAULT,\n                    Importance.LOW, TOPIC_TRACKING_ALLOW_RESET_DOC)\n            .define(TOPIC_CREATION_ENABLE_CONFIG, Type.BOOLEAN, TOPIC_CREATION_ENABLE_DEFAULT, Importance.LOW,\n                    TOPIC_CREATION_ENABLE_DOC)\n            .define(RESPONSE_HTTP_HEADERS_CONFIG, Type.STRING, RESPONSE_HTTP_HEADERS_DEFAULT,\n                    new ResponseHttpHeadersValidator(), Importance.LOW, RESPONSE_HTTP_HEADERS_DOC)\n                \n            .withClientSslSupport();\n}",
        "summary_tokens": [
            "get",
            "a",
            "basic",
            "config",
            "def",
            "for",
            "a",
            "worker",
            "config"
        ]
    },
    {
        "id": 1796,
        "code": "public String bootstrapServers() {\n    return String.join(\",\", getList(BOOTSTRAP_SERVERS_CONFIG));\n}",
        "summary_tokens": [
            "the",
            "common",
            "client",
            "configs",
            "bootstrap",
            "servers",
            "config",
            "bootstrap",
            "servers",
            "property",
            "used",
            "by",
            "the",
            "worker",
            "when",
            "instantiating",
            "kafka",
            "clients",
            "for",
            "connectors",
            "and",
            "tasks",
            "unless",
            "overridden",
            "and",
            "its",
            "internal",
            "topics",
            "if",
            "running",
            "in",
            "distributed",
            "mode"
        ]
    },
    {
        "id": 1797,
        "code": "public boolean exactlyOnceSourceEnabled() {\n    return false;\n}",
        "summary_tokens": [
            "whether",
            "this",
            "worker",
            "is",
            "configured",
            "with",
            "exactly",
            "once",
            "support",
            "for",
            "source",
            "connectors"
        ]
    },
    {
        "id": 1798,
        "code": "public String offsetsTopic() {\n    return null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "internal",
            "topic",
            "used",
            "by",
            "this",
            "worker",
            "to",
            "store",
            "source",
            "connector",
            "offsets"
        ]
    },
    {
        "id": 1799,
        "code": "public boolean connectorOffsetsTopicsPermitted() {\n    return false;\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "this",
            "worker",
            "supports",
            "per",
            "connector",
            "source",
            "offsets",
            "topics"
        ]
    },
    {
        "id": 1800,
        "code": "public long offsetCommitInterval() {\n    return getLong(OFFSET_COMMIT_INTERVAL_MS_CONFIG);\n}",
        "summary_tokens": [
            "the",
            "offset",
            "commit",
            "interval",
            "for",
            "tasks",
            "created",
            "by",
            "this",
            "worker"
        ]
    },
    {
        "id": 1801,
        "code": "public String groupId() {\n    return null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "common",
            "client",
            "configs",
            "group",
            "id",
            "config",
            "group",
            "id",
            "used",
            "by",
            "this",
            "worker",
            "to",
            "form",
            "a",
            "cluster"
        ]
    },
    {
        "id": 1802,
        "code": "public boolean awaitShutdown(long timeoutMs) {\n    try {\n        return shutdownLatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        return false;\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "this",
            "connector",
            "to",
            "finish",
            "shutting",
            "down"
        ]
    },
    {
        "id": 1803,
        "code": "public void logAll() {\n    StringBuilder b = new StringBuilder();\n    b.append(getClass().getSimpleName());\n    b.append(\" values: \");\n    b.append(Utils.NL);\n\n    for (Map.Entry<String, Object> entry : values.entrySet()) {\n        b.append('\\t');\n        b.append(entry.getKey());\n        b.append(\" = \");\n        b.append(format(entry.getValue()));\n        b.append(Utils.NL);\n    }\n    log.info(b.toString());\n}",
        "summary_tokens": [
            "log",
            "the",
            "values",
            "of",
            "this",
            "object",
            "at",
            "level",
            "info"
        ]
    },
    {
        "id": 1804,
        "code": "protected void addRuntimeInfo() {\n    List<String> jvmArgs = RUNTIME.getInputArguments();\n    values.put(\"jvm.args\", Utils.join(jvmArgs, \", \"));\n    String[] jvmSpec = {\n            RUNTIME.getVmVendor(),\n            RUNTIME.getVmName(),\n            RUNTIME.getSystemProperties().get(\"java.version\"),\n            RUNTIME.getVmVersion()\n    };\n    values.put(\"jvm.spec\", Utils.join(jvmSpec, \", \"));\n    values.put(\"jvm.classpath\", RUNTIME.getClassPath());\n}",
        "summary_tokens": [
            "collect",
            "general",
            "runtime",
            "information"
        ]
    },
    {
        "id": 1805,
        "code": "private void onCommitCompleted(Throwable error, long seqno, Map<TopicPartition, OffsetAndMetadata> committedOffsets) {\n    if (commitSeqno != seqno) {\n        log.debug(\"{} Received out of order commit callback for sequence number {}, but most recent sequence number is {}\",\n                this, seqno, commitSeqno);\n        sinkTaskMetricsGroup.recordOffsetCommitSkip();\n    } else {\n        long durationMillis = time.milliseconds() - commitStarted;\n        if (error != null) {\n            log.error(\"{} Commit of offsets threw an unexpected exception for sequence number {}: {}\",\n                    this, seqno, committedOffsets, error);\n            commitFailures++;\n            recordCommitFailure(durationMillis, error);\n        } else {\n            log.debug(\"{} Finished offset commit successfully in {} ms for sequence number {}: {}\",\n                    this, durationMillis, seqno, committedOffsets);\n            if (committedOffsets != null) {\n                log.trace(\"{} Adding to last committed offsets: {}\", this, committedOffsets);\n                lastCommittedOffsets.putAll(committedOffsets);\n                log.debug(\"{} Last committed offsets are now {}\", this, committedOffsets);\n                sinkTaskMetricsGroup.recordCommittedOffsets(committedOffsets);\n            }\n            commitFailures = 0;\n            recordCommitSuccess(durationMillis);\n        }\n        committing = false;\n    }\n}",
        "summary_tokens": [
            "respond",
            "to",
            "a",
            "previous",
            "commit",
            "attempt",
            "that",
            "may",
            "or",
            "may",
            "not",
            "have",
            "succeeded"
        ]
    },
    {
        "id": 1806,
        "code": "protected void initializeAndStart() {\n    SinkConnectorConfig.validate(taskConfig);\n\n    if (SinkConnectorConfig.hasTopicsConfig(taskConfig)) {\n        List<String> topics = SinkConnectorConfig.parseTopicsList(taskConfig);\n        consumer.subscribe(topics, new HandleRebalance());\n        log.debug(\"{} Initializing and starting task for topics {}\", this, Utils.join(topics, \", \"));\n    } else {\n        String topicsRegexStr = taskConfig.get(SinkTask.TOPICS_REGEX_CONFIG);\n        Pattern pattern = Pattern.compile(topicsRegexStr);\n        consumer.subscribe(pattern, new HandleRebalance());\n        log.debug(\"{} Initializing and starting task for topics regex {}\", this, topicsRegexStr);\n    }\n\n    task.initialize(context);\n    task.start(taskConfig);\n    log.info(\"{} Sink task finished initialization and start\", this);\n}",
        "summary_tokens": [
            "initializes",
            "and",
            "starts",
            "the",
            "sink",
            "task"
        ]
    },
    {
        "id": 1807,
        "code": "protected void poll(long timeoutMs) {\n    rewind();\n    long retryTimeout = context.timeout();\n    if (retryTimeout > 0) {\n        timeoutMs = Math.min(timeoutMs, retryTimeout);\n        context.timeout(-1L);\n    }\n\n    log.trace(\"{} Polling consumer with timeout {} ms\", this, timeoutMs);\n    ConsumerRecords<byte[], byte[]> msgs = pollConsumer(timeoutMs);\n    assert messageBatch.isEmpty() || msgs.isEmpty();\n    log.trace(\"{} Polling returned {} messages\", this, msgs.count());\n\n    convertMessages(msgs);\n    deliverMessages();\n}",
        "summary_tokens": [
            "poll",
            "for",
            "new",
            "messages",
            "with",
            "the",
            "given",
            "timeout"
        ]
    },
    {
        "id": 1808,
        "code": "private void doCommit(Map<TopicPartition, OffsetAndMetadata> offsets, boolean closing, int seqno) {\n    if (closing) {\n        doCommitSync(offsets, seqno);\n    } else {\n        doCommitAsync(offsets, seqno);\n    }\n}",
        "summary_tokens": [
            "starts",
            "an",
            "offset",
            "commit",
            "by",
            "flushing",
            "outstanding",
            "messages",
            "from",
            "the",
            "task",
            "and",
            "then",
            "starting",
            "the",
            "write",
            "commit"
        ]
    },
    {
        "id": 1809,
        "code": "public Map<TopicPartition, Long> offsets() {\n    return offsets;\n}",
        "summary_tokens": [
            "get",
            "offsets",
            "that",
            "the",
            "sink",
            "task",
            "has",
            "submitted",
            "to",
            "be",
            "reset"
        ]
    },
    {
        "id": 1810,
        "code": "public long timeout() {\n    return timeoutMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "timeout",
            "in",
            "milliseconds",
            "set",
            "by",
            "sink",
            "tasks"
        ]
    },
    {
        "id": 1811,
        "code": "public void stop() {\n    triggerStop();\n}",
        "summary_tokens": [
            "stop",
            "this",
            "task",
            "from",
            "processing",
            "messages"
        ]
    },
    {
        "id": 1812,
        "code": "public boolean awaitStop(long timeoutMs) {\n    try {\n        return shutdownLatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        return false;\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "this",
            "task",
            "to",
            "finish",
            "stopping"
        ]
    },
    {
        "id": 1813,
        "code": "public void removeMetrics() {\n    taskMetricsGroup.close();\n}",
        "summary_tokens": [
            "remove",
            "all",
            "metrics",
            "published",
            "by",
            "this",
            "task"
        ]
    },
    {
        "id": 1814,
        "code": "protected void recordActiveTopic(String topic) {\n    if (statusBackingStore.getTopic(id.connector(), topic) != null) {\n            \n        return;\n    }\n    statusBackingStore.put(new TopicStatus(topic, id, time.milliseconds()));\n}",
        "summary_tokens": [
            "include",
            "this",
            "topic",
            "to",
            "the",
            "set",
            "of",
            "active",
            "topics",
            "for",
            "the",
            "connector",
            "that",
            "this",
            "worker",
            "task",
            "is",
            "running"
        ]
    },
    {
        "id": 1815,
        "code": "protected void recordCommitSuccess(long duration) {\n    taskMetricsGroup.recordCommit(duration, true, null);\n}",
        "summary_tokens": [
            "record",
            "that",
            "offsets",
            "have",
            "been",
            "committed"
        ]
    },
    {
        "id": 1816,
        "code": "protected void recordCommitFailure(long duration, Throwable error) {\n    taskMetricsGroup.recordCommit(duration, false, error);\n}",
        "summary_tokens": [
            "record",
            "that",
            "offsets",
            "have",
            "been",
            "committed"
        ]
    },
    {
        "id": 1817,
        "code": "protected void recordBatch(int size) {\n    taskMetricsGroup.recordBatch(size);\n}",
        "summary_tokens": [
            "record",
            "that",
            "a",
            "batch",
            "of",
            "records",
            "has",
            "been",
            "processed"
        ]
    },
    {
        "id": 1818,
        "code": "public static ByteBuffer serializeMetadata(WorkerState workerState) {\n    Struct struct = new Struct(CONFIG_STATE_V0);\n    struct.set(URL_KEY_NAME, workerState.url());\n    struct.set(CONFIG_OFFSET_KEY_NAME, workerState.offset());\n    ByteBuffer buffer = ByteBuffer.allocate(CONNECT_PROTOCOL_HEADER_V0.sizeOf() + CONFIG_STATE_V0.sizeOf(struct));\n    CONNECT_PROTOCOL_HEADER_V0.writeTo(buffer);\n    CONFIG_STATE_V0.write(buffer, struct);\n    buffer.flip();\n    return buffer;\n}",
        "summary_tokens": [
            "the",
            "fields",
            "are",
            "serialized",
            "in",
            "sequence",
            "as",
            "follows",
            "subscription",
            "v",
            "0",
            "pre",
            "version",
            "int",
            "0",
            "url",
            "string",
            "config",
            "offset",
            "int",
            "0",
            "pre"
        ]
    },
    {
        "id": 1819,
        "code": "public static JoinGroupRequestProtocolCollection metadataRequest(WorkerState workerState) {\n    return new JoinGroupRequestProtocolCollection(Collections.singleton(\n            new JoinGroupRequestProtocol()\n                    .setName(EAGER.protocol())\n                    .setMetadata(ConnectProtocol.serializeMetadata(workerState).array()))\n            .iterator());\n}",
        "summary_tokens": [
            "returns",
            "the",
            "collection",
            "of",
            "connect",
            "protocols",
            "that",
            "are",
            "supported",
            "by",
            "this",
            "version",
            "along",
            "with",
            "their",
            "serialized",
            "metadata"
        ]
    },
    {
        "id": 1820,
        "code": "public static WorkerState deserializeMetadata(ByteBuffer buffer) {\n    Struct header = CONNECT_PROTOCOL_HEADER_SCHEMA.read(buffer);\n    Short version = header.getShort(VERSION_KEY_NAME);\n    checkVersionCompatibility(version);\n    Struct struct = CONFIG_STATE_V0.read(buffer);\n    long configOffset = struct.getLong(CONFIG_OFFSET_KEY_NAME);\n    String url = struct.getString(URL_KEY_NAME);\n    return new WorkerState(url, configOffset);\n}",
        "summary_tokens": [
            "given",
            "a",
            "byte",
            "buffer",
            "that",
            "contains",
            "protocol",
            "metadata",
            "return",
            "the",
            "deserialized",
            "form",
            "of",
            "the",
            "metadata"
        ]
    },
    {
        "id": 1821,
        "code": "public static ByteBuffer serializeAssignment(Assignment assignment) {\n    Struct struct = new Struct(ASSIGNMENT_V0);\n    struct.set(ERROR_KEY_NAME, assignment.error());\n    struct.set(LEADER_KEY_NAME, assignment.leader());\n    struct.set(LEADER_URL_KEY_NAME, assignment.leaderUrl());\n    struct.set(CONFIG_OFFSET_KEY_NAME, assignment.offset());\n    List<Struct> taskAssignments = new ArrayList<>();\n    for (Map.Entry<String, Collection<Integer>> connectorEntry : assignment.asMap().entrySet()) {\n        Struct taskAssignment = new Struct(CONNECTOR_ASSIGNMENT_V0);\n        taskAssignment.set(CONNECTOR_KEY_NAME, connectorEntry.getKey());\n        Collection<Integer> tasks = connectorEntry.getValue();\n        taskAssignment.set(TASKS_KEY_NAME, tasks.toArray());\n        taskAssignments.add(taskAssignment);\n    }\n    struct.set(ASSIGNMENT_KEY_NAME, taskAssignments.toArray());\n\n    ByteBuffer buffer = ByteBuffer.allocate(CONNECT_PROTOCOL_HEADER_V0.sizeOf() + ASSIGNMENT_V0.sizeOf(struct));\n    CONNECT_PROTOCOL_HEADER_V0.writeTo(buffer);\n    ASSIGNMENT_V0.write(buffer, struct);\n    buffer.flip();\n    return buffer;\n}",
        "summary_tokens": [
            "the",
            "fields",
            "are",
            "serialized",
            "in",
            "sequence",
            "as",
            "follows",
            "complete",
            "assignment",
            "v",
            "0",
            "pre",
            "version",
            "int",
            "0",
            "error",
            "int",
            "0",
            "leader",
            "string",
            "leader",
            "url",
            "string",
            "config",
            "offset",
            "int",
            "0",
            "assignment",
            "connector",
            "assignment",
            "pre"
        ]
    },
    {
        "id": 1822,
        "code": "public static Assignment deserializeAssignment(ByteBuffer buffer) {\n    Struct header = CONNECT_PROTOCOL_HEADER_SCHEMA.read(buffer);\n    Short version = header.getShort(VERSION_KEY_NAME);\n    checkVersionCompatibility(version);\n    Struct struct = ASSIGNMENT_V0.read(buffer);\n    short error = struct.getShort(ERROR_KEY_NAME);\n    String leader = struct.getString(LEADER_KEY_NAME);\n    String leaderUrl = struct.getString(LEADER_URL_KEY_NAME);\n    long offset = struct.getLong(CONFIG_OFFSET_KEY_NAME);\n    List<String> connectorIds = new ArrayList<>();\n    List<ConnectorTaskId> taskIds = new ArrayList<>();\n    for (Object structObj : struct.getArray(ASSIGNMENT_KEY_NAME)) {\n        Struct assignment = (Struct) structObj;\n        String connector = assignment.getString(CONNECTOR_KEY_NAME);\n        for (Object taskIdObj : assignment.getArray(TASKS_KEY_NAME)) {\n            Integer taskId = (Integer) taskIdObj;\n            if (taskId == CONNECTOR_TASK)\n                connectorIds.add(connector);\n            else\n                taskIds.add(new ConnectorTaskId(connector, taskId));\n        }\n    }\n    return new Assignment(error, leader, leaderUrl, offset, connectorIds, taskIds);\n}",
        "summary_tokens": [
            "given",
            "a",
            "byte",
            "buffer",
            "that",
            "contains",
            "an",
            "assignment",
            "as",
            "defined",
            "by",
            "this",
            "protocol",
            "return",
            "the",
            "deserialized",
            "form",
            "of",
            "the",
            "assignment"
        ]
    },
    {
        "id": 1823,
        "code": "public boolean transactionalLeaderEnabled() {\n    return exactlyOnceSourceSupport.usesTransactionalLeader;\n}",
        "summary_tokens": [
            "whether",
            "the",
            "connect",
            "cluster",
            "s",
            "leader",
            "should",
            "use",
            "a",
            "transactional",
            "producer",
            "to",
            "perform",
            "writes",
            "to",
            "the",
            "config",
            "topic",
            "which",
            "is",
            "useful",
            "for",
            "ensuring",
            "that",
            "zombie",
            "leaders",
            "are",
            "fenced",
            "out",
            "and",
            "unable",
            "to",
            "write",
            "to",
            "the",
            "topic",
            "after",
            "a",
            "new",
            "leader",
            "has",
            "been",
            "elected"
        ]
    },
    {
        "id": 1824,
        "code": "public String transactionalProducerId() {\n    return transactionalProducerId(groupId());\n}",
        "summary_tokens": [
            "the",
            "producer",
            "config",
            "transactional",
            "id",
            "config",
            "transactional",
            "id",
            "to",
            "use",
            "for",
            "the",
            "worker",
            "s",
            "producer",
            "if",
            "using",
            "a",
            "transactional",
            "producer",
            "for",
            "writes",
            "to",
            "internal",
            "topics",
            "such",
            "as",
            "the",
            "config",
            "topic"
        ]
    },
    {
        "id": 1825,
        "code": "void processRestartRequests() {\n    List<RestartRequest> restartRequests;\n    synchronized (this) {\n        if (pendingRestartRequests.isEmpty()) {\n            return;\n        }\n            \n        restartRequests = new ArrayList<>(pendingRestartRequests.values());\n        pendingRestartRequests.clear();\n    }\n    restartRequests.forEach(restartRequest -> {\n        try {\n            doRestartConnectorAndTasks(restartRequest);\n        } catch (Exception e) {\n            log.warn(\"Unexpected error while trying to process \" + restartRequest + \", the restart request will be skipped.\", e);\n        }\n    });\n}",
        "summary_tokens": [
            "process",
            "all",
            "pending",
            "restart",
            "requests"
        ]
    },
    {
        "id": 1826,
        "code": "protected synchronized void doRestartConnectorAndTasks(RestartRequest request) {\n    String connectorName = request.connectorName();\n    Optional<RestartPlan> maybePlan = buildRestartPlan(request);\n    if (!maybePlan.isPresent()) {\n        log.debug(\"Skipping restart of connector '{}' since no status is available: {}\", connectorName, request);\n        return;\n    }\n    RestartPlan plan = maybePlan.get();\n    log.info(\"Executing {}\", plan);\n\n        \n    final ExtendedAssignment currentAssignments = assignment;\n    final Collection<ConnectorTaskId> assignedIdsToRestart = plan.taskIdsToRestart()\n            .stream()\n            .filter(taskId -> currentAssignments.tasks().contains(taskId))\n            .collect(Collectors.toList());\n    final boolean restartConnector = plan.shouldRestartConnector() && currentAssignments.connectors().contains(connectorName);\n    final boolean restartTasks = !assignedIdsToRestart.isEmpty();\n    if (restartConnector) {\n        worker.stopAndAwaitConnector(connectorName);\n        onRestart(connectorName);\n    }\n    if (restartTasks) {\n            \n        worker.stopAndAwaitTasks(assignedIdsToRestart);\n        assignedIdsToRestart.forEach(this::onRestart);\n    }\n\n        \n    if (restartConnector) {\n        try {\n            startConnector(connectorName, (error, targetState) -> {\n                if (error == null) {\n                    log.info(\"Connector '{}' restart successful\", connectorName);\n                } else {\n                    log.error(\"Connector '{}' restart failed\", connectorName, error);\n                }\n            });\n        } catch (Throwable t) {\n            log.error(\"Connector '{}' restart failed\", connectorName, t);\n        }\n    }\n    if (restartTasks) {\n        log.debug(\"Restarting {} of {} tasks for {}\", assignedIdsToRestart.size(), plan.totalTaskCount(), request);\n        assignedIdsToRestart.forEach(taskId -> {\n            try {\n                if (startTask(taskId)) {\n                    log.info(\"Task '{}' restart successful\", taskId);\n                } else {\n                    log.error(\"Task '{}' restart failed\", taskId);\n                }\n            } catch (Throwable t) {\n                log.error(\"Task '{}' restart failed\", taskId, t);\n            }\n        });\n        log.debug(\"Restarted {} of {} tasks for {} as requested\", assignedIdsToRestart.size(), plan.totalTaskCount(), request);\n    }\n    log.info(\"Completed {}\", plan);\n}",
        "summary_tokens": [
            "builds",
            "and",
            "executes",
            "a",
            "restart",
            "plan",
            "for",
            "the",
            "connector",
            "and",
            "its",
            "tasks",
            "from",
            "code",
            "request",
            "code"
        ]
    },
    {
        "id": 1827,
        "code": "private String leaderUrl() {\n    if (assignment == null)\n        return null;\n    return assignment.leaderUrl();\n}",
        "summary_tokens": [
            "get",
            "the",
            "url",
            "for",
            "the",
            "leader",
            "s",
            "rest",
            "interface",
            "or",
            "null",
            "if",
            "we",
            "do",
            "not",
            "have",
            "the",
            "leader",
            "s",
            "url",
            "yet"
        ]
    },
    {
        "id": 1828,
        "code": "private void writeToConfigTopicAsLeader(Runnable write) {\n    try {\n        write.run();\n    } catch (PrivilegedWriteException e) {\n        log.warn(\"Failed to write to config topic as leader; will rejoin group if necessary and, if still leader, attempt to reclaim write privileges for the config topic\", e);\n        fencedFromConfigTopic = true;\n        throw new ConnectException(\"Failed to write to config topic; this may be due to a transient error and the request can be safely retried\", e);\n    }\n}",
        "summary_tokens": [
            "perform",
            "an",
            "action",
            "that",
            "writes",
            "to",
            "the",
            "config",
            "topic",
            "and",
            "if",
            "it",
            "fails",
            "because",
            "the",
            "leader",
            "has",
            "been",
            "fenced",
            "out",
            "make",
            "note",
            "of",
            "that",
            "fact",
            "so",
            "that",
            "we",
            "can",
            "try",
            "to",
            "reclaim",
            "write",
            "ownership",
            "if",
            "still",
            "the",
            "leader",
            "of",
            "the",
            "cluster",
            "in",
            "a",
            "subsequent",
            "iteration",
            "of",
            "the",
            "tick",
            "loop"
        ]
    },
    {
        "id": 1829,
        "code": "private boolean handleRebalanceCompleted() {\n    if (rebalanceResolved) {\n        log.trace(\"Returning early because rebalance is marked as resolved (rebalanceResolved: true)\");\n        return true;\n    }\n    log.debug(\"Handling completed but unresolved rebalance\");\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n\n    boolean needsReadToEnd = false;\n    boolean needsRejoin = false;\n    if (assignment.failed()) {\n        needsRejoin = true;\n        if (isLeader()) {\n            log.warn(\"Join group completed, but assignment failed and we are the leader. Reading to end of config and retrying.\");\n            needsReadToEnd = true;\n        } else if (configState.offset() < assignment.offset()) {\n            log.warn(\"Join group completed, but assignment failed and we lagging. Reading to end of config and retrying.\");\n            needsReadToEnd = true;\n        } else {\n            log.warn(\"Join group completed, but assignment failed. We were up to date, so just retrying.\");\n        }\n    } else {\n        if (configState.offset() < assignment.offset()) {\n            log.warn(\"Catching up to assignment's config offset.\");\n            needsReadToEnd = true;\n        }\n    }\n\n    long now = time.milliseconds();\n    if (scheduledRebalance <= now) {\n        log.debug(\"Requesting rebalance because scheduled rebalance timeout has been reached \"\n                + \"(now: {} scheduledRebalance: {}\", scheduledRebalance, now);\n\n        needsRejoin = true;\n        scheduledRebalance = Long.MAX_VALUE;\n    }\n\n    if (needsReadToEnd) {\n            \n            \n            \n            \n        if (readConfigToEnd(workerSyncTimeoutMs)) {\n            canReadConfigs = true;\n        } else {\n            canReadConfigs = false;\n            needsRejoin = true;\n        }\n    }\n\n    if (needsRejoin) {\n        member.requestRejoin();\n        return false;\n    }\n\n        \n        \n    if (configState.offset() != assignment.offset()) {\n        log.info(\"Current config state offset {} does not match group assignment {}. Forcing rebalance.\", configState.offset(), assignment.offset());\n        member.requestRejoin();\n        return false;\n    }\n\n    startWork();\n\n        \n        \n        \n    herderMetrics.rebalanceSucceeded(time.milliseconds());\n    rebalanceResolved = true;\n\n    if (!assignment.revokedConnectors().isEmpty() || !assignment.revokedTasks().isEmpty()) {\n        assignment.revokedConnectors().clear();\n        assignment.revokedTasks().clear();\n        member.requestRejoin();\n        return false;\n    }\n    return true;\n}",
        "summary_tokens": [
            "handle",
            "post",
            "assignment",
            "operations",
            "either",
            "trying",
            "to",
            "resolve",
            "issues",
            "that",
            "kept",
            "assignment",
            "from",
            "completing",
            "getting",
            "this",
            "node",
            "into",
            "sync",
            "and",
            "its",
            "work",
            "started"
        ]
    },
    {
        "id": 1830,
        "code": "private boolean readConfigToEnd(long timeoutMs) {\n    if (configState.offset() < assignment.offset()) {\n        log.info(\"Current config state offset {} is behind group assignment {}, reading to end of config log\", configState.offset(), assignment.offset());\n    } else {\n        log.info(\"Reading to end of config log; current config state offset: {}\", configState.offset());\n    }\n    if (refreshConfigSnapshot(timeoutMs)) {\n        backoffRetries = BACKOFF_RETRIES;\n        return true;\n    } else {\n            \n            \n        member.maybeLeaveGroup(\"taking too long to read the log\");\n        backoff(workerUnsyncBackoffMs);\n        return false;\n    }\n}",
        "summary_tokens": [
            "try",
            "to",
            "read",
            "to",
            "the",
            "end",
            "of",
            "the",
            "config",
            "log",
            "within",
            "the",
            "given",
            "timeout"
        ]
    },
    {
        "id": 1831,
        "code": "private boolean refreshConfigSnapshot(long timeoutMs) {\n    try {\n        configBackingStore.refresh(timeoutMs, TimeUnit.MILLISECONDS);\n        configState = configBackingStore.snapshot();\n        log.info(\"Finished reading to end of log and updated config snapshot, new config log offset: {}\", configState.offset());\n        return true;\n    } catch (TimeoutException e) {\n        log.warn(\"Didn't reach end of config log quickly enough\", e);\n        canReadConfigs = false;\n        return false;\n    }\n}",
        "summary_tokens": [
            "try",
            "to",
            "read",
            "to",
            "the",
            "end",
            "of",
            "the",
            "config",
            "log",
            "within",
            "the",
            "given",
            "timeout",
            "timeout",
            "ms",
            "maximum",
            "time",
            "to",
            "wait",
            "to",
            "sync",
            "to",
            "the",
            "end",
            "of",
            "the",
            "log",
            "true",
            "if",
            "successful",
            "false",
            "if",
            "timed",
            "out"
        ]
    },
    {
        "id": 1832,
        "code": "DistributedHerderRequest runOnTickThread(Callable<Void> action, Callback<Void> callback) {\n    if (Thread.currentThread().equals(herderThread)) {\n        runRequest(action, callback);\n        return null;\n    } else {\n        return addRequest(action, callback);\n    }\n}",
        "summary_tokens": [
            "execute",
            "the",
            "given",
            "action",
            "and",
            "subsequent",
            "callback",
            "immediately",
            "if",
            "the",
            "current",
            "thread",
            "is",
            "the",
            "herder",
            "s",
            "tick",
            "thread",
            "or",
            "use",
            "them",
            "to",
            "create",
            "and",
            "store",
            "a",
            "distributed",
            "herder",
            "request",
            "on",
            "the",
            "request",
            "queue",
            "and",
            "return",
            "the",
            "resulting",
            "request",
            "if",
            "not"
        ]
    },
    {
        "id": 1833,
        "code": "private boolean requestNotSignedProperly(InternalRequestSignature requestSignature, Callback<?> callback) {\n    if (internalRequestValidationEnabled()) {\n        ConnectRestException requestValidationError = null;\n        if (requestSignature == null) {\n            requestValidationError = new BadRequestException(\"Internal request missing required signature\");\n        } else if (!keySignatureVerificationAlgorithms.contains(requestSignature.keyAlgorithm())) {\n            requestValidationError = new BadRequestException(String.format(\n                    \"This worker does not support the '%s' key signing algorithm used by other workers. \"\n                            + \"This worker is currently configured to use: %s. \"\n                            + \"Check that all workers' configuration files permit the same set of signature algorithms, \"\n                            + \"and correct any misconfigured worker and restart it.\",\n                    requestSignature.keyAlgorithm(),\n                    keySignatureVerificationAlgorithms\n            ));\n        } else {\n            if (!requestSignature.isValid(sessionKey)) {\n                requestValidationError = new ConnectRestException(\n                        Response.Status.FORBIDDEN,\n                        \"Internal request contained invalid signature.\"\n                );\n            }\n        }\n        if (requestValidationError != null) {\n            callback.onCompletion(requestValidationError, null);\n            return true;\n        }\n    }\n\n    return false;\n}",
        "summary_tokens": [
            "checks",
            "a",
            "given",
            "internal",
            "request",
            "signature",
            "request",
            "signature",
            "for",
            "validity",
            "and",
            "adds",
            "an",
            "exception",
            "to",
            "the",
            "given",
            "callback",
            "if",
            "any",
            "errors",
            "are",
            "found"
        ]
    },
    {
        "id": 1834,
        "code": "public short version() {\n    return version;\n}",
        "summary_tokens": [
            "return",
            "the",
            "version",
            "of",
            "the",
            "connect",
            "protocol",
            "that",
            "this",
            "assignment",
            "belongs",
            "to"
        ]
    },
    {
        "id": 1835,
        "code": "public Collection<String> revokedConnectors() {\n    return revokedConnectorIds;\n}",
        "summary_tokens": [
            "return",
            "the",
            "ids",
            "of",
            "the",
            "connectors",
            "that",
            "are",
            "revoked",
            "by",
            "this",
            "assignment"
        ]
    },
    {
        "id": 1836,
        "code": "public Collection<ConnectorTaskId> revokedTasks() {\n    return revokedTaskIds;\n}",
        "summary_tokens": [
            "return",
            "the",
            "ids",
            "of",
            "the",
            "tasks",
            "that",
            "are",
            "revoked",
            "by",
            "this",
            "assignment"
        ]
    },
    {
        "id": 1837,
        "code": "public int delay() {\n    return delay;\n}",
        "summary_tokens": [
            "return",
            "the",
            "delay",
            "for",
            "the",
            "rebalance",
            "that",
            "is",
            "scheduled",
            "by",
            "this",
            "assignment"
        ]
    },
    {
        "id": 1838,
        "code": "public static ExtendedAssignment empty() {\n    return EMPTY;\n}",
        "summary_tokens": [
            "return",
            "an",
            "empty",
            "assignment"
        ]
    },
    {
        "id": 1839,
        "code": "public Struct toStruct() {\n    Collection<Struct> assigned = taskAssignments(asMap());\n    Collection<Struct> revoked = taskAssignments(revokedAsMap());\n    return new Struct(ASSIGNMENT_V1)\n            .set(ERROR_KEY_NAME, error())\n            .set(LEADER_KEY_NAME, leader())\n            .set(LEADER_URL_KEY_NAME, leaderUrl())\n            .set(CONFIG_OFFSET_KEY_NAME, offset())\n            .set(ASSIGNMENT_KEY_NAME, assigned != null ? assigned.toArray() : null)\n            .set(REVOKED_KEY_NAME, revoked != null ? revoked.toArray() : null)\n            .set(SCHEDULED_DELAY_KEY_NAME, delay);\n}",
        "summary_tokens": [
            "return",
            "the",
            "struct",
            "that",
            "corresponds",
            "to",
            "this",
            "assignment"
        ]
    },
    {
        "id": 1840,
        "code": "public static ExtendedAssignment fromStruct(short version, Struct struct) {\n    return struct == null\n           ? null\n           : new ExtendedAssignment(\n                   version,\n                   struct.getShort(ERROR_KEY_NAME),\n                   struct.getString(LEADER_KEY_NAME),\n                   struct.getString(LEADER_URL_KEY_NAME),\n                   struct.getLong(CONFIG_OFFSET_KEY_NAME),\n                   extractConnectors(struct, ASSIGNMENT_KEY_NAME),\n                   extractTasks(struct, ASSIGNMENT_KEY_NAME),\n                   extractConnectors(struct, REVOKED_KEY_NAME),\n                   extractTasks(struct, REVOKED_KEY_NAME),\n                   struct.getInt(SCHEDULED_DELAY_KEY_NAME));\n}",
        "summary_tokens": [
            "given",
            "a",
            "struct",
            "that",
            "encodes",
            "an",
            "assignment",
            "return",
            "the",
            "assignment",
            "object"
        ]
    },
    {
        "id": 1841,
        "code": "public ExtendedAssignment assignment() {\n    return assignment;\n}",
        "summary_tokens": [
            "this",
            "method",
            "returns",
            "which",
            "was",
            "the",
            "assignment",
            "of",
            "connectors",
            "and",
            "tasks",
            "on",
            "a",
            "worker",
            "at",
            "the",
            "moment",
            "that",
            "its",
            "state",
            "was",
            "captured",
            "by",
            "this",
            "class"
        ]
    },
    {
        "id": 1842,
        "code": "protected Map<String, ByteBuffer> performTaskAssignment(String leaderId, long maxOffset,\n                                                        Map<String, ExtendedWorkerState> memberConfigs,\n                                                        WorkerCoordinator coordinator, short protocolVersion) {\n    log.debug(\"Performing task assignment during generation: {} with memberId: {}\",\n            coordinator.generationId(), coordinator.memberId());\n    Map<String, ConnectorsAndTasks> memberAssignments = transformValues(\n            memberConfigs,\n            memberConfig -> new ConnectorsAndTasks.Builder()\n                    .with(memberConfig.assignment().connectors(), memberConfig.assignment().tasks())\n                    .build()\n    );\n    ClusterAssignment clusterAssignment = performTaskAssignment(\n            coordinator.configSnapshot(),\n            coordinator.lastCompletedGenerationId(),\n            coordinator.generationId(),\n            memberAssignments\n    );\n\n    coordinator.leaderState(new LeaderState(memberConfigs, clusterAssignment.allAssignedConnectors(), clusterAssignment.allAssignedTasks()));\n\n    Map<String, ExtendedAssignment> assignments =\n            fillAssignments(memberConfigs.keySet(), Assignment.NO_ERROR, leaderId,\n                    memberConfigs.get(leaderId).url(), maxOffset,\n                    clusterAssignment,\n                    delay, protocolVersion);\n\n    log.debug(\"Actual assignments: {}\", assignments);\n    return serializeAssignments(assignments, protocolVersion);\n}",
        "summary_tokens": [
            "performs",
            "task",
            "assignment",
            "based",
            "on",
            "the",
            "incremental",
            "cooperative",
            "connect",
            "protocol"
        ]
    },
    {
        "id": 1843,
        "code": "private Map<String, ConnectorsAndTasks> performTaskRevocation(ConnectorsAndTasks activeAssignments,\n                                                              Collection<WorkerLoad> completeWorkerAssignment) {\n    int totalActiveConnectorsNum = activeAssignments.connectors().size();\n    int totalActiveTasksNum = activeAssignments.tasks().size();\n    Collection<WorkerLoad> existingWorkers = completeWorkerAssignment.stream()\n            .filter(wl -> wl.size() > 0)\n            .collect(Collectors.toList());\n    int existingWorkersNum = existingWorkers.size();\n    int totalWorkersNum = completeWorkerAssignment.size();\n    int newWorkersNum = totalWorkersNum - existingWorkersNum;\n\n    if (log.isDebugEnabled()) {\n        completeWorkerAssignment.forEach(wl -> log.debug(\n                \"Per worker current load size; worker: {} connectors: {} tasks: {}\",\n                wl.worker(), wl.connectorsSize(), wl.tasksSize()));\n    }\n\n    Map<String, ConnectorsAndTasks> revoking = new HashMap<>();\n        \n        \n    if (!(newWorkersNum > 0 && existingWorkersNum > 0)) {\n        log.debug(\"No task revocation required; workers with existing load: {} workers with \"\n                + \"no load {} total workers {}\",\n                existingWorkersNum, newWorkersNum, totalWorkersNum);\n            \n            \n        return revoking;\n    }\n\n    log.debug(\"Task revocation is required; workers with existing load: {} workers with \"\n            + \"no load {} total workers {}\",\n            existingWorkersNum, newWorkersNum, totalWorkersNum);\n\n        \n    log.debug(\"Previous rounded down (floor) average number of connectors per worker {}\", totalActiveConnectorsNum / existingWorkersNum);\n    int floorConnectors = totalActiveConnectorsNum / totalWorkersNum;\n    int ceilConnectors = floorConnectors + ((totalActiveConnectorsNum % totalWorkersNum == 0) ? 0 : 1);\n    log.debug(\"New average number of connectors per worker rounded down (floor) {} and rounded up (ceil) {}\", floorConnectors, ceilConnectors);\n\n\n    log.debug(\"Previous rounded down (floor) average number of tasks per worker {}\", totalActiveTasksNum / existingWorkersNum);\n    int floorTasks = totalActiveTasksNum / totalWorkersNum;\n    int ceilTasks = floorTasks + ((totalActiveTasksNum % totalWorkersNum == 0) ? 0 : 1);\n    log.debug(\"New average number of tasks per worker rounded down (floor) {} and rounded up (ceil) {}\", floorTasks, ceilTasks);\n    int numToRevoke;\n\n    for (WorkerLoad existing : existingWorkers) {\n        Iterator<String> connectors = existing.connectors().iterator();\n        numToRevoke = existing.connectorsSize() - ceilConnectors;\n        for (int i = existing.connectorsSize(); i > floorConnectors && numToRevoke > 0; --i, --numToRevoke) {\n            ConnectorsAndTasks resources = revoking.computeIfAbsent(\n                existing.worker(),\n                w -> new ConnectorsAndTasks.Builder().build());\n            resources.connectors().add(connectors.next());\n        }\n    }\n\n    for (WorkerLoad existing : existingWorkers) {\n        Iterator<ConnectorTaskId> tasks = existing.tasks().iterator();\n        numToRevoke = existing.tasksSize() - ceilTasks;\n        log.debug(\"Tasks on worker {} is higher than ceiling, so revoking {} tasks\", existing, numToRevoke);\n        for (int i = existing.tasksSize(); i > floorTasks && numToRevoke > 0; --i, --numToRevoke) {\n            ConnectorsAndTasks resources = revoking.computeIfAbsent(\n                existing.worker(),\n                w -> new ConnectorsAndTasks.Builder().build());\n            resources.tasks().add(tasks.next());\n        }\n    }\n\n    return revoking;\n}",
        "summary_tokens": [
            "task",
            "revocation",
            "is",
            "based",
            "on",
            "a",
            "rough",
            "estimation",
            "of",
            "the",
            "lower",
            "average",
            "number",
            "of",
            "tasks",
            "before",
            "and",
            "after",
            "new",
            "workers",
            "join",
            "the",
            "group"
        ]
    },
    {
        "id": 1844,
        "code": "protected Map<String, ByteBuffer> serializeAssignments(Map<String, ExtendedAssignment> assignments, short protocolVersion) {\n    boolean sessioned = protocolVersion >= CONNECT_PROTOCOL_V2;\n    return assignments.entrySet()\n            .stream()\n            .collect(Collectors.toMap(\n                Map.Entry::getKey,\n                e -> IncrementalCooperativeConnectProtocol.serializeAssignment(e.getValue(), sessioned)));\n}",
        "summary_tokens": [
            "from",
            "a",
            "map",
            "of",
            "workers",
            "to",
            "assignment",
            "object",
            "generate",
            "the",
            "equivalent",
            "map",
            "of",
            "workers",
            "to",
            "byte",
            "buffers",
            "of",
            "serialized",
            "assignments"
        ]
    },
    {
        "id": 1845,
        "code": "protected void assignConnectors(List<WorkerLoad> workerAssignment, Collection<String> connectors) {\n    workerAssignment.sort(WorkerLoad.connectorComparator());\n    WorkerLoad first = workerAssignment.get(0);\n\n    Iterator<String> load = connectors.iterator();\n    while (load.hasNext()) {\n        int firstLoad = first.connectorsSize();\n        int upTo = IntStream.range(0, workerAssignment.size())\n                .filter(i -> workerAssignment.get(i).connectorsSize() > firstLoad)\n                .findFirst()\n                .orElse(workerAssignment.size());\n        for (WorkerLoad worker : workerAssignment.subList(0, upTo)) {\n            String connector = load.next();\n            log.debug(\"Assigning connector {} to {}\", connector, worker.worker());\n            worker.assign(connector);\n            if (!load.hasNext()) {\n                break;\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "perform",
            "a",
            "round",
            "robin",
            "assignment",
            "of",
            "connectors",
            "to",
            "workers",
            "with",
            "existing",
            "worker",
            "load"
        ]
    },
    {
        "id": 1846,
        "code": "protected void assignTasks(List<WorkerLoad> workerAssignment, Collection<ConnectorTaskId> tasks) {\n    workerAssignment.sort(WorkerLoad.taskComparator());\n    WorkerLoad first = workerAssignment.get(0);\n\n    Iterator<ConnectorTaskId> load = tasks.iterator();\n    while (load.hasNext()) {\n        int firstLoad = first.tasksSize();\n        int upTo = IntStream.range(0, workerAssignment.size())\n                .filter(i -> workerAssignment.get(i).tasksSize() > firstLoad)\n                .findFirst()\n                .orElse(workerAssignment.size());\n        for (WorkerLoad worker : workerAssignment.subList(0, upTo)) {\n            ConnectorTaskId task = load.next();\n            log.debug(\"Assigning task {} to {}\", task, worker.worker());\n            worker.assign(task);\n            if (!load.hasNext()) {\n                break;\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "perform",
            "a",
            "round",
            "robin",
            "assignment",
            "of",
            "tasks",
            "to",
            "workers",
            "with",
            "existing",
            "worker",
            "load"
        ]
    },
    {
        "id": 1847,
        "code": "public static ByteBuffer serializeMetadata(ExtendedWorkerState workerState, boolean sessioned) {\n    Struct configState = new Struct(CONFIG_STATE_V1)\n            .set(URL_KEY_NAME, workerState.url())\n            .set(CONFIG_OFFSET_KEY_NAME, workerState.offset());\n        \n    Struct allocation = new Struct(ALLOCATION_V1)\n            .set(ALLOCATION_KEY_NAME, serializeAssignment(workerState.assignment(), sessioned));\n    Struct connectProtocolHeader = sessioned ? CONNECT_PROTOCOL_HEADER_V2 : CONNECT_PROTOCOL_HEADER_V1;\n    ByteBuffer buffer = ByteBuffer.allocate(connectProtocolHeader.sizeOf()\n                                            + CONFIG_STATE_V1.sizeOf(configState)\n                                            + ALLOCATION_V1.sizeOf(allocation));\n    connectProtocolHeader.writeTo(buffer);\n    CONFIG_STATE_V1.write(buffer, configState);\n    ALLOCATION_V1.write(buffer, allocation);\n    buffer.flip();\n    return buffer;\n}",
        "summary_tokens": [
            "the",
            "fields",
            "are",
            "serialized",
            "in",
            "sequence",
            "as",
            "follows",
            "subscription",
            "v",
            "0",
            "pre",
            "version",
            "int",
            "0",
            "url",
            "string",
            "config",
            "offset",
            "int",
            "0",
            "current",
            "assignment",
            "byte",
            "pre"
        ]
    },
    {
        "id": 1848,
        "code": "public static JoinGroupRequestProtocolCollection metadataRequest(ExtendedWorkerState workerState, boolean sessioned) {\n        \n    List<JoinGroupRequestProtocol> joinGroupRequestProtocols = new ArrayList<>();\n    if (sessioned) {\n        joinGroupRequestProtocols.add(new JoinGroupRequestProtocol()\n            .setName(SESSIONED.protocol())\n            .setMetadata(IncrementalCooperativeConnectProtocol.serializeMetadata(workerState, true).array())\n        );\n    }\n    joinGroupRequestProtocols.add(new JoinGroupRequestProtocol()\n                    .setName(COMPATIBLE.protocol())\n                    .setMetadata(IncrementalCooperativeConnectProtocol.serializeMetadata(workerState, false).array())\n    );\n    joinGroupRequestProtocols.add(new JoinGroupRequestProtocol()\n                    .setName(EAGER.protocol())\n                    .setMetadata(ConnectProtocol.serializeMetadata(workerState).array())\n    );\n    return new JoinGroupRequestProtocolCollection(joinGroupRequestProtocols.iterator());\n}",
        "summary_tokens": [
            "returns",
            "the",
            "collection",
            "of",
            "connect",
            "protocols",
            "that",
            "are",
            "supported",
            "by",
            "this",
            "version",
            "along",
            "with",
            "their",
            "serialized",
            "metadata"
        ]
    },
    {
        "id": 1849,
        "code": "public static ExtendedWorkerState deserializeMetadata(ByteBuffer buffer) {\n    Struct header = CONNECT_PROTOCOL_HEADER_SCHEMA.read(buffer);\n    Short version = header.getShort(VERSION_KEY_NAME);\n    checkVersionCompatibility(version);\n    Struct configState = CONFIG_STATE_V1.read(buffer);\n    long configOffset = configState.getLong(CONFIG_OFFSET_KEY_NAME);\n    String url = configState.getString(URL_KEY_NAME);\n    Struct allocation = ALLOCATION_V1.read(buffer);\n        \n    ExtendedAssignment assignment = deserializeAssignment(allocation.getBytes(ALLOCATION_KEY_NAME));\n    return new ExtendedWorkerState(url, configOffset, assignment);\n}",
        "summary_tokens": [
            "given",
            "a",
            "byte",
            "buffer",
            "that",
            "contains",
            "protocol",
            "metadata",
            "return",
            "the",
            "deserialized",
            "form",
            "of",
            "the",
            "metadata"
        ]
    },
    {
        "id": 1850,
        "code": "public static ByteBuffer serializeAssignment(ExtendedAssignment assignment, boolean sessioned) {\n        \n    if (assignment == null || ExtendedAssignment.empty().equals(assignment)) {\n        return null;\n    }\n    Struct struct = assignment.toStruct();\n    Struct protocolHeader = sessioned ? CONNECT_PROTOCOL_HEADER_V2 : CONNECT_PROTOCOL_HEADER_V1;\n    ByteBuffer buffer = ByteBuffer.allocate(protocolHeader.sizeOf()\n                                            + ASSIGNMENT_V1.sizeOf(struct));\n    protocolHeader.writeTo(buffer);\n    ASSIGNMENT_V1.write(buffer, struct);\n    buffer.flip();\n    return buffer;\n}",
        "summary_tokens": [
            "the",
            "fields",
            "are",
            "serialized",
            "in",
            "sequence",
            "as",
            "follows",
            "complete",
            "assignment",
            "v",
            "0",
            "pre",
            "version",
            "int",
            "0",
            "error",
            "int",
            "0",
            "leader",
            "string",
            "leader",
            "url",
            "string",
            "config",
            "offset",
            "int",
            "0",
            "assignment",
            "connector",
            "assignment",
            "revoked",
            "connector",
            "assignment",
            "scheduled",
            "delay",
            "int",
            "0",
            "pre"
        ]
    },
    {
        "id": 1851,
        "code": "public static ExtendedAssignment deserializeAssignment(ByteBuffer buffer) {\n    if (buffer == null) {\n        return null;\n    }\n    Struct header = CONNECT_PROTOCOL_HEADER_SCHEMA.read(buffer);\n    Short version = header.getShort(VERSION_KEY_NAME);\n    checkVersionCompatibility(version);\n    Struct struct = ASSIGNMENT_V1.read(buffer);\n    return ExtendedAssignment.fromStruct(version, struct);\n}",
        "summary_tokens": [
            "given",
            "a",
            "byte",
            "buffer",
            "that",
            "contains",
            "an",
            "assignment",
            "as",
            "defined",
            "by",
            "this",
            "protocol",
            "return",
            "the",
            "deserialized",
            "form",
            "of",
            "the",
            "assignment"
        ]
    },
    {
        "id": 1852,
        "code": "public int generationId() {\n    return super.generation().generationId;\n}",
        "summary_tokens": [
            "return",
            "the",
            "current",
            "generation"
        ]
    },
    {
        "id": 1853,
        "code": "public int lastCompletedGenerationId() {\n    return lastCompletedGenerationId;\n}",
        "summary_tokens": [
            "return",
            "id",
            "that",
            "corresponds",
            "to",
            "the",
            "group",
            "generation",
            "that",
            "was",
            "active",
            "when",
            "the",
            "last",
            "join",
            "was",
            "successful"
        ]
    },
    {
        "id": 1854,
        "code": "public ClusterConfigState configFreshSnapshot() {\n    return configStorage.snapshot();\n}",
        "summary_tokens": [
            "get",
            "an",
            "up",
            "to",
            "date",
            "snapshot",
            "of",
            "the",
            "cluster",
            "configuration"
        ]
    },
    {
        "id": 1855,
        "code": "public void configSnapshot(ClusterConfigState update) {\n    configSnapshot = update;\n}",
        "summary_tokens": [
            "set",
            "the",
            "state",
            "of",
            "the",
            "cluster",
            "configuration",
            "to",
            "this",
            "worker",
            "coordinator"
        ]
    },
    {
        "id": 1856,
        "code": "public void leaderState(LeaderState update) {\n    leaderState = update;\n}",
        "summary_tokens": [
            "store",
            "the",
            "leader",
            "state",
            "to",
            "this",
            "worker",
            "coordinator"
        ]
    },
    {
        "id": 1857,
        "code": "public short currentProtocolVersion() {\n    return currentConnectProtocol.protocolVersion();\n}",
        "summary_tokens": [
            "get",
            "the",
            "version",
            "of",
            "the",
            "connect",
            "protocol",
            "that",
            "is",
            "currently",
            "active",
            "in",
            "the",
            "group",
            "of",
            "workers"
        ]
    },
    {
        "id": 1858,
        "code": "public void ensureActive() {\n    coordinator.poll(0);\n}",
        "summary_tokens": [
            "ensure",
            "that",
            "the",
            "connection",
            "to",
            "the",
            "broker",
            "coordinator",
            "is",
            "up",
            "and",
            "that",
            "the",
            "worker",
            "is",
            "an",
            "active",
            "member",
            "of",
            "the",
            "group"
        ]
    },
    {
        "id": 1859,
        "code": "public void wakeup() {\n    this.client.wakeup();\n}",
        "summary_tokens": [
            "interrupt",
            "any",
            "running",
            "poll",
            "calls",
            "causing",
            "a",
            "wakeup",
            "exception",
            "to",
            "be",
            "thrown",
            "in",
            "the",
            "thread",
            "invoking",
            "that",
            "method"
        ]
    },
    {
        "id": 1860,
        "code": "public String memberId() {\n    return coordinator.memberId();\n}",
        "summary_tokens": [
            "get",
            "the",
            "member",
            "id",
            "of",
            "this",
            "worker",
            "in",
            "the",
            "group",
            "of",
            "workers"
        ]
    },
    {
        "id": 1861,
        "code": "public short currentProtocolVersion() {\n    return coordinator.currentProtocolVersion();\n}",
        "summary_tokens": [
            "get",
            "the",
            "version",
            "of",
            "the",
            "connect",
            "protocol",
            "that",
            "is",
            "currently",
            "active",
            "in",
            "the",
            "group",
            "of",
            "workers"
        ]
    },
    {
        "id": 1862,
        "code": "public Future<RecordMetadata> report(ProcessingContext context) {\n    if (dlqTopicName.isEmpty()) {\n        return CompletableFuture.completedFuture(null);\n    }\n    errorHandlingMetrics.recordDeadLetterQueueProduceRequest();\n\n    ConsumerRecord<byte[], byte[]> originalMessage = context.consumerRecord();\n    if (originalMessage == null) {\n        errorHandlingMetrics.recordDeadLetterQueueProduceFailed();\n        return CompletableFuture.completedFuture(null);\n    }\n\n    ProducerRecord<byte[], byte[]> producerRecord;\n    if (originalMessage.timestamp() == RecordBatch.NO_TIMESTAMP) {\n        producerRecord = new ProducerRecord<>(dlqTopicName, null,\n                originalMessage.key(), originalMessage.value(), originalMessage.headers());\n    } else {\n        producerRecord = new ProducerRecord<>(dlqTopicName, null, originalMessage.timestamp(),\n                originalMessage.key(), originalMessage.value(), originalMessage.headers());\n    }\n\n    if (connConfig.isDlqContextHeadersEnabled()) {\n        populateContextHeaders(producerRecord, context);\n    }\n\n    return this.kafkaProducer.send(producerRecord, (metadata, exception) -> {\n        if (exception != null) {\n            log.error(\"Could not produce message to dead letter queue. topic=\" + dlqTopicName, exception);\n            errorHandlingMetrics.recordDeadLetterQueueProduceFailed();\n        }\n    });\n}",
        "summary_tokens": [
            "write",
            "the",
            "raw",
            "records",
            "into",
            "a",
            "kafka",
            "topic",
            "and",
            "return",
            "the",
            "producer",
            "future"
        ]
    },
    {
        "id": 1863,
        "code": "public void recordFailure() {\n    recordProcessingFailures.record();\n}",
        "summary_tokens": [
            "increment",
            "the",
            "number",
            "of",
            "failed",
            "operations",
            "retriable",
            "and",
            "non",
            "retriable"
        ]
    },
    {
        "id": 1864,
        "code": "public void recordError() {\n    recordProcessingErrors.record();\n}",
        "summary_tokens": [
            "increment",
            "the",
            "number",
            "of",
            "operations",
            "which",
            "could",
            "not",
            "be",
            "successfully",
            "executed"
        ]
    },
    {
        "id": 1865,
        "code": "public void recordSkipped() {\n    recordsSkipped.record();\n}",
        "summary_tokens": [
            "increment",
            "the",
            "number",
            "of",
            "records",
            "skipped"
        ]
    },
    {
        "id": 1866,
        "code": "public void recordRetry() {\n    retries.record();\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "retries",
            "made",
            "while",
            "executing",
            "operations"
        ]
    },
    {
        "id": 1867,
        "code": "public void recordErrorLogged() {\n    errorsLogged.record();\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "errors",
            "logged",
            "by",
            "the",
            "log",
            "reporter"
        ]
    },
    {
        "id": 1868,
        "code": "public void recordDeadLetterQueueProduceRequest() {\n    dlqProduceRequests.record();\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "produce",
            "requests",
            "to",
            "the",
            "dead",
            "letter",
            "queue",
            "reporter"
        ]
    },
    {
        "id": 1869,
        "code": "public void recordDeadLetterQueueProduceFailed() {\n    dlqProduceFailures.record();\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "produce",
            "requests",
            "to",
            "the",
            "dead",
            "letter",
            "queue",
            "reporter",
            "which",
            "failed",
            "to",
            "be",
            "successfully",
            "produced",
            "into",
            "kafka"
        ]
    },
    {
        "id": 1870,
        "code": "public void recordErrorTimestamp() {\n    this.lastErrorTime = time.milliseconds();\n}",
        "summary_tokens": [
            "record",
            "the",
            "time",
            "of",
            "error"
        ]
    },
    {
        "id": 1871,
        "code": "public ConnectMetrics.MetricGroup metricGroup() {\n    return metricGroup;\n}",
        "summary_tokens": [
            "the",
            "metric",
            "group",
            "for",
            "this",
            "class"
        ]
    },
    {
        "id": 1872,
        "code": "private void reset() {\n    attempt = 0;\n    position = null;\n    klass = null;\n    error = null;\n}",
        "summary_tokens": [
            "reset",
            "the",
            "internal",
            "fields",
            "before",
            "executing",
            "operations",
            "on",
            "a",
            "new",
            "record"
        ]
    },
    {
        "id": 1873,
        "code": "public ConsumerRecord<byte[], byte[]> consumerRecord() {\n    return consumedMessage;\n}",
        "summary_tokens": [
            "the",
            "record",
            "consumed",
            "from",
            "kafka"
        ]
    },
    {
        "id": 1874,
        "code": "public void sourceRecord(SourceRecord record) {\n    this.sourceRecord = record;\n    reset();\n}",
        "summary_tokens": [
            "set",
            "the",
            "source",
            "record",
            "being",
            "processed",
            "in",
            "the",
            "connect",
            "pipeline"
        ]
    },
    {
        "id": 1875,
        "code": "public void position(Stage position) {\n    this.position = position;\n}",
        "summary_tokens": [
            "set",
            "the",
            "stage",
            "in",
            "the",
            "connector",
            "pipeline",
            "which",
            "is",
            "currently",
            "executing"
        ]
    },
    {
        "id": 1876,
        "code": "public Stage stage() {\n    return position;\n}",
        "summary_tokens": [
            "the",
            "stage",
            "in",
            "the",
            "connector",
            "pipeline",
            "which",
            "is",
            "currently",
            "executing"
        ]
    },
    {
        "id": 1877,
        "code": "public void executingClass(Class<?> klass) {\n    this.klass = klass;\n}",
        "summary_tokens": [
            "klass",
            "set",
            "the",
            "class",
            "which",
            "is",
            "currently",
            "executing"
        ]
    },
    {
        "id": 1878,
        "code": "public void currentContext(Stage stage, Class<?> klass) {\n    position(stage);\n    executingClass(klass);\n}",
        "summary_tokens": [
            "a",
            "helper",
            "method",
            "to",
            "set",
            "both",
            "the",
            "stage",
            "and",
            "the",
            "class"
        ]
    },
    {
        "id": 1879,
        "code": "public int attempt() {\n    return attempt;\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "attempts",
            "made",
            "to",
            "execute",
            "the",
            "current",
            "operation"
        ]
    },
    {
        "id": 1880,
        "code": "public void error(Throwable error) {\n    this.error = error;\n}",
        "summary_tokens": [
            "the",
            "error",
            "if",
            "any",
            "which",
            "was",
            "encountered",
            "while",
            "processing",
            "the",
            "current",
            "stage"
        ]
    },
    {
        "id": 1881,
        "code": "public boolean failed() {\n    return error() != null;\n}",
        "summary_tokens": [
            "true",
            "if",
            "the",
            "last",
            "operation",
            "encountered",
            "an",
            "error",
            "false",
            "otherwise"
        ]
    },
    {
        "id": 1882,
        "code": "public void reporters(Collection<ErrorReporter> reporters) {\n    Objects.requireNonNull(reporters);\n    this.reporters = reporters;\n}",
        "summary_tokens": [
            "set",
            "the",
            "error",
            "reporters",
            "for",
            "this",
            "connector"
        ]
    },
    {
        "id": 1883,
        "code": "public synchronized <V> V execute(Operation<V> operation, Stage stage, Class<?> executingClass) {\n    context.currentContext(stage, executingClass);\n\n    if (context.failed()) {\n        log.debug(\"ProcessingContext is already in failed state. Ignoring requested operation.\");\n        return null;\n    }\n\n    try {\n        Class<? extends Exception> ex = TOLERABLE_EXCEPTIONS.getOrDefault(context.stage(), RetriableException.class);\n        return execAndHandleError(operation, ex);\n    } finally {\n        if (context.failed()) {\n            errorHandlingMetrics.recordError();\n            context.report();\n        }\n    }\n}",
        "summary_tokens": [
            "execute",
            "the",
            "recoverable",
            "operation"
        ]
    },
    {
        "id": 1884,
        "code": "protected <V> V execAndRetry(Operation<V> operation) throws Exception {\n    int attempt = 0;\n    long startTime = time.milliseconds();\n    long deadline = startTime + errorRetryTimeout;\n    do {\n        try {\n            attempt++;\n            return operation.call();\n        } catch (RetriableException e) {\n            log.trace(\"Caught a retriable exception while executing {} operation with {}\", context.stage(), context.executingClass());\n            errorHandlingMetrics.recordFailure();\n            if (checkRetry(startTime)) {\n                backoff(attempt, deadline);\n                if (Thread.currentThread().isInterrupted()) {\n                    log.trace(\"Thread was interrupted. Marking operation as failed.\");\n                    context.error(e);\n                    return null;\n                }\n                errorHandlingMetrics.recordRetry();\n            } else {\n                log.trace(\"Can't retry. start={}, attempt={}, deadline={}\", startTime, attempt, deadline);\n                context.error(e);\n                return null;\n            }\n        } finally {\n            context.attempt(attempt);\n        }\n    } while (true);\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "execute",
            "an",
            "operation"
        ]
    },
    {
        "id": 1885,
        "code": "protected <V> V execAndHandleError(Operation<V> operation, Class<? extends Exception> tolerated) {\n    try {\n        V result = execAndRetry(operation);\n        if (context.failed()) {\n            markAsFailed();\n            errorHandlingMetrics.recordSkipped();\n        }\n        return result;\n    } catch (Exception e) {\n        errorHandlingMetrics.recordFailure();\n        markAsFailed();\n        context.error(e);\n\n        if (!tolerated.isAssignableFrom(e.getClass())) {\n            throw new ConnectException(\"Unhandled exception in error handler\", e);\n        }\n\n        if (!withinToleranceLimits()) {\n            throw new ConnectException(\"Tolerance exceeded in error handler\", e);\n        }\n\n        errorHandlingMetrics.recordSkipped();\n        return null;\n    }\n}",
        "summary_tokens": [
            "execute",
            "a",
            "given",
            "operation",
            "multiple",
            "times",
            "if",
            "needed",
            "and",
            "tolerate",
            "certain",
            "exceptions"
        ]
    },
    {
        "id": 1886,
        "code": "public synchronized void reporters(List<ErrorReporter> reporters) {\n    this.context.reporters(reporters);\n}",
        "summary_tokens": [
            "set",
            "the",
            "error",
            "reporters",
            "for",
            "this",
            "connector"
        ]
    },
    {
        "id": 1887,
        "code": "public synchronized void sourceRecord(SourceRecord preTransformRecord) {\n    this.context.sourceRecord(preTransformRecord);\n}",
        "summary_tokens": [
            "set",
            "the",
            "source",
            "record",
            "being",
            "processed",
            "in",
            "the",
            "connect",
            "pipeline"
        ]
    },
    {
        "id": 1888,
        "code": "public synchronized void consumerRecord(ConsumerRecord<byte[], byte[]> consumedMessage) {\n    this.context.consumerRecord(consumedMessage);\n}",
        "summary_tokens": [
            "set",
            "the",
            "record",
            "consumed",
            "from",
            "kafka",
            "in",
            "a",
            "sink",
            "connector"
        ]
    },
    {
        "id": 1889,
        "code": "public synchronized boolean failed() {\n    return this.context.failed();\n}",
        "summary_tokens": [
            "true",
            "if",
            "the",
            "last",
            "operation",
            "encountered",
            "an",
            "error",
            "false",
            "otherwise"
        ]
    },
    {
        "id": 1890,
        "code": "public synchronized Throwable error() {\n    return this.context.error();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "error",
            "encountered",
            "when",
            "processing",
            "the",
            "current",
            "stage"
        ]
    },
    {
        "id": 1891,
        "code": "public void awaitFutures(Collection<TopicPartition> topicPartitions) {\n    futuresFor(topicPartitions).forEach(future -> {\n        try {\n            future.get();\n        } catch (InterruptedException | ExecutionException e) {\n            log.error(\"Encountered an error while awaiting an errant record future's completion.\", e);\n            throw new ConnectException(e);\n        }\n    });\n}",
        "summary_tokens": [
            "awaits",
            "the",
            "completion",
            "of",
            "all",
            "error",
            "reports",
            "for",
            "a",
            "given",
            "set",
            "of",
            "topic",
            "partitions",
            "topic",
            "partitions",
            "the",
            "topic",
            "partitions",
            "to",
            "await",
            "reporter",
            "completion",
            "for"
        ]
    },
    {
        "id": 1892,
        "code": "public void cancelFutures(Collection<TopicPartition> topicPartitions) {\n    futuresFor(topicPartitions).forEach(future -> {\n        try {\n            future.cancel(true);\n        } catch (Exception e) {\n            log.error(\"Encountered an error while cancelling an errant record future\", e);\n                \n        }\n    });\n}",
        "summary_tokens": [
            "cancels",
            "all",
            "active",
            "error",
            "reports",
            "for",
            "a",
            "given",
            "set",
            "of",
            "topic",
            "partitions",
            "topic",
            "partitions",
            "the",
            "topic",
            "partitions",
            "to",
            "cancel",
            "reporting",
            "for"
        ]
    },
    {
        "id": 1893,
        "code": "public PluginClassLoader pluginClassLoader(String name) {\n    if (!PluginUtils.shouldLoadInIsolation(name)) {\n        return null;\n    }\n    SortedMap<PluginDesc<?>, ClassLoader> inner = pluginLoaders.get(name);\n    if (inner == null) {\n        return null;\n    }\n    ClassLoader pluginLoader = inner.get(inner.lastKey());\n    return pluginLoader instanceof PluginClassLoader\n           ? (PluginClassLoader) pluginLoader\n           : null;\n}",
        "summary_tokens": [
            "retrieve",
            "the",
            "plugin",
            "class",
            "loader",
            "associated",
            "with",
            "a",
            "plugin",
            "class",
            "name",
            "the",
            "fully",
            "qualified",
            "class",
            "name",
            "of",
            "the",
            "plugin",
            "the",
            "plugin",
            "class",
            "loader",
            "that",
            "should",
            "be",
            "used",
            "to",
            "load",
            "this",
            "or",
            "null",
            "if",
            "the",
            "plugin",
            "is",
            "not",
            "isolated"
        ]
    },
    {
        "id": 1894,
        "code": "public String location() {\n    return pluginLocation.toString();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "top",
            "level",
            "location",
            "of",
            "the",
            "classes",
            "and",
            "dependencies",
            "required",
            "by",
            "the",
            "plugin",
            "that",
            "is",
            "loaded",
            "by",
            "this",
            "classloader"
        ]
    },
    {
        "id": 1895,
        "code": "public static boolean shouldLoadInIsolation(String name) {\n    return !(EXCLUDE.matcher(name).matches() && !INCLUDE.matcher(name).matches());\n}",
        "summary_tokens": [
            "return",
            "whether",
            "the",
            "class",
            "with",
            "the",
            "given",
            "name",
            "should",
            "be",
            "loaded",
            "in",
            "isolation",
            "using",
            "a",
            "plugin",
            "classloader"
        ]
    },
    {
        "id": 1896,
        "code": "public static boolean isConcrete(Class<?> klass) {\n    int mod = klass.getModifiers();\n    return !Modifier.isAbstract(mod) && !Modifier.isInterface(mod);\n}",
        "summary_tokens": [
            "verify",
            "the",
            "given",
            "class",
            "corresponds",
            "to",
            "a",
            "concrete",
            "class",
            "and",
            "not",
            "to",
            "an",
            "abstract",
            "class",
            "or",
            "interface"
        ]
    },
    {
        "id": 1897,
        "code": "public static boolean isArchive(Path path) {\n    String archivePath = path.toString().toLowerCase(Locale.ROOT);\n    return archivePath.endsWith(\".jar\") || archivePath.endsWith(\".zip\");\n}",
        "summary_tokens": [
            "return",
            "whether",
            "a",
            "path",
            "corresponds",
            "to",
            "a",
            "jar",
            "or",
            "zip",
            "archive"
        ]
    },
    {
        "id": 1898,
        "code": "public static boolean isClassFile(Path path) {\n    return path.toString().toLowerCase(Locale.ROOT).endsWith(\".class\");\n}",
        "summary_tokens": [
            "return",
            "whether",
            "a",
            "path",
            "corresponds",
            "java",
            "class",
            "file"
        ]
    },
    {
        "id": 1899,
        "code": "public static List<Path> pluginUrls(Path topPath) throws IOException {\n    boolean containsClassFiles = false;\n    Set<Path> archives = new TreeSet<>();\n    LinkedList<DirectoryEntry> dfs = new LinkedList<>();\n    Set<Path> visited = new HashSet<>();\n\n    if (isArchive(topPath)) {\n        return Collections.singletonList(topPath);\n    }\n\n    DirectoryStream<Path> topListing = Files.newDirectoryStream(\n            topPath,\n            PLUGIN_PATH_FILTER\n    );\n    dfs.push(new DirectoryEntry(topListing));\n    visited.add(topPath);\n    try {\n        while (!dfs.isEmpty()) {\n            Iterator<Path> neighbors = dfs.peek().iterator;\n            if (!neighbors.hasNext()) {\n                dfs.pop().stream.close();\n                continue;\n            }\n\n            Path adjacent = neighbors.next();\n            if (Files.isSymbolicLink(adjacent)) {\n                try {\n                    Path symlink = Files.readSymbolicLink(adjacent);\n                        \n                    Path parent = adjacent.getParent();\n                    if (parent == null) {\n                        continue;\n                    }\n                    Path absolute = parent.resolve(symlink).toRealPath();\n                    if (Files.exists(absolute)) {\n                        adjacent = absolute;\n                    } else {\n                        continue;\n                    }\n                } catch (IOException e) {\n                        \n                        \n                        \n                        \n                    log.warn(\n                            \"Resolving symbolic link '{}' failed. Ignoring this path.\",\n                            adjacent,\n                            e\n                    );\n                    continue;\n                }\n            }\n\n            if (!visited.contains(adjacent)) {\n                visited.add(adjacent);\n                if (isArchive(adjacent)) {\n                    archives.add(adjacent);\n                } else if (isClassFile(adjacent)) {\n                    containsClassFiles = true;\n                } else {\n                    DirectoryStream<Path> listing = Files.newDirectoryStream(\n                            adjacent,\n                            PLUGIN_PATH_FILTER\n                    );\n                    dfs.push(new DirectoryEntry(listing));\n                }\n            }\n        }\n    } finally {\n        while (!dfs.isEmpty()) {\n            dfs.pop().stream.close();\n        }\n    }\n\n    if (containsClassFiles) {\n        if (archives.isEmpty()) {\n            return Collections.singletonList(topPath);\n        }\n        log.warn(\"Plugin path contains both java archives and class files. Returning only the\"\n                + \" archives\");\n    }\n    return Arrays.asList(archives.toArray(new Path[0]));\n}",
        "summary_tokens": [
            "given",
            "a",
            "top",
            "path",
            "in",
            "the",
            "filesystem",
            "return",
            "a",
            "list",
            "of",
            "paths",
            "to",
            "archives",
            "jar",
            "or",
            "zip",
            "files",
            "contained",
            "under",
            "this",
            "top",
            "path"
        ]
    },
    {
        "id": 1900,
        "code": "public static String simpleName(PluginDesc<?> plugin) {\n    return plugin.pluginClass().getSimpleName();\n}",
        "summary_tokens": [
            "return",
            "the",
            "simple",
            "class",
            "name",
            "of",
            "a",
            "plugin",
            "as",
            "string"
        ]
    },
    {
        "id": 1901,
        "code": "public static String prunedName(PluginDesc<?> plugin) {\n        \n    switch (plugin.type()) {\n        case SOURCE:\n        case SINK:\n            return prunePluginName(plugin, \"Connector\");\n        default:\n            return prunePluginName(plugin, plugin.type().simpleName());\n    }\n}",
        "summary_tokens": [
            "remove",
            "the",
            "plugin",
            "type",
            "name",
            "at",
            "the",
            "end",
            "of",
            "a",
            "plugin",
            "class",
            "name",
            "if",
            "such",
            "suffix",
            "is",
            "present"
        ]
    },
    {
        "id": 1902,
        "code": "public static <U> boolean isAliasUnique(\n        PluginDesc<U> alias,\n        Collection<PluginDesc<U>> plugins\n) {\n    boolean matched = false;\n    for (PluginDesc<U> plugin : plugins) {\n        if (simpleName(alias).equals(simpleName(plugin))\n                || prunedName(alias).equals(prunedName(plugin))) {\n            if (matched) {\n                return false;\n            }\n            matched = true;\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "verify",
            "whether",
            "a",
            "given",
            "plugin",
            "s",
            "alias",
            "matches",
            "another",
            "alias",
            "in",
            "a",
            "collection",
            "of",
            "plugins"
        ]
    },
    {
        "id": 1903,
        "code": "public Converter newConverter(AbstractConfig config, String classPropertyName, ClassLoaderUsage classLoaderUsage) {\n    if (!config.originals().containsKey(classPropertyName)) {\n            \n        return null;\n    }\n\n    Class<? extends Converter> klass = null;\n    switch (classLoaderUsage) {\n        case CURRENT_CLASSLOADER:\n                \n                \n                \n            klass = pluginClassFromConfig(config, classPropertyName, Converter.class, delegatingLoader.converters());\n            break;\n        case PLUGINS:\n                \n            String converterClassOrAlias = config.getClass(classPropertyName).getName();\n            try {\n                klass = pluginClass(delegatingLoader, converterClassOrAlias, Converter.class);\n            } catch (ClassNotFoundException e) {\n                throw new ConnectException(\n                        \"Failed to find any class that implements Converter and which name matches \"\n                        + converterClassOrAlias + \", available converters are: \"\n                        + pluginNames(delegatingLoader.converters())\n                );\n            }\n            break;\n    }\n    if (klass == null) {\n        throw new ConnectException(\"Unable to initialize the Converter specified in '\" + classPropertyName + \"'\");\n    }\n\n        \n    final boolean isKeyConverter = WorkerConfig.KEY_CONVERTER_CLASS_CONFIG.equals(classPropertyName);\n\n        \n    String configPrefix = classPropertyName + \".\";\n    Map<String, Object> converterConfig = config.originalsWithPrefix(configPrefix);\n    log.debug(\"Configuring the {} converter with configuration keys:{}{}\",\n              isKeyConverter ? \"key\" : \"value\", System.lineSeparator(), converterConfig.keySet());\n\n    Converter plugin;\n    ClassLoader savedLoader = compareAndSwapLoaders(klass.getClassLoader());\n    try {\n        plugin = newPlugin(klass);\n        plugin.configure(converterConfig, isKeyConverter);\n    } finally {\n        compareAndSwapLoaders(savedLoader);\n    }\n    return plugin;\n}",
        "summary_tokens": [
            "if",
            "the",
            "given",
            "configuration",
            "defines",
            "a",
            "converter",
            "using",
            "the",
            "named",
            "configuration",
            "property",
            "return",
            "a",
            "new",
            "configured",
            "instance"
        ]
    },
    {
        "id": 1904,
        "code": "public Converter newInternalConverter(boolean isKey, String className, Map<String, String> converterConfig) {\n    Class<? extends Converter> klass;\n    try {\n        klass = pluginClass(delegatingLoader, className, Converter.class);\n    } catch (ClassNotFoundException e) {\n        throw new ConnectException(\"Failed to load internal converter class \" + className);\n    }\n\n    Converter plugin;\n    ClassLoader savedLoader = compareAndSwapLoaders(klass.getClassLoader());\n    try {\n        plugin = newPlugin(klass);\n        plugin.configure(converterConfig, isKey);\n    } finally {\n        compareAndSwapLoaders(savedLoader);\n    }\n    return plugin;\n}",
        "summary_tokens": [
            "load",
            "an",
            "internal",
            "converter",
            "used",
            "by",
            "the",
            "worker",
            "for",
            "de",
            "serializing",
            "data",
            "in",
            "internal",
            "topics"
        ]
    },
    {
        "id": 1905,
        "code": "public HeaderConverter newHeaderConverter(AbstractConfig config, String classPropertyName, ClassLoaderUsage classLoaderUsage) {\n    Class<? extends HeaderConverter> klass = null;\n    switch (classLoaderUsage) {\n        case CURRENT_CLASSLOADER:\n            if (!config.originals().containsKey(classPropertyName)) {\n                    \n                return null;\n            }\n                \n                \n                \n            klass = pluginClassFromConfig(config, classPropertyName, HeaderConverter.class, delegatingLoader.headerConverters());\n            break;\n        case PLUGINS:\n                \n                \n            String converterClassOrAlias = config.getClass(classPropertyName).getName();\n            try {\n                klass = pluginClass(\n                        delegatingLoader,\n                        converterClassOrAlias,\n                        HeaderConverter.class\n                );\n            } catch (ClassNotFoundException e) {\n                throw new ConnectException(\n                        \"Failed to find any class that implements HeaderConverter and which name matches \"\n                                + converterClassOrAlias\n                                + \", available header converters are: \"\n                                + pluginNames(delegatingLoader.headerConverters())\n                );\n            }\n    }\n    if (klass == null) {\n        throw new ConnectException(\"Unable to initialize the HeaderConverter specified in '\" + classPropertyName + \"'\");\n    }\n\n    String configPrefix = classPropertyName + \".\";\n    Map<String, Object> converterConfig = config.originalsWithPrefix(configPrefix);\n    converterConfig.put(ConverterConfig.TYPE_CONFIG, ConverterType.HEADER.getName());\n    log.debug(\"Configuring the header converter with configuration keys:{}{}\", System.lineSeparator(), converterConfig.keySet());\n\n    HeaderConverter plugin;\n    ClassLoader savedLoader = compareAndSwapLoaders(klass.getClassLoader());\n    try {\n        plugin = newPlugin(klass);\n        plugin.configure(converterConfig);\n    } finally {\n        compareAndSwapLoaders(savedLoader);\n    }\n    return plugin;\n}",
        "summary_tokens": [
            "if",
            "the",
            "given",
            "configuration",
            "defines",
            "a",
            "header",
            "converter",
            "using",
            "the",
            "named",
            "configuration",
            "property",
            "return",
            "a",
            "new",
            "configured",
            "instance"
        ]
    },
    {
        "id": 1906,
        "code": "public <T> List<T> newPlugins(List<String> klassNames, AbstractConfig config, Class<T> pluginKlass) {\n    List<T> plugins = new ArrayList<>();\n    if (klassNames != null) {\n        for (String klassName : klassNames) {\n            plugins.add(newPlugin(klassName, config, pluginKlass));\n        }\n    }\n    return plugins;\n}",
        "summary_tokens": [
            "if",
            "the",
            "given",
            "class",
            "names",
            "are",
            "available",
            "in",
            "the",
            "classloader",
            "return",
            "a",
            "list",
            "of",
            "new",
            "configured",
            "instances"
        ]
    },
    {
        "id": 1907,
        "code": "public static void addToRequest(SecretKey key, byte[] requestBody, String signatureAlgorithm, Request request) {\n    Mac mac;\n    try {\n        mac = mac(signatureAlgorithm);\n    }  catch (NoSuchAlgorithmException e) {\n        throw new ConnectException(e);\n    }\n    byte[] requestSignature = sign(mac, key, requestBody);\n    request.header(InternalRequestSignature.SIGNATURE_HEADER, Base64.getEncoder().encodeToString(requestSignature))\n           .header(InternalRequestSignature.SIGNATURE_ALGORITHM_HEADER, signatureAlgorithm);\n}",
        "summary_tokens": [
            "add",
            "a",
            "signature",
            "to",
            "a",
            "request"
        ]
    },
    {
        "id": 1908,
        "code": "public static InternalRequestSignature fromHeaders(byte[] requestBody, HttpHeaders headers) {\n    if (headers == null) {\n        return null;\n    }\n\n    String signatureAlgorithm = headers.getHeaderString(SIGNATURE_ALGORITHM_HEADER);\n    String encodedSignature = headers.getHeaderString(SIGNATURE_HEADER);\n    if (signatureAlgorithm == null || encodedSignature == null) {\n        return null;\n    }\n\n    Mac mac;\n    try {\n        mac = mac(signatureAlgorithm);\n    } catch (NoSuchAlgorithmException e) {\n        throw new BadRequestException(e.getMessage());\n    }\n\n    byte[] decodedSignature;\n    try {\n        decodedSignature = Base64.getDecoder().decode(encodedSignature);\n    } catch (IllegalArgumentException e) {\n        throw new BadRequestException(e.getMessage());\n    }\n\n    return new InternalRequestSignature(\n        requestBody,\n        mac,\n        decodedSignature\n    );\n}",
        "summary_tokens": [
            "extract",
            "a",
            "signature",
            "from",
            "a",
            "request"
        ]
    },
    {
        "id": 1909,
        "code": "public static <T> HttpResponse<T> httpRequest(String url, String method, HttpHeaders headers, Object requestBodyData,\n                                              TypeReference<T> responseFormat, WorkerConfig config,\n                                              SecretKey sessionKey, String requestSignatureAlgorithm) {\n    HttpClient client;\n\n    if (url.startsWith(\"https://\")) {\n        client = new HttpClient(SSLUtils.createClientSideSslContextFactory(config));\n    } else {\n        client = new HttpClient();\n    }\n\n    client.setFollowRedirects(false);\n\n    try {\n        client.start();\n    } catch (Exception e) {\n        log.error(\"Failed to start RestClient: \", e);\n        throw new ConnectRestException(Response.Status.INTERNAL_SERVER_ERROR, \"Failed to start RestClient: \" + e.getMessage(), e);\n    }\n\n    try {\n        return httpRequest(client, url, method, headers, requestBodyData, responseFormat, sessionKey, requestSignatureAlgorithm);\n    } finally {\n        try {\n            client.stop();\n        } catch (Exception e) {\n            log.error(\"Failed to stop HTTP client\", e);\n        }\n    }\n}",
        "summary_tokens": [
            "sends",
            "http",
            "request",
            "to",
            "remote",
            "rest",
            "server"
        ]
    },
    {
        "id": 1910,
        "code": "private static void addHeadersToRequest(HttpHeaders headers, Request req) {\n    if (headers != null) {\n        String credentialAuthorization = headers.getHeaderString(HttpHeaders.AUTHORIZATION);\n        if (credentialAuthorization != null) {\n            req.header(HttpHeaders.AUTHORIZATION, credentialAuthorization);\n        }\n    }\n}",
        "summary_tokens": [
            "extract",
            "headers",
            "from",
            "rest",
            "call",
            "and",
            "add",
            "to",
            "client",
            "request",
            "headers",
            "headers",
            "from",
            "rest",
            "endpoint",
            "req",
            "the",
            "client",
            "request",
            "to",
            "modify"
        ]
    },
    {
        "id": 1911,
        "code": "private static Map<String, String> convertHttpFieldsToMap(HttpFields httpFields) {\n    Map<String, String> headers = new HashMap<>();\n\n    if (httpFields == null || httpFields.size() == 0)\n        return headers;\n\n    for (HttpField field : httpFields) {\n        headers.put(field.getName(), field.getValue());\n    }\n\n    return headers;\n}",
        "summary_tokens": [
            "convert",
            "response",
            "parameters",
            "from",
            "jetty",
            "format",
            "http",
            "fields",
            "http",
            "fields"
        ]
    },
    {
        "id": 1912,
        "code": "public void createConnectors(List<String> listeners, List<String> adminListeners) {\n    List<Connector> connectors = new ArrayList<>();\n\n    for (String listener : listeners) {\n        Connector connector = createConnector(listener);\n        connectors.add(connector);\n        log.info(\"Added connector for {}\", listener);\n    }\n\n    jettyServer.setConnectors(connectors.toArray(new Connector[0]));\n\n    if (adminListeners != null && !adminListeners.isEmpty()) {\n        for (String adminListener : adminListeners) {\n            Connector conn = createConnector(adminListener, true);\n            jettyServer.addConnector(conn);\n            log.info(\"Added admin connector for {}\", adminListener);\n        }\n    }\n}",
        "summary_tokens": [
            "adds",
            "jetty",
            "connector",
            "for",
            "each",
            "configured",
            "listener"
        ]
    },
    {
        "id": 1913,
        "code": "public Connector createConnector(String listener, boolean isAdmin) {\n    Matcher listenerMatcher = LISTENER_PATTERN.matcher(listener);\n\n    if (!listenerMatcher.matches())\n        throw new ConfigException(\"Listener doesn't have the right format (protocol://hostname:port).\");\n\n    String protocol = listenerMatcher.group(1).toLowerCase(Locale.ENGLISH);\n\n    if (!PROTOCOL_HTTP.equals(protocol) && !PROTOCOL_HTTPS.equals(protocol))\n        throw new ConfigException(String.format(\"Listener protocol must be either \\\"%s\\\" or \\\"%s\\\".\", PROTOCOL_HTTP, PROTOCOL_HTTPS));\n\n    String hostname = listenerMatcher.group(2);\n    int port = Integer.parseInt(listenerMatcher.group(3));\n\n    ServerConnector connector;\n\n    if (PROTOCOL_HTTPS.equals(protocol)) {\n        SslContextFactory ssl;\n        if (isAdmin) {\n            ssl = SSLUtils.createServerSideSslContextFactory(config, ADMIN_LISTENERS_HTTPS_CONFIGS_PREFIX);\n        } else {\n            ssl = SSLUtils.createServerSideSslContextFactory(config);\n        }\n        connector = new ServerConnector(jettyServer, ssl);\n        if (!isAdmin) {\n            connector.setName(String.format(\"%s_%s%d\", PROTOCOL_HTTPS, hostname, port));\n        }\n    } else {\n        connector = new ServerConnector(jettyServer);\n        if (!isAdmin) {\n            connector.setName(String.format(\"%s_%s%d\", PROTOCOL_HTTP, hostname, port));\n        }\n    }\n\n    if (isAdmin) {\n        connector.setName(ADMIN_SERVER_CONNECTOR_NAME);\n    }\n\n    if (!hostname.isEmpty())\n        connector.setHost(hostname);\n\n    connector.setPort(port);\n\n    return connector;\n}",
        "summary_tokens": [
            "creates",
            "jetty",
            "connector",
            "according",
            "to",
            "configuration"
        ]
    },
    {
        "id": 1914,
        "code": "public URI advertisedUrl() {\n    UriBuilder builder = UriBuilder.fromUri(jettyServer.getURI());\n\n    String advertisedSecurityProtocol = determineAdvertisedProtocol();\n    ServerConnector serverConnector = findConnector(advertisedSecurityProtocol);\n    builder.scheme(advertisedSecurityProtocol);\n\n    String advertisedHostname = config.getString(WorkerConfig.REST_ADVERTISED_HOST_NAME_CONFIG);\n    if (advertisedHostname != null && !advertisedHostname.isEmpty())\n        builder.host(advertisedHostname);\n    else if (serverConnector != null && serverConnector.getHost() != null && serverConnector.getHost().length() > 0)\n        builder.host(serverConnector.getHost());\n\n    Integer advertisedPort = config.getInt(WorkerConfig.REST_ADVERTISED_PORT_CONFIG);\n    if (advertisedPort != null)\n        builder.port(advertisedPort);\n    else if (serverConnector != null && serverConnector.getPort() > 0)\n        builder.port(serverConnector.getPort());\n\n    log.info(\"Advertised URI: {}\", builder.build());\n\n    return builder.build();\n}",
        "summary_tokens": [
            "get",
            "the",
            "url",
            "to",
            "advertise",
            "to",
            "other",
            "workers",
            "and",
            "clients"
        ]
    },
    {
        "id": 1915,
        "code": "public URI adminUrl() {\n    ServerConnector adminConnector = null;\n    for (Connector connector : jettyServer.getConnectors()) {\n        if (ADMIN_SERVER_CONNECTOR_NAME.equals(connector.getName()))\n            adminConnector = (ServerConnector) connector;\n    }\n\n    if (adminConnector == null) {\n        List<String> adminListeners = config.getList(WorkerConfig.ADMIN_LISTENERS_CONFIG);\n        if (adminListeners == null) {\n            return advertisedUrl();\n        } else if (adminListeners.isEmpty()) {\n            return null;\n        } else {\n            log.error(\"No admin connector found for listeners {}\", adminListeners);\n            return null;\n        }\n    }\n\n    UriBuilder builder = UriBuilder.fromUri(jettyServer.getURI());\n    builder.port(adminConnector.getLocalPort());\n\n    return builder.build();\n}",
        "summary_tokens": [
            "the",
            "admin",
            "url",
            "for",
            "this",
            "worker"
        ]
    },
    {
        "id": 1916,
        "code": "ServerConnector findConnector(String protocol) {\n    for (Connector connector : jettyServer.getConnectors()) {\n        String connectorName = connector.getName();\n            \n            \n            \n            \n            \n        if (connectorName.startsWith(protocol + \"_\") && !ADMIN_SERVER_CONNECTOR_NAME.equals(connectorName))\n            return (ServerConnector) connector;\n    }\n\n    return null;\n}",
        "summary_tokens": [
            "locate",
            "a",
            "jetty",
            "connector",
            "for",
            "the",
            "standard",
            "non",
            "admin",
            "rest",
            "api",
            "that",
            "uses",
            "the",
            "given",
            "protocol"
        ]
    },
    {
        "id": 1917,
        "code": "protected void configureHttpResponsHeaderFilter(ServletContextHandler context) {\n    String headerConfig = config.getString(WorkerConfig.RESPONSE_HTTP_HEADERS_CONFIG);\n    FilterHolder headerFilterHolder = new FilterHolder(HeaderFilter.class);\n    headerFilterHolder.setInitParameter(\"headerConfig\", headerConfig);\n    context.addFilter(headerFilterHolder, \"/*\", EnumSet.of(DispatcherType.REQUEST));\n}",
        "summary_tokens": [
            "register",
            "header",
            "filter",
            "to",
            "servlet",
            "context",
            "handler"
        ]
    },
    {
        "id": 1918,
        "code": "public Response listLoggers() {\n    Map<String, Map<String, String>> loggers = new TreeMap<>();\n    Enumeration<Logger> enumeration = currentLoggers();\n    Collections.list(enumeration)\n            .stream()\n            .filter(logger -> logger.getLevel() != null)\n            .forEach(logger -> loggers.put(logger.getName(), levelToMap(logger)));\n\n    Logger root = rootLogger();\n    if (root.getLevel() != null) {\n        loggers.put(ROOT_LOGGER_NAME, levelToMap(root));\n    }\n\n    return Response.ok(loggers).build();\n}",
        "summary_tokens": [
            "list",
            "the",
            "current",
            "loggers",
            "that",
            "have",
            "their",
            "levels",
            "explicitly",
            "set",
            "and",
            "their",
            "log",
            "levels"
        ]
    },
    {
        "id": 1919,
        "code": "public Response getLogger(final @PathParam(\"logger\") String namedLogger) {\n    Objects.requireNonNull(namedLogger, \"require non-null name\");\n\n    Logger logger = null;\n    if (ROOT_LOGGER_NAME.equalsIgnoreCase(namedLogger)) {\n        logger = rootLogger();\n    } else {\n        Enumeration<Logger> en = currentLoggers();\n            \n            \n            \n        while (en.hasMoreElements()) {\n            Logger l = en.nextElement();\n            if (namedLogger.equals(l.getName())) {\n                logger = l;\n                break;\n            }\n        }\n    }\n    if (logger == null) {\n        throw new NotFoundException(\"Logger \" + namedLogger + \" not found.\");\n    } else {\n        return Response.ok(effectiveLevelToMap(logger)).build();\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "log",
            "level",
            "of",
            "a",
            "named",
            "logger"
        ]
    },
    {
        "id": 1920,
        "code": "public Response setLevel(final @PathParam(\"logger\") String namedLogger,\n                         final Map<String, String> levelMap) {\n    String desiredLevelStr = levelMap.get(\"level\");\n    if (desiredLevelStr == null) {\n        throw new BadRequestException(\"Desired 'level' parameter was not specified in request.\");\n    }\n\n    Level level = Level.toLevel(desiredLevelStr.toUpperCase(Locale.ROOT), null);\n    if (level == null) {\n        throw new NotFoundException(\"invalid log level '\" + desiredLevelStr + \"'.\");\n    }\n\n    List<Logger> childLoggers;\n    if (ROOT_LOGGER_NAME.equalsIgnoreCase(namedLogger)) {\n        childLoggers = Collections.list(currentLoggers());\n        childLoggers.add(rootLogger());\n    } else {\n        childLoggers = new ArrayList<>();\n        Logger ancestorLogger = lookupLogger(namedLogger);\n        Enumeration<Logger> en = currentLoggers();\n        boolean present = false;\n        while (en.hasMoreElements()) {\n            Logger current = en.nextElement();\n            if (current.getName().startsWith(namedLogger)) {\n                childLoggers.add(current);\n            }\n            if (namedLogger.equals(current.getName())) {\n                present = true;\n            }\n        }\n        if (!present) {\n            childLoggers.add(ancestorLogger);\n        }\n    }\n\n    List<String> modifiedLoggerNames = new ArrayList<>();\n    for (Logger logger: childLoggers) {\n        logger.setLevel(level);\n        modifiedLoggerNames.add(logger.getName());\n    }\n    Collections.sort(modifiedLoggerNames);\n\n    return Response.ok(modifiedLoggerNames).build();\n}",
        "summary_tokens": [
            "adjust",
            "level",
            "of",
            "a",
            "named",
            "logger"
        ]
    },
    {
        "id": 1921,
        "code": "private static Map<String, String> effectiveLevelToMap(Logger logger) {\n    Level level = logger.getLevel();\n    if (level == null) {\n        level = logger.getEffectiveLevel();\n    }\n    return Collections.singletonMap(\"level\", String.valueOf(level));\n}",
        "summary_tokens": [
            "map",
            "representation",
            "of",
            "a",
            "logger",
            "s",
            "effective",
            "log",
            "level"
        ]
    },
    {
        "id": 1922,
        "code": "private static Map<String, String> levelToMap(Logger logger) {\n    return Collections.singletonMap(\"level\", String.valueOf(logger.getLevel()));\n}",
        "summary_tokens": [
            "map",
            "representation",
            "of",
            "a",
            "logger",
            "s",
            "log",
            "level"
        ]
    },
    {
        "id": 1923,
        "code": "public static SslContextFactory createServerSideSslContextFactory(WorkerConfig config) {\n    return createServerSideSslContextFactory(config, \"listeners.https.\");\n}",
        "summary_tokens": [
            "configures",
            "ssl",
            "tls",
            "for",
            "https",
            "jetty",
            "server"
        ]
    },
    {
        "id": 1924,
        "code": "public static SslContextFactory createClientSideSslContextFactory(WorkerConfig config) {\n    Map<String, Object> sslConfigValues = config.valuesWithPrefixAllOrNothing(\"listeners.https.\");\n\n    final SslContextFactory.Client ssl = new SslContextFactory.Client();\n\n    configureSslContextFactoryKeyStore(ssl, sslConfigValues);\n    configureSslContextFactoryTrustStore(ssl, sslConfigValues);\n    configureSslContextFactoryAlgorithms(ssl, sslConfigValues);\n    configureSslContextFactoryEndpointIdentification(ssl, sslConfigValues);\n\n    return ssl;\n}",
        "summary_tokens": [
            "configures",
            "ssl",
            "tls",
            "for",
            "https",
            "jetty",
            "client"
        ]
    },
    {
        "id": 1925,
        "code": "protected static void configureSslContextFactoryKeyStore(SslContextFactory ssl, Map<String, Object> sslConfigValues) {\n    ssl.setKeyStoreType((String) getOrDefault(sslConfigValues, SslConfigs.SSL_KEYSTORE_TYPE_CONFIG, SslConfigs.DEFAULT_SSL_KEYSTORE_TYPE));\n\n    String sslKeystoreLocation = (String) sslConfigValues.get(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG);\n    if (sslKeystoreLocation != null)\n        ssl.setKeyStorePath(sslKeystoreLocation);\n\n    Password sslKeystorePassword = (Password) sslConfigValues.get(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG);\n    if (sslKeystorePassword != null)\n        ssl.setKeyStorePassword(sslKeystorePassword.value());\n\n    Password sslKeyPassword = (Password) sslConfigValues.get(SslConfigs.SSL_KEY_PASSWORD_CONFIG);\n    if (sslKeyPassword != null)\n        ssl.setKeyManagerPassword(sslKeyPassword.value());\n}",
        "summary_tokens": [
            "configures",
            "key",
            "store",
            "related",
            "settings",
            "in",
            "ssl",
            "context",
            "factory"
        ]
    },
    {
        "id": 1926,
        "code": "protected static void configureSslContextFactoryTrustStore(SslContextFactory ssl, Map<String, Object> sslConfigValues) {\n    ssl.setTrustStoreType((String) getOrDefault(sslConfigValues, SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, SslConfigs.DEFAULT_SSL_TRUSTSTORE_TYPE));\n\n    String sslTruststoreLocation = (String) sslConfigValues.get(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG);\n    if (sslTruststoreLocation != null)\n        ssl.setTrustStorePath(sslTruststoreLocation);\n\n    Password sslTruststorePassword = (Password) sslConfigValues.get(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG);\n    if (sslTruststorePassword != null)\n        ssl.setTrustStorePassword(sslTruststorePassword.value());\n}",
        "summary_tokens": [
            "configures",
            "trust",
            "store",
            "related",
            "settings",
            "in",
            "ssl",
            "context",
            "factory"
        ]
    },
    {
        "id": 1927,
        "code": "protected static void configureSslContextFactoryAlgorithms(SslContextFactory ssl, Map<String, Object> sslConfigValues) {\n    List<String> sslEnabledProtocols = (List<String>) getOrDefault(sslConfigValues, SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(COMMA_WITH_WHITESPACE.split(SslConfigs.DEFAULT_SSL_ENABLED_PROTOCOLS)));\n    ssl.setIncludeProtocols(sslEnabledProtocols.toArray(new String[0]));\n\n    String sslProvider = (String) sslConfigValues.get(SslConfigs.SSL_PROVIDER_CONFIG);\n    if (sslProvider != null)\n        ssl.setProvider(sslProvider);\n\n    ssl.setProtocol((String) getOrDefault(sslConfigValues, SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL));\n\n    List<String> sslCipherSuites = (List<String>) sslConfigValues.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG);\n    if (sslCipherSuites != null)\n        ssl.setIncludeCipherSuites(sslCipherSuites.toArray(new String[0]));\n\n    ssl.setKeyManagerFactoryAlgorithm((String) getOrDefault(sslConfigValues, SslConfigs.SSL_KEYMANAGER_ALGORITHM_CONFIG, SslConfigs.DEFAULT_SSL_KEYMANGER_ALGORITHM));\n\n    String sslSecureRandomImpl = (String) sslConfigValues.get(SslConfigs.SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG);\n    if (sslSecureRandomImpl != null)\n        ssl.setSecureRandomAlgorithm(sslSecureRandomImpl);\n\n    ssl.setTrustManagerFactoryAlgorithm((String) getOrDefault(sslConfigValues, SslConfigs.SSL_TRUSTMANAGER_ALGORITHM_CONFIG, SslConfigs.DEFAULT_SSL_TRUSTMANAGER_ALGORITHM));\n}",
        "summary_tokens": [
            "configures",
            "protocol",
            "algorithm",
            "and",
            "provider",
            "related",
            "settings",
            "in",
            "ssl",
            "context",
            "factory"
        ]
    },
    {
        "id": 1928,
        "code": "protected static void configureSslContextFactoryEndpointIdentification(SslContextFactory ssl, Map<String, Object> sslConfigValues) {\n    String sslEndpointIdentificationAlg = (String) sslConfigValues.get(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG);\n    if (sslEndpointIdentificationAlg != null)\n        ssl.setEndpointIdentificationAlgorithm(sslEndpointIdentificationAlg);\n}",
        "summary_tokens": [
            "configures",
            "protocol",
            "algorithm",
            "and",
            "provider",
            "related",
            "settings",
            "in",
            "ssl",
            "context",
            "factory"
        ]
    },
    {
        "id": 1929,
        "code": "protected static void configureSslContextFactoryAuthentication(SslContextFactory.Server ssl, Map<String, Object> sslConfigValues) {\n    String sslClientAuth = (String) getOrDefault(sslConfigValues, BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"none\");\n    switch (sslClientAuth) {\n        case \"requested\":\n            ssl.setWantClientAuth(true);\n            break;\n        case \"required\":\n            ssl.setNeedClientAuth(true);\n            break;\n        default:\n            ssl.setNeedClientAuth(false);\n            ssl.setWantClientAuth(false);\n    }\n}",
        "summary_tokens": [
            "configures",
            "authentication",
            "related",
            "settings",
            "in",
            "ssl",
            "context",
            "factory"
        ]
    },
    {
        "id": 1930,
        "code": "public long offset() {\n    return offset;\n}",
        "summary_tokens": [
            "get",
            "the",
            "last",
            "offset",
            "read",
            "to",
            "generate",
            "this",
            "config",
            "state"
        ]
    },
    {
        "id": 1931,
        "code": "public SessionKey sessionKey() {\n    return sessionKey;\n}",
        "summary_tokens": [
            "get",
            "the",
            "latest",
            "session",
            "key",
            "from",
            "the",
            "config",
            "state",
            "the",
            "session",
            "key",
            "session",
            "key",
            "may",
            "be",
            "null",
            "if",
            "no",
            "key",
            "has",
            "been",
            "read",
            "yet"
        ]
    },
    {
        "id": 1932,
        "code": "public boolean contains(String connector) {\n    return connectorConfigs.containsKey(connector);\n}",
        "summary_tokens": [
            "check",
            "whether",
            "this",
            "snapshot",
            "contains",
            "configuration",
            "for",
            "a",
            "connector"
        ]
    },
    {
        "id": 1933,
        "code": "public Set<String> connectors() {\n    return connectorConfigs.keySet();\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "the",
            "connectors",
            "in",
            "this",
            "configuration"
        ]
    },
    {
        "id": 1934,
        "code": "public Map<String, String> connectorConfig(String connector) {\n    Map<String, String> configs = connectorConfigs.get(connector);\n    if (configTransformer != null) {\n        configs = configTransformer.transform(connector, configs);\n    }\n    return configs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configuration",
            "for",
            "a",
            "connector"
        ]
    },
    {
        "id": 1935,
        "code": "public TargetState targetState(String connector) {\n    return connectorTargetStates.get(connector);\n}",
        "summary_tokens": [
            "get",
            "the",
            "target",
            "state",
            "of",
            "the",
            "connector",
            "connector",
            "name",
            "of",
            "the",
            "connector",
            "the",
            "target",
            "state"
        ]
    },
    {
        "id": 1936,
        "code": "public Map<String, String> taskConfig(ConnectorTaskId task) {\n    Map<String, String> configs = taskConfigs.get(task);\n    if (configTransformer != null) {\n        configs = configTransformer.transform(task.connector(), configs);\n    }\n    return configs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configuration",
            "for",
            "a",
            "task"
        ]
    },
    {
        "id": 1937,
        "code": "public List<Map<String, String>> allTaskConfigs(String connector) {\n    Map<Integer, Map<String, String>> taskConfigs = new TreeMap<>();\n    for (Map.Entry<ConnectorTaskId, Map<String, String>> taskConfigEntry : this.taskConfigs.entrySet()) {\n        if (taskConfigEntry.getKey().connector().equals(connector)) {\n            Map<String, String> configs = taskConfigEntry.getValue();\n            if (configTransformer != null) {\n                configs = configTransformer.transform(connector, configs);\n            }\n            taskConfigs.put(taskConfigEntry.getKey().task(), configs);\n        }\n    }\n    return Collections.unmodifiableList(new ArrayList<>(taskConfigs.values()));\n}",
        "summary_tokens": [
            "get",
            "all",
            "task",
            "configs",
            "for",
            "a",
            "connector"
        ]
    },
    {
        "id": 1938,
        "code": "public int taskCount(String connectorName) {\n    Integer count = connectorTaskCounts.get(connectorName);\n    return count == null ? 0 : count;\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "tasks",
            "assigned",
            "for",
            "the",
            "given",
            "connector"
        ]
    },
    {
        "id": 1939,
        "code": "public boolean pendingFencing(String connectorName) {\n    return connectorsPendingFencing.contains(connectorName);\n}",
        "summary_tokens": [
            "get",
            "whether",
            "the",
            "connector",
            "requires",
            "a",
            "round",
            "of",
            "zombie",
            "fencing",
            "before",
            "a",
            "new",
            "generation",
            "of",
            "tasks",
            "can",
            "be",
            "brought",
            "up",
            "for",
            "it"
        ]
    },
    {
        "id": 1940,
        "code": "public List<ConnectorTaskId> tasks(String connectorName) {\n    if (inconsistentConnectors.contains(connectorName)) {\n        return Collections.emptyList();\n    }\n\n    Integer numTasks = connectorTaskCounts.get(connectorName);\n    if (numTasks == null) {\n        return Collections.emptyList();\n    }\n\n    List<ConnectorTaskId> taskIds = new ArrayList<>(numTasks);\n    for (int taskIndex = 0; taskIndex < numTasks; taskIndex++) {\n        ConnectorTaskId taskId = new ConnectorTaskId(connectorName, taskIndex);\n        taskIds.add(taskId);\n    }\n    return Collections.unmodifiableList(taskIds);\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "set",
            "of",
            "task",
            "ids",
            "for",
            "the",
            "specified",
            "connector"
        ]
    },
    {
        "id": 1941,
        "code": "public Integer taskCountRecord(String connector) {\n    return connectorTaskCountRecords.get(connector);\n}",
        "summary_tokens": [
            "get",
            "the",
            "task",
            "count",
            "record",
            "for",
            "the",
            "connector",
            "if",
            "one",
            "exists",
            "connector",
            "name",
            "of",
            "the",
            "connector",
            "the",
            "latest",
            "task",
            "count",
            "record",
            "for",
            "the",
            "connector",
            "or",
            "null",
            "if",
            "none",
            "exists"
        ]
    },
    {
        "id": 1942,
        "code": "public Integer taskConfigGeneration(String connector) {\n    return connectorTaskConfigGenerations.get(connector);\n}",
        "summary_tokens": [
            "get",
            "the",
            "generation",
            "number",
            "for",
            "the",
            "connector",
            "s",
            "task",
            "configurations",
            "if",
            "one",
            "exists"
        ]
    },
    {
        "id": 1943,
        "code": "public Set<String> inconsistentConnectors() {\n    return inconsistentConnectors;\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "connectors",
            "which",
            "have",
            "inconsistent",
            "data",
            "in",
            "this",
            "snapshot"
        ]
    },
    {
        "id": 1944,
        "code": "default void claimWritePrivileges() {\n}",
        "summary_tokens": [
            "prepare",
            "to",
            "write",
            "to",
            "the",
            "backing",
            "config",
            "store"
        ]
    },
    {
        "id": 1945,
        "code": "public static ConnectorOffsetBackingStore withConnectorAndWorkerStores(\n        Supplier<LoggingContext> loggingContext,\n        OffsetBackingStore workerStore,\n        KafkaOffsetBackingStore connectorStore,\n        String connectorOffsetsTopic,\n        TopicAdmin connectorStoreAdmin\n) {\n    Objects.requireNonNull(loggingContext);\n    Objects.requireNonNull(workerStore);\n    Objects.requireNonNull(connectorStore);\n    Objects.requireNonNull(connectorOffsetsTopic);\n    Objects.requireNonNull(connectorStoreAdmin);\n    return new ConnectorOffsetBackingStore(\n            Time.SYSTEM,\n            loggingContext,\n            connectorOffsetsTopic,\n            workerStore,\n            connectorStore,\n            connectorStoreAdmin\n    );\n}",
        "summary_tokens": [
            "builds",
            "an",
            "offset",
            "store",
            "that",
            "uses",
            "a",
            "connector",
            "specific",
            "offset",
            "topic",
            "as",
            "the",
            "primary",
            "store",
            "and",
            "the",
            "worker",
            "global",
            "offset",
            "store",
            "as",
            "the",
            "secondary",
            "store"
        ]
    },
    {
        "id": 1946,
        "code": "public static ConnectorOffsetBackingStore withOnlyWorkerStore(\n        Supplier<LoggingContext> loggingContext,\n        OffsetBackingStore workerStore,\n        String workerOffsetsTopic\n) {\n    Objects.requireNonNull(loggingContext);\n    Objects.requireNonNull(workerStore);\n    return new ConnectorOffsetBackingStore(Time.SYSTEM, loggingContext, workerOffsetsTopic, workerStore, null, null);\n}",
        "summary_tokens": [
            "builds",
            "an",
            "offset",
            "store",
            "that",
            "uses",
            "the",
            "worker",
            "global",
            "offset",
            "store",
            "as",
            "the",
            "primary",
            "store",
            "and",
            "no",
            "secondary",
            "store"
        ]
    },
    {
        "id": 1947,
        "code": "public static ConnectorOffsetBackingStore withOnlyConnectorStore(\n        Supplier<LoggingContext> loggingContext,\n        KafkaOffsetBackingStore connectorStore,\n        String connectorOffsetsTopic,\n        TopicAdmin connectorStoreAdmin\n) {\n    Objects.requireNonNull(loggingContext);\n    Objects.requireNonNull(connectorOffsetsTopic);\n    Objects.requireNonNull(connectorStoreAdmin);\n    return new ConnectorOffsetBackingStore(\n            Time.SYSTEM,\n            loggingContext,\n            connectorOffsetsTopic,\n            null,\n            connectorStore,\n            connectorStoreAdmin\n    );\n}",
        "summary_tokens": [
            "builds",
            "an",
            "offset",
            "store",
            "that",
            "uses",
            "a",
            "connector",
            "specific",
            "offset",
            "topic",
            "as",
            "the",
            "primary",
            "store",
            "and",
            "no",
            "secondary",
            "store"
        ]
    },
    {
        "id": 1948,
        "code": "public void start() {\n        \n    connectorStore.ifPresent(OffsetBackingStore::start);\n}",
        "summary_tokens": [
            "if",
            "configured",
            "to",
            "use",
            "a",
            "connector",
            "specific",
            "offset",
            "store",
            "offset",
            "backing",
            "store",
            "start",
            "start",
            "that",
            "store"
        ]
    },
    {
        "id": 1949,
        "code": "public void stop() {\n        \n    connectorStore.ifPresent(OffsetBackingStore::stop);\n    connectorStoreAdmin.ifPresent(TopicAdmin::close);\n}",
        "summary_tokens": [
            "if",
            "configured",
            "to",
            "use",
            "a",
            "connector",
            "specific",
            "offset",
            "store",
            "offset",
            "backing",
            "store",
            "stop",
            "stop",
            "that",
            "store",
            "and",
            "topic",
            "admin",
            "close",
            "duration",
            "close",
            "the",
            "topic",
            "admin",
            "used",
            "by",
            "that",
            "store"
        ]
    },
    {
        "id": 1950,
        "code": "public Future<Map<ByteBuffer, ByteBuffer>> get(Collection<ByteBuffer> keys) {\n    Future<Map<ByteBuffer, ByteBuffer>> workerGetFuture = getFromStore(workerStore, keys);\n    Future<Map<ByteBuffer, ByteBuffer>> connectorGetFuture = getFromStore(connectorStore, keys);\n\n    return new Future<Map<ByteBuffer, ByteBuffer>>() {\n        @Override\n        public boolean cancel(boolean mayInterruptIfRunning) {\n                \n                \n            return workerGetFuture.cancel(mayInterruptIfRunning)\n                    | connectorGetFuture.cancel(mayInterruptIfRunning);\n        }\n\n        @Override\n        public boolean isCancelled() {\n            return workerGetFuture.isCancelled()\n                    || connectorGetFuture.isCancelled();\n        }\n\n        @Override\n        public boolean isDone() {\n            return workerGetFuture.isDone()\n                    && connectorGetFuture.isDone();\n        }\n\n        @Override\n        public Map<ByteBuffer, ByteBuffer> get() throws InterruptedException, ExecutionException {\n            Map<ByteBuffer, ByteBuffer> result = new HashMap<>(workerGetFuture.get());\n            result.putAll(connectorGetFuture.get());\n            return result;\n        }\n\n        @Override\n        public Map<ByteBuffer, ByteBuffer> get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {\n            long timeoutMs = unit.toMillis(timeout);\n            long endTime = time.milliseconds() + timeoutMs;\n            Map<ByteBuffer, ByteBuffer> result = new HashMap<>(workerGetFuture.get(timeoutMs, unit));\n            timeoutMs = Math.max(1, endTime - time.milliseconds());\n            result.putAll(connectorGetFuture.get(timeoutMs, TimeUnit.MILLISECONDS));\n            return result;\n        }\n    };\n}",
        "summary_tokens": [
            "get",
            "the",
            "offset",
            "values",
            "for",
            "the",
            "specified",
            "keys"
        ]
    },
    {
        "id": 1951,
        "code": "public Future<Void> set(Map<ByteBuffer, ByteBuffer> values, Callback<Void> callback) {\n    final OffsetBackingStore primaryStore;\n    final OffsetBackingStore secondaryStore;\n    if (connectorStore.isPresent()) {\n        primaryStore = connectorStore.get();\n        secondaryStore = workerStore.orElse(null);\n    } else if (workerStore.isPresent()) {\n        primaryStore = workerStore.get();\n        secondaryStore = null;\n    } else {\n            \n            \n        throw new IllegalStateException(\"At least one non-null offset store must be provided\");\n    }\n\n    return primaryStore.set(values, (primaryWriteError, ignored) -> {\n        if (secondaryStore != null) {\n            if (primaryWriteError != null) {\n                log.trace(\"Skipping offsets write to secondary store because primary write has failed\", primaryWriteError);\n            } else {\n                try {\n                        \n                        \n                    secondaryStore.set(values, (secondaryWriteError, ignored2) -> {\n                        try (LoggingContext context = loggingContext()) {\n                            if (secondaryWriteError != null) {\n                                log.warn(\"Failed to write offsets to secondary backing store\", secondaryWriteError);\n                            } else {\n                                log.debug(\"Successfully flushed offsets to secondary backing store\");\n                            }\n                        }\n                    });\n                } catch (Exception e) {\n                    log.warn(\"Failed to write offsets to secondary backing store\", e);\n                }\n            }\n        }\n        try (LoggingContext context = loggingContext()) {\n            callback.onCompletion(primaryWriteError, ignored);\n        }\n    });\n}",
        "summary_tokens": [
            "store",
            "the",
            "specified",
            "offset",
            "key",
            "value",
            "pairs"
        ]
    },
    {
        "id": 1952,
        "code": "public void configure(WorkerConfig config) {\n        \n    connectorStore.ifPresent(store -> store.configure(config));\n}",
        "summary_tokens": [
            "if",
            "configured",
            "to",
            "use",
            "a",
            "connector",
            "specific",
            "offset",
            "store",
            "offset",
            "backing",
            "store",
            "configure",
            "worker",
            "config",
            "configure",
            "that",
            "store"
        ]
    },
    {
        "id": 1953,
        "code": "public ClusterConfigState snapshot() {\n    synchronized (lock) {\n            \n            \n        return new ClusterConfigState(\n                offset,\n                sessionKey,\n                new HashMap<>(connectorTaskCounts),\n                new HashMap<>(connectorConfigs),\n                new HashMap<>(connectorTargetStates),\n                new HashMap<>(taskConfigs),\n                new HashMap<>(connectorTaskCountRecords),\n                new HashMap<>(connectorTaskConfigGenerations),\n                new HashSet<>(connectorsPendingFencing),\n                new HashSet<>(inconsistent),\n                configTransformer\n        );\n    }\n}",
        "summary_tokens": [
            "get",
            "a",
            "snapshot",
            "of",
            "the",
            "current",
            "state",
            "of",
            "the",
            "cluster"
        ]
    },
    {
        "id": 1954,
        "code": "public void putConnectorConfig(String connector, Map<String, String> properties) {\n    log.debug(\"Writing connector configuration for connector '{}'\", connector);\n    Struct connectConfig = new Struct(CONNECTOR_CONFIGURATION_V0);\n    connectConfig.put(\"properties\", properties);\n    byte[] serializedConfig = converter.fromConnectData(topic, CONNECTOR_CONFIGURATION_V0, connectConfig);\n    try {\n        sendPrivileged(CONNECTOR_KEY(connector), serializedConfig);\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write connector configuration to Kafka: \", e);\n        throw new ConnectException(\"Error writing connector configuration to Kafka\", e);\n    }\n}",
        "summary_tokens": [
            "write",
            "this",
            "connector",
            "configuration",
            "to",
            "persistent",
            "storage",
            "and",
            "wait",
            "until",
            "it",
            "has",
            "been",
            "acknowledged",
            "and",
            "read",
            "back",
            "by",
            "tailing",
            "the",
            "kafka",
            "log",
            "with",
            "a",
            "consumer"
        ]
    },
    {
        "id": 1955,
        "code": "public void removeConnectorConfig(String connector) {\n    log.debug(\"Removing connector configuration for connector '{}'\", connector);\n    try {\n        sendPrivileged(CONNECTOR_KEY(connector), null);\n        sendPrivileged(TARGET_STATE_KEY(connector), null);\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to remove connector configuration from Kafka: \", e);\n        throw new ConnectException(\"Error removing connector configuration from Kafka\", e);\n    }\n}",
        "summary_tokens": [
            "remove",
            "configuration",
            "for",
            "a",
            "given",
            "connector"
        ]
    },
    {
        "id": 1956,
        "code": "public void putTaskConfigs(String connector, List<Map<String, String>> configs) {\n        \n        \n    try {\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write root configuration to Kafka: \", e);\n        throw new ConnectException(\"Error writing root configuration to Kafka\", e);\n    }\n\n    int taskCount = configs.size();\n\n        \n    int index = 0;\n    for (Map<String, String> taskConfig: configs) {\n        Struct connectConfig = new Struct(TASK_CONFIGURATION_V0);\n        connectConfig.put(\"properties\", taskConfig);\n        byte[] serializedConfig = converter.fromConnectData(topic, TASK_CONFIGURATION_V0, connectConfig);\n        log.debug(\"Writing configuration for connector '{}' task {}\", connector, index);\n        ConnectorTaskId connectorTaskId = new ConnectorTaskId(connector, index);\n        sendPrivileged(TASK_KEY(connectorTaskId), serializedConfig);\n        index++;\n    }\n\n        \n        \n    try {\n            \n        if (taskCount > 0) {\n            configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n        }\n            \n        Struct connectConfig = new Struct(CONNECTOR_TASKS_COMMIT_V0);\n        connectConfig.put(\"tasks\", taskCount);\n        byte[] serializedConfig = converter.fromConnectData(topic, CONNECTOR_TASKS_COMMIT_V0, connectConfig);\n        log.debug(\"Writing commit for connector '{}' with {} tasks.\", connector, taskCount);\n        sendPrivileged(COMMIT_TASKS_KEY(connector), serializedConfig);\n\n            \n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write root configuration to Kafka: \", e);\n        throw new ConnectException(\"Error writing root configuration to Kafka\", e);\n    }\n}",
        "summary_tokens": [
            "write",
            "these",
            "task",
            "configurations",
            "and",
            "associated",
            "commit",
            "messages",
            "unless",
            "an",
            "inconsistency",
            "is",
            "found",
            "that",
            "indicates",
            "that",
            "we",
            "would",
            "be",
            "leaving",
            "one",
            "of",
            "the",
            "referenced",
            "connectors",
            "with",
            "an",
            "inconsistent",
            "state"
        ]
    },
    {
        "id": 1957,
        "code": "public void putTargetState(String connector, TargetState state) {\n    Struct connectTargetState = new Struct(TARGET_STATE_V0);\n    connectTargetState.put(\"state\", state.name());\n    byte[] serializedTargetState = converter.fromConnectData(topic, TARGET_STATE_V0, connectTargetState);\n    log.debug(\"Writing target state {} for connector {}\", state, connector);\n    configLog.send(TARGET_STATE_KEY(connector), serializedTargetState);\n}",
        "summary_tokens": [
            "write",
            "a",
            "new",
            "target",
            "state",
            "for",
            "the",
            "connector"
        ]
    },
    {
        "id": 1958,
        "code": "public void putTaskCountRecord(String connector, int taskCount) {\n    Struct taskCountRecord = new Struct(TASK_COUNT_RECORD_V0);\n    taskCountRecord.put(\"task-count\", taskCount);\n    byte[] serializedTaskCountRecord = converter.fromConnectData(topic, TASK_COUNT_RECORD_V0, taskCountRecord);\n    log.debug(\"Writing task count record {} for connector {}\", taskCount, connector);\n    try {\n        sendPrivileged(TASK_COUNT_RECORD_KEY(connector), serializedTaskCountRecord);\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write task count record with {} tasks for connector {} to Kafka: \", taskCount, connector, e);\n        throw new ConnectException(\"Error writing task count record to Kafka\", e);\n    }\n}",
        "summary_tokens": [
            "write",
            "a",
            "task",
            "count",
            "record",
            "for",
            "a",
            "connector",
            "to",
            "persistent",
            "storage",
            "and",
            "wait",
            "until",
            "it",
            "has",
            "been",
            "acknowledged",
            "and",
            "read",
            "back",
            "by",
            "tailing",
            "the",
            "kafka",
            "log",
            "with",
            "a",
            "consumer"
        ]
    },
    {
        "id": 1959,
        "code": "public void putSessionKey(SessionKey sessionKey) {\n    log.debug(\"Distributing new session key\");\n    Struct sessionKeyStruct = new Struct(SESSION_KEY_V0);\n    sessionKeyStruct.put(\"key\", Base64.getEncoder().encodeToString(sessionKey.key().getEncoded()));\n    sessionKeyStruct.put(\"algorithm\", sessionKey.key().getAlgorithm());\n    sessionKeyStruct.put(\"creation-timestamp\", sessionKey.creationTimestamp());\n    byte[] serializedSessionKey = converter.fromConnectData(topic, SESSION_KEY_V0, sessionKeyStruct);\n    try {\n        sendPrivileged(SESSION_KEY_KEY, serializedSessionKey);\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write session key to Kafka: \", e);\n        throw new ConnectException(\"Error writing session key to Kafka\", e);\n    }\n}",
        "summary_tokens": [
            "write",
            "a",
            "session",
            "key",
            "to",
            "persistent",
            "storage",
            "and",
            "wait",
            "until",
            "it",
            "has",
            "been",
            "acknowledged",
            "and",
            "read",
            "back",
            "by",
            "tailing",
            "the",
            "kafka",
            "log",
            "with",
            "a",
            "consumer"
        ]
    },
    {
        "id": 1960,
        "code": "public void putRestartRequest(RestartRequest restartRequest) {\n    log.debug(\"Writing {} to Kafka\", restartRequest);\n    String key = RESTART_KEY(restartRequest.connectorName());\n    Struct value = new Struct(RESTART_REQUEST_V0);\n    value.put(INCLUDE_TASKS_FIELD_NAME, restartRequest.includeTasks());\n    value.put(ONLY_FAILED_FIELD_NAME, restartRequest.onlyFailed());\n    byte[] serializedValue = converter.fromConnectData(topic, value.schema(), value);\n    try {\n        sendPrivileged(key, serializedValue);\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write {} to Kafka: \", restartRequest, e);\n        throw new ConnectException(\"Error writing \" + restartRequest + \" to Kafka\", e);\n    }\n}",
        "summary_tokens": [
            "write",
            "a",
            "restart",
            "request",
            "for",
            "the",
            "connector",
            "and",
            "optionally",
            "its",
            "tasks",
            "to",
            "persistent",
            "storage",
            "and",
            "wait",
            "until",
            "it",
            "has",
            "been",
            "acknowledged",
            "and",
            "read",
            "back",
            "by",
            "tailing",
            "the",
            "kafka",
            "log",
            "with",
            "a",
            "consumer"
        ]
    },
    {
        "id": 1961,
        "code": "private Set<Integer> taskIds(String connector, Map<ConnectorTaskId, Map<String, String>> configs) {\n    Set<Integer> tasks = new TreeSet<>();\n    if (configs == null) {\n        return tasks;\n    }\n    for (ConnectorTaskId taskId : configs.keySet()) {\n        assert taskId.connector().equals(connector);\n        tasks.add(taskId.task());\n    }\n    return tasks;\n}",
        "summary_tokens": [
            "given",
            "task",
            "configurations",
            "get",
            "a",
            "set",
            "of",
            "integer",
            "task",
            "ids",
            "for",
            "the",
            "connector"
        ]
    },
    {
        "id": 1962,
        "code": "public static KafkaOffsetBackingStore forTask(\n        String topic,\n        Producer<byte[], byte[]> producer,\n        Consumer<byte[], byte[]> consumer,\n        TopicAdmin topicAdmin\n) {\n    return new KafkaOffsetBackingStore(() -> topicAdmin) {\n        @Override\n        public void configure(final WorkerConfig config) {\n            this.exactlyOnce = config.exactlyOnceSourceEnabled();\n            this.offsetLog = KafkaBasedLog.withExistingClients(\n                    topic,\n                    consumer,\n                    producer,\n                    topicAdmin,\n                    consumedCallback,\n                    Time.SYSTEM,\n                    initialize(topic, newTopicDescription(topic, config))\n            );\n        }\n    };\n}",
        "summary_tokens": [
            "build",
            "a",
            "connector",
            "specific",
            "offset",
            "store",
            "with",
            "read",
            "and",
            "write",
            "support"
        ]
    },
    {
        "id": 1963,
        "code": "public static KafkaOffsetBackingStore forConnector(\n        String topic,\n        Consumer<byte[], byte[]> consumer,\n        TopicAdmin topicAdmin\n) {\n    return new KafkaOffsetBackingStore(() -> topicAdmin) {\n        @Override\n        public void configure(final WorkerConfig config) {\n            this.exactlyOnce = config.exactlyOnceSourceEnabled();\n            this.offsetLog = KafkaBasedLog.withExistingClients(\n                    topic,\n                    consumer,\n                    null,\n                    topicAdmin,\n                    consumedCallback,\n                    Time.SYSTEM,\n                    initialize(topic, newTopicDescription(topic, config))\n            );\n        }\n    };\n}",
        "summary_tokens": [
            "build",
            "a",
            "connector",
            "specific",
            "offset",
            "store",
            "with",
            "read",
            "only",
            "support"
        ]
    },
    {
        "id": 1964,
        "code": "public void stop() {\n    log.info(\"Stopping KafkaOffsetBackingStore\");\n    try {\n        offsetLog.stop();\n    } finally {\n        if (ownTopicAdmin != null) {\n            ownTopicAdmin.close();\n        }\n    }\n    log.info(\"Stopped KafkaOffsetBackingStore\");\n}",
        "summary_tokens": [
            "stop",
            "reading",
            "from",
            "and",
            "writing",
            "to",
            "the",
            "offsets",
            "topic",
            "and",
            "relinquish",
            "resources",
            "allocated",
            "for",
            "interacting",
            "with",
            "it",
            "including",
            "kafka",
            "clients"
        ]
    },
    {
        "id": 1965,
        "code": "public synchronized void offset(Map<String, ?> partition, Map<String, ?> offset) {\n    data.put((Map<String, Object>) partition, (Map<String, Object>) offset);\n}",
        "summary_tokens": [
            "set",
            "an",
            "offset",
            "for",
            "a",
            "partition",
            "using",
            "connect",
            "data",
            "values",
            "partition",
            "the",
            "partition",
            "to",
            "store",
            "an",
            "offset",
            "for",
            "offset",
            "the",
            "offset"
        ]
    },
    {
        "id": 1966,
        "code": "public synchronized boolean beginFlush() {\n    if (flushing()) {\n        log.error(\"Invalid call to OffsetStorageWriter flush() while already flushing, the \"\n                + \"framework should not allow this\");\n        throw new ConnectException(\"OffsetStorageWriter is already flushing\");\n    }\n\n    if (data.isEmpty())\n        return false;\n\n    toFlush = data;\n    data = new HashMap<>();\n    return true;\n}",
        "summary_tokens": [
            "performs",
            "the",
            "first",
            "step",
            "of",
            "a",
            "flush",
            "operation",
            "snapshotting",
            "the",
            "current",
            "state"
        ]
    },
    {
        "id": 1967,
        "code": "public synchronized boolean willFlush() {\n    return !data.isEmpty();\n}",
        "summary_tokens": [
            "whether",
            "there",
            "s",
            "anything",
            "to",
            "flush",
            "right",
            "now"
        ]
    },
    {
        "id": 1968,
        "code": "public Future<Void> doFlush(final Callback<Void> callback) {\n\n    final long flushId;\n        \n    final Map<ByteBuffer, ByteBuffer> offsetsSerialized;\n\n    synchronized (this) {\n        flushId = currentFlushId;\n\n        try {\n            offsetsSerialized = new HashMap<>(toFlush.size());\n            for (Map.Entry<Map<String, Object>, Map<String, Object>> entry : toFlush.entrySet()) {\n                    \n                    \n                OffsetUtils.validateFormat(entry.getKey());\n                OffsetUtils.validateFormat(entry.getValue());\n                    \n                byte[] key = keyConverter.fromConnectData(namespace, null, Arrays.asList(namespace, entry.getKey()));\n                ByteBuffer keyBuffer = (key != null) ? ByteBuffer.wrap(key) : null;\n                byte[] value = valueConverter.fromConnectData(namespace, null, entry.getValue());\n                ByteBuffer valueBuffer = (value != null) ? ByteBuffer.wrap(value) : null;\n                offsetsSerialized.put(keyBuffer, valueBuffer);\n            }\n        } catch (Throwable t) {\n                \n                \n            log.error(\"CRITICAL: Failed to serialize offset data, making it impossible to commit \"\n                    + \"offsets under namespace {}. This likely won't recover unless the \"\n                    + \"unserializable partition or offset information is overwritten.\", namespace);\n            log.error(\"Cause of serialization failure:\", t);\n            callback.onCompletion(t, null);\n            return null;\n        }\n\n            \n        log.debug(\"Submitting {} entries to backing store. The offsets are: {}\", offsetsSerialized.size(), toFlush);\n    }\n\n    return backingStore.set(offsetsSerialized, (error, result) -> {\n        boolean isCurrent = handleFinishWrite(flushId, error, result);\n        if (isCurrent && callback != null) {\n            callback.onCompletion(error, result);\n        }\n    });\n}",
        "summary_tokens": [
            "flush",
            "the",
            "current",
            "offsets",
            "and",
            "clear",
            "them",
            "from",
            "this",
            "writer"
        ]
    },
    {
        "id": 1969,
        "code": "public synchronized void cancelFlush() {\n        \n        \n    if (flushing()) {\n            \n        toFlush.putAll(data);\n        data = toFlush;\n        currentFlushId++;\n        toFlush = null;\n    }\n}",
        "summary_tokens": [
            "cancel",
            "a",
            "flush",
            "that",
            "has",
            "been",
            "initiated",
            "by",
            "begin",
            "flush"
        ]
    },
    {
        "id": 1970,
        "code": "private synchronized boolean handleFinishWrite(long flushId, Throwable error, Void result) {\n        \n        \n    if (flushId != currentFlushId)\n        return false;\n\n    if (error != null) {\n        cancelFlush();\n    } else {\n        currentFlushId++;\n        toFlush = null;\n    }\n    return true;\n}",
        "summary_tokens": [
            "handle",
            "completion",
            "of",
            "a",
            "write"
        ]
    },
    {
        "id": 1971,
        "code": "public static void ensureProperty(\n        Map<String, ? super String> props,\n        String key,\n        String expectedValue,\n        String justification,\n        boolean caseSensitive\n) {\n    ensurePropertyAndGetWarning(props, key, expectedValue, justification, caseSensitive).ifPresent(log::warn);\n}",
        "summary_tokens": [
            "ensure",
            "that",
            "the",
            "map",
            "properties",
            "contain",
            "an",
            "expected",
            "value",
            "for",
            "the",
            "given",
            "key",
            "inserting",
            "the",
            "expected",
            "value",
            "into",
            "the",
            "properties",
            "if",
            "necessary"
        ]
    },
    {
        "id": 1972,
        "code": "static Optional<String> ensurePropertyAndGetWarning(\n        Map<String, ? super String> props,\n        String key,\n        String expectedValue,\n        String justification,\n        boolean caseSensitive) {\n    if (!props.containsKey(key)) {\n            \n        props.put(key, expectedValue);\n            \n        return Optional.empty();\n    }\n\n    String value = Objects.toString(props.get(key));\n    boolean matchesExpectedValue = caseSensitive ? expectedValue.equals(value) : expectedValue.equalsIgnoreCase(value);\n    if (matchesExpectedValue) {\n        return Optional.empty();\n    }\n\n        \n    props.put(key, expectedValue);\n\n    justification = justification != null ? \" \" + justification : \"\";\n        \n    return Optional.of(String.format(\n            \"The value '%s' for the '%s' property will be ignored as it cannot be overridden%s. \"\n                    + \"The value '%s' will be used instead.\",\n            value, key, justification, expectedValue\n    ));\n}",
        "summary_tokens": [
            "ensure",
            "that",
            "a",
            "given",
            "key",
            "has",
            "an",
            "expected",
            "value",
            "in",
            "the",
            "properties",
            "inserting",
            "the",
            "expected",
            "value",
            "into",
            "the",
            "properties",
            "if",
            "necessary"
        ]
    },
    {
        "id": 1973,
        "code": "public static <K, V> KafkaBasedLog<K, V> withExistingClients(String topic,\n                                                             Consumer<K, V> consumer,\n                                                             Producer<K, V> producer,\n                                                             TopicAdmin topicAdmin,\n                                                             Callback<ConsumerRecord<K, V>> consumedCallback,\n                                                             Time time,\n                                                             java.util.function.Consumer<TopicAdmin> initializer) {\n    Objects.requireNonNull(topicAdmin);\n    return new KafkaBasedLog<K, V>(topic,\n            Collections.emptyMap(),\n            Collections.emptyMap(),\n            () -> topicAdmin,\n            consumedCallback,\n            time,\n            initializer) {\n\n        @Override\n        protected Producer<K, V> createProducer() {\n            return producer;\n        }\n\n        @Override\n        protected Consumer<K, V> createConsumer() {\n            return consumer;\n        }\n    };\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "kafka",
            "based",
            "log",
            "object",
            "using",
            "pre",
            "existing",
            "kafka",
            "clients"
        ]
    },
    {
        "id": 1974,
        "code": "public Future<Void> readToEnd() {\n    FutureCallback<Void> future = new FutureCallback<>(null);\n    readToEnd(future);\n    return future;\n}",
        "summary_tokens": [
            "same",
            "as",
            "read",
            "to",
            "end",
            "callback",
            "but",
            "provides",
            "a",
            "future",
            "instead",
            "of",
            "using",
            "a",
            "callback"
        ]
    },
    {
        "id": 1975,
        "code": "public void flush() {\n    producer.ifPresent(Producer::flush);\n}",
        "summary_tokens": [
            "flush",
            "the",
            "underlying",
            "producer",
            "to",
            "ensure",
            "that",
            "all",
            "pending",
            "writes",
            "have",
            "been",
            "sent"
        ]
    },
    {
        "id": 1976,
        "code": "private void readToLogEnd(boolean shouldRetry) {\n    Set<TopicPartition> assignment = consumer.assignment();\n    Map<TopicPartition, Long> endOffsets = readEndOffsets(assignment, shouldRetry);\n    log.trace(\"Reading to end of log offsets {}\", endOffsets);\n\n    while (!endOffsets.isEmpty()) {\n        Iterator<Map.Entry<TopicPartition, Long>> it = endOffsets.entrySet().iterator();\n        while (it.hasNext()) {\n            Map.Entry<TopicPartition, Long> entry = it.next();\n            TopicPartition topicPartition = entry.getKey();\n            long endOffset = entry.getValue();\n            long lastConsumedOffset = consumer.position(topicPartition);\n            if (lastConsumedOffset >= endOffset) {\n                log.trace(\"Read to end offset {} for {}\", endOffset, topicPartition);\n                it.remove();\n            } else {\n                log.trace(\"Behind end offset {} for {}; last-read offset is {}\",\n                        endOffset, topicPartition, lastConsumedOffset);\n                poll(Integer.MAX_VALUE);\n                break;\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "finds",
            "the",
            "end",
            "offsets",
            "of",
            "the",
            "kafka",
            "log",
            "s",
            "topic",
            "partitions",
            "optionally",
            "retrying",
            "if",
            "the",
            "list",
            "offsets",
            "method",
            "of",
            "the",
            "admin",
            "client",
            "throws",
            "a",
            "retriable",
            "exception"
        ]
    },
    {
        "id": 1977,
        "code": "Map<TopicPartition, Long> readEndOffsets(Set<TopicPartition> assignment, boolean shouldRetry) throws UnsupportedVersionException {\n    log.trace(\"Reading to end of offset log\");\n\n        \n        \n        \n        \n        \n        \n\n        \n    if (admin != null) {\n            \n            \n        try {\n            if (shouldRetry) {\n                return admin.retryEndOffsets(assignment,\n                        ADMIN_CLIENT_RETRY_DURATION,\n                        ADMIN_CLIENT_RETRY_BACKOFF_MS);\n            }\n\n            return admin.endOffsets(assignment);\n        } catch (UnsupportedVersionException e) {\n                \n                \n            if (requireAdminForOffsets) {\n                    \n                throw e;\n            }\n            log.debug(\"Reading to end of log offsets with consumer since admin client is unsupported: {}\", e.getMessage());\n                \n            admin = null;\n                \n        }\n            \n    }\n        \n        \n    return consumer.endOffsets(assignment);\n}",
        "summary_tokens": [
            "read",
            "to",
            "the",
            "end",
            "of",
            "the",
            "given",
            "list",
            "of",
            "topic",
            "partitions",
            "assignment",
            "the",
            "topic",
            "partitions",
            "to",
            "read",
            "to",
            "the",
            "end",
            "of",
            "should",
            "retry",
            "boolean",
            "flag",
            "to",
            "enable",
            "retry",
            "for",
            "the",
            "admin",
            "client",
            "list",
            "offsets",
            "call"
        ]
    },
    {
        "id": 1978,
        "code": "public static void clear() {\n    MDC.clear();\n}",
        "summary_tokens": [
            "clear",
            "all",
            "mdc",
            "parameters"
        ]
    },
    {
        "id": 1979,
        "code": "public static LoggingContext forConnector(String connectorName) {\n    Objects.requireNonNull(connectorName);\n    LoggingContext context = new LoggingContext();\n    MDC.put(CONNECTOR_CONTEXT, prefixFor(connectorName, Scope.WORKER, null));\n    return context;\n}",
        "summary_tokens": [
            "modify",
            "the",
            "current",
            "mdc",
            "logging",
            "context",
            "to",
            "set",
            "the",
            "connector",
            "context",
            "connector",
            "context",
            "to",
            "include",
            "the",
            "supplied",
            "name",
            "and",
            "the",
            "scope",
            "worker",
            "scope"
        ]
    },
    {
        "id": 1980,
        "code": "public static LoggingContext forValidation(String connectorName) {\n    LoggingContext context = new LoggingContext();\n    MDC.put(CONNECTOR_CONTEXT, prefixFor(connectorName, Scope.VALIDATE, null));\n    return context;\n}",
        "summary_tokens": [
            "modify",
            "the",
            "current",
            "mdc",
            "logging",
            "context",
            "to",
            "set",
            "the",
            "connector",
            "context",
            "connector",
            "context",
            "to",
            "include",
            "the",
            "supplied",
            "connector",
            "name",
            "and",
            "the",
            "scope",
            "validate",
            "scope"
        ]
    },
    {
        "id": 1981,
        "code": "public static LoggingContext forTask(ConnectorTaskId id) {\n    Objects.requireNonNull(id);\n    LoggingContext context = new LoggingContext();\n    MDC.put(CONNECTOR_CONTEXT, prefixFor(id.connector(), Scope.TASK, id.task()));\n    return context;\n}",
        "summary_tokens": [
            "modify",
            "the",
            "current",
            "mdc",
            "logging",
            "context",
            "to",
            "set",
            "the",
            "connector",
            "context",
            "connector",
            "context",
            "to",
            "include",
            "the",
            "connector",
            "name",
            "and",
            "task",
            "number",
            "using",
            "the",
            "supplied",
            "connector",
            "task",
            "id",
            "and",
            "to",
            "set",
            "the",
            "scope",
            "to",
            "scope",
            "task"
        ]
    },
    {
        "id": 1982,
        "code": "public static LoggingContext forOffsets(ConnectorTaskId id) {\n    Objects.requireNonNull(id);\n    LoggingContext context = new LoggingContext();\n    MDC.put(CONNECTOR_CONTEXT, prefixFor(id.connector(), Scope.OFFSETS, id.task()));\n    return context;\n}",
        "summary_tokens": [
            "modify",
            "the",
            "current",
            "mdc",
            "logging",
            "context",
            "to",
            "set",
            "the",
            "connector",
            "context",
            "connector",
            "context",
            "to",
            "include",
            "the",
            "connector",
            "name",
            "and",
            "task",
            "number",
            "using",
            "the",
            "supplied",
            "connector",
            "task",
            "id",
            "and",
            "to",
            "set",
            "the",
            "scope",
            "to",
            "scope",
            "offsets"
        ]
    },
    {
        "id": 1983,
        "code": "protected static String prefixFor(String connectorName, Scope scope, Integer taskNumber) {\n    StringBuilder sb = new StringBuilder();\n    sb.append(\"[\");\n    sb.append(connectorName);\n    if (taskNumber != null) {\n            \n        sb.append(\"|\");\n        sb.append(Scope.TASK);\n        sb.append(\"-\");\n        sb.append(taskNumber);\n    }\n        \n    if (scope != Scope.TASK) {\n        sb.append(\"|\");\n        sb.append(scope.toString());\n    }\n    sb.append(\"] \");\n    return sb.toString();\n}",
        "summary_tokens": [
            "return",
            "the",
            "prefix",
            "that",
            "uses",
            "the",
            "specified",
            "connector",
            "name",
            "task",
            "number",
            "and",
            "scope"
        ]
    },
    {
        "id": 1984,
        "code": "public void close() {\n    for (String param : ALL_CONTEXTS) {\n        if (previous != null && previous.containsKey(param)) {\n            MDC.put(param, previous.get(param));\n        } else {\n            MDC.remove(param);\n        }\n    }\n}",
        "summary_tokens": [
            "close",
            "this",
            "logging",
            "context",
            "restoring",
            "the",
            "connect",
            "mdc",
            "parameters",
            "back",
            "to",
            "the",
            "state",
            "just",
            "before",
            "this",
            "context",
            "was",
            "created"
        ]
    },
    {
        "id": 1985,
        "code": "public static <T> T retryUntilTimeout(Callable<T> callable, Supplier<String> description, Duration timeoutDuration, long retryBackoffMs) throws Exception {\n        \n    final String descriptionStr = Optional.ofNullable(description)\n            .map(Supplier::get)\n            .orElse(\"callable\");\n\n        \n    final long timeoutMs = Optional.ofNullable(timeoutDuration)\n            .map(Duration::toMillis)\n            .orElse(0L);\n\n    if (retryBackoffMs < 0) {\n        log.debug(\"Assuming no retry backoff since retryBackoffMs={} is negative\", retryBackoffMs);\n        retryBackoffMs = 0;\n    }\n    if (timeoutMs <= 0 || retryBackoffMs >= timeoutMs) {\n        log.debug(\"Executing {} only once, since timeoutMs={} is not larger than retryBackoffMs={}\",\n                descriptionStr, timeoutMs, retryBackoffMs);\n        return callable.call();\n    }\n\n    final long end = System.currentTimeMillis() + timeoutMs;\n    int attempt = 0;\n    Throwable lastError = null;\n    do {\n        attempt++;\n        try {\n            return callable.call();\n        } catch (RetriableException | org.apache.kafka.connect.errors.RetriableException e) {\n            log.warn(\"Attempt {} to {} resulted in RetriableException; retrying automatically. \" +\n                    \"Reason: {}\", attempt, descriptionStr, e.getMessage(), e);\n            lastError = e;\n        } catch (WakeupException e) {\n            lastError = e;\n        }\n\n        if (retryBackoffMs > 0) {\n            long millisRemaining = Math.max(0, end - System.currentTimeMillis());\n            if (millisRemaining < retryBackoffMs) {\n                    \n                break;\n            }\n            Utils.sleep(retryBackoffMs);\n        }\n    } while (System.currentTimeMillis() < end);\n\n    throw new ConnectException(\"Fail to \" + descriptionStr + \" after \" + attempt + \" attempts.  Reason: \" + lastError.getMessage(), lastError);\n}",
        "summary_tokens": [
            "the",
            "method",
            "executes",
            "the",
            "callable",
            "at",
            "least",
            "once",
            "optionally",
            "retrying",
            "the",
            "callable",
            "if",
            "org"
        ]
    },
    {
        "id": 1986,
        "code": "public TopicAdmin get() {\n    return topicAdmin();\n}",
        "summary_tokens": [
            "get",
            "the",
            "shared",
            "topic",
            "admin",
            "instance"
        ]
    },
    {
        "id": 1987,
        "code": "public TopicAdmin topicAdmin() {\n    return admin.updateAndGet(this::createAdmin);\n}",
        "summary_tokens": [
            "get",
            "the",
            "shared",
            "topic",
            "admin",
            "instance"
        ]
    },
    {
        "id": 1988,
        "code": "public String bootstrapServers() {\n    return adminProps.getOrDefault(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"<unknown>\").toString();\n}",
        "summary_tokens": [
            "get",
            "the",
            "string",
            "containing",
            "the",
            "list",
            "of",
            "bootstrap",
            "server",
            "addresses",
            "to",
            "the",
            "kafka",
            "broker",
            "s",
            "to",
            "which",
            "the",
            "admin",
            "client",
            "connects"
        ]
    },
    {
        "id": 1989,
        "code": "public void close(Duration timeout) {\n    Objects.requireNonNull(timeout);\n    if (this.closed.compareAndSet(false, true)) {\n        TopicAdmin admin = this.admin.getAndSet(null);\n        if (admin != null) {\n            admin.close(timeout);\n        }\n    }\n}",
        "summary_tokens": [
            "close",
            "the",
            "underlying",
            "topic",
            "admin",
            "instance",
            "if",
            "one",
            "has",
            "been",
            "created",
            "and",
            "prevent",
            "new",
            "ones",
            "from",
            "being",
            "created"
        ]
    },
    {
        "id": 1990,
        "code": "protected TopicAdmin createAdmin(TopicAdmin existing) {\n    if (closed.get()) {\n        throw new ConnectException(\"The \" + this + \" has already been closed and cannot be used.\");\n    }\n    if (existing != null) {\n        return existing;\n    }\n    return factory.apply(adminProps);\n}",
        "summary_tokens": [
            "method",
            "used",
            "to",
            "create",
            "a",
            "topic",
            "admin",
            "instance"
        ]
    },
    {
        "id": 1991,
        "code": "public static NewTopicBuilder defineTopic(String topicName) {\n    return new NewTopicBuilder(topicName);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "new",
            "topic",
            "builder",
            "builder",
            "to",
            "define",
            "a",
            "new",
            "topic"
        ]
    },
    {
        "id": 1992,
        "code": "public boolean createTopic(NewTopic topic) {\n    if (topic == null) return false;\n    Set<String> newTopicNames = createTopics(topic);\n    return newTopicNames.contains(topic.name());\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "create",
            "the",
            "topic",
            "described",
            "by",
            "the",
            "given",
            "definition",
            "returning",
            "true",
            "if",
            "the",
            "topic",
            "was",
            "created",
            "or",
            "false",
            "if",
            "the",
            "topic",
            "already",
            "existed"
        ]
    },
    {
        "id": 1993,
        "code": "public Set<String> createTopics(NewTopic... topics) {\n    return createOrFindTopics(topics).createdTopics();\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "create",
            "the",
            "topics",
            "described",
            "by",
            "the",
            "given",
            "definitions",
            "returning",
            "all",
            "of",
            "the",
            "names",
            "of",
            "those",
            "topics",
            "that",
            "were",
            "created",
            "by",
            "this",
            "request"
        ]
    },
    {
        "id": 1994,
        "code": "public boolean createOrFindTopic(NewTopic topic) {\n    if (topic == null) return false;\n    return createOrFindTopics(topic).isCreatedOrExisting(topic.name());\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "find",
            "or",
            "create",
            "the",
            "topic",
            "described",
            "by",
            "the",
            "given",
            "definition",
            "returning",
            "true",
            "if",
            "the",
            "topic",
            "was",
            "created",
            "or",
            "had",
            "already",
            "existed",
            "or",
            "false",
            "if",
            "the",
            "topic",
            "did",
            "not",
            "exist",
            "and",
            "could",
            "not",
            "be",
            "created"
        ]
    },
    {
        "id": 1995,
        "code": "public TopicCreationResponse createOrFindTopics(NewTopic... topics) {\n    Map<String, NewTopic> topicsByName = new HashMap<>();\n    if (topics != null) {\n        for (NewTopic topic : topics) {\n            if (topic != null) topicsByName.put(topic.name(), topic);\n        }\n    }\n    if (topicsByName.isEmpty()) return EMPTY_CREATION;\n    String topicNameList = Utils.join(topicsByName.keySet(), \"', '\");\n\n        \n    CreateTopicsOptions args = new CreateTopicsOptions().validateOnly(false);\n    Map<String, KafkaFuture<Void>> newResults = admin.createTopics(topicsByName.values(), args).values();\n\n        \n    Set<String> newlyCreatedTopicNames = new HashSet<>();\n    Set<String> existingTopicNames = new HashSet<>();\n    for (Map.Entry<String, KafkaFuture<Void>> entry : newResults.entrySet()) {\n        String topic = entry.getKey();\n        try {\n            entry.getValue().get();\n            if (logCreation) {\n                log.info(\"Created topic {} on brokers at {}\", topicsByName.get(topic), bootstrapServers);\n            }\n            newlyCreatedTopicNames.add(topic);\n        } catch (ExecutionException e) {\n            Throwable cause = e.getCause();\n            if (cause instanceof TopicExistsException) {\n                log.debug(\"Found existing topic '{}' on the brokers at {}\", topic, bootstrapServers);\n                existingTopicNames.add(topic);\n                continue;\n            }\n            if (cause instanceof UnsupportedVersionException) {\n                log.debug(\"Unable to create topic(s) '{}' since the brokers at {} do not support the CreateTopics API.\" +\n                        \" Falling back to assume topic(s) exist or will be auto-created by the broker.\",\n                        topicNameList, bootstrapServers);\n                return EMPTY_CREATION;\n            }\n            if (cause instanceof ClusterAuthorizationException) {\n                log.debug(\"Not authorized to create topic(s) '{}' upon the brokers {}.\" +\n                        \" Falling back to assume topic(s) exist or will be auto-created by the broker.\",\n                        topicNameList, bootstrapServers);\n                return EMPTY_CREATION;\n            }\n            if (cause instanceof TopicAuthorizationException) {\n                log.debug(\"Not authorized to create topic(s) '{}' upon the brokers {}.\" +\n                                \" Falling back to assume topic(s) exist or will be auto-created by the broker.\",\n                        topicNameList, bootstrapServers);\n                return EMPTY_CREATION;\n            }\n            if (cause instanceof InvalidConfigurationException) {\n                throw new ConnectException(\"Unable to create topic(s) '\" + topicNameList + \"': \" + cause.getMessage(),\n                        cause);\n            }\n            if (cause instanceof TimeoutException) {\n                    \n                throw new ConnectException(\"Timed out while checking for or creating topic(s) '\" + topicNameList + \"'.\" +\n                        \" This could indicate a connectivity issue, unavailable topic partitions, or if\" +\n                        \" this is your first use of the topic it may have taken too long to create.\", cause);\n            }\n            throw new ConnectException(\"Error while attempting to create/find topic(s) '\" + topicNameList + \"'\", e);\n        } catch (InterruptedException e) {\n            Thread.interrupted();\n            throw new ConnectException(\"Interrupted while attempting to create/find topic(s) '\" + topicNameList + \"'\", e);\n        }\n    }\n    return new TopicCreationResponse(newlyCreatedTopicNames, existingTopicNames);\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "create",
            "the",
            "topics",
            "described",
            "by",
            "the",
            "given",
            "definitions",
            "returning",
            "all",
            "of",
            "the",
            "names",
            "of",
            "those",
            "topics",
            "that",
            "were",
            "created",
            "by",
            "this",
            "request"
        ]
    },
    {
        "id": 1996,
        "code": "public Map<String, TopicDescription> describeTopics(String... topics) {\n    if (topics == null) {\n        return Collections.emptyMap();\n    }\n    String topicNameList = String.join(\", \", topics);\n\n    Map<String, KafkaFuture<TopicDescription>> newResults =\n            admin.describeTopics(Arrays.asList(topics), new DescribeTopicsOptions()).topicNameValues();\n\n        \n    Map<String, TopicDescription> existingTopics = new HashMap<>();\n    newResults.forEach((topic, desc) -> {\n        try {\n            existingTopics.put(topic, desc.get());\n        } catch (ExecutionException e) {\n            Throwable cause = e.getCause();\n            if (cause instanceof UnknownTopicOrPartitionException) {\n                log.debug(\"Topic '{}' does not exist on the brokers at {}\", topic, bootstrapServers);\n                return;\n            }\n            if (cause instanceof ClusterAuthorizationException || cause instanceof TopicAuthorizationException) {\n                String msg = String.format(\"Not authorized to describe topic(s) '%s' on the brokers %s\",\n                        topicNameList, bootstrapServers);\n                throw new ConnectException(msg, cause);\n            }\n            if (cause instanceof UnsupportedVersionException) {\n                String msg = String.format(\"Unable to describe topic(s) '%s' since the brokers \"\n                                + \"at %s do not support the DescribeTopics API.\",\n                        topicNameList, bootstrapServers);\n                throw new ConnectException(msg, cause);\n            }\n            if (cause instanceof TimeoutException) {\n                    \n                throw new RetriableException(\"Timed out while describing topics '\" + topicNameList + \"'\", cause);\n            }\n            throw new ConnectException(\"Error while attempting to describe topics '\" + topicNameList + \"'\", e);\n        } catch (InterruptedException e) {\n            Thread.interrupted();\n            throw new RetriableException(\"Interrupted while attempting to describe topics '\" + topicNameList + \"'\", e);\n        }\n    });\n    return existingTopics;\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "fetch",
            "the",
            "descriptions",
            "of",
            "the",
            "given",
            "topics",
            "apache",
            "kafka",
            "added",
            "support",
            "for",
            "describing",
            "topics",
            "in",
            "0"
        ]
    },
    {
        "id": 1997,
        "code": "public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n        String topicPurpose) {\n    Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n    if (cleanupPolicies.isEmpty()) {\n        log.info(\"Unable to use admin client to verify the cleanup policy of '{}' \"\n                  + \"topic is '{}', either because the broker is an older \"\n                  + \"version or because the Kafka principal used for Connect \"\n                  + \"internal topics does not have the required permission to \"\n                  + \"describe topic configurations.\", topic, TopicConfig.CLEANUP_POLICY_COMPACT);\n        return false;\n    }\n    Set<String> expectedPolicies = Collections.singleton(TopicConfig.CLEANUP_POLICY_COMPACT);\n    if (!cleanupPolicies.equals(expectedPolicies)) {\n        String expectedPolicyStr = String.join(\",\", expectedPolicies);\n        String cleanupPolicyStr = String.join(\",\", cleanupPolicies);\n        String msg = String.format(\"Topic '%s' supplied via the '%s' property is required \"\n                + \"to have '%s=%s' to guarantee consistency and durability of \"\n                + \"%s, but found the topic currently has '%s=%s'. Continuing would likely \"\n                + \"result in eventually losing %s and problems restarting this Connect \"\n                + \"cluster in the future. Change the '%s' property in the \"\n                + \"Connect worker configurations to use a topic with '%s=%s'.\",\n                topic, workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr,\n                topicPurpose, TopicConfig.CLEANUP_POLICY_CONFIG, cleanupPolicyStr, topicPurpose,\n                workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr);\n        throw new ConfigException(msg);\n    }\n    return true;\n}",
        "summary_tokens": [
            "verify",
            "the",
            "named",
            "topic",
            "uses",
            "only",
            "compaction",
            "for",
            "the",
            "cleanup",
            "policy"
        ]
    },
    {
        "id": 1998,
        "code": "public Set<String> topicCleanupPolicy(String topic) {\n    Config topicConfig = describeTopicConfig(topic);\n    if (topicConfig == null) {\n            \n        log.debug(\"Unable to find topic '{}' when getting cleanup policy\", topic);\n        return Collections.emptySet();\n    }\n    ConfigEntry entry = topicConfig.get(CLEANUP_POLICY_CONFIG);\n    if (entry != null && entry.value() != null) {\n        String policyStr = entry.value();\n        log.debug(\"Found cleanup.policy={} for topic '{}'\", policyStr, topic);\n        return Arrays.stream(policyStr.split(\",\"))\n                     .map(String::trim)\n                     .filter(s -> !s.isEmpty())\n                     .map(String::toLowerCase)\n                     .collect(Collectors.toSet());\n    }\n        \n        \n    log.debug(\"Found no cleanup.policy for topic '{}'\", topic);\n    return Collections.emptySet();\n}",
        "summary_tokens": [
            "get",
            "the",
            "cleanup",
            "policy",
            "for",
            "a",
            "topic"
        ]
    },
    {
        "id": 1999,
        "code": "public Config describeTopicConfig(String topic) {\n    return describeTopicConfigs(topic).get(topic);\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "fetch",
            "the",
            "topic",
            "configuration",
            "for",
            "the",
            "given",
            "topic"
        ]
    },
    {
        "id": 2000,
        "code": "public Map<String, Config> describeTopicConfigs(String... topicNames) {\n    if (topicNames == null) {\n        return Collections.emptyMap();\n    }\n    Collection<String> topics = Arrays.stream(topicNames)\n                                      .filter(Objects::nonNull)\n                                      .map(String::trim)\n                                      .filter(s -> !s.isEmpty())\n                                      .collect(Collectors.toList());\n    if (topics.isEmpty()) {\n        return Collections.emptyMap();\n    }\n    String topicNameList = String.join(\", \", topics);\n    Collection<ConfigResource> resources = topics.stream()\n                                                 .map(t -> new ConfigResource(ConfigResource.Type.TOPIC, t))\n                                                 .collect(Collectors.toList());\n\n    Map<ConfigResource, KafkaFuture<Config>> newResults = admin.describeConfigs(resources, new DescribeConfigsOptions()).values();\n\n        \n    Map<String, Config> result = new HashMap<>();\n    newResults.forEach((resource, configs) -> {\n        String topic = resource.name();\n        try {\n            result.put(topic, configs.get());\n        } catch (ExecutionException e) {\n            Throwable cause = e.getCause();\n            if (cause instanceof UnknownTopicOrPartitionException) {\n                log.debug(\"Topic '{}' does not exist on the brokers at {}\", topic, bootstrapServers);\n                result.put(topic, null);\n            } else if (cause instanceof ClusterAuthorizationException || cause instanceof TopicAuthorizationException) {\n                log.debug(\"Not authorized to describe topic config for topic '{}' on brokers at {}\", topic, bootstrapServers);\n            } else if (cause instanceof UnsupportedVersionException) {\n                log.debug(\"API to describe topic config for topic '{}' is unsupported on brokers at {}\", topic, bootstrapServers);\n            } else if (cause instanceof TimeoutException) {\n                String msg = String.format(\"Timed out while waiting to describe topic config for topic '%s' on brokers at %s\",\n                        topic, bootstrapServers);\n                throw new RetriableException(msg, e);\n            } else {\n                String msg = String.format(\"Error while attempting to describe topic config for topic '%s' on brokers at %s\",\n                        topic, bootstrapServers);\n                throw new ConnectException(msg, e);\n            }\n        } catch (InterruptedException e) {\n            Thread.interrupted();\n            String msg = String.format(\"Interrupted while attempting to describe topic configs '%s'\", topicNameList);\n            throw new RetriableException(msg, e);\n        }\n    });\n    return result;\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "fetch",
            "the",
            "topic",
            "configurations",
            "for",
            "the",
            "given",
            "topics"
        ]
    },
    {
        "id": 2001,
        "code": "public Map<TopicPartition, Long> endOffsets(Set<TopicPartition> partitions) {\n    if (partitions == null || partitions.isEmpty()) {\n        return Collections.emptyMap();\n    }\n    Map<TopicPartition, OffsetSpec> offsetSpecMap = partitions.stream().collect(Collectors.toMap(Function.identity(), tp -> OffsetSpec.latest()));\n    ListOffsetsResult resultFuture = admin.listOffsets(offsetSpecMap, new ListOffsetsOptions(IsolationLevel.READ_UNCOMMITTED));\n        \n    Map<TopicPartition, Long> result = new HashMap<>();\n    for (TopicPartition partition : partitions) {\n        try {\n            ListOffsetsResultInfo info = resultFuture.partitionResult(partition).get();\n            result.put(partition, info.offset());\n        } catch (ExecutionException e) {\n            Throwable cause = e.getCause();\n            String topic = partition.topic();\n            if (cause instanceof AuthorizationException) {\n                String msg = String.format(\"Not authorized to get the end offsets for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new ConnectException(msg, e);\n            } else if (cause instanceof UnsupportedVersionException) {\n                    \n                    \n                String msg = String.format(\"API to get the get the end offsets for topic '%s' is unsupported on brokers at %s\", topic, bootstrapServers);\n                throw new UnsupportedVersionException(msg, e);\n            } else if (cause instanceof TimeoutException) {\n                String msg = String.format(\"Timed out while waiting to get end offsets for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new TimeoutException(msg, e);\n            } else if (cause instanceof LeaderNotAvailableException) {\n                String msg = String.format(\"Unable to get end offsets during leader election for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new LeaderNotAvailableException(msg, e);\n            } else if (cause instanceof org.apache.kafka.common.errors.RetriableException) {\n                throw (org.apache.kafka.common.errors.RetriableException) cause;\n            } else {\n                String msg = String.format(\"Error while getting end offsets for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new ConnectException(msg, e);\n            }\n        } catch (InterruptedException e) {\n            Thread.interrupted();\n            String msg = String.format(\"Interrupted while attempting to read end offsets for topic '%s' on brokers at %s\", partition.topic(), bootstrapServers);\n            throw new RetriableException(msg, e);\n        }\n    }\n    return result;\n}",
        "summary_tokens": [
            "fetch",
            "the",
            "most",
            "recent",
            "offset",
            "for",
            "each",
            "of",
            "the",
            "supplied",
            "topic",
            "partition",
            "objects"
        ]
    },
    {
        "id": 2002,
        "code": "public Map<TopicPartition, Long> retryEndOffsets(Set<TopicPartition> partitions, Duration timeoutDuration, long retryBackoffMs) {\n\n    try {\n        return RetryUtil.retryUntilTimeout(\n                () -> endOffsets(partitions),\n                () -> \"list offsets for topic partitions\",\n                timeoutDuration,\n                retryBackoffMs);\n    } catch (UnsupportedVersionException e) {\n            \n        throw e;\n    } catch (Exception e) {\n        throw new ConnectException(\"Failed to list offsets for topic partitions.\", e);\n    }\n}",
        "summary_tokens": [
            "fetch",
            "the",
            "most",
            "recent",
            "offset",
            "for",
            "each",
            "of",
            "the",
            "supplied",
            "topic",
            "partition",
            "objects",
            "and",
            "performs",
            "retry",
            "when",
            "org"
        ]
    },
    {
        "id": 2003,
        "code": "public static TopicCreation empty() {\n    return EMPTY;\n}",
        "summary_tokens": [
            "return",
            "an",
            "instance",
            "of",
            "this",
            "utility",
            "that",
            "represents",
            "what",
            "the",
            "state",
            "of",
            "the",
            "internal",
            "data",
            "structures",
            "should",
            "be",
            "when",
            "topic",
            "creation",
            "is",
            "disabled"
        ]
    },
    {
        "id": 2004,
        "code": "public boolean isTopicCreationEnabled() {\n    return isTopicCreationEnabled;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "topic",
            "creation",
            "is",
            "enabled",
            "for",
            "this",
            "utility",
            "instance"
        ]
    },
    {
        "id": 2005,
        "code": "public boolean isTopicCreationRequired(String topic) {\n    return isTopicCreationEnabled && !topicCache.contains(topic);\n}",
        "summary_tokens": [
            "check",
            "whether",
            "topic",
            "creation",
            "may",
            "be",
            "required",
            "for",
            "a",
            "specific",
            "topic",
            "name"
        ]
    },
    {
        "id": 2006,
        "code": "public TopicCreationGroup defaultTopicGroup() {\n    return defaultTopicGroup;\n}",
        "summary_tokens": [
            "return",
            "the",
            "default",
            "topic",
            "creation",
            "group"
        ]
    },
    {
        "id": 2007,
        "code": "public Map<String, TopicCreationGroup> topicGroups() {\n    return topicGroups;\n}",
        "summary_tokens": [
            "return",
            "the",
            "topic",
            "creation",
            "groups",
            "defined",
            "for",
            "a",
            "source",
            "connector",
            "as",
            "a",
            "map",
            "of",
            "topic",
            "creation",
            "group",
            "name",
            "to",
            "topic",
            "creation",
            "group",
            "instance"
        ]
    },
    {
        "id": 2008,
        "code": "public void addTopic(String topic) {\n    if (isTopicCreationEnabled) {\n        topicCache.add(topic);\n    }\n}",
        "summary_tokens": [
            "inform",
            "this",
            "utility",
            "instance",
            "that",
            "a",
            "topic",
            "has",
            "been",
            "created",
            "and",
            "its",
            "creation",
            "will",
            "no",
            "longer",
            "be",
            "required"
        ]
    },
    {
        "id": 2009,
        "code": "public TopicCreationGroup findFirstGroup(String topic) {\n    return topicGroups.values().stream()\n            .filter(group -> group.matches(topic))\n            .findFirst()\n            .orElse(defaultTopicGroup);\n}",
        "summary_tokens": [
            "get",
            "the",
            "first",
            "topic",
            "creation",
            "group",
            "that",
            "is",
            "configured",
            "to",
            "match",
            "the",
            "given",
            "topic",
            "name"
        ]
    },
    {
        "id": 2010,
        "code": "public static Map<String, TopicCreationGroup> configuredGroups(SourceConnectorConfig config) {\n    if (!config.usesTopicCreation()) {\n        return Collections.emptyMap();\n    }\n    List<String> groupNames = config.getList(TOPIC_CREATION_GROUPS_CONFIG);\n    Map<String, TopicCreationGroup> groups = new LinkedHashMap<>();\n    for (String group : groupNames) {\n        groups.put(group, new TopicCreationGroup(group, config));\n    }\n        \n        \n        \n    groups.put(DEFAULT_TOPIC_CREATION_GROUP, new TopicCreationGroup(DEFAULT_TOPIC_CREATION_GROUP, config));\n    return groups;\n}",
        "summary_tokens": [
            "parses",
            "the",
            "configuration",
            "of",
            "a",
            "source",
            "connector",
            "and",
            "returns",
            "the",
            "topic",
            "creation",
            "groups",
            "defined",
            "in",
            "the",
            "given",
            "configuration",
            "as",
            "a",
            "map",
            "of",
            "group",
            "names",
            "to",
            "topic",
            "creation",
            "objects"
        ]
    },
    {
        "id": 2011,
        "code": "public String name() {\n    return name;\n}",
        "summary_tokens": [
            "return",
            "the",
            "name",
            "of",
            "the",
            "topic",
            "creation",
            "group"
        ]
    },
    {
        "id": 2012,
        "code": "public boolean matches(String topic) {\n    return !exclusionPattern.matcher(topic).matches() && inclusionPattern.matcher(topic)\n            .matches();\n}",
        "summary_tokens": [
            "answer",
            "whether",
            "this",
            "topic",
            "creation",
            "group",
            "is",
            "configured",
            "to",
            "allow",
            "the",
            "creation",
            "of",
            "the",
            "given",
            "topic",
            "name"
        ]
    },
    {
        "id": 2013,
        "code": "public NewTopic newTopic(String topic) {\n    TopicAdmin.NewTopicBuilder builder = new TopicAdmin.NewTopicBuilder(topic);\n    return builder.partitions(numPartitions)\n            .replicationFactor(replicationFactor)\n            .config(otherConfigs)\n            .build();\n}",
        "summary_tokens": [
            "return",
            "the",
            "description",
            "for",
            "a",
            "new",
            "topic",
            "with",
            "the",
            "given",
            "topic",
            "name",
            "with",
            "the",
            "topic",
            "settings",
            "defined",
            "for",
            "this",
            "topic",
            "creation",
            "group"
        ]
    },
    {
        "id": 2014,
        "code": "public void testAddAndRemoveWorker() throws Exception {\n    connect = connectBuilder.build();\n        \n    connect.start();\n\n        \n    connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);\n\n        \n    Map<String, String> props = defaultSourceConnectorProps(TOPIC_NAME);\n\n    connect.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n            \"Initial group of workers did not start in time.\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, NUM_TASKS,\n            \"Connector tasks did not start in time.\");\n\n    WorkerHandle extraWorker = connect.addWorker();\n\n    connect.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS + 1,\n            \"Expanded group of workers did not start in time.\");\n\n    connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, NUM_TASKS,\n            \"Connector tasks are not all in running state.\");\n\n    Set<WorkerHandle> workers = connect.activeWorkers();\n    assertTrue(workers.contains(extraWorker));\n\n    connect.removeWorker(extraWorker);\n\n    connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n            \"Group of workers did not shrink in time.\");\n\n    workers = connect.activeWorkers();\n    assertFalse(workers.contains(extraWorker));\n}",
        "summary_tokens": [
            "simple",
            "test",
            "case",
            "to",
            "add",
            "and",
            "then",
            "remove",
            "a",
            "worker",
            "from",
            "the",
            "embedded",
            "connect",
            "cluster",
            "while",
            "running",
            "a",
            "simple",
            "source",
            "connector"
        ]
    },
    {
        "id": 2015,
        "code": "public void testRestartFailedTask() throws Exception {\n    connect = connectBuilder.build();\n        \n    connect.start();\n\n    int numTasks = 1;\n\n        \n    Map<String, String> props = defaultSourceConnectorProps(TOPIC_NAME);\n        \n    props.put(TASKS_MAX_CONFIG, Objects.toString(numTasks));\n    props.put(CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX + BOOTSTRAP_SERVERS_CONFIG, \"nobrokerrunningatthisaddress\");\n\n    connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n            \"Initial group of workers did not start in time.\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    connect.assertions().assertConnectorIsRunningAndTasksHaveFailed(CONNECTOR_NAME, numTasks,\n            \"Connector tasks did not fail in time\");\n\n        \n    props.remove(CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX + BOOTSTRAP_SERVERS_CONFIG);\n    connect.configureConnector(CONNECTOR_NAME, props);\n\n        \n    String taskRestartEndpoint = connect.endpointForResource(\n        String.format(\"connectors/%s/tasks/0/restart\", CONNECTOR_NAME));\n    connect.requestPost(taskRestartEndpoint, \"\", Collections.emptyMap());\n\n        \n    connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, numTasks,\n        \"Connector tasks are not all in running state.\");\n}",
        "summary_tokens": [
            "verify",
            "that",
            "a",
            "failed",
            "task",
            "can",
            "be",
            "restarted",
            "successfully"
        ]
    },
    {
        "id": 2016,
        "code": "public void testBrokerCoordinator() throws Exception {\n    ConnectorHandle connectorHandle = RuntimeHandles.get().connectorHandle(CONNECTOR_NAME);\n    workerProps.put(DistributedConfig.SCHEDULED_REBALANCE_MAX_DELAY_MS_CONFIG, String.valueOf(5000));\n    connect = connectBuilder.workerProps(workerProps).build();\n        \n    connect.start();\n    int numTasks = 4;\n        \n    connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);\n\n        \n    Map<String, String> props = defaultSourceConnectorProps(TOPIC_NAME);\n\n    connect.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n            \"Initial group of workers did not start in time.\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, numTasks,\n            \"Connector tasks did not start in time.\");\n\n        \n    StartAndStopLatch stopLatch = connectorHandle.expectedStops(1, false);\n\n    connect.kafka().stopOnlyKafka();\n\n    connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n            \"Group of workers did not remain the same after broker shutdown\");\n\n        \n        \n    Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n\n        \n    assertTrue(\"Failed to stop connector and tasks after coordinator failure within \"\n                    + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n            stopLatch.await(CONNECTOR_SETUP_DURATION_MS, TimeUnit.MILLISECONDS));\n\n    StartAndStopLatch startLatch = connectorHandle.expectedStarts(1, false);\n    connect.kafka().startOnlyKafkaOnSamePorts();\n\n        \n    Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n\n    connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n            \"Group of workers did not remain the same within the designated time.\");\n\n        \n    Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n\n    connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, numTasks,\n            \"Connector tasks did not start in time.\");\n\n        \n    assertTrue(\"Failed to stop connector and tasks after coordinator failure within \"\n                    + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n            startLatch.await(CONNECTOR_SETUP_DURATION_MS, TimeUnit.MILLISECONDS));\n}",
        "summary_tokens": [
            "verify",
            "that",
            "a",
            "set",
            "of",
            "tasks",
            "restarts",
            "correctly",
            "after",
            "a",
            "broker",
            "goes",
            "offline",
            "and",
            "back",
            "online"
        ]
    },
    {
        "id": 2017,
        "code": "public void testTaskStatuses() throws Exception {\n    connect = connectBuilder.build();\n        \n    connect.start();\n\n    connect.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n            \"Initial group of workers did not start in time.\");\n\n        \n    Map<String, String> props = defaultSourceConnectorProps(TOPIC_NAME);\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());\n\n        \n    int initialNumTasks = 1;\n    props.put(TASKS_MAX_CONFIG, String.valueOf(initialNumTasks));\n    connect.configureConnector(CONNECTOR_NAME, props);\n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME,\n            initialNumTasks, \"Connector tasks did not start in time\");\n\n        \n    int increasedNumTasks = 5;\n    props.put(TASKS_MAX_CONFIG, String.valueOf(increasedNumTasks));\n    connect.configureConnector(CONNECTOR_NAME, props);\n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME,\n            increasedNumTasks, \"Connector task statuses did not update in time.\");\n\n        \n    int decreasedNumTasks = 3;\n    props.put(TASKS_MAX_CONFIG, String.valueOf(decreasedNumTasks));\n    connect.configureConnector(CONNECTOR_NAME, props);\n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME,\n            decreasedNumTasks, \"Connector task statuses did not update in time.\");\n}",
        "summary_tokens": [
            "verify",
            "that",
            "the",
            "number",
            "of",
            "tasks",
            "listed",
            "in",
            "the",
            "rest",
            "api",
            "is",
            "updated",
            "correctly",
            "after",
            "changes",
            "to",
            "the",
            "tasks"
        ]
    },
    {
        "id": 2018,
        "code": "public TaskHandle taskHandle(String taskId, Consumer<SinkRecord> consumer) {\n    return taskHandles.computeIfAbsent(taskId, k -> new TaskHandle(this, taskId, consumer));\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "a",
            "task",
            "handle",
            "for",
            "a",
            "given",
            "task",
            "id"
        ]
    },
    {
        "id": 2019,
        "code": "public StartAndStopCounter startAndStopCounter() {\n    return startAndStopCounter;\n}",
        "summary_tokens": [
            "gets",
            "the",
            "start",
            "and",
            "stop",
            "counter",
            "corresponding",
            "to",
            "this",
            "handle"
        ]
    },
    {
        "id": 2020,
        "code": "public String name() {\n    return connectorName;\n}",
        "summary_tokens": [
            "get",
            "the",
            "connector",
            "s",
            "name",
            "corresponding",
            "to",
            "this",
            "handle"
        ]
    },
    {
        "id": 2021,
        "code": "public Collection<TaskHandle> tasks() {\n    return taskHandles.values();\n}",
        "summary_tokens": [
            "get",
            "the",
            "list",
            "of",
            "tasks",
            "handles",
            "monitored",
            "by",
            "this",
            "connector",
            "handle"
        ]
    },
    {
        "id": 2022,
        "code": "public void deleteTask(String taskId) {\n    log.info(\"Removing handle for {} task in connector {}\", taskId, connectorName);\n    taskHandles.remove(taskId);\n}",
        "summary_tokens": [
            "delete",
            "the",
            "task",
            "handle",
            "for",
            "this",
            "task",
            "id"
        ]
    },
    {
        "id": 2023,
        "code": "public void clearTasks() {\n    log.info(\"Clearing {} existing task handles for connector {}\", taskHandles.size(), connectorName);\n    taskHandles.clear();\n}",
        "summary_tokens": [
            "delete",
            "all",
            "task",
            "handles",
            "for",
            "this",
            "connector"
        ]
    },
    {
        "id": 2024,
        "code": "public void expectedRecords(int expected) {\n    expectedRecords = expected;\n    recordsRemainingLatch = new CountDownLatch(expected);\n}",
        "summary_tokens": [
            "set",
            "the",
            "number",
            "of",
            "expected",
            "records",
            "for",
            "this",
            "connector"
        ]
    },
    {
        "id": 2025,
        "code": "public void expectedCommits(int expected) {\n    expectedCommits = expected;\n    recordsToCommitLatch = new CountDownLatch(expected);\n}",
        "summary_tokens": [
            "set",
            "the",
            "number",
            "of",
            "expected",
            "commits",
            "performed",
            "by",
            "this",
            "connector"
        ]
    },
    {
        "id": 2026,
        "code": "public void record(int batchSize) {\n    if (recordsRemainingLatch != null) {\n        IntStream.range(0, batchSize).forEach(i -> recordsRemainingLatch.countDown());\n    }\n}",
        "summary_tokens": [
            "record",
            "arrival",
            "of",
            "a",
            "batch",
            "of",
            "messages",
            "at",
            "the",
            "connector"
        ]
    },
    {
        "id": 2027,
        "code": "public void commit(int batchSize) {\n    if (recordsToCommitLatch != null) {\n        IntStream.range(0, batchSize).forEach(i -> recordsToCommitLatch.countDown());\n    }\n}",
        "summary_tokens": [
            "record",
            "commit",
            "on",
            "a",
            "batch",
            "of",
            "messages",
            "from",
            "the",
            "connector"
        ]
    },
    {
        "id": 2028,
        "code": "public void awaitRecords(long timeout) throws InterruptedException {\n    if (recordsRemainingLatch == null || expectedRecords < 0) {\n        throw new IllegalStateException(\"expectedRecords() was not set for this connector?\");\n    }\n    if (!recordsRemainingLatch.await(timeout, TimeUnit.MILLISECONDS)) {\n        String msg = String.format(\n                \"Insufficient records seen by connector %s in %d millis. Records expected=%d, actual=%d\",\n                connectorName,\n                timeout,\n                expectedRecords,\n                expectedRecords - recordsRemainingLatch.getCount());\n        throw new DataException(msg);\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "this",
            "connector",
            "to",
            "meet",
            "the",
            "expected",
            "number",
            "of",
            "records",
            "as",
            "defined",
            "by",
            "expected",
            "records"
        ]
    },
    {
        "id": 2029,
        "code": "public void awaitCommits(long timeout) throws InterruptedException {\n    if (recordsToCommitLatch == null || expectedCommits < 0) {\n        throw new IllegalStateException(\"expectedCommits() was not set for this connector?\");\n    }\n    if (!recordsToCommitLatch.await(timeout, TimeUnit.MILLISECONDS)) {\n        String msg = String.format(\n                \"Insufficient records committed by connector %s in %d millis. Records expected=%d, actual=%d\",\n                connectorName,\n                timeout,\n                expectedCommits,\n                expectedCommits - recordsToCommitLatch.getCount());\n        throw new DataException(msg);\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "this",
            "connector",
            "to",
            "meet",
            "the",
            "expected",
            "number",
            "of",
            "commits",
            "as",
            "defined",
            "by",
            "expected",
            "commits"
        ]
    },
    {
        "id": 2030,
        "code": "public void recordConnectorStart() {\n    startAndStopCounter.recordStart();\n}",
        "summary_tokens": [
            "record",
            "that",
            "this",
            "connector",
            "has",
            "been",
            "started"
        ]
    },
    {
        "id": 2031,
        "code": "public void recordConnectorStop() {\n    startAndStopCounter.recordStop();\n}",
        "summary_tokens": [
            "record",
            "that",
            "this",
            "connector",
            "has",
            "been",
            "stopped"
        ]
    },
    {
        "id": 2032,
        "code": "public StartAndStopLatch expectedStarts(int expectedStarts, boolean includeTasks) {\n    List<StartAndStopLatch> taskLatches = includeTasks\n            ? taskHandles.values().stream()\n            .map(task -> task.expectedStarts(expectedStarts))\n            .collect(Collectors.toList())\n            : Collections.emptyList();\n    return startAndStopCounter.expectedStarts(expectedStarts, taskLatches);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "wait",
            "until",
            "the",
            "connector",
            "using",
            "this",
            "handle",
            "and",
            "optionally",
            "all",
            "tasks",
            "using",
            "task",
            "handle",
            "have",
            "completed",
            "the",
            "expected",
            "number",
            "of",
            "starts",
            "starting",
            "the",
            "counts",
            "at",
            "the",
            "time",
            "this",
            "method",
            "is",
            "called"
        ]
    },
    {
        "id": 2033,
        "code": "public StartAndStopLatch expectedStops(int expectedStops, boolean includeTasks) {\n    List<StartAndStopLatch> taskLatches = includeTasks\n            ? taskHandles.values().stream()\n            .map(task -> task.expectedStops(expectedStops))\n            .collect(Collectors.toList())\n            : Collections.emptyList();\n    return startAndStopCounter.expectedStops(expectedStops, taskLatches);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "wait",
            "until",
            "the",
            "connector",
            "using",
            "this",
            "handle",
            "and",
            "optionally",
            "all",
            "tasks",
            "using",
            "task",
            "handle",
            "have",
            "completed",
            "the",
            "minimum",
            "number",
            "of",
            "stops",
            "starting",
            "the",
            "counts",
            "at",
            "the",
            "time",
            "this",
            "method",
            "is",
            "called"
        ]
    },
    {
        "id": 2034,
        "code": "private boolean checkForPartitionAssignment() {\n    try {\n        ConnectorStateInfo info = connect.connectorStatus(CONNECTOR_NAME);\n        return info != null && info.tasks().size() == NUM_TASKS\n                && connectorHandle.taskHandle(TASK_ID).numPartitionsAssigned() == 1;\n    }  catch (Exception e) {\n            \n        log.error(\"Could not check connector state info.\", e);\n        return false;\n    }\n}",
        "summary_tokens": [
            "check",
            "if",
            "a",
            "partition",
            "was",
            "assigned",
            "to",
            "each",
            "task"
        ]
    },
    {
        "id": 2035,
        "code": "public void testPreflightValidation() {\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, \"1\");\n    props.put(TOPIC_CONFIG, \"topic\");\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n\n        \n    props.put(EXACTLY_ONCE_SUPPORT_CONFIG, \"required\");\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_NULL);\n    ConfigInfos validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    ConfigInfo propertyValidation = findConfigInfo(EXACTLY_ONCE_SUPPORT_CONFIG, validation);\n    assertFalse(\"Preflight validation for exactly-once support property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_UNSUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(EXACTLY_ONCE_SUPPORT_CONFIG, validation);\n    assertFalse(\"Preflight validation for exactly-once support property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_FAIL);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(EXACTLY_ONCE_SUPPORT_CONFIG, validation);\n    assertFalse(\"Preflight validation for exactly-once support property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_SUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have zero errors\", 0, validation.errorCount());\n\n        \n    props.put(TRANSACTION_BOUNDARY_CONFIG, CONNECTOR.toString());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_NULL);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(TRANSACTION_BOUNDARY_CONFIG, validation);\n    assertFalse(\"Preflight validation for transaction boundary property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_UNSUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(TRANSACTION_BOUNDARY_CONFIG, validation);\n    assertFalse(\"Preflight validation for transaction boundary property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_FAIL);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(TRANSACTION_BOUNDARY_CONFIG, validation);\n    assertFalse(\"Preflight validation for transaction boundary property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_SUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have zero errors\", 0, validation.errorCount());\n}",
        "summary_tokens": [
            "a",
            "simple",
            "test",
            "for",
            "the",
            "pre",
            "flight",
            "validation",
            "api",
            "for",
            "connectors",
            "to",
            "provide",
            "their",
            "own",
            "delivery",
            "guarantees"
        ]
    },
    {
        "id": 2036,
        "code": "public void testPollBoundary() throws Exception {\n        \n    workerProps.put(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_CONFIG, \"600000\");\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int numTasks = 1;\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, Integer.toString(numTasks));\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TRANSACTION_BOUNDARY_CONFIG, POLL.toString());\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n\n        \n    connectorHandle.expectedRecords(recordsProduced);\n    connectorHandle.expectedCommits(recordsProduced);\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    log.info(\"Waiting for records to be provided to worker by task\");\n        \n    connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n    log.info(\"Waiting for records to be committed to Kafka by worker\");\n        \n    connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n    StartAndStopLatch connectorStop = connectorHandle.expectedStops(1, true);\n    connect.deleteConnector(CONNECTOR_NAME);\n    assertConnectorStopped(connectorStop);\n\n        \n    ConsumerRecords<byte[], byte[]> records = connect.kafka().consumeAll(\n            CONSUME_RECORDS_TIMEOUT_MS,\n            Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n            null,\n            topic\n    );\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + records.count(),\n            records.count() >= recordsProduced);\n    assertExactlyOnceSeqnos(records, numTasks);\n}",
        "summary_tokens": [
            "a",
            "simple",
            "green",
            "path",
            "test",
            "that",
            "ensures",
            "the",
            "worker",
            "can",
            "start",
            "up",
            "a",
            "source",
            "task",
            "with",
            "exactly",
            "once",
            "support",
            "enabled",
            "and",
            "write",
            "some",
            "records",
            "to",
            "kafka",
            "that",
            "will",
            "be",
            "visible",
            "to",
            "a",
            "downstream",
            "consumer",
            "using",
            "the",
            "read",
            "committed",
            "isolation",
            "level"
        ]
    },
    {
        "id": 2037,
        "code": "public void testIntervalBoundary() throws Exception {\n        \n    workerProps.put(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_CONFIG, \"600000\");\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int numTasks = 1;\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, Integer.toString(numTasks));\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TRANSACTION_BOUNDARY_CONFIG, INTERVAL.toString());\n    props.put(TRANSACTION_BOUNDARY_INTERVAL_CONFIG, \"10000\");\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n\n        \n    connectorHandle.expectedRecords(recordsProduced);\n    connectorHandle.expectedCommits(recordsProduced);\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    log.info(\"Waiting for records to be provided to worker by task\");\n        \n    connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n    log.info(\"Waiting for records to be committed to Kafka by worker\");\n        \n    connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n    StartAndStopLatch connectorStop = connectorHandle.expectedStops(1, true);\n    connect.deleteConnector(CONNECTOR_NAME);\n    assertConnectorStopped(connectorStop);\n\n        \n    ConsumerRecords<byte[], byte[]> records = connect.kafka().consumeAll(\n            CONSUME_RECORDS_TIMEOUT_MS,\n            Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n            null,\n            topic\n    );\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + records.count(),\n            records.count() >= recordsProduced);\n    assertExactlyOnceSeqnos(records, numTasks);\n}",
        "summary_tokens": [
            "a",
            "simple",
            "green",
            "path",
            "test",
            "that",
            "ensures",
            "the",
            "worker",
            "can",
            "start",
            "up",
            "a",
            "source",
            "task",
            "with",
            "exactly",
            "once",
            "support",
            "enabled",
            "and",
            "write",
            "some",
            "records",
            "to",
            "kafka",
            "that",
            "will",
            "be",
            "visible",
            "to",
            "a",
            "downstream",
            "consumer",
            "using",
            "the",
            "read",
            "committed",
            "isolation",
            "level"
        ]
    },
    {
        "id": 2038,
        "code": "public void testConnectorBoundary() throws Exception {\n    String offsetsTopic = \"exactly-once-source-cluster-offsets\";\n    workerProps.put(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, offsetsTopic);\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, \"1\");\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TRANSACTION_BOUNDARY_CONFIG, CONNECTOR.toString());\n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_SUPPORTED);\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n\n        \n    connectorHandle.expectedRecords(recordsProduced);\n    connectorHandle.expectedCommits(recordsProduced);\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    log.info(\"Waiting for records to be provided to worker by task\");\n        \n    connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n    log.info(\"Waiting for records to be committed to Kafka by worker\");\n        \n    connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n    Map<String, Object> consumerProps = new HashMap<>();\n    consumerProps.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\");\n        \n    ConsumerRecords<byte[], byte[]> sourceRecords = connect.kafka().consumeAll(\n            CONSUME_RECORDS_TIMEOUT_MS,\n            Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n            null,\n            topic\n    );\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + sourceRecords.count(),\n            sourceRecords.count() >= recordsProduced);\n\n        \n        \n    List<Long> expectedOffsetSeqnos = new ArrayList<>();\n    long lastExpectedOffsetSeqno = 1;\n    long nextExpectedOffsetSeqno = 1;\n    while (nextExpectedOffsetSeqno <= recordsProduced) {\n        expectedOffsetSeqnos.add(nextExpectedOffsetSeqno);\n        nextExpectedOffsetSeqno += lastExpectedOffsetSeqno;\n        lastExpectedOffsetSeqno = nextExpectedOffsetSeqno - lastExpectedOffsetSeqno;\n    }\n    ConsumerRecords<byte[], byte[]> offsetRecords = connect.kafka()\n            .consume(\n                    expectedOffsetSeqnos.size(),\n                    TimeUnit.MINUTES.toMillis(1),\n                    consumerProps,\n                    offsetsTopic\n            );\n\n    List<Long> actualOffsetSeqnos = parseAndAssertOffsetsForSingleTask(offsetRecords);\n\n    assertEquals(\"Committed offsets should match connector-defined transaction boundaries\",\n            expectedOffsetSeqnos, actualOffsetSeqnos.subList(0, expectedOffsetSeqnos.size()));\n\n    List<Long> expectedRecordSeqnos = LongStream.range(1, recordsProduced + 1).boxed().collect(Collectors.toList());\n    long priorBoundary = 1;\n    long nextBoundary = 2;\n    while (priorBoundary < expectedRecordSeqnos.get(expectedRecordSeqnos.size() - 1)) {\n        if (nextBoundary % 2 == 0) {\n            for (long i = priorBoundary + 1; i < nextBoundary + 1; i++) {\n                expectedRecordSeqnos.remove(i);\n            }\n        }\n        nextBoundary += priorBoundary;\n        priorBoundary = nextBoundary - priorBoundary;\n    }\n    List<Long> actualRecordSeqnos = parseAndAssertValuesForSingleTask(sourceRecords);\n        \n    Collections.sort(actualRecordSeqnos);\n    assertEquals(\"Committed records should exclude connector-aborted transactions\",\n            expectedRecordSeqnos, actualRecordSeqnos.subList(0, expectedRecordSeqnos.size()));\n}",
        "summary_tokens": [
            "a",
            "simple",
            "green",
            "path",
            "test",
            "that",
            "ensures",
            "the",
            "worker",
            "can",
            "start",
            "up",
            "a",
            "source",
            "task",
            "with",
            "exactly",
            "once",
            "support",
            "enabled",
            "and",
            "write",
            "some",
            "records",
            "to",
            "kafka",
            "that",
            "will",
            "be",
            "visible",
            "to",
            "a",
            "downstream",
            "consumer",
            "using",
            "the",
            "read",
            "committed",
            "isolation",
            "level"
        ]
    },
    {
        "id": 2039,
        "code": "public void testFencedLeaderRecovery() throws Exception {\n    connectBuilder.numWorkers(1);\n        \n    workerProps.put(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_CONFIG, \"600000\");\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int numTasks = 1;\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, Integer.toString(numTasks));\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TRANSACTION_BOUNDARY_CONFIG, POLL.toString());\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n\n        \n    connectorHandle.expectedRecords(recordsProduced);\n    connectorHandle.expectedCommits(recordsProduced);\n\n        \n    assertEquals(404, connect.requestGet(connect.endpointForResource(\"connectors/nonexistent\")).getStatus());\n\n        \n    Producer<?, ?> zombieLeader = transactionalProducer(\n            \"simulated-zombie-leader\",\n            DistributedConfig.transactionalProducerId(CLUSTER_GROUP_ID)\n    );\n    zombieLeader.initTransactions();\n    zombieLeader.close();\n\n        \n    assertThrows(ConnectRestException.class, () -> connect.configureConnector(CONNECTOR_NAME, props));\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    log.info(\"Waiting for records to be provided to worker by task\");\n        \n    connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n    log.info(\"Waiting for records to be committed to Kafka by worker\");\n        \n    connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n    StartAndStopLatch connectorStop = connectorHandle.expectedStops(1, true);\n    connect.deleteConnector(CONNECTOR_NAME);\n    assertConnectorStopped(connectorStop);\n\n        \n    ConsumerRecords<byte[], byte[]> records = connect.kafka().consumeAll(\n            CONSUME_RECORDS_TIMEOUT_MS,\n            Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n            null,\n            topic\n    );\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + records.count(),\n            records.count() >= recordsProduced);\n    assertExactlyOnceSeqnos(records, numTasks);\n}",
        "summary_tokens": [
            "brings",
            "up",
            "a",
            "one",
            "node",
            "cluster",
            "then",
            "intentionally",
            "fences",
            "out",
            "the",
            "transactional",
            "producer",
            "used",
            "by",
            "the",
            "leader",
            "for",
            "writes",
            "to",
            "the",
            "config",
            "topic",
            "to",
            "simulate",
            "a",
            "zombie",
            "leader",
            "being",
            "active",
            "in",
            "the",
            "cluster"
        ]
    },
    {
        "id": 2040,
        "code": "public void testConnectorReconfiguration() throws Exception {\n        \n    workerProps.put(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_CONFIG, \"600000\");\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n\n        \n    connectorHandle.expectedRecords(recordsProduced);\n    connectorHandle.expectedCommits(recordsProduced);\n\n    StartAndStopLatch connectorStart = connectorAndTaskStart(3);\n    props.put(TASKS_MAX_CONFIG, \"3\");\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n    assertConnectorStarted(connectorStart);\n\n    assertProducersAreFencedOnReconfiguration(3, 5, topic, props);\n    assertProducersAreFencedOnReconfiguration(5, 1, topic, props);\n    assertProducersAreFencedOnReconfiguration(1, 5, topic, props);\n    assertProducersAreFencedOnReconfiguration(5, 3, topic, props);\n\n        \n    log.info(\"Waiting for records to be provided to worker by task\");\n        \n    connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n    log.info(\"Waiting for records to be committed to Kafka by worker\");\n        \n    connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n    StartAndStopLatch connectorStop = connectorHandle.expectedStops(1, true);\n    connect.deleteConnector(CONNECTOR_NAME);\n    assertConnectorStopped(connectorStop);\n\n        \n    ConsumerRecords<byte[], byte[]> records = connect.kafka().consumeAll(\n            CONSUME_RECORDS_TIMEOUT_MS,\n            Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n            null,\n            topic\n    );\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + records.count(),\n            records.count() >= recordsProduced);\n        \n    assertExactlyOnceSeqnos(records, 5);\n}",
        "summary_tokens": [
            "a",
            "moderately",
            "complex",
            "green",
            "path",
            "test",
            "that",
            "ensures",
            "the",
            "worker",
            "can",
            "start",
            "up",
            "and",
            "run",
            "tasks",
            "for",
            "a",
            "source",
            "connector",
            "that",
            "gets",
            "reconfigured",
            "and",
            "will",
            "fence",
            "out",
            "potential",
            "zombie",
            "tasks",
            "for",
            "older",
            "generations",
            "before",
            "bringing",
            "up",
            "new",
            "task",
            "instances"
        ]
    },
    {
        "id": 2041,
        "code": "public void testTasksFailOnInabilityToFence() throws Exception {\n    brokerProps.put(\"authorizer.class.name\", \"kafka.security.authorizer.AclAuthorizer\");\n    brokerProps.put(\"sasl.enabled.mechanisms\", \"PLAIN\");\n    brokerProps.put(\"sasl.mechanism.inter.broker.protocol\", \"PLAIN\");\n    brokerProps.put(\"security.inter.broker.protocol\", \"SASL_PLAINTEXT\");\n    brokerProps.put(\"listeners\", \"SASL_PLAINTEXT://localhost:0\");\n    brokerProps.put(\"listener.name.sasl_plaintext.plain.sasl.jaas.config\",\n            \"org.apache.kafka.common.security.plain.PlainLoginModule required \"\n                    + \"username=\\\"super\\\" \"\n                    + \"password=\\\"super_pwd\\\" \"\n                    + \"user_connector=\\\"connector_pwd\\\" \"\n                    + \"user_super=\\\"super_pwd\\\";\");\n    brokerProps.put(\"super.users\", \"User:super\");\n\n    Map<String, String> superUserClientConfig = new HashMap<>();\n    superUserClientConfig.put(\"sasl.mechanism\", \"PLAIN\");\n    superUserClientConfig.put(\"security.protocol\", \"SASL_PLAINTEXT\");\n    superUserClientConfig.put(\"sasl.jaas.config\",\n            \"org.apache.kafka.common.security.plain.PlainLoginModule required \"\n                    + \"username=\\\"super\\\" \"\n                    + \"password=\\\"super_pwd\\\";\");\n        \n    workerProps.putAll(superUserClientConfig);\n\n    final String globalOffsetsTopic = \"connect-worker-offsets-topic\";\n    workerProps.put(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, globalOffsetsTopic);\n\n    startConnect();\n\n    String topic = \"test-topic\";\n    Admin admin = connect.kafka().createAdminClient(Utils.mkProperties(superUserClientConfig));\n    admin.createTopics(Collections.singleton(new NewTopic(topic, 3, (short) 1))).all().get();\n\n    Map<String, String> props = new HashMap<>();\n    int tasksMax = 2; \n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TASKS_MAX_CONFIG, Integer.toString(tasksMax));\n        \n    superUserClientConfig.forEach((property, value) -> {\n        props.put(CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX + property, value);\n        props.put(CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX + property, value);\n    });\n        \n    props.put(CONNECTOR_CLIENT_ADMIN_OVERRIDES_PREFIX + \"sasl.mechanism\", \"PLAIN\");\n    props.put(CONNECTOR_CLIENT_ADMIN_OVERRIDES_PREFIX + \"security.protocol\", \"SASL_PLAINTEXT\");\n    props.put(CONNECTOR_CLIENT_ADMIN_OVERRIDES_PREFIX + \"sasl.jaas.config\",\n            \"org.apache.kafka.common.security.plain.PlainLoginModule required \"\n                    + \"username=\\\"connector\\\" \"\n                    + \"password=\\\"connector_pwd\\\";\");\n        \n        \n    admin.createAcls(Arrays.asList(\n            new AclBinding(\n                    new ResourcePattern(ResourceType.TOPIC, topic, PatternType.LITERAL),\n                    new AccessControlEntry(\"User:connector\", \"*\", AclOperation.ALL, AclPermissionType.ALLOW)\n            ),\n            new AclBinding(\n                    new ResourcePattern(ResourceType.TOPIC, globalOffsetsTopic, PatternType.LITERAL),\n                    new AccessControlEntry(\"User:connector\", \"*\", AclOperation.ALL, AclPermissionType.ALLOW)\n            )\n    )).all().get();\n\n    StartAndStopLatch connectorStart = connectorAndTaskStart(tasksMax);\n\n    log.info(\"Bringing up connector with fresh slate; fencing should not be necessary\");\n    connect.configureConnector(CONNECTOR_NAME, props);\n    assertConnectorStarted(connectorStart);\n        \n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME, tasksMax, \"Connector and task should have started successfully\");\n\n    log.info(\"Reconfiguring connector; fencing should be necessary, and tasks should fail to start\");\n    props.put(\"message.in.a.bottle\", \"19e184427ac45bd34c8588a4e771aa1a\");\n    connect.configureConnector(CONNECTOR_NAME, props);\n\n        \n    connect.assertions().assertConnectorIsRunningAndTasksHaveFailed(CONNECTOR_NAME, tasksMax, \"Task should have failed on startup\");\n\n        \n    admin.createAcls(Arrays.asList(\n            new AclBinding(\n                    new ResourcePattern(ResourceType.TRANSACTIONAL_ID, Worker.taskTransactionalId(CLUSTER_GROUP_ID, CONNECTOR_NAME, 0), PatternType.LITERAL),\n                    new AccessControlEntry(\"User:connector\", \"*\", AclOperation.ALL, AclPermissionType.ALLOW)\n            ),\n            new AclBinding(\n                    new ResourcePattern(ResourceType.TRANSACTIONAL_ID, Worker.taskTransactionalId(CLUSTER_GROUP_ID, CONNECTOR_NAME, 1), PatternType.LITERAL),\n                    new AccessControlEntry(\"User:connector\", \"*\", AclOperation.ALL, AclPermissionType.ALLOW)\n            )\n    ));\n\n    log.info(\"Restarting connector after tweaking its ACLs; fencing should succeed this time\");\n    connect.restartConnectorAndTasks(CONNECTOR_NAME, false, true, false);\n        \n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME, tasksMax, \"Connector and task should have restarted successfully\");\n}",
        "summary_tokens": [
            "this",
            "test",
            "ensures",
            "that",
            "tasks",
            "are",
            "marked",
            "failed",
            "in",
            "the",
            "status",
            "api",
            "when",
            "the",
            "round",
            "of",
            "zombie",
            "fencing",
            "that",
            "takes",
            "place",
            "before",
            "they",
            "are",
            "brought",
            "up",
            "fails"
        ]
    },
    {
        "id": 2042,
        "code": "public void testSeparateOffsetsTopic() throws Exception {\n    final String globalOffsetsTopic = \"connect-worker-offsets-topic\";\n    workerProps.put(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, globalOffsetsTopic);\n\n    startConnect();\n    EmbeddedKafkaCluster connectorTargetedCluster = new EmbeddedKafkaCluster(1, brokerProps);\n    try (Closeable clusterShutdown = connectorTargetedCluster::stop) {\n        connectorTargetedCluster.start();\n        String topic = \"test-topic\";\n        connectorTargetedCluster.createTopic(topic, 3);\n\n        int numTasks = 1;\n        int recordsProduced = 100;\n\n        Map<String, String> props = new HashMap<>();\n        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n        props.put(TASKS_MAX_CONFIG, Integer.toString(numTasks));\n        props.put(TOPIC_CONFIG, topic);\n        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n        props.put(NAME_CONFIG, CONNECTOR_NAME);\n        props.put(TRANSACTION_BOUNDARY_CONFIG, POLL.toString());\n        props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n        props.put(CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX + BOOTSTRAP_SERVERS_CONFIG, connectorTargetedCluster.bootstrapServers());\n        props.put(CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX + BOOTSTRAP_SERVERS_CONFIG, connectorTargetedCluster.bootstrapServers());\n        props.put(CONNECTOR_CLIENT_ADMIN_OVERRIDES_PREFIX + BOOTSTRAP_SERVERS_CONFIG, connectorTargetedCluster.bootstrapServers());\n        String offsetsTopic = CONNECTOR_NAME + \"-offsets\";\n        props.put(OFFSETS_TOPIC_CONFIG, offsetsTopic);\n\n            \n        connectorHandle.expectedRecords(recordsProduced);\n        connectorHandle.expectedCommits(recordsProduced);\n\n            \n        connect.configureConnector(CONNECTOR_NAME, props);\n\n        log.info(\"Waiting for records to be provided to worker by task\");\n            \n        connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n        log.info(\"Waiting for records to be committed to Kafka by worker\");\n            \n        connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n            \n        int recordNum = connectorTargetedCluster\n                .consume(\n                        recordsProduced,\n                        TimeUnit.MINUTES.toMillis(1),\n                        Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n                        \"test-topic\")\n                .count();\n        assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + recordNum,\n                recordNum >= recordsProduced);\n\n            \n        ConsumerRecords<byte[], byte[]> offsetRecords = connectorTargetedCluster\n                .consumeAll(\n                        TimeUnit.MINUTES.toMillis(1),\n                        Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n                        null,\n                        offsetsTopic\n                );\n        List<Long> seqnos = parseAndAssertOffsetsForSingleTask(offsetRecords);\n        seqnos.forEach(seqno ->\n            assertEquals(\"Offset commits should occur on connector-defined poll boundaries, which happen every \" + recordsProduced + \" records\",\n                    0, seqno % recordsProduced)\n        );\n\n            \n        offsetRecords = connect.kafka()\n                .consumeAll(\n                        TimeUnit.MINUTES.toMillis(1),\n                        null,\n                        null,\n                        globalOffsetsTopic\n                );\n        seqnos = parseAndAssertOffsetsForSingleTask(offsetRecords);\n        seqnos.forEach(seqno ->\n            assertEquals(\"Offset commits should occur on connector-defined poll boundaries, which happen every \" + recordsProduced + \" records\",\n                    0, seqno % recordsProduced)\n        );\n\n            \n        connect.workers().forEach(connect::removeWorker);\n            \n        workerProps.put(EXACTLY_ONCE_SOURCE_SUPPORT_CONFIG, \"disabled\");\n\n            \n        connectorHandle.expectedRecords(recordsProduced);\n        connectorHandle.expectedCommits(recordsProduced);\n\n            \n        for (int i = 0; i < DEFAULT_NUM_WORKERS; i++) {\n            connect.addWorker();\n        }\n\n            \n            \n        connect.assertions().assertAtLeastNumWorkersAreUp(DEFAULT_NUM_WORKERS, \"cluster did not restart in time\");\n        connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(\n                CONNECTOR_NAME,\n                1,\n                \"connector and tasks did not resume running after cluster restart in time\"\n        );\n\n        log.info(\"Waiting for records to be provided to worker by task\");\n            \n        connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n        log.info(\"Waiting for records to be committed to Kafka by worker\");\n            \n        connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n        StartAndStopLatch connectorStop = connectorHandle.expectedStops(1, true);\n        connect.deleteConnector(CONNECTOR_NAME);\n        assertConnectorStopped(connectorStop);\n\n            \n        ConsumerRecords<byte[], byte[]> sourceRecords = connectorTargetedCluster.consumeAll(\n                CONSUME_RECORDS_TIMEOUT_MS,\n                Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n                null,\n                topic\n        );\n        assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + sourceRecords.count(),\n                sourceRecords.count() >= recordsProduced);\n            \n        offsetRecords = connectorTargetedCluster.consumeAll(\n                CONSUME_RECORDS_TIMEOUT_MS,\n                Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n                null,\n                offsetsTopic\n        );\n        assertAtLeastOnceSeqnos(sourceRecords, offsetRecords, numTasks);\n    }\n}",
        "summary_tokens": [
            "this",
            "test",
            "focuses",
            "extensively",
            "on",
            "the",
            "per",
            "connector",
            "offsets",
            "feature"
        ]
    },
    {
        "id": 2043,
        "code": "public void testPotentialDeadlockWhenProducingToOffsetsTopic() throws Exception {\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n        \n        \n    props.put(CONNECTOR_CLASS_CONFIG, NaughtyConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, \"1\");\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TRANSACTION_BOUNDARY_CONFIG, INTERVAL.toString());\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n    props.put(OFFSETS_TOPIC_CONFIG, \"whoops\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    connect.assertions().assertConnectorIsRunningAndTasksHaveFailed(\n        CONNECTOR_NAME, 1, \"Task should have failed after trying to produce to its own offsets topic\");\n}",
        "summary_tokens": [
            "a",
            "simple",
            "test",
            "to",
            "ensure",
            "that",
            "source",
            "tasks",
            "fail",
            "when",
            "trying",
            "to",
            "produce",
            "to",
            "their",
            "own",
            "offsets",
            "topic"
        ]
    },
    {
        "id": 2044,
        "code": "private StartAndStopLatch connectorAndTaskStart(int numTasks) {\n    connectorHandle.clearTasks();\n    IntStream.range(0, numTasks)\n            .mapToObj(i -> MonitorableSourceConnector.taskId(CONNECTOR_NAME, i))\n            .forEach(connectorHandle::taskHandle);\n    return connectorHandle.expectedStarts(1, true);\n}",
        "summary_tokens": [
            "clear",
            "all",
            "existing",
            "task",
            "handles",
            "for",
            "the",
            "connector",
            "then",
            "preemptively",
            "create",
            "num",
            "tasks",
            "many",
            "task",
            "handles",
            "for",
            "it",
            "and",
            "return",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "start",
            "and",
            "stop",
            "latch",
            "await",
            "long",
            "time",
            "unit",
            "await",
            "the",
            "startup",
            "of",
            "that",
            "connector",
            "and",
            "the",
            "expected",
            "number",
            "of",
            "tasks"
        ]
    },
    {
        "id": 2045,
        "code": "public void testSinkConnector() throws Exception {\n        \n    connect.kafka().createTopic(\"test-topic\", NUM_TOPIC_PARTITIONS);\n\n        \n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, SINK_CONNECTOR_CLASS_NAME);\n    props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));\n    props.put(TOPICS_CONFIG, \"test-topic\");\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n\n        \n    connectorHandle.expectedRecords(NUM_RECORDS_PRODUCED);\n\n        \n    connectorHandle.expectedCommits(NUM_RECORDS_PRODUCED);\n\n        \n    connect.assertions().assertExactlyNumErrorsOnConnectorConfigValidation(SINK_CONNECTOR_CLASS_NAME, props, 1,\n        \"Validating connector configuration produced an unexpected number or errors.\");\n\n        \n    props.put(\"name\", CONNECTOR_NAME);\n\n        \n    connect.assertions().assertExactlyNumErrorsOnConnectorConfigValidation(SINK_CONNECTOR_CLASS_NAME, props, 0,\n        \"Validating connector configuration produced an unexpected number or errors.\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    waitForCondition(this::checkForPartitionAssignment,\n            CONNECTOR_SETUP_DURATION_MS,\n            \"Connector tasks were not assigned a partition each.\");\n\n        \n    for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {\n        connect.kafka().produce(\"test-topic\", i % NUM_TOPIC_PARTITIONS, \"key\", \"simple-message-value-\" + i);\n    }\n\n        \n    assertEquals(\"Unexpected number of records consumed\", NUM_RECORDS_PRODUCED,\n            connect.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic\").count());\n\n        \n    connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);\n\n        \n    connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);\n\n        \n    connect.deleteConnector(CONNECTOR_NAME);\n}",
        "summary_tokens": [
            "simple",
            "test",
            "case",
            "to",
            "configure",
            "and",
            "execute",
            "an",
            "embedded",
            "connect",
            "cluster"
        ]
    },
    {
        "id": 2046,
        "code": "public void testSourceConnector() throws Exception {\n        \n    connect.kafka().createTopic(\"test-topic\", NUM_TOPIC_PARTITIONS);\n\n        \n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, SOURCE_CONNECTOR_CLASS_NAME);\n    props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));\n    props.put(\"topic\", \"test-topic\");\n    props.put(\"throughput\", String.valueOf(500));\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(DEFAULT_TOPIC_CREATION_PREFIX + REPLICATION_FACTOR_CONFIG, String.valueOf(1));\n    props.put(DEFAULT_TOPIC_CREATION_PREFIX + PARTITIONS_CONFIG, String.valueOf(1));\n\n        \n    connectorHandle.expectedRecords(NUM_RECORDS_PRODUCED);\n\n        \n    connectorHandle.expectedCommits(NUM_RECORDS_PRODUCED);\n\n        \n    connect.assertions().assertExactlyNumErrorsOnConnectorConfigValidation(SOURCE_CONNECTOR_CLASS_NAME, props, 1,\n        \"Validating connector configuration produced an unexpected number or errors.\");\n\n        \n    props.put(\"name\", CONNECTOR_NAME);\n\n        \n    connect.assertions().assertExactlyNumErrorsOnConnectorConfigValidation(SOURCE_CONNECTOR_CLASS_NAME, props, 0,\n        \"Validating connector configuration produced an unexpected number or errors.\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n        \n    connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);\n\n        \n    connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);\n\n        \n    int recordNum = connect.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic\").count();\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + NUM_RECORDS_PRODUCED + \" + but got \" + recordNum,\n            recordNum >= NUM_RECORDS_PRODUCED);\n\n        \n    connect.deleteConnector(CONNECTOR_NAME);\n}",
        "summary_tokens": [
            "simple",
            "test",
            "case",
            "to",
            "configure",
            "and",
            "execute",
            "an",
            "embedded",
            "connect",
            "cluster"
        ]
    },
    {
        "id": 2047,
        "code": "private boolean checkForPartitionAssignment() {\n    try {\n        ConnectorStateInfo info = connect.connectorStatus(CONNECTOR_NAME);\n        return info != null && info.tasks().size() == NUM_TASKS\n                && connectorHandle.tasks().stream().allMatch(th -> th.numPartitionsAssigned() == 1);\n    } catch (Exception e) {\n            \n        log.error(\"Could not check connector state info.\", e);\n        return false;\n    }\n}",
        "summary_tokens": [
            "check",
            "if",
            "a",
            "partition",
            "was",
            "assigned",
            "to",
            "each",
            "task"
        ]
    },
    {
        "id": 2048,
        "code": "public static RuntimeHandles get() {\n    return INSTANCE;\n}",
        "summary_tokens": [
            "the",
            "shared",
            "runtime",
            "handles",
            "instance"
        ]
    },
    {
        "id": 2049,
        "code": "public ConnectorHandle connectorHandle(String connectorName) {\n    return connectorHandles.computeIfAbsent(connectorName, k -> new ConnectorHandle(connectorName));\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "a",
            "connector",
            "handle",
            "for",
            "a",
            "given",
            "connector",
            "name"
        ]
    },
    {
        "id": 2050,
        "code": "public void deleteConnector(String connectorName) {\n    connectorHandles.remove(connectorName);\n}",
        "summary_tokens": [
            "delete",
            "the",
            "connector",
            "handle",
            "for",
            "this",
            "connector",
            "name"
        ]
    },
    {
        "id": 2051,
        "code": "public int starts() {\n    return startCounter.get();\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "starts"
        ]
    },
    {
        "id": 2052,
        "code": "public int stops() {\n    return stopCounter.get();\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "stops"
        ]
    },
    {
        "id": 2053,
        "code": "public StartAndStopLatch expectedRestarts(int expectedRestarts, List<StartAndStopLatch> dependents) {\n    return expectedRestarts(expectedRestarts, expectedRestarts, dependents);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "wait",
            "until",
            "the",
            "expected",
            "number",
            "of",
            "restarts",
            "has",
            "been",
            "completed"
        ]
    },
    {
        "id": 2054,
        "code": "public StartAndStopLatch expectedStarts(int expectedStarts, List<StartAndStopLatch> dependents) {\n    return expectedRestarts(expectedStarts, 0, dependents);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "wait",
            "until",
            "the",
            "expected",
            "number",
            "of",
            "starts",
            "has",
            "been",
            "completed"
        ]
    },
    {
        "id": 2055,
        "code": "public StartAndStopLatch expectedStops(int expectedStops, List<StartAndStopLatch> dependents) {\n    return expectedRestarts(0, expectedStops, dependents);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "wait",
            "until",
            "the",
            "expected",
            "number",
            "of",
            "stops",
            "has",
            "been",
            "completed"
        ]
    },
    {
        "id": 2056,
        "code": "public boolean await(long timeout, TimeUnit unit) throws InterruptedException {\n    final long start = clock.milliseconds();\n    final long end = start + unit.toMillis(timeout);\n    if (!startLatch.await(end - start, TimeUnit.MILLISECONDS)) {\n        return false;\n    }\n    if (!stopLatch.await(end - clock.milliseconds(), TimeUnit.MILLISECONDS)) {\n        return false;\n    }\n\n    if (dependents != null) {\n        for (StartAndStopLatch dependent : dependents) {\n            if (!dependent.await(end - clock.milliseconds(), TimeUnit.MILLISECONDS)) {\n                return false;\n            }\n        }\n    }\n    if (uponCompletion != null) {\n        uponCompletion.accept(this);\n    }\n    return true;\n}",
        "summary_tokens": [
            "causes",
            "the",
            "current",
            "thread",
            "to",
            "wait",
            "until",
            "the",
            "latch",
            "has",
            "counted",
            "down",
            "the",
            "starts",
            "and",
            "stops",
            "to",
            "zero",
            "unless",
            "the",
            "thread",
            "is",
            "thread",
            "interrupt",
            "interrupted",
            "or",
            "the",
            "specified",
            "waiting",
            "time",
            "elapses"
        ]
    },
    {
        "id": 2057,
        "code": "public void record(int batchSize) {\n    if (recordsRemainingLatch != null) {\n        IntStream.range(0, batchSize).forEach(i -> recordsRemainingLatch.countDown());\n    }\n    connectorHandle.record(batchSize);\n}",
        "summary_tokens": [
            "record",
            "arrival",
            "of",
            "a",
            "batch",
            "of",
            "messages",
            "at",
            "the",
            "task",
            "and",
            "the",
            "connector",
            "overall"
        ]
    },
    {
        "id": 2058,
        "code": "public void commit(int batchSize) {\n    if (recordsToCommitLatch != null) {\n        IntStream.range(0, batchSize).forEach(i -> recordsToCommitLatch.countDown());\n    }\n    connectorHandle.commit(batchSize);\n}",
        "summary_tokens": [
            "record",
            "commit",
            "on",
            "a",
            "batch",
            "of",
            "messages",
            "from",
            "the",
            "task",
            "and",
            "the",
            "connector",
            "overall"
        ]
    },
    {
        "id": 2059,
        "code": "public void expectedRecords(int expected) {\n    expectedRecords = expected;\n    recordsRemainingLatch = new CountDownLatch(expected);\n}",
        "summary_tokens": [
            "set",
            "the",
            "number",
            "of",
            "expected",
            "records",
            "for",
            "this",
            "task"
        ]
    },
    {
        "id": 2060,
        "code": "public void expectedCommits(int expected) {\n    expectedRecords = expected;\n    recordsToCommitLatch = new CountDownLatch(expected);\n}",
        "summary_tokens": [
            "set",
            "the",
            "number",
            "of",
            "expected",
            "record",
            "commits",
            "performed",
            "by",
            "this",
            "task"
        ]
    },
    {
        "id": 2061,
        "code": "public void partitionsAssigned(Collection<TopicPartition> partitions) {\n    partitions.forEach(partition -> this.partitions.computeIfAbsent(partition, PartitionHistory::new).assigned());\n}",
        "summary_tokens": [
            "adds",
            "a",
            "set",
            "of",
            "partitions",
            "to",
            "the",
            "sink",
            "task",
            "s",
            "assignment"
        ]
    },
    {
        "id": 2062,
        "code": "public void partitionsRevoked(Collection<TopicPartition> partitions) {\n    partitions.forEach(partition -> this.partitions.computeIfAbsent(partition, PartitionHistory::new).revoked());\n}",
        "summary_tokens": [
            "removes",
            "a",
            "set",
            "of",
            "partitions",
            "to",
            "the",
            "sink",
            "task",
            "s",
            "assignment"
        ]
    },
    {
        "id": 2063,
        "code": "public void partitionsCommitted(Collection<TopicPartition> partitions) {\n    partitions.forEach(partition -> this.partitions.computeIfAbsent(partition, PartitionHistory::new).committed());\n}",
        "summary_tokens": [
            "records",
            "offset",
            "commits",
            "for",
            "a",
            "sink",
            "task",
            "s",
            "partitions"
        ]
    },
    {
        "id": 2064,
        "code": "public Collection<TopicPartition> assignment() {\n    return partitions.values().stream()\n            .filter(PartitionHistory::isAssigned)\n            .map(PartitionHistory::topicPartition)\n            .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "the",
            "complete",
            "set",
            "of",
            "partitions",
            "currently",
            "assigned",
            "to",
            "this",
            "sink",
            "task"
        ]
    },
    {
        "id": 2065,
        "code": "public int numPartitionsAssigned() {\n    return assignment().size();\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "topic",
            "partitions",
            "assigned",
            "to",
            "this",
            "sink",
            "task"
        ]
    },
    {
        "id": 2066,
        "code": "public int timesAssigned(TopicPartition partition) {\n    return partitions.computeIfAbsent(partition, PartitionHistory::new).timesAssigned();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "times",
            "the",
            "partition",
            "has",
            "been",
            "assigned",
            "to",
            "this",
            "sink",
            "task"
        ]
    },
    {
        "id": 2067,
        "code": "public int timesRevoked(TopicPartition partition) {\n    return partitions.computeIfAbsent(partition, PartitionHistory::new).timesRevoked();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "times",
            "the",
            "partition",
            "has",
            "been",
            "revoked",
            "from",
            "this",
            "sink",
            "task"
        ]
    },
    {
        "id": 2068,
        "code": "public int timesCommitted(TopicPartition partition) {\n    return partitions.computeIfAbsent(partition, PartitionHistory::new).timesCommitted();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "times",
            "the",
            "framework",
            "has",
            "committed",
            "offsets",
            "for",
            "this",
            "partition",
            "partition",
            "the",
            "partition",
            "the",
            "number",
            "of",
            "times",
            "it",
            "has",
            "been",
            "committed",
            "may",
            "be",
            "0",
            "if",
            "never",
            "committed"
        ]
    },
    {
        "id": 2069,
        "code": "public void awaitRecords(long timeout, TimeUnit unit) throws InterruptedException {\n    if (recordsRemainingLatch == null) {\n        throw new IllegalStateException(\"Illegal state encountered. expectedRecords() was not set for this task?\");\n    }\n    if (!recordsRemainingLatch.await(timeout, unit)) {\n        String msg = String.format(\n                \"Insufficient records seen by task %s in %d millis. Records expected=%d, actual=%d\",\n                taskId,\n                unit.toMillis(timeout),\n                expectedRecords,\n                expectedRecords - recordsRemainingLatch.getCount());\n        throw new DataException(msg);\n    }\n    log.debug(\"Task {} saw {} records, expected {} records\",\n              taskId, expectedRecords - recordsRemainingLatch.getCount(), expectedRecords);\n}",
        "summary_tokens": [
            "wait",
            "up",
            "to",
            "the",
            "specified",
            "timeout",
            "for",
            "this",
            "task",
            "to",
            "meet",
            "the",
            "expected",
            "number",
            "of",
            "records",
            "as",
            "defined",
            "by",
            "expected",
            "records"
        ]
    },
    {
        "id": 2070,
        "code": "public void awaitCommits(long timeout, TimeUnit unit) throws InterruptedException {\n    if (recordsToCommitLatch == null) {\n        throw new IllegalStateException(\"Illegal state encountered. expectedRecords() was not set for this task?\");\n    }\n    if (!recordsToCommitLatch.await(timeout, unit)) {\n        String msg = String.format(\n                \"Insufficient records seen by task %s in %d millis. Records expected=%d, actual=%d\",\n                taskId,\n                unit.toMillis(timeout),\n                expectedCommits,\n                expectedCommits - recordsToCommitLatch.getCount());\n        throw new DataException(msg);\n    }\n    log.debug(\"Task {} saw {} records, expected {} records\",\n              taskId, expectedCommits - recordsToCommitLatch.getCount(), expectedCommits);\n}",
        "summary_tokens": [
            "wait",
            "up",
            "to",
            "the",
            "specified",
            "timeout",
            "for",
            "this",
            "task",
            "to",
            "meet",
            "the",
            "expected",
            "number",
            "of",
            "commits",
            "as",
            "defined",
            "by",
            "expected",
            "commits"
        ]
    },
    {
        "id": 2071,
        "code": "public StartAndStopCounter startAndStopCounter() {\n    return startAndStopCounter;\n}",
        "summary_tokens": [
            "gets",
            "the",
            "start",
            "and",
            "stop",
            "counter",
            "corresponding",
            "to",
            "this",
            "handle"
        ]
    },
    {
        "id": 2072,
        "code": "public void recordTaskStart() {\n    startAndStopCounter.recordStart();\n}",
        "summary_tokens": [
            "record",
            "that",
            "this",
            "task",
            "has",
            "been",
            "stopped"
        ]
    },
    {
        "id": 2073,
        "code": "public void recordTaskStop() {\n    startAndStopCounter.recordStop();\n}",
        "summary_tokens": [
            "record",
            "that",
            "this",
            "task",
            "has",
            "been",
            "stopped"
        ]
    },
    {
        "id": 2074,
        "code": "public StartAndStopLatch expectedStarts(int expectedStarts) {\n    return startAndStopCounter.expectedStarts(expectedStarts);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "wait",
            "until",
            "this",
            "task",
            "has",
            "completed",
            "the",
            "expected",
            "number",
            "of",
            "starts"
        ]
    },
    {
        "id": 2075,
        "code": "public StartAndStopLatch expectedStops(int expectedStops) {\n    return startAndStopCounter.expectedStops(expectedStops);\n}",
        "summary_tokens": [
            "obtain",
            "a",
            "start",
            "and",
            "stop",
            "latch",
            "that",
            "can",
            "be",
            "used",
            "to",
            "wait",
            "until",
            "this",
            "task",
            "has",
            "completed",
            "the",
            "expected",
            "number",
            "of",
            "starts"
        ]
    },
    {
        "id": 2076,
        "code": "public void testFilterOnTopicNameWithSinkConnector() throws Exception {\n    assertConnectReady();\n\n    Map<String, Long> observedRecords = observeRecords();\n\n        \n    String fooTopic = \"foo-topic\";\n    String barTopic = \"bar-topic\";\n    int numFooRecords = NUM_RECORDS_PRODUCED;\n    int numBarRecords = NUM_RECORDS_PRODUCED;\n    connect.kafka().createTopic(fooTopic, NUM_TOPIC_PARTITIONS);\n    connect.kafka().createTopic(barTopic, NUM_TOPIC_PARTITIONS);\n\n        \n    Map<String, String> props = new HashMap<>();\n    props.put(\"name\", CONNECTOR_NAME);\n    props.put(CONNECTOR_CLASS_CONFIG, SINK_CONNECTOR_CLASS_NAME);\n    props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));\n    props.put(TOPICS_CONFIG, String.join(\",\", fooTopic, barTopic));\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(TRANSFORMS_CONFIG, \"filter\");\n    props.put(TRANSFORMS_CONFIG + \".filter.type\", Filter.class.getSimpleName());\n    props.put(TRANSFORMS_CONFIG + \".filter.predicate\", \"barPredicate\");\n    props.put(PREDICATES_CONFIG, \"barPredicate\");\n    props.put(PREDICATES_CONFIG + \".barPredicate.type\", TopicNameMatches.class.getSimpleName());\n    props.put(PREDICATES_CONFIG + \".barPredicate.pattern\", \"bar-.*\");\n\n        \n    connectorHandle.expectedRecords(numFooRecords);\n\n        \n    connectorHandle.expectedCommits(numFooRecords);\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n    assertConnectorRunning();\n\n        \n    for (int i = 0; i < numBarRecords; i++) {\n        connect.kafka().produce(barTopic, i % NUM_TOPIC_PARTITIONS, \"key\", \"simple-message-value-\" + i);\n    }\n    for (int i = 0; i < numFooRecords; i++) {\n        connect.kafka().produce(fooTopic, i % NUM_TOPIC_PARTITIONS, \"key\", \"simple-message-value-\" + i);\n    }\n\n        \n    assertEquals(\"Unexpected number of records consumed\", numFooRecords,\n            connect.kafka().consume(numFooRecords, RECORD_TRANSFER_DURATION_MS, fooTopic).count());\n    assertEquals(\"Unexpected number of records consumed\", numBarRecords,\n            connect.kafka().consume(numBarRecords, RECORD_TRANSFER_DURATION_MS, barTopic).count());\n\n        \n    connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);\n\n        \n    connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);\n\n        \n    Map<String, Long> expectedRecordCounts = singletonMap(fooTopic, (long) numFooRecords);\n    assertObservedRecords(observedRecords, expectedRecordCounts);\n\n        \n    connect.deleteConnector(CONNECTOR_NAME);\n}",
        "summary_tokens": [
            "test",
            "the",
            "filter",
            "transformer",
            "with",
            "a",
            "topic",
            "name",
            "matches",
            "predicate",
            "on",
            "a",
            "sink",
            "connector"
        ]
    },
    {
        "id": 2077,
        "code": "public void testFilterOnTombstonesWithSinkConnector() throws Exception {\n    assertConnectReady();\n\n    Map<String, Long> observedRecords = observeRecords();\n\n        \n    String topic = \"foo-topic\";\n    int numRecords = NUM_RECORDS_PRODUCED;\n    connect.kafka().createTopic(topic, NUM_TOPIC_PARTITIONS);\n\n        \n    Map<String, String> props = new HashMap<>();\n    props.put(\"name\", CONNECTOR_NAME);\n    props.put(CONNECTOR_CLASS_CONFIG, SINK_CONNECTOR_CLASS_NAME);\n    props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));\n    props.put(TOPICS_CONFIG, String.join(\",\", topic));\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(TRANSFORMS_CONFIG, \"filter\");\n    props.put(TRANSFORMS_CONFIG + \".filter.type\", Filter.class.getSimpleName());\n    props.put(TRANSFORMS_CONFIG + \".filter.predicate\", \"barPredicate\");\n    props.put(PREDICATES_CONFIG, \"barPredicate\");\n    props.put(PREDICATES_CONFIG + \".barPredicate.type\", RecordIsTombstone.class.getSimpleName());\n\n        \n    connectorHandle.expectedCommits(numRecords / 2);\n    connectorHandle.expectedRecords(numRecords / 2);\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n    assertConnectorRunning();\n\n        \n    for (int i = 0; i < numRecords; i++) {\n        connect.kafka().produce(topic, i % NUM_TOPIC_PARTITIONS, \"key\", i % 2 == 0 ? \"simple-message-value-\" + i : null);\n    }\n\n        \n    assertEquals(\"Unexpected number of records consumed\", numRecords,\n            connect.kafka().consume(numRecords, RECORD_TRANSFER_DURATION_MS, topic).count());\n\n        \n    connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);\n\n        \n    connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);\n\n    Map<String, Long> expectedRecordCounts = singletonMap(topic, (long) (numRecords / 2));\n    assertObservedRecords(observedRecords, expectedRecordCounts);\n\n        \n    connect.deleteConnector(CONNECTOR_NAME);\n}",
        "summary_tokens": [
            "test",
            "the",
            "filter",
            "transformer",
            "with",
            "a",
            "record",
            "is",
            "tombstone",
            "predicate",
            "on",
            "a",
            "sink",
            "connector"
        ]
    },
    {
        "id": 2078,
        "code": "public void testFilterOnHasHeaderKeyWithSourceConnectorAndTopicCreation() throws Exception {\n    assertConnectReady();\n\n        \n    Map<String, String> props = new HashMap<>();\n    props.put(\"name\", CONNECTOR_NAME);\n    props.put(CONNECTOR_CLASS_CONFIG, SOURCE_CONNECTOR_CLASS_NAME);\n    props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));\n    props.put(\"topic\", \"test-topic\");\n    props.put(\"throughput\", String.valueOf(500));\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(TRANSFORMS_CONFIG, \"filter\");\n    props.put(TRANSFORMS_CONFIG + \".filter.type\", Filter.class.getSimpleName());\n    props.put(TRANSFORMS_CONFIG + \".filter.predicate\", \"headerPredicate\");\n    props.put(TRANSFORMS_CONFIG + \".filter.negate\", \"true\");\n    props.put(PREDICATES_CONFIG, \"headerPredicate\");\n    props.put(PREDICATES_CONFIG + \".headerPredicate.type\", HasHeaderKey.class.getSimpleName());\n    props.put(PREDICATES_CONFIG + \".headerPredicate.name\", \"header-8\");\n        \n    props.put(DEFAULT_TOPIC_CREATION_PREFIX + REPLICATION_FACTOR_CONFIG, String.valueOf(-1));\n    props.put(DEFAULT_TOPIC_CREATION_PREFIX + PARTITIONS_CONFIG, String.valueOf(NUM_TOPIC_PARTITIONS));\n\n        \n    connectorHandle.expectedRecords(NUM_RECORDS_PRODUCED);\n\n        \n    connectorHandle.expectedCommits(NUM_RECORDS_PRODUCED);\n\n        \n    connect.assertions().assertExactlyNumErrorsOnConnectorConfigValidation(SOURCE_CONNECTOR_CLASS_NAME, props, 0,\n            \"Validating connector configuration produced an unexpected number or errors.\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n    assertConnectorRunning();\n\n        \n    connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);\n\n        \n    connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);\n\n        \n    for (ConsumerRecord<byte[], byte[]> record : connect.kafka().consume(1, RECORD_TRANSFER_DURATION_MS, \"test-topic\")) {\n        assertNotNull(\"Expected header to exist\",\n                record.headers().lastHeader(\"header-8\"));\n    }\n\n        \n    connect.deleteConnector(CONNECTOR_NAME);\n}",
        "summary_tokens": [
            "test",
            "the",
            "filter",
            "transformer",
            "with",
            "a",
            "has",
            "header",
            "key",
            "predicate",
            "on",
            "a",
            "source",
            "connector"
        ]
    },
    {
        "id": 2079,
        "code": "public static Object currentMetricValue(ConnectMetrics metrics, MetricGroup metricGroup, String name) {\n    MetricName metricName = metricGroup.metricName(name);\n    for (MetricsReporter reporter : metrics.metrics().reporters()) {\n        if (reporter instanceof MockMetricsReporter) {\n            return ((MockMetricsReporter) reporter).currentMetricValue(metricName);\n        }\n    }\n    return null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "value",
            "of",
            "the",
            "named",
            "metric",
            "which",
            "may",
            "have",
            "already",
            "been",
            "removed",
            "from",
            "the",
            "org"
        ]
    },
    {
        "id": 2080,
        "code": "public static double currentMetricValueAsDouble(ConnectMetrics metrics, MetricGroup metricGroup, String name) {\n    Object value = currentMetricValue(metrics, metricGroup, name);\n    return value instanceof Double ? (Double) value : Double.NaN;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "value",
            "of",
            "the",
            "named",
            "metric",
            "which",
            "may",
            "have",
            "already",
            "been",
            "removed",
            "from",
            "the",
            "org"
        ]
    },
    {
        "id": 2081,
        "code": "public static String currentMetricValueAsString(ConnectMetrics metrics, MetricGroup metricGroup, String name) {\n    Object value = currentMetricValue(metrics, metricGroup, name);\n    return value instanceof String ? (String) value : null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "value",
            "of",
            "the",
            "named",
            "metric",
            "which",
            "may",
            "have",
            "already",
            "been",
            "removed",
            "from",
            "the",
            "org"
        ]
    },
    {
        "id": 2082,
        "code": "public void testExternalZombieFencingRequestImmediateCompletion() throws Exception {\n    expectHerderStartup();\n    EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n    EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V2);\n    expectConfigRefreshAndSnapshot(SNAPSHOT);\n\n    expectRebalance(1, Collections.emptyList(), Collections.emptyList(), true);\n    SessionKey sessionKey = expectNewSessionKey();\n\n    expectAnyTicks();\n\n    member.wakeup();\n    EasyMock.expectLastCall();\n\n    ClusterConfigState configState = exactlyOnceSnapshot(\n            sessionKey,\n            TASK_CONFIGS_MAP,\n            Collections.singletonMap(CONN1, 2),\n            Collections.singletonMap(CONN1, 5),\n            Collections.singleton(CONN1)\n    );\n    expectConfigRefreshAndSnapshot(configState);\n\n        \n    KafkaFuture<Void> workerFencingFuture = EasyMock.mock(KafkaFuture.class);\n        \n    KafkaFuture<Void> herderFencingFuture = EasyMock.mock(KafkaFuture.class);\n\n        \n    for (int i = 0; i < 2; i++) {\n        Capture<KafkaFuture.BiConsumer<Void, Throwable>> herderFencingCallback = EasyMock.newCapture();\n        EasyMock.expect(herderFencingFuture.whenComplete(EasyMock.capture(herderFencingCallback))).andAnswer(() -> {\n            herderFencingCallback.getValue().accept(null, null);\n            return null;\n        });\n    }\n\n    Capture<KafkaFuture.BaseFunction<Void, Void>> fencingFollowup = EasyMock.newCapture();\n    EasyMock.expect(workerFencingFuture.thenApply(EasyMock.capture(fencingFollowup))).andAnswer(() -> {\n        fencingFollowup.getValue().apply(null);\n        return herderFencingFuture;\n    });\n    EasyMock.expect(worker.fenceZombies(EasyMock.eq(CONN1), EasyMock.eq(2), EasyMock.eq(CONN1_CONFIG)))\n            .andReturn(workerFencingFuture);\n\n    expectConfigRefreshAndSnapshot(configState);\n\n    configBackingStore.putTaskCountRecord(CONN1, 1);\n    EasyMock.expectLastCall();\n\n    expectHerderShutdown(true);\n\n    PowerMock.replayAll(workerFencingFuture, herderFencingFuture);\n\n\n    startBackgroundHerder();\n\n    FutureCallback<Void> fencing = new FutureCallback<>();\n    herder.fenceZombieSourceTasks(CONN1, fencing);\n\n    fencing.get(10, TimeUnit.SECONDS);\n\n    stopBackgroundHerder();\n\n    PowerMock.verifyAll();\n}",
        "summary_tokens": [
            "tests",
            "zombie",
            "fencing",
            "that",
            "completes",
            "extremely",
            "quickly",
            "and",
            "causes",
            "all",
            "callback",
            "related",
            "logic",
            "to",
            "be",
            "invoked",
            "effectively",
            "as",
            "soon",
            "as",
            "it",
            "s",
            "put",
            "into",
            "place"
        ]
    },
    {
        "id": 2083,
        "code": "public void testExternalZombieFencingRequestSynchronousFailure() throws Exception {\n    expectHerderStartup();\n    EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n    EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V2);\n    expectConfigRefreshAndSnapshot(SNAPSHOT);\n\n    expectRebalance(1, Collections.emptyList(), Collections.emptyList(), true);\n    SessionKey sessionKey = expectNewSessionKey();\n\n    expectAnyTicks();\n\n    member.wakeup();\n    EasyMock.expectLastCall();\n\n    ClusterConfigState configState = exactlyOnceSnapshot(\n            sessionKey,\n            TASK_CONFIGS_MAP,\n            Collections.singletonMap(CONN1, 2),\n            Collections.singletonMap(CONN1, 5),\n            Collections.singleton(CONN1)\n    );\n    expectConfigRefreshAndSnapshot(configState);\n\n    Exception fencingException = new KafkaException(\"whoops!\");\n    EasyMock.expect(worker.fenceZombies(EasyMock.eq(CONN1), EasyMock.eq(2), EasyMock.eq(CONN1_CONFIG)))\n            .andThrow(fencingException);\n\n    expectHerderShutdown(true);\n\n    PowerMock.replayAll();\n\n\n    startBackgroundHerder();\n\n    FutureCallback<Void> fencing = new FutureCallback<>();\n    herder.fenceZombieSourceTasks(CONN1, fencing);\n\n    ExecutionException exception = assertThrows(ExecutionException.class, () -> fencing.get(10, TimeUnit.SECONDS));\n    assertEquals(fencingException, exception.getCause());\n\n    stopBackgroundHerder();\n\n    PowerMock.verifyAll();\n}",
        "summary_tokens": [
            "the",
            "herder",
            "tries",
            "to",
            "perform",
            "a",
            "round",
            "of",
            "fencing",
            "but",
            "fails",
            "synchronously",
            "while",
            "invoking",
            "worker",
            "fence",
            "zombies"
        ]
    },
    {
        "id": 2084,
        "code": "public void testExternalZombieFencingRequestAsynchronousFailure() throws Exception {\n    expectHerderStartup();\n    EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n    EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V2);\n    expectConfigRefreshAndSnapshot(SNAPSHOT);\n\n    expectRebalance(1, Collections.emptyList(), Collections.emptyList(), true);\n    SessionKey sessionKey = expectNewSessionKey();\n\n    expectAnyTicks();\n\n    member.wakeup();\n    EasyMock.expectLastCall();\n\n    ClusterConfigState configState = exactlyOnceSnapshot(\n            sessionKey,\n            TASK_CONFIGS_MAP,\n            Collections.singletonMap(CONN1, 2),\n            Collections.singletonMap(CONN1, 5),\n            Collections.singleton(CONN1)\n    );\n    expectConfigRefreshAndSnapshot(configState);\n\n        \n    KafkaFuture<Void> workerFencingFuture = EasyMock.mock(KafkaFuture.class);\n        \n    KafkaFuture<Void> herderFencingFuture = EasyMock.mock(KafkaFuture.class);\n        \n    Capture<KafkaFuture.BiConsumer<Void, Throwable>> herderFencingCallbacks = EasyMock.newCapture(CaptureType.ALL);\n\n    EasyMock.expect(worker.fenceZombies(EasyMock.eq(CONN1), EasyMock.eq(2), EasyMock.eq(CONN1_CONFIG)))\n            .andReturn(workerFencingFuture);\n\n    EasyMock.expect(workerFencingFuture.thenApply(EasyMock.<KafkaFuture.BaseFunction<Void, Void>>anyObject()))\n            .andReturn(herderFencingFuture);\n\n    CountDownLatch callbacksInstalled = new CountDownLatch(2);\n    for (int i = 0; i < 2; i++) {\n        EasyMock.expect(herderFencingFuture.whenComplete(EasyMock.capture(herderFencingCallbacks))).andAnswer(() -> {\n            callbacksInstalled.countDown();\n            return null;\n        });\n    }\n\n    expectHerderShutdown(true);\n\n    PowerMock.replayAll(workerFencingFuture, herderFencingFuture);\n\n\n    startBackgroundHerder();\n\n    FutureCallback<Void> fencing = new FutureCallback<>();\n    herder.fenceZombieSourceTasks(CONN1, fencing);\n\n    assertTrue(callbacksInstalled.await(10, TimeUnit.SECONDS));\n\n    Exception fencingException = new AuthorizationException(\"you didn't say the magic word\");\n    herderFencingCallbacks.getValues().forEach(cb -> cb.accept(null, fencingException));\n\n    ExecutionException exception = assertThrows(ExecutionException.class, () -> fencing.get(10, TimeUnit.SECONDS));\n    assertTrue(exception.getCause() instanceof ConnectException);\n\n    stopBackgroundHerder();\n\n    PowerMock.verifyAll();\n}",
        "summary_tokens": [
            "the",
            "herder",
            "tries",
            "to",
            "perform",
            "a",
            "round",
            "of",
            "fencing",
            "and",
            "is",
            "able",
            "to",
            "retrieve",
            "a",
            "future",
            "from",
            "worker",
            "fence",
            "zombies",
            "but",
            "the",
            "attempt",
            "fails",
            "at",
            "a",
            "later",
            "point"
        ]
    },
    {
        "id": 2085,
        "code": "public void testExternalZombieFencingRequestDelayedCompletion() throws Exception {\n    final String conn3 = \"SourceC\";\n    final Map<String, Integer> tasksPerConnector = new HashMap<>();\n    tasksPerConnector.put(CONN1, 5);\n    tasksPerConnector.put(CONN2, 3);\n    tasksPerConnector.put(conn3, 12);\n\n    expectHerderStartup();\n    EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n    EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V2);\n    expectConfigRefreshAndSnapshot(SNAPSHOT);\n\n    expectRebalance(1, Collections.emptyList(), Collections.emptyList(), true);\n    SessionKey sessionKey = expectNewSessionKey();\n\n    expectAnyTicks();\n\n        \n        \n        \n        \n        \n    member.wakeup();\n    EasyMock.expectLastCall().anyTimes();\n\n    Map<String, Integer> taskCountRecords = new HashMap<>();\n    taskCountRecords.put(CONN1, 2);\n    taskCountRecords.put(CONN2, 3);\n    taskCountRecords.put(conn3, 5);\n    Map<String, Integer> taskConfigGenerations = new HashMap<>();\n    taskConfigGenerations.put(CONN1, 3);\n    taskConfigGenerations.put(CONN2, 4);\n    taskConfigGenerations.put(conn3, 2);\n    Set<String> pendingFencing = new HashSet<>(Arrays.asList(CONN1, CONN2, conn3));\n    ClusterConfigState configState = exactlyOnceSnapshot(\n            sessionKey,\n            TASK_CONFIGS_MAP,\n            taskCountRecords,\n            taskConfigGenerations,\n            pendingFencing,\n            tasksPerConnector\n    );\n    tasksPerConnector.keySet().forEach(c -> expectConfigRefreshAndSnapshot(configState));\n\n        \n        \n    Map<String, Capture<KafkaFuture.BiConsumer<Void, Throwable>>> herderFencingCallbacks = new HashMap<>();\n        \n        \n    Map<String, Capture<KafkaFuture.BaseFunction<Void, Void>>> workerFencingFollowups = new HashMap<>();\n\n    Map<String, CountDownLatch> callbacksInstalled = new HashMap<>();\n    tasksPerConnector.forEach((connector, numStackedRequests) -> {\n            \n        KafkaFuture<Void> workerFencingFuture = EasyMock.mock(KafkaFuture.class);\n            \n        KafkaFuture<Void> herderFencingFuture = EasyMock.mock(KafkaFuture.class);\n\n        Capture<KafkaFuture.BiConsumer<Void, Throwable>> herderFencingCallback = EasyMock.newCapture(CaptureType.ALL);\n        herderFencingCallbacks.put(connector, herderFencingCallback);\n\n            \n            \n        EasyMock.expect(herderFencingFuture.whenComplete(EasyMock.capture(herderFencingCallback)))\n                .andReturn(null)\n                .times(numStackedRequests + 1);\n\n        Capture<KafkaFuture.BaseFunction<Void, Void>> fencingFollowup = EasyMock.newCapture();\n        CountDownLatch callbackInstalled = new CountDownLatch(1);\n        workerFencingFollowups.put(connector, fencingFollowup);\n        callbacksInstalled.put(connector, callbackInstalled);\n        EasyMock.expect(workerFencingFuture.thenApply(EasyMock.capture(fencingFollowup))).andAnswer(() -> {\n            callbackInstalled.countDown();\n            return herderFencingFuture;\n        });\n\n            \n        EasyMock.expect(worker.fenceZombies(\n                EasyMock.eq(connector), EasyMock.eq(taskCountRecords.get(connector)), EasyMock.anyObject())\n        ).andReturn(workerFencingFuture);\n\n        for (int i = 0; i < numStackedRequests; i++) {\n            expectConfigRefreshAndSnapshot(configState);\n        }\n\n        PowerMock.replay(workerFencingFuture, herderFencingFuture);\n    });\n\n    tasksPerConnector.forEach((connector, taskCount) -> {\n        configBackingStore.putTaskCountRecord(connector, taskCount);\n        EasyMock.expectLastCall();\n    });\n\n    expectHerderShutdown(false);\n\n    PowerMock.replayAll();\n\n\n    startBackgroundHerder();\n\n    List<FutureCallback<Void>> stackedFencingRequests = new ArrayList<>();\n    tasksPerConnector.forEach((connector, numStackedRequests) -> {\n        List<FutureCallback<Void>> connectorFencingRequests = IntStream.range(0, numStackedRequests)\n                .mapToObj(i -> new FutureCallback<Void>())\n                .collect(Collectors.toList());\n\n        connectorFencingRequests.forEach(fencing ->\n                herder.fenceZombieSourceTasks(connector, fencing)\n        );\n\n        stackedFencingRequests.addAll(connectorFencingRequests);\n    });\n\n    callbacksInstalled.forEach((connector, latch) -> {\n        try {\n            assertTrue(latch.await(10, TimeUnit.SECONDS));\n            workerFencingFollowups.get(connector).getValue().apply(null);\n            herderFencingCallbacks.get(connector).getValues().forEach(cb -> cb.accept(null, null));\n        } catch (InterruptedException e) {\n            fail(\"Unexpectedly interrupted\");\n        }\n    });\n\n    for (FutureCallback<Void> fencing : stackedFencingRequests) {\n        fencing.get(10, TimeUnit.SECONDS);\n    }\n\n    stopBackgroundHerder();\n\n    PowerMock.verifyAll();\n}",
        "summary_tokens": [
            "issues",
            "multiple",
            "rapid",
            "fencing",
            "requests",
            "for",
            "a",
            "handful",
            "of",
            "connectors",
            "each",
            "of",
            "which",
            "takes",
            "a",
            "little",
            "while",
            "to",
            "complete"
        ]
    },
    {
        "id": 2086,
        "code": "private void assertConnectorAllocations(int... connectorCounts) {\n    assertAllocations(\"connectors\", ConnectorsAndTasks::connectors, connectorCounts);\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "connector",
            "counts",
            "for",
            "each",
            "worker",
            "in",
            "the",
            "cluster",
            "match",
            "the",
            "expected",
            "counts"
        ]
    },
    {
        "id": 2087,
        "code": "private void assertTaskAllocations(int... taskCounts) {\n    assertAllocations(\"tasks\", ConnectorsAndTasks::tasks, taskCounts);\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "task",
            "counts",
            "for",
            "each",
            "worker",
            "in",
            "the",
            "cluster",
            "match",
            "the",
            "expected",
            "counts"
        ]
    },
    {
        "id": 2088,
        "code": "private void assertNoRedundantAssignments() {\n    List<String> existingConnectors = ConnectUtils.combineCollections(memberAssignments.values(), ConnectorsAndTasks::connectors);\n    List<String> newConnectors = ConnectUtils.combineCollections(returnedAssignments.newlyAssignedConnectors().values());\n    List<ConnectorTaskId> existingTasks = ConnectUtils.combineCollections(memberAssignments.values(), ConnectorsAndTasks::tasks);\n    List<ConnectorTaskId> newTasks = ConnectUtils.combineCollections(returnedAssignments.newlyAssignedTasks().values());\n\n    assertNoDuplicates(\n            newConnectors,\n            \"Connectors should be unique in assignments but duplicates were found; the set of newly-assigned connectors is \" + newConnectors\n    );\n    assertNoDuplicates(\n            newTasks,\n            \"Tasks should be unique in assignments but duplicates were found; the set of newly-assigned tasks is \" + newTasks\n    );\n\n    existingConnectors.retainAll(newConnectors);\n    assertEquals(\"Found connectors in new assignment that already exist in current assignment\",\n            Collections.emptyList(),\n            existingConnectors);\n    existingTasks.retainAll(newTasks);\n    assertEquals(\"Found tasks in new assignment that already exist in current assignment\",\n            Collections.emptyList(),\n            existingConnectors);\n}",
        "summary_tokens": [
            "ensure",
            "that",
            "no",
            "connectors",
            "or",
            "tasks",
            "that",
            "were",
            "already",
            "assigned",
            "during",
            "the",
            "previous",
            "round",
            "are",
            "newly",
            "assigned",
            "in",
            "this",
            "round",
            "and",
            "that",
            "each",
            "newly",
            "assigned",
            "connector",
            "and",
            "task",
            "is",
            "only",
            "assigned",
            "to",
            "a",
            "single",
            "worker"
        ]
    },
    {
        "id": 2089,
        "code": "public Map<String, SamplingTestPlugin> otherSamples() {\n    return Collections.emptyMap();\n}",
        "summary_tokens": [
            "a",
            "group",
            "of",
            "other",
            "sampling",
            "test",
            "plugin",
            "instances",
            "known",
            "by",
            "this",
            "plugin",
            "this",
            "should",
            "only",
            "return",
            "direct",
            "children",
            "and",
            "not",
            "reference",
            "this",
            "instance",
            "directly"
        ]
    },
    {
        "id": 2090,
        "code": "public Map<String, SamplingTestPlugin> flatten() {\n    Map<String, SamplingTestPlugin> out = new HashMap<>();\n    Map<String, SamplingTestPlugin> otherSamples = otherSamples();\n    if (otherSamples != null) {\n        for (Entry<String, SamplingTestPlugin> child : otherSamples.entrySet()) {\n            for (Entry<String, SamplingTestPlugin> flattened : child.getValue().flatten().entrySet()) {\n                String key = child.getKey();\n                if (flattened.getKey().length() > 0) {\n                    key += \".\" + flattened.getKey();\n                }\n                out.put(key, flattened.getValue());\n            }\n        }\n    }\n    out.put(\"\", this);\n    return out;\n}",
        "summary_tokens": [
            "a",
            "flattened",
            "list",
            "of",
            "child",
            "samples",
            "including",
            "this",
            "entry",
            "keyed",
            "as",
            "this"
        ]
    },
    {
        "id": 2091,
        "code": "public void logMethodCall(Map<String, SamplingTestPlugin> samples) {\n    StackTraceElement[] stackTraces = Thread.currentThread().getStackTrace();\n    if (stackTraces.length < 2) {\n        return;\n    }\n        \n        \n        \n    StackTraceElement caller = stackTraces[2];\n\n    samples.put(caller.getMethodName(), new MethodCallSample(\n        caller,\n        Thread.currentThread().getContextClassLoader(),\n        getClass().getClassLoader()\n    ));\n}",
        "summary_tokens": [
            "log",
            "the",
            "parent",
            "method",
            "call",
            "as",
            "a",
            "child",
            "sample"
        ]
    },
    {
        "id": 2092,
        "code": "public static void assertAvailable() throws AssertionError {\n    if (INITIALIZATION_EXCEPTION != null) {\n        throw new AssertionError(\"TestPlugins did not initialize completely\",\n            INITIALIZATION_EXCEPTION);\n    }\n    if (PLUGIN_JARS.isEmpty()) {\n        throw new AssertionError(\"No test plugins loaded\");\n    }\n}",
        "summary_tokens": [
            "ensure",
            "that",
            "the",
            "test",
            "plugin",
            "jars",
            "were",
            "assembled",
            "without",
            "error",
            "before",
            "continuing"
        ]
    },
    {
        "id": 2093,
        "code": "public static List<String> pluginPath() {\n    return PLUGIN_JARS.values()\n        .stream()\n        .map(File::getPath)\n        .collect(Collectors.toList());\n}",
        "summary_tokens": [
            "a",
            "list",
            "of",
            "jar",
            "files",
            "containing",
            "test",
            "plugins",
            "a",
            "list",
            "of",
            "plugin",
            "jar",
            "filenames"
        ]
    },
    {
        "id": 2094,
        "code": "public static List<String> pluginClasses() {\n    return new ArrayList<>(PLUGIN_JARS.keySet());\n}",
        "summary_tokens": [
            "get",
            "all",
            "of",
            "the",
            "classes",
            "that",
            "were",
            "successfully",
            "built",
            "by",
            "this",
            "class",
            "a",
            "list",
            "of",
            "plugin",
            "class",
            "names"
        ]
    },
    {
        "id": 2095,
        "code": "private static void compileJavaSources(Path sourceDir, Path binDir) throws IOException {\n    JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();\n    List<File> sourceFiles = Files.walk(sourceDir)\n        .filter(Files::isRegularFile)\n        .filter(path -> path.toFile().getName().endsWith(\".java\"))\n        .map(Path::toFile)\n        .collect(Collectors.toList());\n    StringWriter writer = new StringWriter();\n    List<String> options = Arrays.asList(\n        \"-d\", binDir.toString() \n    );\n\n    try (StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null)) {\n        boolean success = compiler.getTask(\n            writer,\n            fileManager,\n            null,\n            options,\n            null,\n            fileManager.getJavaFileObjectsFromFiles(sourceFiles)\n        ).call();\n        if (!success) {\n            throw new RuntimeException(\"Failed to compile test plugin:\\n\" + writer);\n        }\n    }\n}",
        "summary_tokens": [
            "compile",
            "a",
            "directory",
            "of"
        ]
    },
    {
        "id": 2096,
        "code": "private void expectStore(Map<String, Object> key, byte[] keySerialized,\n                         Map<String, Object> value, byte[] valueSerialized,\n                         final boolean fail,\n                         final CountDownLatch waitForCompletion) {\n    List<Object> keyWrapped = Arrays.asList(NAMESPACE, key);\n    when(keyConverter.fromConnectData(NAMESPACE, null, keyWrapped)).thenReturn(keySerialized);\n    when(valueConverter.fromConnectData(NAMESPACE, null, value)).thenReturn(valueSerialized);\n\n    final ArgumentCaptor<Callback<Void>> storeCallback = ArgumentCaptor.forClass(Callback.class);\n    final Map<ByteBuffer, ByteBuffer> offsetsSerialized = Collections.singletonMap(\n            keySerialized == null ? null : ByteBuffer.wrap(keySerialized),\n            valueSerialized == null ? null : ByteBuffer.wrap(valueSerialized));\n    when(store.set(eq(offsetsSerialized), storeCallback.capture())).thenAnswer(invocation -> {\n        final Callback<Void> cb = storeCallback.getValue();\n        return service.submit(() -> {\n            if (waitForCompletion != null)\n                assertTrue(waitForCompletion.await(10000, TimeUnit.MILLISECONDS));\n\n            if (fail) {\n                cb.onCompletion(EXCEPTION, null);\n            } else {\n                cb.onCompletion(null, null);\n            }\n            return null;\n        });\n    });\n}",
        "summary_tokens": [
            "expect",
            "a",
            "request",
            "to",
            "store",
            "data",
            "to",
            "the",
            "underlying",
            "offset",
            "backing",
            "store"
        ]
    },
    {
        "id": 2097,
        "code": "public void resolveOnGet(Throwable t) {\n    resolveOnGet = true;\n    resolveOnGetException = t;\n}",
        "summary_tokens": [
            "set",
            "a",
            "flag",
            "to",
            "resolve",
            "the",
            "future",
            "as",
            "soon",
            "as",
            "one",
            "of",
            "the",
            "get",
            "methods",
            "has",
            "been",
            "called"
        ]
    },
    {
        "id": 2098,
        "code": "public void waitForGetAndResolve(Throwable t) {\n    waitForGet();\n    resolve(t);\n}",
        "summary_tokens": [
            "block",
            "waiting",
            "for",
            "another",
            "thread",
            "to",
            "call",
            "one",
            "of",
            "the",
            "get",
            "methods",
            "and",
            "then",
            "immediately",
            "resolve",
            "the",
            "future",
            "with",
            "the",
            "specified",
            "value"
        ]
    },
    {
        "id": 2099,
        "code": "public void retryEndOffsetsShouldRethrowUnknownVersionException() {\n    String topicName = \"myTopic\";\n    TopicPartition tp1 = new TopicPartition(topicName, 0);\n    Set<TopicPartition> tps = Collections.singleton(tp1);\n    Long offset = null; \n    Cluster cluster = createCluster(1, topicName, 1);\n    try (AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(new MockTime(), cluster)) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        env.kafkaClient().prepareResponse(prepareMetadataResponse(cluster, Errors.NONE));\n            \n        env.kafkaClient().prepareResponse(listOffsetsResultWithUnsupportedVersion(tp1, offset));\n        TopicAdmin admin = new TopicAdmin(null, env.adminClient());\n            \n        assertThrows(UnsupportedVersionException.class, () -> admin.retryEndOffsets(tps, Duration.ofMillis(100), 1));\n    }\n}",
        "summary_tokens": [
            "topic",
            "admin",
            "can",
            "be",
            "used",
            "to",
            "read",
            "the",
            "end",
            "offsets",
            "but",
            "the",
            "admin",
            "client",
            "api",
            "used",
            "to",
            "do",
            "this",
            "was",
            "added",
            "to",
            "the",
            "broker",
            "in",
            "0"
        ]
    },
    {
        "id": 2100,
        "code": "private ListOffsetsResponse listOffsetsResult(ApiError error, Map<TopicPartition, Long> offsetsByPartitions) {\n    if (error == null) error = new ApiError(Errors.UNKNOWN_TOPIC_OR_PARTITION, \"unknown topic\");\n    List<ListOffsetsTopicResponse> tpResponses = new ArrayList<>();\n    for (TopicPartition partition : offsetsByPartitions.keySet()) {\n        Long offset = offsetsByPartitions.get(partition);\n        ListOffsetsTopicResponse topicResponse;\n        if (offset == null) {\n            topicResponse = ListOffsetsResponse.singletonListOffsetsTopicResponse(partition, error.error(), -1L, 0, 321);\n        } else {\n            topicResponse = ListOffsetsResponse.singletonListOffsetsTopicResponse(partition, Errors.NONE, -1L, offset, 321);\n        }\n        tpResponses.add(topicResponse);\n    }\n    ListOffsetsResponseData responseData = new ListOffsetsResponseData()\n            .setThrottleTimeMs(0)\n            .setTopics(tpResponses);\n\n    return new ListOffsetsResponse(responseData);\n}",
        "summary_tokens": [
            "create",
            "a",
            "list",
            "offset",
            "response",
            "that",
            "exposes",
            "the",
            "supplied",
            "error",
            "and",
            "includes",
            "offsets",
            "for",
            "the",
            "supplied",
            "partitions"
        ]
    },
    {
        "id": 2101,
        "code": "public void start() {\n    if (maskExitProcedures) {\n        Exit.setExitProcedure(exitProcedure);\n        Exit.setHaltProcedure(haltProcedure);\n    }\n    kafkaCluster.start();\n    startConnect();\n}",
        "summary_tokens": [
            "start",
            "the",
            "connect",
            "cluster",
            "and",
            "the",
            "embedded",
            "kafka",
            "and",
            "zookeeper",
            "cluster"
        ]
    },
    {
        "id": 2102,
        "code": "public void stop() {\n    connectCluster.forEach(this::stopWorker);\n    try {\n        kafkaCluster.stop();\n    } catch (UngracefulShutdownException e) {\n        log.warn(\"Kafka did not shutdown gracefully\");\n    } catch (Exception e) {\n        log.error(\"Could not stop kafka\", e);\n        throw new RuntimeException(\"Could not stop brokers\", e);\n    } finally {\n        if (maskExitProcedures) {\n            Exit.resetExitProcedure();\n            Exit.resetHaltProcedure();\n        }\n        Plugins.compareAndSwapLoaders(originalClassLoader);\n    }\n}",
        "summary_tokens": [
            "stop",
            "the",
            "connect",
            "cluster",
            "and",
            "the",
            "embedded",
            "kafka",
            "and",
            "zookeeper",
            "cluster"
        ]
    },
    {
        "id": 2103,
        "code": "public WorkerHandle addWorker() {\n    WorkerHandle worker = WorkerHandle.start(workerNamePrefix + nextWorkerId.getAndIncrement(), workerProps);\n    connectCluster.add(worker);\n    log.info(\"Started worker {}\", worker);\n    return worker;\n}",
        "summary_tokens": [
            "provision",
            "and",
            "start",
            "an",
            "additional",
            "worker",
            "to",
            "the",
            "connect",
            "cluster"
        ]
    },
    {
        "id": 2104,
        "code": "public void removeWorker(WorkerHandle worker) {\n    if (connectCluster.isEmpty()) {\n        throw new IllegalStateException(\"Cannot remove worker. Cluster is empty\");\n    }\n    stopWorker(worker);\n    connectCluster.remove(worker);\n}",
        "summary_tokens": [
            "decommission",
            "a",
            "specific",
            "worker",
            "from",
            "this",
            "connect",
            "cluster"
        ]
    },
    {
        "id": 2105,
        "code": "public void requestTimeout(long requestTimeoutMs) {\n    connectCluster.forEach(worker -> worker.requestTimeout(requestTimeoutMs));\n}",
        "summary_tokens": [
            "set",
            "a",
            "new",
            "timeout",
            "for",
            "rest",
            "requests",
            "to",
            "each",
            "worker",
            "in",
            "the",
            "cluster"
        ]
    },
    {
        "id": 2106,
        "code": "public boolean anyWorkersRunning() {\n    return workers().stream().anyMatch(WorkerHandle::isRunning);\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "the",
            "connect",
            "cluster",
            "has",
            "any",
            "workers",
            "running"
        ]
    },
    {
        "id": 2107,
        "code": "public boolean allWorkersRunning() {\n    return workers().stream().allMatch(WorkerHandle::isRunning);\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "the",
            "connect",
            "cluster",
            "has",
            "all",
            "workers",
            "running"
        ]
    },
    {
        "id": 2108,
        "code": "public Set<WorkerHandle> activeWorkers() {\n    ObjectMapper mapper = new ObjectMapper();\n    return connectCluster.stream()\n            .filter(w -> {\n                try {\n                    mapper.readerFor(ServerInfo.class)\n                            .readValue(responseToString(requestGet(w.url().toString())));\n                    return true;\n                } catch (ConnectException | IOException e) {\n                        \n                    return false;\n                }\n            })\n            .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "get",
            "the",
            "workers",
            "that",
            "are",
            "up",
            "and",
            "running"
        ]
    },
    {
        "id": 2109,
        "code": "public Set<WorkerHandle> workers() {\n    return new LinkedHashSet<>(connectCluster);\n}",
        "summary_tokens": [
            "get",
            "the",
            "provisioned",
            "workers"
        ]
    },
    {
        "id": 2110,
        "code": "public ConfigInfos validateConnectorConfig(String connClassName, Map<String, String> connConfig) {\n    String url = endpointForResource(String.format(\"connector-plugins/%s/config/validate\", connClassName));\n    String response = putConnectorConfig(url, connConfig);\n    ConfigInfos configInfos;\n    try {\n        configInfos = new ObjectMapper().readValue(response, ConfigInfos.class);\n    } catch (IOException e) {\n        throw new ConnectException(\"Unable deserialize response into a ConfigInfos object\");\n    }\n    return configInfos;\n}",
        "summary_tokens": [
            "validate",
            "a",
            "given",
            "connector",
            "configuration"
        ]
    },
    {
        "id": 2111,
        "code": "protected String putConnectorConfig(String url, Map<String, String> connConfig) {\n    ObjectMapper mapper = new ObjectMapper();\n    String content;\n    try {\n        content = mapper.writeValueAsString(connConfig);\n    } catch (IOException e) {\n        throw new ConnectException(\"Could not serialize connector configuration and execute PUT request\");\n    }\n    Response response = requestPut(url, content);\n    if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n        return responseToString(response);\n    }\n    throw new ConnectRestException(response.getStatus(),\n            \"Could not execute PUT request. Error response: \" + responseToString(response));\n}",
        "summary_tokens": [
            "execute",
            "a",
            "put",
            "request",
            "with",
            "the",
            "given",
            "connector",
            "configuration",
            "on",
            "the",
            "given",
            "url",
            "endpoint"
        ]
    },
    {
        "id": 2112,
        "code": "public void deleteConnector(String connName) {\n    String url = endpointForResource(String.format(\"connectors/%s\", connName));\n    Response response = requestDelete(url);\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n                \"Could not execute DELETE request. Error response: \" + responseToString(response));\n    }\n}",
        "summary_tokens": [
            "delete",
            "an",
            "existing",
            "connector"
        ]
    },
    {
        "id": 2113,
        "code": "public void pauseConnector(String connName) {\n    String url = endpointForResource(String.format(\"connectors/%s/pause\", connName));\n    Response response = requestPut(url, \"\");\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n            \"Could not execute PUT request. Error response: \" + responseToString(response));\n    }\n}",
        "summary_tokens": [
            "pause",
            "an",
            "existing",
            "connector"
        ]
    },
    {
        "id": 2114,
        "code": "public void resumeConnector(String connName) {\n    String url = endpointForResource(String.format(\"connectors/%s/resume\", connName));\n    Response response = requestPut(url, \"\");\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n            \"Could not execute PUT request. Error response: \" + responseToString(response));\n    }\n}",
        "summary_tokens": [
            "resume",
            "an",
            "existing",
            "connector"
        ]
    },
    {
        "id": 2115,
        "code": "public void restartConnector(String connName) {\n    String url = endpointForResource(String.format(\"connectors/%s/restart\", connName));\n    Response response = requestPost(url, \"\", Collections.emptyMap());\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n            \"Could not execute POST request. Error response: \" + responseToString(response));\n    }\n}",
        "summary_tokens": [
            "restart",
            "an",
            "existing",
            "connector"
        ]
    },
    {
        "id": 2116,
        "code": "public ConnectorStateInfo restartConnectorAndTasks(String connName, boolean onlyFailed, boolean includeTasks, boolean onlyCallOnEmptyWorker) {\n    ObjectMapper mapper = new ObjectMapper();\n    String restartPath = String.format(\"connectors/%s/restart?onlyFailed=\" + onlyFailed + \"&includeTasks=\" + includeTasks, connName);\n    String restartEndpoint;\n    if (onlyCallOnEmptyWorker) {\n        restartEndpoint = endpointForResourceNotRunningConnector(restartPath, connName);\n    } else {\n        restartEndpoint = endpointForResource(restartPath);\n    }\n    Response response = requestPost(restartEndpoint, \"\", Collections.emptyMap());\n    try {\n        if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n                \n            if (response.getStatus() == Response.Status.ACCEPTED.getStatusCode()) {\n                return mapper.readerFor(ConnectorStateInfo.class)\n                        .readValue(responseToString(response));\n            }\n        }\n        return null;\n    } catch (IOException e) {\n        log.error(\"Could not read connector state from response: {}\",\n                responseToString(response), e);\n        throw new ConnectException(\"Could not not parse connector state\", e);\n    }\n}",
        "summary_tokens": [
            "restart",
            "an",
            "existing",
            "connector",
            "and",
            "its",
            "tasks"
        ]
    },
    {
        "id": 2117,
        "code": "public Collection<String> connectors() {\n    ObjectMapper mapper = new ObjectMapper();\n    String url = endpointForResource(\"connectors\");\n    Response response = requestGet(url);\n    if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n        try {\n            return mapper.readerFor(Collection.class).readValue(responseToString(response));\n        } catch (IOException e) {\n            log.error(\"Could not parse connector list from response: {}\",\n                    responseToString(response), e\n            );\n            throw new ConnectException(\"Could not not parse connector list\", e);\n        }\n    }\n    throw new ConnectRestException(response.getStatus(),\n            \"Could not read connector list. Error response: \" + responseToString(response));\n}",
        "summary_tokens": [
            "get",
            "the",
            "connector",
            "names",
            "of",
            "the",
            "connectors",
            "currently",
            "running",
            "on",
            "this",
            "cluster"
        ]
    },
    {
        "id": 2118,
        "code": "public ConnectorStateInfo connectorStatus(String connectorName) {\n    ObjectMapper mapper = new ObjectMapper();\n    String url = endpointForResource(String.format(\"connectors/%s/status\", connectorName));\n    Response response = requestGet(url);\n    try {\n        if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n            return mapper.readerFor(ConnectorStateInfo.class)\n                    .readValue(responseToString(response));\n        }\n    } catch (IOException e) {\n        log.error(\"Could not read connector state from response: {}\",\n                responseToString(response), e);\n        throw new ConnectException(\"Could not not parse connector state\", e);\n    }\n    throw new ConnectRestException(response.getStatus(),\n            \"Could not read connector state. Error response: \" + responseToString(response));\n}",
        "summary_tokens": [
            "get",
            "the",
            "status",
            "for",
            "a",
            "connector",
            "running",
            "in",
            "this",
            "cluster"
        ]
    },
    {
        "id": 2119,
        "code": "public ActiveTopicsInfo connectorTopics(String connectorName) {\n    ObjectMapper mapper = new ObjectMapper();\n    String url = endpointForResource(String.format(\"connectors/%s/topics\", connectorName));\n    Response response = requestGet(url);\n    try {\n        if (response.getStatus() < Response.Status.BAD_REQUEST.getStatusCode()) {\n            Map<String, Map<String, List<String>>> activeTopics = mapper\n                    .readerFor(new TypeReference<Map<String, Map<String, List<String>>>>() { })\n                    .readValue(responseToString(response));\n            return new ActiveTopicsInfo(connectorName,\n                    activeTopics.get(connectorName).getOrDefault(\"topics\", Collections.emptyList()));\n        }\n    } catch (IOException e) {\n        log.error(\"Could not read connector state from response: {}\",\n                responseToString(response), e);\n        throw new ConnectException(\"Could not not parse connector state\", e);\n    }\n    throw new ConnectRestException(response.getStatus(),\n            \"Could not read connector state. Error response: \" + responseToString(response));\n}",
        "summary_tokens": [
            "get",
            "the",
            "active",
            "topics",
            "of",
            "a",
            "connector",
            "running",
            "in",
            "this",
            "cluster"
        ]
    },
    {
        "id": 2120,
        "code": "public void resetConnectorTopics(String connectorName) {\n    String url = endpointForResource(String.format(\"connectors/%s/topics/reset\", connectorName));\n    Response response = requestPut(url, null);\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n                \"Resetting active topics for connector \" + connectorName + \" failed. \"\n                + \"Error response: \" + responseToString(response));\n    }\n}",
        "summary_tokens": [
            "reset",
            "the",
            "set",
            "of",
            "active",
            "topics",
            "of",
            "a",
            "connector",
            "running",
            "in",
            "this",
            "cluster"
        ]
    },
    {
        "id": 2121,
        "code": "public String adminEndpoint(String resource) {\n    String url = connectCluster.stream()\n            .map(WorkerHandle::adminUrl)\n            .filter(Objects::nonNull)\n            .findFirst()\n            .orElseThrow(() -> new ConnectException(\"Admin endpoint is disabled.\"))\n            .toString();\n    return url + resource;\n}",
        "summary_tokens": [
            "get",
            "the",
            "full",
            "url",
            "of",
            "the",
            "admin",
            "endpoint",
            "that",
            "corresponds",
            "to",
            "the",
            "given",
            "rest",
            "resource"
        ]
    },
    {
        "id": 2122,
        "code": "public String endpointForResource(String resource) {\n    String url = connectCluster.stream()\n            .map(WorkerHandle::url)\n            .filter(Objects::nonNull)\n            .findFirst()\n            .orElseThrow(() -> new ConnectException(\"Connect workers have not been provisioned\"))\n            .toString();\n    return url + resource;\n}",
        "summary_tokens": [
            "get",
            "the",
            "full",
            "url",
            "of",
            "the",
            "endpoint",
            "that",
            "corresponds",
            "to",
            "the",
            "given",
            "rest",
            "resource"
        ]
    },
    {
        "id": 2123,
        "code": "public String endpointForResourceNotRunningConnector(String resource, String connectorName) {\n    ConnectorStateInfo info = connectorStatus(connectorName);\n    Set<String> activeWorkerUrls = new HashSet<>();\n    activeWorkerUrls.add(String.format(\"http://%s/\", info.connector().workerId()));\n    info.tasks().forEach(t -> activeWorkerUrls.add(String.format(\"http://%s/\", t.workerId())));\n    String url = connectCluster.stream()\n            .map(WorkerHandle::url)\n            .filter(Objects::nonNull)\n            .filter(workerUrl -> !activeWorkerUrls.contains(workerUrl.toString()))\n            .findFirst()\n            .orElseThrow(() -> new ConnectException(\n                    String.format(\"Connect workers have not been provisioned or no free worker found that is not running this connector(%s) or its tasks\", connectorName)))\n            .toString();\n    return url + resource;\n}",
        "summary_tokens": [
            "get",
            "the",
            "full",
            "url",
            "of",
            "the",
            "endpoint",
            "that",
            "corresponds",
            "to",
            "the",
            "given",
            "rest",
            "resource",
            "using",
            "a",
            "worker",
            "that",
            "is",
            "not",
            "running",
            "any",
            "tasks",
            "or",
            "connector",
            "instance",
            "for",
            "the",
            "connector",
            "name",
            "provided",
            "in",
            "the",
            "arguments"
        ]
    },
    {
        "id": 2124,
        "code": "public EmbeddedKafkaCluster kafka() {\n    return kafkaCluster;\n}",
        "summary_tokens": [
            "return",
            "the",
            "handle",
            "to",
            "the",
            "kafka",
            "cluster",
            "this",
            "connect",
            "cluster",
            "connects",
            "to"
        ]
    },
    {
        "id": 2125,
        "code": "public String executeGet(String url) {\n    return responseToString(requestGet(url));\n}",
        "summary_tokens": [
            "execute",
            "a",
            "get",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2126,
        "code": "public Response requestGet(String url) {\n    return requestHttpMethod(url, null, Collections.emptyMap(), \"GET\");\n}",
        "summary_tokens": [
            "execute",
            "a",
            "get",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2127,
        "code": "public int executePut(String url, String body) {\n    return requestPut(url, body).getStatus();\n}",
        "summary_tokens": [
            "execute",
            "a",
            "put",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2128,
        "code": "public Response requestPut(String url, String body) {\n    return requestHttpMethod(url, body, Collections.emptyMap(), \"PUT\");\n}",
        "summary_tokens": [
            "execute",
            "a",
            "put",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2129,
        "code": "public int executePost(String url, String body, Map<String, String> headers) {\n    return requestPost(url, body, headers).getStatus();\n}",
        "summary_tokens": [
            "execute",
            "a",
            "post",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2130,
        "code": "public Response requestPost(String url, String body, Map<String, String> headers) {\n    return requestHttpMethod(url, body, headers, \"POST\");\n}",
        "summary_tokens": [
            "execute",
            "a",
            "post",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2131,
        "code": "public int executeDelete(String url) {\n    return requestDelete(url).getStatus();\n}",
        "summary_tokens": [
            "execute",
            "a",
            "delete",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2132,
        "code": "public Response requestDelete(String url) {\n    return requestHttpMethod(url, null, Collections.emptyMap(), \"DELETE\");\n}",
        "summary_tokens": [
            "execute",
            "a",
            "delete",
            "request",
            "on",
            "the",
            "given",
            "url"
        ]
    },
    {
        "id": 2133,
        "code": "protected Response requestHttpMethod(String url, String body, Map<String, String> headers,\n                                  String httpMethod) {\n    log.debug(\"Executing {} request to URL={}.\" + (body != null ? \" Payload={}\" : \"\"),\n            httpMethod, url, body);\n    try {\n        HttpURLConnection httpCon = (HttpURLConnection) new URL(url).openConnection();\n        httpCon.setDoOutput(true);\n        httpCon.setRequestMethod(httpMethod);\n        if (body != null) {\n            httpCon.setRequestProperty(\"Content-Type\", \"application/json\");\n            headers.forEach(httpCon::setRequestProperty);\n            try (OutputStreamWriter out = new OutputStreamWriter(httpCon.getOutputStream())) {\n                out.write(body);\n            }\n        }\n        try (InputStream is = httpCon.getResponseCode() < HttpURLConnection.HTTP_BAD_REQUEST\n                              ? httpCon.getInputStream()\n                              : httpCon.getErrorStream()\n        ) {\n            String responseEntity = responseToString(is);\n            log.info(\"{} response for URL={} is {}\",\n                    httpMethod, url, responseEntity.isEmpty() ? \"empty\" : responseEntity);\n            return Response.status(Response.Status.fromStatusCode(httpCon.getResponseCode()))\n                    .entity(responseEntity)\n                    .build();\n        }\n    } catch (IOException e) {\n        log.error(\"Could not execute \" + httpMethod + \" request to \" + url, e);\n        throw new ConnectException(e);\n    }\n}",
        "summary_tokens": [
            "a",
            "general",
            "method",
            "that",
            "executes",
            "an",
            "http",
            "request",
            "on",
            "a",
            "given",
            "url"
        ]
    },
    {
        "id": 2134,
        "code": "public EmbeddedConnectClusterAssertions assertions() {\n    return assertions;\n}",
        "summary_tokens": [
            "return",
            "the",
            "available",
            "assertions",
            "for",
            "this",
            "connect",
            "cluster"
        ]
    },
    {
        "id": 2135,
        "code": "public void assertAtLeastNumWorkersAreUp(int numWorkers, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkWorkersUp(numWorkers, (actual, expected) -> actual >= expected).orElse(false),\n            WORKER_SETUP_DURATION_MS,\n            \"Didn't meet the minimum requested number of online workers: \" + numWorkers);\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "at",
            "least",
            "the",
            "requested",
            "number",
            "of",
            "workers",
            "are",
            "up",
            "and",
            "running"
        ]
    },
    {
        "id": 2136,
        "code": "public void assertExactlyNumWorkersAreUp(int numWorkers, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkWorkersUp(numWorkers, (actual, expected) -> actual == expected).orElse(false),\n            WORKER_SETUP_DURATION_MS,\n            \"Didn't meet the exact requested number of online workers: \" + numWorkers);\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "at",
            "least",
            "the",
            "requested",
            "number",
            "of",
            "workers",
            "are",
            "up",
            "and",
            "running"
        ]
    },
    {
        "id": 2137,
        "code": "protected Optional<Boolean> checkWorkersUp(int numWorkers, BiFunction<Integer, Integer, Boolean> comp) {\n    try {\n        int numUp = connect.activeWorkers().size();\n        return Optional.of(comp.apply(numUp, numWorkers));\n    } catch (Exception e) {\n        log.error(\"Could not check active workers.\", e);\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "confirm",
            "that",
            "the",
            "requested",
            "number",
            "of",
            "workers",
            "are",
            "up",
            "and",
            "running"
        ]
    },
    {
        "id": 2138,
        "code": "public void assertExactlyNumBrokersAreUp(int numBrokers, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkBrokersUp(numBrokers, (actual, expected) -> actual == expected).orElse(false),\n            WORKER_SETUP_DURATION_MS,\n            \"Didn't meet the exact requested number of online brokers: \" + numBrokers);\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "at",
            "least",
            "the",
            "requested",
            "number",
            "of",
            "workers",
            "are",
            "up",
            "and",
            "running"
        ]
    },
    {
        "id": 2139,
        "code": "protected Optional<Boolean> checkBrokersUp(int numBrokers, BiFunction<Integer, Integer, Boolean> comp) {\n    try {\n        int numRunning = connect.kafka().runningBrokers().size();\n        return Optional.of(comp.apply(numRunning, numBrokers));\n    } catch (Exception e) {\n        log.error(\"Could not check running brokers.\", e);\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "confirm",
            "that",
            "the",
            "requested",
            "number",
            "of",
            "brokers",
            "are",
            "up",
            "and",
            "running"
        ]
    },
    {
        "id": 2140,
        "code": "public void assertTopicsDoNotExist(String... topicNames) throws InterruptedException {\n    Set<String> topicNameSet = new HashSet<>(Arrays.asList(topicNames));\n    AtomicReference<Set<String>> existingTopics = new AtomicReference<>(topicNameSet);\n    waitForCondition(\n        () -> checkTopicsExist(topicNameSet, (actual, expected) -> {\n            existingTopics.set(actual);\n            return actual.isEmpty();\n        }).orElse(false),\n        CONNECTOR_SETUP_DURATION_MS,\n        \"Unexpectedly found topics \" + existingTopics.get());\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "topics",
            "with",
            "the",
            "specified",
            "names",
            "do",
            "not",
            "exist"
        ]
    },
    {
        "id": 2141,
        "code": "public void assertTopicsExist(String... topicNames) throws InterruptedException {\n    Set<String> topicNameSet = new HashSet<>(Arrays.asList(topicNames));\n    AtomicReference<Set<String>> missingTopics = new AtomicReference<>(topicNameSet);\n    waitForCondition(\n        () -> checkTopicsExist(topicNameSet, (actual, expected) -> {\n            Set<String> missing = new HashSet<>(expected);\n            missing.removeAll(actual);\n            missingTopics.set(missing);\n            return missing.isEmpty();\n        }).orElse(false),\n        CONNECTOR_SETUP_DURATION_MS,\n        \"Didn't find the topics \" + missingTopics.get());\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "topics",
            "with",
            "the",
            "specified",
            "names",
            "do",
            "exist"
        ]
    },
    {
        "id": 2142,
        "code": "public void assertTopicSettings(String topicName, int replicas, int partitions, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkTopicSettings(\n                topicName,\n                replicas,\n                partitions\n            ).orElse(false),\n            VALIDATION_DURATION_MS,\n            \"Topic \" + topicName + \" does not exist or does not have exactly \"\n                    + partitions + \" partitions or at least \"\n                    + replicas + \" per partition\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "named",
            "topic",
            "is",
            "configured",
            "to",
            "have",
            "the",
            "specified",
            "replication",
            "factor",
            "and",
            "number",
            "of",
            "partitions"
        ]
    },
    {
        "id": 2143,
        "code": "public void assertExactlyNumErrorsOnConnectorConfigValidation(String connectorClass, Map<String, String> connConfig,\n    int numErrors, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkValidationErrors(\n                connectorClass,\n                connConfig,\n                numErrors,\n                (actual, expected) -> actual == expected\n            ).orElse(false),\n            VALIDATION_DURATION_MS,\n            \"Didn't meet the exact requested number of validation errors: \" + numErrors);\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "required",
            "number",
            "of",
            "errors",
            "are",
            "produced",
            "by",
            "a",
            "connector",
            "config",
            "validation"
        ]
    },
    {
        "id": 2144,
        "code": "protected Optional<Boolean> checkValidationErrors(String connectorClass, Map<String, String> connConfig,\n    int numErrors, BiFunction<Integer, Integer, Boolean> comp) {\n    try {\n        int numErrorsProduced = connect.validateConnectorConfig(connectorClass, connConfig).errorCount();\n        return Optional.of(comp.apply(numErrorsProduced, numErrors));\n    } catch (Exception e) {\n        log.error(\"Could not check config validation error count.\", e);\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "confirm",
            "that",
            "the",
            "requested",
            "number",
            "of",
            "errors",
            "are",
            "produced",
            "by",
            "embedded",
            "connect",
            "cluster",
            "validate",
            "connector",
            "config"
        ]
    },
    {
        "id": 2145,
        "code": "public void assertConnectorAndAtLeastNumTasksAreRunning(String connectorName, int numTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorState(\n                connectorName,\n                AbstractStatus.State.RUNNING,\n                numTasks,\n                AbstractStatus.State.RUNNING,\n                (actual, expected) -> actual >= expected\n            ).orElse(false),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"The connector or at least \" + numTasks + \" of tasks are not running.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "connector",
            "is",
            "running",
            "with",
            "at",
            "least",
            "the",
            "given",
            "number",
            "of",
            "tasks",
            "all",
            "in",
            "running",
            "state"
        ]
    },
    {
        "id": 2146,
        "code": "public void assertConnectorAndExactlyNumTasksAreRunning(String connectorName, int numTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorState(\n                connectorName,\n                AbstractStatus.State.RUNNING,\n                numTasks,\n                AbstractStatus.State.RUNNING,\n                (actual, expected) -> actual == expected\n            ).orElse(false),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"The connector or exactly \" + numTasks + \" tasks are not running.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "connector",
            "is",
            "running",
            "with",
            "at",
            "least",
            "the",
            "given",
            "number",
            "of",
            "tasks",
            "all",
            "in",
            "running",
            "state"
        ]
    },
    {
        "id": 2147,
        "code": "public void assertConnectorIsRunningAndTasksHaveFailed(String connectorName, int numTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorState(\n                connectorName,\n                AbstractStatus.State.RUNNING,\n                numTasks,\n                AbstractStatus.State.FAILED,\n                (actual, expected) -> actual >= expected\n            ).orElse(false),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"Either the connector is not running or not all the \" + numTasks + \" tasks have failed.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "connector",
            "is",
            "running",
            "that",
            "it",
            "has",
            "a",
            "specific",
            "number",
            "of",
            "tasks",
            "and",
            "that",
            "all",
            "of",
            "its",
            "tasks",
            "are",
            "in",
            "the",
            "failed",
            "state"
        ]
    },
    {
        "id": 2148,
        "code": "public void assertConnectorIsRunningAndNumTasksHaveFailed(String connectorName, int numTasks, int numFailedTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n                () -> checkConnectorState(\n                        connectorName,\n                        AbstractStatus.State.RUNNING,\n                        numTasks,\n                        numFailedTasks,\n                        AbstractStatus.State.FAILED,\n                        (actual, expected) -> actual >= expected\n                ).orElse(false),\n                CONNECTOR_SETUP_DURATION_MS,\n                \"Either the connector is not running or not all the \" + numTasks + \" tasks have failed.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "connector",
            "is",
            "running",
            "that",
            "it",
            "has",
            "a",
            "specific",
            "number",
            "of",
            "tasks",
            "out",
            "of",
            "that",
            "num",
            "failed",
            "tasks",
            "are",
            "in",
            "the",
            "failed",
            "state"
        ]
    },
    {
        "id": 2149,
        "code": "public void assertConnectorIsFailedAndTasksHaveFailed(String connectorName, int numTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n                () -> checkConnectorState(\n                        connectorName,\n                        AbstractStatus.State.FAILED,\n                        numTasks,\n                        AbstractStatus.State.FAILED,\n                        (actual, expected) -> actual >= expected\n                ).orElse(false),\n                CONNECTOR_SETUP_DURATION_MS,\n                \"Either the connector is running or not all the \" + numTasks + \" tasks have failed.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "connector",
            "is",
            "in",
            "failed",
            "state",
            "that",
            "it",
            "has",
            "a",
            "specific",
            "number",
            "of",
            "tasks",
            "and",
            "that",
            "all",
            "of",
            "its",
            "tasks",
            "are",
            "in",
            "the",
            "failed",
            "state"
        ]
    },
    {
        "id": 2150,
        "code": "public void assertConnectorAndTasksAreStopped(String connectorName, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorAndTasksAreStopped(connectorName),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"At least the connector or one of its tasks is still running\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "connector",
            "and",
            "its",
            "tasks",
            "are",
            "not",
            "running"
        ]
    },
    {
        "id": 2151,
        "code": "protected boolean checkConnectorAndTasksAreStopped(String connectorName) {\n    ConnectorStateInfo info;\n    try {\n        info = connect.connectorStatus(connectorName);\n    } catch (ConnectRestException e) {\n        return e.statusCode() == Response.Status.NOT_FOUND.getStatusCode();\n    } catch (Exception e) {\n        log.error(\"Could not check connector state info.\", e);\n        return false;\n    }\n    if (info == null) {\n        return true;\n    }\n    return !info.connector().state().equals(AbstractStatus.State.RUNNING.toString())\n            && info.tasks().stream().noneMatch(s -> s.state().equals(AbstractStatus.State.RUNNING.toString()));\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "connector",
            "or",
            "any",
            "of",
            "its",
            "tasks",
            "are",
            "still",
            "in",
            "running",
            "state"
        ]
    },
    {
        "id": 2152,
        "code": "protected Optional<Boolean> checkConnectorState(\n        String connectorName,\n        AbstractStatus.State connectorState,\n        int numTasks,\n        int numTasksInTasksState,\n        AbstractStatus.State tasksState,\n        BiFunction<Integer, Integer, Boolean> comp\n) {\n    try {\n        ConnectorStateInfo info = connect.connectorStatus(connectorName);\n        boolean result = info != null\n                && comp.apply(info.tasks().size(), numTasks)\n                && info.connector().state().equals(connectorState.toString())\n                && info.tasks().stream().filter(s -> s.state().equals(tasksState.toString())).count() == numTasksInTasksState;\n        return Optional.of(result);\n    } catch (Exception e) {\n        log.error(\"Could not check connector state info.\", e);\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "given",
            "connector",
            "state",
            "matches",
            "the",
            "current",
            "state",
            "of",
            "the",
            "connector",
            "and",
            "whether",
            "it",
            "has",
            "at",
            "least",
            "the",
            "given",
            "number",
            "of",
            "tasks",
            "with",
            "num",
            "tasks",
            "in",
            "tasks",
            "state",
            "matching",
            "the",
            "given",
            "task",
            "state"
        ]
    },
    {
        "id": 2153,
        "code": "public void assertConnectorActiveTopics(String connectorName, Collection<String> topics, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorActiveTopics(connectorName, topics).orElse(false),\n            CONNECT_INTERNAL_TOPIC_UPDATES_DURATION_MS,\n            \"Connector active topics don't match the expected collection\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "connector",
            "s",
            "set",
            "of",
            "active",
            "topics",
            "matches",
            "the",
            "given",
            "collection",
            "of",
            "topic",
            "names"
        ]
    },
    {
        "id": 2154,
        "code": "protected Optional<Boolean> checkConnectorActiveTopics(String connectorName, Collection<String> topics) {\n    try {\n        ActiveTopicsInfo info = connect.connectorTopics(connectorName);\n        boolean result = info != null\n                && topics.size() == info.topics().size()\n                && topics.containsAll(info.topics());\n        log.debug(\"Found connector {} using topics: {}\", connectorName, info.topics());\n        return Optional.of(result);\n    } catch (Exception e) {\n        log.error(\"Could not check connector {} state info.\", connectorName, e);\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "check",
            "whether",
            "a",
            "connector",
            "s",
            "set",
            "of",
            "active",
            "topics",
            "matches",
            "the",
            "given",
            "collection",
            "of",
            "topic",
            "names"
        ]
    },
    {
        "id": 2155,
        "code": "public void startOnlyKafkaOnSamePorts() {\n    doStart();\n}",
        "summary_tokens": [
            "starts",
            "the",
            "kafka",
            "cluster",
            "alone",
            "using",
            "the",
            "ports",
            "that",
            "were",
            "assigned",
            "during",
            "initialization",
            "of",
            "the",
            "harness"
        ]
    },
    {
        "id": 2156,
        "code": "public Set<KafkaServer> runningBrokers() {\n    return brokersInState(state -> state == BrokerState.RUNNING);\n}",
        "summary_tokens": [
            "get",
            "the",
            "brokers",
            "that",
            "have",
            "a",
            "broker",
            "state",
            "running",
            "state"
        ]
    },
    {
        "id": 2157,
        "code": "public Set<KafkaServer> brokersInState(Predicate<BrokerState> desiredState) {\n    return Arrays.stream(brokers)\n                 .filter(b -> hasState(b, desiredState))\n                 .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "get",
            "the",
            "brokers",
            "whose",
            "state",
            "match",
            "the",
            "given",
            "predicate"
        ]
    },
    {
        "id": 2158,
        "code": "public Map<String, Optional<TopicDescription>> describeTopics(Set<String> topicNames) {\n    Map<String, Optional<TopicDescription>> results = new HashMap<>();\n    log.info(\"Describing topics {}\", topicNames);\n    try (Admin admin = createAdminClient()) {\n        DescribeTopicsResult result = admin.describeTopics(topicNames);\n        Map<String, KafkaFuture<TopicDescription>> byName = result.topicNameValues();\n        for (Map.Entry<String, KafkaFuture<TopicDescription>> entry : byName.entrySet()) {\n            String topicName = entry.getKey();\n            try {\n                TopicDescription desc = entry.getValue().get();\n                results.put(topicName, Optional.of(desc));\n                log.info(\"Found topic {} : {}\", topicName, desc);\n            } catch (ExecutionException e) {\n                Throwable cause = e.getCause();\n                if (cause instanceof UnknownTopicOrPartitionException) {\n                    results.put(topicName, Optional.empty());\n                    log.info(\"Found non-existant topic {}\", topicName);\n                    continue;\n                }\n                throw new AssertionError(\"Could not describe topic(s)\" + topicNames, e);\n            }\n        }\n    } catch (Exception e) {\n        throw new AssertionError(\"Could not describe topic(s) \" + topicNames, e);\n    }\n    log.info(\"Found topics {}\", results);\n    return results;\n}",
        "summary_tokens": [
            "get",
            "the",
            "topic",
            "descriptions",
            "of",
            "the",
            "named",
            "topics"
        ]
    },
    {
        "id": 2159,
        "code": "public void createTopic(String topic, int partitions, int replication, Map<String, String> topicConfig, Properties adminClientConfig) {\n    if (replication > brokers.length) {\n        throw new InvalidReplicationFactorException(\"Insufficient brokers (\"\n                + brokers.length + \") for desired replication (\" + replication + \")\");\n    }\n\n    log.info(\"Creating topic { name: {}, partitions: {}, replication: {}, config: {} }\",\n            topic, partitions, replication, topicConfig);\n    final NewTopic newTopic = new NewTopic(topic, partitions, (short) replication);\n    newTopic.configs(topicConfig);\n\n    try (final Admin adminClient = createAdminClient(adminClientConfig)) {\n        adminClient.createTopics(Collections.singletonList(newTopic)).all().get();\n    } catch (final InterruptedException | ExecutionException e) {\n        throw new RuntimeException(e);\n    }\n}",
        "summary_tokens": [
            "create",
            "a",
            "kafka",
            "topic",
            "with",
            "the",
            "given",
            "parameters"
        ]
    },
    {
        "id": 2160,
        "code": "public void deleteTopic(String topic) {\n    try (final Admin adminClient = createAdminClient()) {\n        adminClient.deleteTopics(Collections.singleton(topic)).all().get();\n    } catch (final InterruptedException | ExecutionException e) {\n        throw new RuntimeException(e);\n    }\n}",
        "summary_tokens": [
            "delete",
            "a",
            "kafka",
            "topic"
        ]
    },
    {
        "id": 2161,
        "code": "public ConsumerRecords<byte[], byte[]> consume(int n, long maxDuration, Map<String, Object> consumerProps, String... topics) {\n    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> records = new HashMap<>();\n    int consumedRecords = 0;\n    try (KafkaConsumer<byte[], byte[]> consumer = createConsumerAndSubscribeTo(consumerProps, topics)) {\n        final long startMillis = System.currentTimeMillis();\n        long allowedDuration = maxDuration;\n        while (allowedDuration > 0) {\n            log.debug(\"Consuming from {} for {} millis.\", Arrays.toString(topics), allowedDuration);\n            ConsumerRecords<byte[], byte[]> rec = consumer.poll(Duration.ofMillis(allowedDuration));\n            if (rec.isEmpty()) {\n                allowedDuration = maxDuration - (System.currentTimeMillis() - startMillis);\n                continue;\n            }\n            for (TopicPartition partition: rec.partitions()) {\n                final List<ConsumerRecord<byte[], byte[]>> r = rec.records(partition);\n                records.computeIfAbsent(partition, t -> new ArrayList<>()).addAll(r);\n                consumedRecords += r.size();\n            }\n            if (consumedRecords >= n) {\n                return new ConsumerRecords<>(records);\n            }\n            allowedDuration = maxDuration - (System.currentTimeMillis() - startMillis);\n        }\n    }\n\n    throw new RuntimeException(\"Could not find enough records. found \" + consumedRecords + \", expected \" + n);\n}",
        "summary_tokens": [
            "consume",
            "at",
            "least",
            "n",
            "records",
            "in",
            "a",
            "given",
            "duration",
            "or",
            "throw",
            "an",
            "exception"
        ]
    },
    {
        "id": 2162,
        "code": "public ConsumerRecords<byte[], byte[]> consumeAll(\n        long maxDurationMs,\n        Map<String, Object> consumerProps,\n        Map<String, Object> adminProps,\n        String... topics\n) throws TimeoutException, InterruptedException, ExecutionException {\n    long endTimeMs = System.currentTimeMillis() + maxDurationMs;\n\n    Consumer<byte[], byte[]> consumer = createConsumer(consumerProps != null ? consumerProps : Collections.emptyMap());\n    Admin admin = createAdminClient(Utils.mkObjectProperties(adminProps != null ? adminProps : Collections.emptyMap()));\n\n    long remainingTimeMs = endTimeMs - System.currentTimeMillis();\n    Set<TopicPartition> topicPartitions = listPartitions(remainingTimeMs, admin, Arrays.asList(topics));\n\n    remainingTimeMs = endTimeMs - System.currentTimeMillis();\n    Map<TopicPartition, Long> endOffsets = readEndOffsets(remainingTimeMs, admin, topicPartitions);\n\n    Map<TopicPartition, List<ConsumerRecord<byte[], byte[]>>> records = topicPartitions.stream()\n            .collect(Collectors.toMap(\n                    Function.identity(),\n                    tp -> new ArrayList<>()\n            ));\n    consumer.assign(topicPartitions);\n\n    while (!endOffsets.isEmpty()) {\n        Iterator<Map.Entry<TopicPartition, Long>> it = endOffsets.entrySet().iterator();\n        while (it.hasNext()) {\n            Map.Entry<TopicPartition, Long> entry = it.next();\n            TopicPartition topicPartition = entry.getKey();\n            long endOffset = entry.getValue();\n            long lastConsumedOffset = consumer.position(topicPartition);\n            if (lastConsumedOffset >= endOffset) {\n                    \n                it.remove();\n            } else {\n                remainingTimeMs = endTimeMs - System.currentTimeMillis();\n                if (remainingTimeMs <= 0) {\n                    throw new AssertionError(\"failed to read to end of topic(s) \" + Arrays.asList(topics) + \" within \" + maxDurationMs + \"ms\");\n                }\n                    \n                ConsumerRecords<byte[], byte[]> recordBatch = consumer.poll(Duration.ofMillis(remainingTimeMs));\n                recordBatch.partitions().forEach(tp -> records.get(tp)\n                        .addAll(recordBatch.records(tp))\n                );\n            }\n        }\n    }\n\n    return new ConsumerRecords<>(records);\n}",
        "summary_tokens": [
            "consume",
            "all",
            "currently",
            "available",
            "records",
            "for",
            "the",
            "specified",
            "topics",
            "in",
            "a",
            "given",
            "duration",
            "or",
            "throw",
            "an",
            "exception"
        ]
    },
    {
        "id": 2163,
        "code": "private Set<TopicPartition> listPartitions(\n        long maxDurationMs,\n        Admin admin,\n        Collection<String> topics\n) throws TimeoutException, InterruptedException, ExecutionException {\n    assertFalse(\"collection of topics may not be empty\", topics.isEmpty());\n    return admin.describeTopics(topics)\n            .allTopicNames().get(maxDurationMs, TimeUnit.MILLISECONDS)\n            .entrySet().stream()\n            .flatMap(e -> e.getValue().partitions().stream().map(p -> new TopicPartition(e.getKey(), p.partition())))\n            .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "list",
            "all",
            "the",
            "known",
            "partitions",
            "for",
            "the",
            "given",
            "collection",
            "of",
            "topics",
            "max",
            "duration",
            "ms",
            "the",
            "max",
            "duration",
            "to",
            "wait",
            "for",
            "while",
            "fetching",
            "metadata",
            "from",
            "kafka",
            "in",
            "milliseconds"
        ]
    },
    {
        "id": 2164,
        "code": "private Map<TopicPartition, Long> readEndOffsets(\n        long maxDurationMs,\n        Admin admin,\n        Collection<TopicPartition> topicPartitions\n) throws TimeoutException, InterruptedException, ExecutionException {\n    assertFalse(\"collection of topic partitions may not be empty\", topicPartitions.isEmpty());\n    Map<TopicPartition, OffsetSpec> offsetSpecMap = topicPartitions.stream().collect(Collectors.toMap(Function.identity(), tp -> OffsetSpec.latest()));\n    return admin.listOffsets(offsetSpecMap, new ListOffsetsOptions(IsolationLevel.READ_UNCOMMITTED))\n            .all().get(maxDurationMs, TimeUnit.MILLISECONDS)\n            .entrySet().stream()\n            .collect(Collectors.toMap(\n                    Map.Entry::getKey,\n                    e -> e.getValue().offset()\n            ));\n}",
        "summary_tokens": [
            "list",
            "the",
            "latest",
            "current",
            "offsets",
            "for",
            "the",
            "given",
            "collection",
            "of",
            "topic",
            "partition",
            "topic",
            "partitions",
            "max",
            "duration",
            "ms",
            "the",
            "max",
            "duration",
            "to",
            "wait",
            "for",
            "while",
            "fetching",
            "metadata",
            "from",
            "kafka",
            "in",
            "milliseconds",
            "admin",
            "the",
            "admin",
            "client",
            "to",
            "use",
            "for",
            "fetching",
            "metadata",
            "from",
            "the",
            "kafka",
            "cluster",
            "topic",
            "partitions",
            "the",
            "topic",
            "partitions",
            "to",
            "list",
            "end",
            "offsets",
            "for",
            "a",
            "map",
            "containing",
            "the",
            "latest",
            "offset",
            "for",
            "each",
            "requested",
            "topic",
            "partition",
            "topic",
            "partition",
            "never",
            "null",
            "and",
            "never",
            "empty"
        ]
    },
    {
        "id": 2165,
        "code": "public static WorkerHandle start(String name, Map<String, String> workerProperties) {\n    return new WorkerHandle(name, new ConnectDistributed().startConnect(workerProperties));\n}",
        "summary_tokens": [
            "create",
            "and",
            "start",
            "a",
            "new",
            "worker",
            "with",
            "the",
            "given",
            "properties"
        ]
    },
    {
        "id": 2166,
        "code": "public boolean isRunning() {\n    return worker.isRunning();\n}",
        "summary_tokens": [
            "determine",
            "if",
            "this",
            "worker",
            "is",
            "running"
        ]
    },
    {
        "id": 2167,
        "code": "public String name() {\n    return workerName;\n}",
        "summary_tokens": [
            "get",
            "the",
            "workers",
            "s",
            "name",
            "corresponding",
            "to",
            "this",
            "handle"
        ]
    },
    {
        "id": 2168,
        "code": "public URI url() {\n    return worker.rest().serverUrl();\n}",
        "summary_tokens": [
            "get",
            "the",
            "workers",
            "s",
            "url",
            "that",
            "accepts",
            "requests",
            "to",
            "its",
            "rest",
            "endpoint"
        ]
    },
    {
        "id": 2169,
        "code": "public URI adminUrl() {\n    return worker.rest().adminUrl();\n}",
        "summary_tokens": [
            "get",
            "the",
            "workers",
            "s",
            "url",
            "that",
            "accepts",
            "requests",
            "to",
            "its",
            "admin",
            "rest",
            "endpoint"
        ]
    },
    {
        "id": 2170,
        "code": "public void requestTimeout(long requestTimeoutMs) {\n    worker.rest().requestTimeout(requestTimeoutMs);\n}",
        "summary_tokens": [
            "set",
            "a",
            "new",
            "timeout",
            "for",
            "rest",
            "requests",
            "to",
            "the",
            "worker"
        ]
    },
    {
        "id": 2171,
        "code": "private void buildUpdatedSchema(Schema schema, String fieldNamePrefix, SchemaBuilder newSchema, boolean optional, Struct defaultFromParent) {\n    for (Field field : schema.fields()) {\n        final String fieldName = fieldName(fieldNamePrefix, field.name());\n        final boolean fieldIsOptional = optional || field.schema().isOptional();\n        Object fieldDefaultValue = null;\n        if (field.schema().defaultValue() != null) {\n            fieldDefaultValue = field.schema().defaultValue();\n        } else if (defaultFromParent != null) {\n            fieldDefaultValue = defaultFromParent.get(field);\n        }\n        switch (field.schema().type()) {\n            case INT8:\n            case INT16:\n            case INT32:\n            case INT64:\n            case FLOAT32:\n            case FLOAT64:\n            case BOOLEAN:\n            case STRING:\n            case BYTES:\n            case ARRAY:\n                newSchema.field(fieldName, convertFieldSchema(field.schema(), fieldIsOptional, fieldDefaultValue));\n                break;\n            case STRUCT:\n                buildUpdatedSchema(field.schema(), fieldName, newSchema, fieldIsOptional, (Struct) fieldDefaultValue);\n                break;\n            default:\n                throw new DataException(\"Flatten transformation does not support \" + field.schema().type()\n                        + \" for record with schemas (for field \" + fieldName + \").\");\n        }\n    }\n}",
        "summary_tokens": [
            "build",
            "an",
            "updated",
            "struct",
            "schema",
            "which",
            "flattens",
            "all",
            "nested",
            "fields",
            "into",
            "a",
            "single",
            "struct",
            "handling",
            "cases",
            "where",
            "optionality",
            "and",
            "default",
            "values",
            "of",
            "the",
            "flattened",
            "fields",
            "are",
            "affected",
            "by",
            "the",
            "optionality",
            "and",
            "default",
            "values",
            "of",
            "parent",
            "ancestor",
            "schemas",
            "e"
        ]
    },
    {
        "id": 2172,
        "code": "private Schema convertFieldSchema(Schema orig, boolean optional, Object defaultFromParent) {\n        \n        \n\n    final SchemaBuilder builder = SchemaUtil.copySchemaBasics(orig);\n    if (optional)\n        builder.optional();\n    if (defaultFromParent != null)\n        builder.defaultValue(defaultFromParent);\n    return builder.build();\n}",
        "summary_tokens": [
            "convert",
            "the",
            "schema",
            "for",
            "a",
            "field",
            "of",
            "a",
            "struct",
            "with",
            "a",
            "primitive",
            "schema",
            "to",
            "the",
            "schema",
            "to",
            "be",
            "used",
            "for",
            "the",
            "flattened",
            "version",
            "taking",
            "into",
            "account",
            "that",
            "we",
            "may",
            "need",
            "to",
            "override",
            "optionality",
            "and",
            "default",
            "values",
            "in",
            "the",
            "flattened",
            "version",
            "to",
            "take",
            "into",
            "account",
            "the",
            "optionality",
            "and",
            "default",
            "values",
            "of",
            "parent",
            "ancestor",
            "schemas",
            "orig",
            "the",
            "original",
            "schema",
            "for",
            "the",
            "field",
            "optional",
            "whether",
            "the",
            "new",
            "flattened",
            "field",
            "should",
            "be",
            "optional",
            "default",
            "from",
            "parent",
            "the",
            "default",
            "value",
            "either",
            "taken",
            "from",
            "the",
            "existing",
            "field",
            "or",
            "provided",
            "by",
            "the",
            "parent"
        ]
    },
    {
        "id": 2173,
        "code": "protected static Object updateSchemaIn(Object keyOrValue, Schema updatedSchema) {\n    if (keyOrValue instanceof Struct) {\n        Struct origStruct = (Struct) keyOrValue;\n        Struct newStruct = new Struct(updatedSchema);\n        for (Field field : updatedSchema.fields()) {\n                \n            newStruct.put(field, origStruct.get(field));\n        }\n        return newStruct;\n    }\n    return keyOrValue;\n}",
        "summary_tokens": [
            "utility",
            "to",
            "check",
            "the",
            "supplied",
            "key",
            "or",
            "value",
            "for",
            "references",
            "to",
            "the",
            "old",
            "schema",
            "and",
            "if",
            "so",
            "to",
            "return",
            "an",
            "updated",
            "key",
            "or",
            "value",
            "object",
            "that",
            "references",
            "the",
            "new",
            "schema"
        ]
    },
    {
        "id": 2174,
        "code": "private String timestampTypeFromSchema(Schema schema) {\n    if (Timestamp.LOGICAL_NAME.equals(schema.name())) {\n        return TYPE_TIMESTAMP;\n    } else if (org.apache.kafka.connect.data.Date.LOGICAL_NAME.equals(schema.name())) {\n        return TYPE_DATE;\n    } else if (Time.LOGICAL_NAME.equals(schema.name())) {\n        return TYPE_TIME;\n    } else if (schema.type().equals(Schema.Type.STRING)) {\n            \n        return TYPE_STRING;\n    } else if (schema.type().equals(Schema.Type.INT64)) {\n            \n        return TYPE_UNIX;\n    }\n    throw new ConnectException(\"Schema \" + schema + \" does not correspond to a known timestamp type format\");\n}",
        "summary_tokens": [
            "determine",
            "the",
            "type",
            "format",
            "of",
            "the",
            "timestamp",
            "based",
            "on",
            "the",
            "schema"
        ]
    },
    {
        "id": 2175,
        "code": "private String inferTimestampType(Object timestamp) {\n        \n        \n    if (timestamp instanceof Date) {\n        return TYPE_TIMESTAMP;\n    } else if (timestamp instanceof Long) {\n        return TYPE_UNIX;\n    } else if (timestamp instanceof String) {\n        return TYPE_STRING;\n    }\n    throw new DataException(\"TimestampConverter does not support \" + timestamp.getClass() + \" objects as timestamps\");\n}",
        "summary_tokens": [
            "infer",
            "the",
            "type",
            "format",
            "of",
            "the",
            "timestamp",
            "based",
            "on",
            "the",
            "raw",
            "java",
            "type"
        ]
    },
    {
        "id": 2176,
        "code": "private Object convertTimestamp(Object timestamp, String timestampFormat) {\n    if (timestamp == null) {\n        return null;\n    }\n    if (timestampFormat == null) {\n        timestampFormat = inferTimestampType(timestamp);\n    }\n\n    TimestampTranslator sourceTranslator = TRANSLATORS.get(timestampFormat);\n    if (sourceTranslator == null) {\n        throw new ConnectException(\"Unsupported timestamp type: \" + timestampFormat);\n    }\n    Date rawTimestamp = sourceTranslator.toRaw(config, timestamp);\n\n    TimestampTranslator targetTranslator = TRANSLATORS.get(config.type);\n    if (targetTranslator == null) {\n        throw new ConnectException(\"Unsupported timestamp type: \" + config.type);\n    }\n    return targetTranslator.toType(config, rawTimestamp);\n}",
        "summary_tokens": [
            "convert",
            "the",
            "given",
            "timestamp",
            "to",
            "the",
            "target",
            "timestamp",
            "format"
        ]
    },
    {
        "id": 2177,
        "code": "default Optional<ListenerName> controllerListenerName() {\n    return Optional.empty();\n}",
        "summary_tokens": [
            "the",
            "listener",
            "for",
            "the",
            "kraft",
            "cluster",
            "controller",
            "configured",
            "by",
            "controller"
        ]
    },
    {
        "id": 2178,
        "code": "default Optional<ListenerName> controlPlaneListenerName() {\n    return Optional.empty();\n}",
        "summary_tokens": [
            "the",
            "listener",
            "for",
            "the",
            "zk",
            "controller",
            "configured",
            "by",
            "control"
        ]
    },
    {
        "id": 2179,
        "code": "public void waitForReadyBrokers() throws ExecutionException, InterruptedException {\n        \n        \n    ControllerServer controllerServer = controllers.values().iterator().next();\n    Controller controller = controllerServer.controller();\n    controller.waitForReadyBrokers(brokers.size()).get();\n\n        \n    TestUtils.waitForCondition(() ->\n            brokers().values().stream().allMatch(brokerServer -> brokerServer.metadataCache().getAliveBrokers().size() == brokers.size()),\n        \"Failed to wait for publisher to publish the metadata update to each broker.\");\n}",
        "summary_tokens": [
            "wait",
            "for",
            "a",
            "controller",
            "to",
            "mark",
            "all",
            "the",
            "brokers",
            "as",
            "ready",
            "registered",
            "and",
            "unfenced"
        ]
    },
    {
        "id": 2180,
        "code": "String fieldDefault(HeaderGenerator headerGenerator,\n                    StructRegistry structRegistry) {\n    if (type instanceof FieldType.BoolFieldType) {\n        if (fieldDefault.isEmpty()) {\n            return \"false\";\n        } else if (fieldDefault.equalsIgnoreCase(\"true\")) {\n            return \"true\";\n        } else if (fieldDefault.equalsIgnoreCase(\"false\")) {\n            return \"false\";\n        } else {\n            throw new RuntimeException(\"Invalid default for boolean field \" +\n                name + \": \" + fieldDefault);\n        }\n    } else if ((type instanceof FieldType.Int8FieldType) ||\n        (type instanceof FieldType.Int16FieldType) ||\n        (type instanceof FieldType.Uint16FieldType) ||\n        (type instanceof FieldType.Uint32FieldType) ||\n        (type instanceof FieldType.Int32FieldType) ||\n        (type instanceof FieldType.Int64FieldType)) {\n        int base = 10;\n        String defaultString = fieldDefault;\n        if (defaultString.startsWith(\"0x\")) {\n            base = 16;\n            defaultString = defaultString.substring(2);\n        }\n        if (type instanceof FieldType.Int8FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"(byte) 0\";\n            } else {\n                try {\n                    Byte.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int8 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return \"(byte) \" + fieldDefault;\n            }\n        } else if (type instanceof FieldType.Int16FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"(short) 0\";\n            } else {\n                try {\n                    Short.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int16 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return \"(short) \" + fieldDefault;\n            }\n        } else if (type instanceof FieldType.Uint16FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0\";\n            } else {\n                try {\n                    int value = Integer.valueOf(defaultString, base);\n                    if (value < 0 || value > MessageGenerator.UNSIGNED_SHORT_MAX) {\n                        throw new RuntimeException(\"Invalid default for uint16 field \" +\n                                name + \": out of range.\");\n                    }\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for uint16 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return fieldDefault;\n            }\n        } else if (type instanceof FieldType.Uint32FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0\";\n            } else {\n                try {\n                    long value = Long.valueOf(defaultString, base);\n                    if (value < 0 || value > MessageGenerator.UNSIGNED_INT_MAX) {\n                        throw new RuntimeException(\"Invalid default for uint32 field \" +\n                                name + \": out of range.\");\n                    }\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for uint32 field \" +\n                            name + \": \" + defaultString, e);\n                }\n                return fieldDefault;\n            }\n        } else if (type instanceof FieldType.Int32FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0\";\n            } else {\n                try {\n                    Integer.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int32 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return fieldDefault;\n            }\n        } else if (type instanceof FieldType.Int64FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0L\";\n            } else {\n                try {\n                    Long.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int64 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return fieldDefault + \"L\";\n            }\n        } else {\n            throw new RuntimeException(\"Unsupported field type \" + type);\n        }\n    } else if (type instanceof FieldType.UUIDFieldType) {\n        headerGenerator.addImport(MessageGenerator.UUID_CLASS);\n        if (fieldDefault.isEmpty()) {\n            return \"Uuid.ZERO_UUID\";\n        } else {\n            try {\n                ByteBuffer uuidBytes = ByteBuffer.wrap(Base64.getUrlDecoder().decode(fieldDefault));\n                uuidBytes.getLong();\n                uuidBytes.getLong();\n            } catch (IllegalArgumentException e) {\n                throw new RuntimeException(\"Invalid default for uuid field \" +\n                    name + \": \" + fieldDefault, e);\n            }\n            headerGenerator.addImport(MessageGenerator.UUID_CLASS);\n            return \"Uuid.fromString(\\\"\" + fieldDefault + \"\\\")\";\n        }\n    } else if (type instanceof FieldType.Float64FieldType) {\n        if (fieldDefault.isEmpty()) {\n            return \"0.0\";\n        } else {\n            try {\n                Double.parseDouble(fieldDefault);\n            } catch (NumberFormatException e) {\n                throw new RuntimeException(\"Invalid default for float64 field \" +\n                    name + \": \" + fieldDefault, e);\n            }\n            return \"Double.parseDouble(\\\"\" + fieldDefault + \"\\\")\";\n        }\n    } else if (type instanceof FieldType.StringFieldType) {\n        if (fieldDefault.equals(\"null\")) {\n            validateNullDefault();\n            return \"null\";\n        } else {\n            return \"\\\"\" + fieldDefault + \"\\\"\";\n        }\n    } else if (type.isBytes()) {\n        if (fieldDefault.equals(\"null\")) {\n            validateNullDefault();\n            return \"null\";\n        } else if (!fieldDefault.isEmpty()) {\n            throw new RuntimeException(\"Invalid default for bytes field \" +\n                name + \".  The only valid default for a bytes field \" +\n                \"is empty or null.\");\n        }\n        if (zeroCopy) {\n            headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n            return \"ByteUtils.EMPTY_BUF\";\n        } else {\n            headerGenerator.addImport(MessageGenerator.BYTES_CLASS);\n            return \"Bytes.EMPTY\";\n        }\n    } else if (type.isRecords()) {\n        return \"null\";\n    } else if (type.isStruct()) {\n        if (!fieldDefault.isEmpty()) {\n            throw new RuntimeException(\"Invalid default for struct field \" +\n                name + \": custom defaults are not supported for struct fields.\");\n        }\n        return \"new \" + type.toString() + \"()\";\n    } else if (type.isArray()) {\n        if (fieldDefault.equals(\"null\")) {\n            validateNullDefault();\n            return \"null\";\n        } else if (!fieldDefault.isEmpty()) {\n            throw new RuntimeException(\"Invalid default for array field \" +\n                name + \".  The only valid default for an array field \" +\n                \"is the empty array or null.\");\n        }\n        return String.format(\"new %s(0)\",\n            concreteJavaType(headerGenerator, structRegistry));\n    } else {\n        throw new RuntimeException(\"Unsupported field type \" + type);\n    }\n}",
        "summary_tokens": [
            "get",
            "a",
            "string",
            "representation",
            "of",
            "the",
            "field",
            "default"
        ]
    },
    {
        "id": 2181,
        "code": "String fieldAbstractJavaType(HeaderGenerator headerGenerator,\n                             StructRegistry structRegistry) {\n    if (type instanceof FieldType.BoolFieldType) {\n        return \"boolean\";\n    } else if (type instanceof FieldType.Int8FieldType) {\n        return \"byte\";\n    } else if (type instanceof FieldType.Int16FieldType) {\n        return \"short\";\n    } else if (type instanceof FieldType.Uint16FieldType) {\n        return \"int\";\n    } else if (type instanceof FieldType.Uint32FieldType) {\n        return \"long\";\n    } else if (type instanceof FieldType.Int32FieldType) {\n        return \"int\";\n    } else if (type instanceof FieldType.Int64FieldType) {\n        return \"long\";\n    } else if (type instanceof FieldType.UUIDFieldType) {\n        headerGenerator.addImport(MessageGenerator.UUID_CLASS);\n        return \"Uuid\";\n    } else if (type instanceof FieldType.Float64FieldType) {\n        return \"double\";\n    } else if (type.isString()) {\n        return \"String\";\n    } else if (type.isBytes()) {\n        if (zeroCopy) {\n            headerGenerator.addImport(MessageGenerator.BYTE_BUFFER_CLASS);\n            return \"ByteBuffer\";\n        } else {\n            return \"byte[]\";\n        }\n    } else if (type instanceof FieldType.RecordsFieldType) {\n        headerGenerator.addImport(MessageGenerator.BASE_RECORDS_CLASS);\n        return \"BaseRecords\";\n    } else if (type.isStruct()) {\n        return MessageGenerator.capitalizeFirst(typeString());\n    } else if (type.isArray()) {\n        FieldType.ArrayType arrayType = (FieldType.ArrayType) type;\n        if (structRegistry.isStructArrayWithKeys(this)) {\n            headerGenerator.addImport(MessageGenerator.IMPLICIT_LINKED_HASH_MULTI_COLLECTION_CLASS);\n            return collectionType(arrayType.elementType().toString());\n        } else {\n            headerGenerator.addImport(MessageGenerator.LIST_CLASS);\n            return String.format(\"List<%s>\",\n                arrayType.elementType().getBoxedJavaType(headerGenerator));\n        }\n    } else {\n        throw new RuntimeException(\"Unknown field type \" + type);\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "abstract",
            "java",
            "type",
            "of",
            "the",
            "field",
            "for",
            "example",
            "list"
        ]
    },
    {
        "id": 2182,
        "code": "String concreteJavaType(HeaderGenerator headerGenerator,\n                        StructRegistry structRegistry) {\n    if (type.isArray()) {\n        FieldType.ArrayType arrayType = (FieldType.ArrayType) type;\n        if (structRegistry.isStructArrayWithKeys(this)) {\n            return collectionType(arrayType.elementType().toString());\n        } else {\n            headerGenerator.addImport(MessageGenerator.ARRAYLIST_CLASS);\n            return String.format(\"ArrayList<%s>\",\n                arrayType.elementType().getBoxedJavaType(headerGenerator));\n        }\n    } else {\n        return fieldAbstractJavaType(headerGenerator, structRegistry);\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "concrete",
            "java",
            "type",
            "of",
            "the",
            "field",
            "for",
            "example",
            "array",
            "list"
        ]
    },
    {
        "id": 2183,
        "code": "    void generateNonDefaultValueCheck(HeaderGenerator headerGenerator,\n                                      StructRegistry structRegistry,\n                                      CodeBuffer buffer,\n                                      String fieldPrefix,\n                                      Versions nullableVersions) {\n        String fieldDefault = fieldDefault(headerGenerator, structRegistry);\n        if (type().isArray()) {\n            if (fieldDefault.equals(\"null\")) {\n                buffer.printf(\"if (%s%s != null) {%n\", fieldPrefix, camelCaseName());\n            } else if (nullableVersions.empty()) {\n                buffer.printf(\"if (!%s%s.isEmpty()) {%n\", fieldPrefix, camelCaseName());\n            } else {\n                buffer.printf(\"if (%s%s == null || !%s%s.isEmpty()) {%n\",\n                    fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName());\n            }\n        } else if (type().isBytes()) {\n            if (fieldDefault.equals(\"null\")) {\n                buffer.printf(\"if (%s%s != null) {%n\", fieldPrefix, camelCaseName());\n            } else if (nullableVersions.empty()) {\n                if (zeroCopy()) {\n                    buffer.printf(\"if (%s%s.hasRemaining()) {%n\",\n                        fieldPrefix, camelCaseName());\n                } else {\n                    buffer.printf(\"if (%s%s.length != 0) {%n\",\n                        fieldPrefix, camelCaseName());\n                }\n            } else {\n                if (zeroCopy()) {\n                    buffer.printf(\"if (%s%s == null || %s%s.remaining() > 0) {%n\",\n                        fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName());\n                } else {\n                    buffer.printf(\"if (%s%s == null || %s%s.length != 0) {%n\",\n                        fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName());\n                }\n            }\n        } else if (type().isString() || type().isStruct() || type() instanceof FieldType.UUIDFieldType) {\n            if (fieldDefault.equals(\"null\")) {\n                buffer.printf(\"if (%s%s != null) {%n\", fieldPrefix, camelCaseName());\n            } else if (nullableVersions.empty()) {\n                buffer.printf(\"if (!%s%s.equals(%s)) {%n\",\n                    fieldPrefix, camelCaseName(), fieldDefault);\n            } else {\n                buffer.printf(\"if (%s%s == null || !%s%s.equals(%s)) {%n\",\n                    fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName(),\n                    fieldDefault);\n            }\n        } else if (type() instanceof FieldType.BoolFieldType) {\n            buffer.printf(\"if (%s%s%s) {%n\",\n                fieldDefault.equals(\"true\") ? \"!\" : \"\",\n                fieldPrefix, camelCaseName());\n        } else {\n            buffer.printf(\"if (%s%s != %s) {%n\",\n                fieldPrefix, camelCaseName(), fieldDefault);\n        }\n    }\n\n    \n    void generateNonIgnorableFieldCheck(HeaderGenerator headerGenerator,\n                                        StructRegistry structRegistry,\n                                        String fieldPrefix,\n                                        CodeBuffer buffer) {\n        generateNonDefaultValueCheck(headerGenerator, structRegistry,\n            buffer, fieldPrefix, nullableVersions());\n        buffer.incrementIndent();\n        headerGenerator.addImport(MessageGenerator.UNSUPPORTED_VERSION_EXCEPTION_CLASS);\n        buffer.printf(\"throw new UnsupportedVersionException(\" +\n                \"\\\"Attempted to write a non-default %s at version \\\" + _version);%n\",\n            camelCaseName());\n        buffer.decrementIndent();\n        buffer.printf(\"}%n\");\n    }\n}\n",
        "summary_tokens": [
            "generate",
            "an",
            "if",
            "statement",
            "that",
            "checks",
            "if",
            "this",
            "field",
            "has",
            "a",
            "non",
            "default",
            "value"
        ]
    },
    {
        "id": 2184,
        "code": "void generateNonIgnorableFieldCheck(HeaderGenerator headerGenerator,\n                                    StructRegistry structRegistry,\n                                    String fieldPrefix,\n                                    CodeBuffer buffer) {\n    generateNonDefaultValueCheck(headerGenerator, structRegistry,\n        buffer, fieldPrefix, nullableVersions());\n    buffer.incrementIndent();\n    headerGenerator.addImport(MessageGenerator.UNSUPPORTED_VERSION_EXCEPTION_CLASS);\n    buffer.printf(\"throw new UnsupportedVersionException(\" +\n            \"\\\"Attempted to write a non-default %s at version \\\" + _version);%n\",\n        camelCaseName());\n    buffer.decrementIndent();\n    buffer.printf(\"}%n\");",
        "summary_tokens": [
            "generate",
            "an",
            "if",
            "statement",
            "that",
            "checks",
            "if",
            "this",
            "field",
            "is",
            "non",
            "default",
            "and",
            "also",
            "non",
            "ignorable"
        ]
    },
    {
        "id": 2185,
        "code": "default boolean isArray() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "an",
            "array",
            "type"
        ]
    },
    {
        "id": 2186,
        "code": "default boolean isStructArray() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "an",
            "array",
            "of",
            "structures"
        ]
    },
    {
        "id": 2187,
        "code": "default boolean serializationIsDifferentInFlexibleVersions() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "serialization",
            "of",
            "this",
            "type",
            "is",
            "different",
            "in",
            "flexible",
            "versions"
        ]
    },
    {
        "id": 2188,
        "code": "default boolean isString() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "a",
            "string",
            "type"
        ]
    },
    {
        "id": 2189,
        "code": "default boolean isBytes() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "a",
            "bytes",
            "type"
        ]
    },
    {
        "id": 2190,
        "code": "default boolean isRecords() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "a",
            "records",
            "type"
        ]
    },
    {
        "id": 2191,
        "code": "default boolean isFloat() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "a",
            "floating",
            "point",
            "type"
        ]
    },
    {
        "id": 2192,
        "code": "default boolean isStruct() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "is",
            "a",
            "struct",
            "type"
        ]
    },
    {
        "id": 2193,
        "code": "default boolean canBeNullable() {\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "field",
            "type",
            "is",
            "compatible",
            "with",
            "nullability"
        ]
    },
    {
        "id": 2194,
        "code": "default Optional<Integer> fixedLength() {\n    return Optional.empty();\n}",
        "summary_tokens": [
            "gets",
            "the",
            "fixed",
            "length",
            "of",
            "the",
            "field",
            "or",
            "none",
            "if",
            "the",
            "field",
            "is",
            "variable",
            "length"
        ]
    },
    {
        "id": 2195,
        "code": "private void generateVariableLengthArrayElementSize(Versions flexibleVersions,\n                                                    String fieldName,\n                                                    FieldType type,\n                                                    Versions versions) {\n    if (type instanceof FieldType.StringFieldType) {\n        generateStringToBytes(fieldName);\n        VersionConditional.forVersions(flexibleVersions, versions).\n            ifNotMember(__ -> {\n                buffer.printf(\"_size.addBytes(_stringBytes.length + 2);%n\");\n            }).\n            ifMember(__ -> {\n                headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                buffer.printf(\"_size.addBytes(_stringBytes.length + \" +\n                    \"ByteUtils.sizeOfUnsignedVarint(_stringBytes.length + 1));%n\");\n            }).\n            generate(buffer);\n    } else if (type instanceof FieldType.BytesFieldType) {\n        buffer.printf(\"_size.addBytes(%s.length);%n\", fieldName);\n        VersionConditional.forVersions(flexibleVersions, versions).\n            ifNotMember(__ -> {\n                buffer.printf(\"_size.addBytes(4);%n\");\n            }).\n            ifMember(__ -> {\n                headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n                buffer.printf(\"_size.addBytes(\" +\n                        \"ByteUtils.sizeOfUnsignedVarint(%s.length + 1));%n\",\n                    fieldName);\n            }).\n            generate(buffer);\n    } else if (type instanceof FieldType.StructType) {\n        buffer.printf(\"%s.addSize(_size, _cache, _version);%n\", fieldName);\n    } else {\n        throw new RuntimeException(\"Unsupported type \" + type);\n    }\n}",
        "summary_tokens": [
            "generate",
            "the",
            "size",
            "calculator",
            "for",
            "a",
            "variable",
            "length",
            "array",
            "element"
        ]
    },
    {
        "id": 2196,
        "code": "static int sizeOfUnsignedVarint(int value) {\n    int bytes = 1;\n    while ((value & 0xffffff80) != 0L) {\n        bytes += 1;\n        value >>>= 7;\n    }\n    return bytes;\n}",
        "summary_tokens": [
            "return",
            "the",
            "number",
            "of",
            "bytes",
            "needed",
            "to",
            "encode",
            "an",
            "integer",
            "in",
            "unsigned",
            "variable",
            "length",
            "format"
        ]
    },
    {
        "id": 2197,
        "code": "private short floorVersion(String className, short v) {\n    MessageInfo message = messages.get(className);\n    return message.schemaForVersion.floorKey(v);\n}",
        "summary_tokens": [
            "find",
            "the",
            "lowest",
            "schema",
            "version",
            "for",
            "a",
            "given",
            "class",
            "that",
            "is",
            "the",
            "same",
            "as",
            "the",
            "given",
            "version"
        ]
    },
    {
        "id": 2198,
        "code": "void writeSchema(String className, CodeBuffer buffer) throws Exception {\n    MessageInfo messageInfo = messages.get(className);\n    Versions versions = messageInfo.versions;\n\n    for (short v = versions.lowest(); v <= versions.highest(); v++) {\n        CodeBuffer declaration = messageInfo.schemaForVersion.get(v);\n        if (declaration == null) {\n            buffer.printf(\"public static final Schema SCHEMA_%d = SCHEMA_%d;%n\", v, v - 1);\n        } else {\n            buffer.printf(\"public static final Schema SCHEMA_%d =%n\", v);\n            buffer.incrementIndent();\n            declaration.write(buffer);\n            buffer.decrementIndent();\n        }\n        buffer.printf(\"%n\");\n    }\n    buffer.printf(\"public static final Schema[] SCHEMAS = new Schema[] {%n\");\n    buffer.incrementIndent();\n    for (short v = 0; v < versions.lowest(); v++) {\n        buffer.printf(\"null%s%n\", (v == versions.highest()) ? \"\" : \",\");\n    }\n    for (short v = versions.lowest(); v <= versions.highest(); v++) {\n        buffer.printf(\"SCHEMA_%d%s%n\", v, (v == versions.highest()) ? \"\" : \",\");\n    }\n    buffer.decrementIndent();\n    buffer.printf(\"};%n\");\n    buffer.printf(\"%n\");\n\n    buffer.printf(\"public static final short LOWEST_SUPPORTED_VERSION = %d;%n\", versions.lowest());\n    buffer.printf(\"public static final short HIGHEST_SUPPORTED_VERSION = %d;%n\", versions.highest());\n    buffer.printf(\"%n\");\n}",
        "summary_tokens": [
            "write",
            "the",
            "message",
            "schema",
            "to",
            "the",
            "provided",
            "buffer"
        ]
    },
    {
        "id": 2199,
        "code": "void register(MessageSpec message) throws Exception {\n        \n    for (StructSpec struct : message.commonStructs()) {\n        if (!MessageGenerator.firstIsCapitalized(struct.name())) {\n            throw new RuntimeException(\"Can't process structure \" + struct.name() +\n                    \": the first letter of structure names must be capitalized.\");\n        }\n        if (structs.containsKey(struct.name())) {\n            throw new RuntimeException(\"Common struct \" + struct.name() + \" was specified twice.\");\n        }\n        structs.put(struct.name(), new StructInfo(struct, struct.versions()));\n        commonStructNames.add(struct.name());\n    }\n        \n    addStructSpecs(message.validVersions(), message.fields());\n}",
        "summary_tokens": [
            "register",
            "all",
            "the",
            "structures",
            "contained",
            "a",
            "message",
            "spec"
        ]
    },
    {
        "id": 2200,
        "code": "StructSpec findStruct(FieldSpec field) {\n    String structFieldName;\n    if (field.type().isArray()) {\n        FieldType.ArrayType arrayType = (FieldType.ArrayType) field.type();\n        structFieldName = arrayType.elementName();\n    } else if (field.type().isStruct()) {\n        FieldType.StructType structType = (FieldType.StructType) field.type();\n        structFieldName = structType.typeName();\n    } else {\n        throw new RuntimeException(\"Field \" + field.name() +\n                \" cannot be treated as a structure.\");\n    }\n    StructInfo structInfo = structs.get(structFieldName);\n    if (structInfo == null) {\n        throw new RuntimeException(\"Unable to locate a specification for the structure \" +\n                structFieldName);\n    }\n    return structInfo.spec;\n}",
        "summary_tokens": [
            "locate",
            "the",
            "struct",
            "corresponding",
            "to",
            "a",
            "field"
        ]
    },
    {
        "id": 2201,
        "code": "boolean isStructArrayWithKeys(FieldSpec field) {\n    if (!field.type().isArray()) {\n        return false;\n    }\n    FieldType.ArrayType arrayType = (FieldType.ArrayType) field.type();\n    if (!arrayType.isStructArray()) {\n        return false;\n    }\n    StructInfo structInfo = structs.get(arrayType.elementName());\n    if (structInfo == null) {\n        throw new RuntimeException(\"Unable to locate a specification for the structure \" +\n                arrayType.elementName());\n    }\n    return structInfo.spec.hasKeys();\n}",
        "summary_tokens": [
            "return",
            "true",
            "if",
            "the",
            "field",
            "is",
            "a",
            "struct",
            "array",
            "with",
            "keys"
        ]
    },
    {
        "id": 2202,
        "code": "Iterator<StructSpec> commonStructs() {\n    return new Iterator<StructSpec>() {\n        private final Iterator<String> iter = commonStructNames.iterator();\n\n        @Override\n        public boolean hasNext() {\n            return iter.hasNext();\n        }\n\n        @Override\n        public StructSpec next() {\n            return structs.get(iter.next()).spec;\n        }\n    };\n}",
        "summary_tokens": [
            "returns",
            "an",
            "iterator",
            "that",
            "will",
            "step",
            "through",
            "all",
            "the",
            "common",
            "structures"
        ]
    },
    {
        "id": 2203,
        "code": "static VersionConditional forVersions(Versions containingVersions,\n                                      Versions possibleVersions) {\n    return new VersionConditional(containingVersions, possibleVersions);\n}",
        "summary_tokens": [
            "create",
            "a",
            "version",
            "conditional"
        ]
    },
    {
        "id": 2204,
        "code": "VersionConditional alwaysEmitBlockScope(boolean alwaysEmitBlockScope) {\n    this.alwaysEmitBlockScope = alwaysEmitBlockScope;\n    return this;\n}",
        "summary_tokens": [
            "if",
            "this",
            "is",
            "set",
            "we",
            "will",
            "always",
            "create",
            "a",
            "new",
            "block",
            "scope",
            "even",
            "if",
            "there",
            "are",
            "no",
            "if",
            "statements"
        ]
    },
    {
        "id": 2205,
        "code": "VersionConditional allowMembershipCheckAlwaysFalse(boolean allowMembershipCheckAlwaysFalse) {\n    this.allowMembershipCheckAlwaysFalse = allowMembershipCheckAlwaysFalse;\n    return this;\n}",
        "summary_tokens": [
            "if",
            "this",
            "is",
            "set",
            "version",
            "conditional",
            "generate",
            "will",
            "throw",
            "an",
            "exception",
            "if",
            "the",
            "if",
            "member",
            "clause",
            "is",
            "never",
            "used"
        ]
    },
    {
        "id": 2206,
        "code": "public Versions intersect(Versions other) {\n    short newLowest = lowest > other.lowest ? lowest : other.lowest;\n    short newHighest = highest < other.highest ? highest : other.highest;\n    if (newLowest > newHighest) {\n        return Versions.NONE;\n    }\n    return new Versions(newLowest, newHighest);\n}",
        "summary_tokens": [
            "return",
            "the",
            "intersection",
            "of",
            "two",
            "version",
            "ranges"
        ]
    },
    {
        "id": 2207,
        "code": "public Versions subtract(Versions other) {\n    if (other.lowest() <= lowest) {\n        if (other.highest >= highest) {\n                \n            return Versions.NONE;\n        } else if (other.highest < lowest) {\n                \n            return this;\n        } else {\n                \n                \n                \n                \n                \n            return new Versions((short) (other.highest() + 1), highest);\n        }\n    } else if (other.highest >= highest) {\n        int newHighest = other.lowest - 1;\n        if (newHighest < 0) {\n                \n            return this;\n        } else if (newHighest < highest) {\n                \n            return new Versions(lowest, (short) newHighest);\n        } else {\n                \n            return this;\n        }\n    } else {\n            \n        return null;\n    }\n}",
        "summary_tokens": [
            "return",
            "a",
            "new",
            "version",
            "range",
            "that",
            "trims",
            "some",
            "versions",
            "from",
            "this",
            "range",
            "if",
            "possible"
        ]
    },
    {
        "id": 2208,
        "code": "public void testInvalidFieldName() {\n    assertStringContains(\"Invalid field name\",\n        assertThrows(Throwable.class, () -> {\n            MessageGenerator.JSON_SERDE.readValue(String.join(\"\", Arrays.asList(\n                \"{\",\n                \"  \\\"type\\\": \\\"request\\\",\",\n                \"  \\\"name\\\": \\\"FooBar\\\",\",\n                \"  \\\"validVersions\\\": \\\"0-2\\\",\",\n                \"  \\\"flexibleVersions\\\": \\\"0+\\\",\",\n                \"  \\\"fields\\\": [\",\n                \"    { \\\"name\\\": \\\"_badName\\\", \\\"type\\\": \\\"[]int32\\\", \\\"versions\\\": \\\"0+\\\" }\",\n                \"  ]\",\n                \"}\")), MessageSpec.class);\n        }).getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "create",
            "a",
            "field",
            "with",
            "an",
            "invalid",
            "name"
        ]
    },
    {
        "id": 2209,
        "code": "public ImplicitLinkedHashCollection<TestElement> testCollectionSort() {\n    coll.sort(TestElementComparator.INSTANCE);\n    return coll;\n}",
        "summary_tokens": [
            "test",
            "sorting",
            "the",
            "collection",
            "entries"
        ]
    },
    {
        "id": 2210,
        "code": "private static ProduceResponse response() {\n    return new ProduceResponse(PARTITION_RESPONSE_MAP);\n}",
        "summary_tokens": [
            "this",
            "method",
            "is",
            "still",
            "used",
            "by",
            "production",
            "so",
            "we",
            "benchmark",
            "it"
        ]
    },
    {
        "id": 2211,
        "code": "void fence(int brokerId) {\n    BrokerHeartbeatState broker = brokers.get(brokerId);\n    if (broker != null) {\n        untrack(broker);\n    }\n}",
        "summary_tokens": [
            "mark",
            "a",
            "broker",
            "as",
            "fenced"
        ]
    },
    {
        "id": 2212,
        "code": "private void untrack(BrokerHeartbeatState broker) {\n    if (!broker.fenced()) {\n        unfenced.remove(broker);\n        if (!broker.shuttingDown()) {\n            active.remove(broker);\n        }\n    }\n}",
        "summary_tokens": [
            "stop",
            "tracking",
            "the",
            "broker",
            "in",
            "the",
            "unfenced",
            "list",
            "and",
            "active",
            "set",
            "if",
            "it",
            "was",
            "tracked",
            "in",
            "either",
            "of",
            "these"
        ]
    },
    {
        "id": 2213,
        "code": "private boolean hasValidSession(BrokerHeartbeatState broker) {\n    if (broker.fenced()) {\n        return false;\n    } else {\n        return broker.lastContactNs + sessionTimeoutNs >= time.nanoseconds();\n    }\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "given",
            "broker",
            "has",
            "a",
            "valid",
            "session"
        ]
    },
    {
        "id": 2214,
        "code": "void register(int brokerId, boolean fenced) {\n    BrokerHeartbeatState broker = brokers.get(brokerId);\n    if (broker == null) {\n        touch(brokerId, fenced, -1);\n    } else if (broker.fenced() != fenced) {\n        touch(brokerId, fenced, broker.metadataOffset);\n    }\n}",
        "summary_tokens": [
            "register",
            "this",
            "broker",
            "if",
            "we",
            "haven",
            "t",
            "already",
            "and",
            "make",
            "sure",
            "its",
            "fencing",
            "state",
            "is",
            "correct"
        ]
    },
    {
        "id": 2215,
        "code": "void touch(int brokerId, boolean fenced, long metadataOffset) {\n    BrokerHeartbeatState broker = brokers.get(brokerId);\n    if (broker == null) {\n        broker = new BrokerHeartbeatState(brokerId);\n        brokers.put(brokerId, broker);\n    } else {\n            \n            \n            \n        untrack(broker);\n    }\n    broker.lastContactNs = time.nanoseconds();\n    broker.metadataOffset = metadataOffset;\n    if (fenced) {\n            \n            \n        broker.controlledShutDownOffset = -1;\n    } else {\n        unfenced.add(broker);\n        if (!broker.shuttingDown()) {\n            active.add(broker);\n        }\n    }\n}",
        "summary_tokens": [
            "update",
            "broker",
            "state",
            "including",
            "last",
            "contact",
            "ns"
        ]
    },
    {
        "id": 2216,
        "code": "void updateControlledShutdownOffset(int brokerId, long controlledShutDownOffset) {\n    BrokerHeartbeatState broker = brokers.get(brokerId);\n    if (broker == null) {\n        throw new RuntimeException(\"Unable to locate broker \" + brokerId);\n    }\n    if (broker.fenced()) {\n        throw new RuntimeException(\"Fenced brokers cannot enter controlled shutdown.\");\n    }\n    active.remove(broker);\n    broker.controlledShutDownOffset = controlledShutDownOffset;\n    log.debug(\"Updated the controlled shutdown offset for broker {} to {}.\",\n        brokerId, controlledShutDownOffset);\n}",
        "summary_tokens": [
            "mark",
            "a",
            "broker",
            "as",
            "being",
            "in",
            "the",
            "controlled",
            "shutdown",
            "state"
        ]
    },
    {
        "id": 2217,
        "code": "long nextCheckTimeNs() {\n    BrokerHeartbeatState broker = unfenced.first();\n    if (broker == null) {\n        return Long.MAX_VALUE;\n    } else {\n        return broker.lastContactNs + sessionTimeoutNs;\n    }\n}",
        "summary_tokens": [
            "return",
            "the",
            "time",
            "in",
            "monotonic",
            "nanoseconds",
            "at",
            "which",
            "we",
            "should",
            "check",
            "if",
            "a",
            "broker",
            "session",
            "needs",
            "to",
            "be",
            "expired"
        ]
    },
    {
        "id": 2218,
        "code": "Optional<Integer> findOneStaleBroker() {\n    BrokerHeartbeatStateIterator iterator = unfenced.iterator();\n    if (iterator.hasNext()) {\n        BrokerHeartbeatState broker = iterator.next();\n            \n            \n        if (!hasValidSession(broker)) {\n            return Optional.of(broker.id);\n        }\n    }\n    return Optional.empty();\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "oldest",
            "broker",
            "to",
            "have",
            "hearbeated",
            "has",
            "already",
            "violated",
            "the",
            "session",
            "timeout",
            "ns",
            "timeout",
            "and",
            "needs",
            "to",
            "be",
            "fenced"
        ]
    },
    {
        "id": 2219,
        "code": "BrokerControlStates calculateNextBrokerState(int brokerId,\n                                             BrokerHeartbeatRequestData request,\n                                             long registerBrokerRecordOffset,\n                                             Supplier<Boolean> hasLeaderships) {\n    BrokerHeartbeatState broker = brokers.getOrDefault(brokerId,\n        new BrokerHeartbeatState(brokerId));\n    BrokerControlState currentState = currentBrokerState(broker);\n    switch (currentState) {\n        case FENCED:\n            if (request.wantShutDown()) {\n                log.info(\"Fenced broker {} has requested and been granted an immediate \" +\n                    \"shutdown.\", brokerId);\n                return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n            } else if (!request.wantFence()) {\n                if (request.currentMetadataOffset() >= registerBrokerRecordOffset) {\n                    log.info(\"The request from broker {} to unfence has been granted \" +\n                            \"because it has caught up with the offset of it's register \" +\n                            \"broker record {}.\", brokerId, registerBrokerRecordOffset);\n                    return new BrokerControlStates(currentState, UNFENCED);\n                } else {\n                    if (log.isDebugEnabled()) {\n                        log.debug(\"The request from broker {} to unfence cannot yet \" +\n                            \"be granted because it has not caught up with the offset of \" +\n                            \"it's register broker record {}. It is still at offset {}.\",\n                            brokerId, registerBrokerRecordOffset, request.currentMetadataOffset());\n                    }\n                    return new BrokerControlStates(currentState, FENCED);\n                }\n            }\n            return new BrokerControlStates(currentState, FENCED);\n\n        case UNFENCED:\n            if (request.wantFence()) {\n                if (request.wantShutDown()) {\n                    log.info(\"Unfenced broker {} has requested and been granted an \" +\n                        \"immediate shutdown.\", brokerId);\n                    return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n                } else {\n                    log.info(\"Unfenced broker {} has requested and been granted \" +\n                        \"fencing\", brokerId);\n                    return new BrokerControlStates(currentState, FENCED);\n                }\n            } else if (request.wantShutDown()) {\n                if (hasLeaderships.get()) {\n                    log.info(\"Unfenced broker {} has requested and been granted a \" +\n                        \"controlled shutdown.\", brokerId);\n                    return new BrokerControlStates(currentState, CONTROLLED_SHUTDOWN);\n                } else {\n                    log.info(\"Unfenced broker {} has requested and been granted an \" +\n                        \"immediate shutdown.\", brokerId);\n                    return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n                }\n            }\n            return new BrokerControlStates(currentState, UNFENCED);\n\n        case CONTROLLED_SHUTDOWN:\n            if (hasLeaderships.get()) {\n                log.debug(\"Broker {} is in controlled shutdown state, but can not \" +\n                    \"shut down because more leaders still need to be moved.\", brokerId);\n                return new BrokerControlStates(currentState, CONTROLLED_SHUTDOWN);\n            }\n            long lowestActiveOffset = lowestActiveOffset();\n            if (broker.controlledShutDownOffset <= lowestActiveOffset) {\n                log.info(\"The request from broker {} to shut down has been granted \" +\n                    \"since the lowest active offset {} is now greater than the \" +\n                    \"broker's controlled shutdown offset {}.\", brokerId,\n                    lowestActiveOffset, broker.controlledShutDownOffset);\n                return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n            }\n            log.debug(\"The request from broker {} to shut down can not yet be granted \" +\n                \"because the lowest active offset {} is not greater than the broker's \" +\n                \"shutdown offset {}.\", brokerId, lowestActiveOffset,\n                broker.controlledShutDownOffset);\n            return new BrokerControlStates(currentState, CONTROLLED_SHUTDOWN);\n\n        default:\n            return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n    }\n}",
        "summary_tokens": [
            "calculate",
            "the",
            "next",
            "broker",
            "state",
            "for",
            "a",
            "broker",
            "that",
            "just",
            "sent",
            "a",
            "heartbeat",
            "request"
        ]
    },
    {
        "id": 2220,
        "code": "void update(Uuid topicId, int partitionId, int[] prevIsr, int[] nextIsr,\n            int prevLeader, int nextLeader) {\n    int[] prev;\n    if (prevIsr == null) {\n        prev = NONE;\n    } else {\n        if (prevLeader == NO_LEADER) {\n            prev = Replicas.copyWith(prevIsr, NO_LEADER);\n            if (nextLeader != NO_LEADER) {\n                offlinePartitionCount.decrement();\n            }\n        } else {\n            prev = Replicas.clone(prevIsr);\n        }\n        Arrays.sort(prev);\n    }\n    int[] next;\n    if (nextIsr == null) {\n        next = NONE;\n    } else {\n        if (nextLeader == NO_LEADER) {\n            next = Replicas.copyWith(nextIsr, NO_LEADER);\n            if (prevLeader != NO_LEADER) {\n                offlinePartitionCount.increment();\n            }\n        } else {\n            next = Replicas.clone(nextIsr);\n        }\n        Arrays.sort(next);\n    }\n    int i = 0, j = 0;\n    while (true) {\n        if (i == prev.length) {\n            if (j == next.length) {\n                break;\n            }\n            int newReplica = next[j];\n            add(newReplica, topicId, partitionId, newReplica == nextLeader);\n            j++;\n        } else if (j == next.length) {\n            int prevReplica = prev[i];\n            remove(prevReplica, topicId, partitionId, prevReplica == prevLeader);\n            i++;\n        } else {\n            int prevReplica = prev[i];\n            int newReplica = next[j];\n            if (prevReplica < newReplica) {\n                remove(prevReplica, topicId, partitionId, prevReplica == prevLeader);\n                i++;\n            } else if (prevReplica > newReplica) {\n                add(newReplica, topicId, partitionId, newReplica == nextLeader);\n                j++;\n            } else {\n                boolean wasLeader = prevReplica == prevLeader;\n                boolean isLeader = prevReplica == nextLeader;\n                if (wasLeader != isLeader) {\n                    change(prevReplica, topicId, partitionId, wasLeader, isLeader);\n                }\n                i++;\n                j++;\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "update",
            "our",
            "records",
            "of",
            "a",
            "partition",
            "s",
            "isr"
        ]
    },
    {
        "id": 2221,
        "code": "ControllerResult<Map<ClientQuotaEntity, ApiError>> alterClientQuotas(\n        Collection<ClientQuotaAlteration> quotaAlterations) {\n    List<ApiMessageAndVersion> outputRecords = new ArrayList<>();\n    Map<ClientQuotaEntity, ApiError> outputResults = new HashMap<>();\n\n    quotaAlterations.forEach(quotaAlteration -> {\n            \n        Map<String, Double> alterations = new HashMap<>(quotaAlteration.ops().size());\n        quotaAlteration.ops().forEach(op -> {\n            if (alterations.containsKey(op.key())) {\n                outputResults.put(quotaAlteration.entity(), ApiError.fromThrowable(\n                        new InvalidRequestException(\"Duplicate quota key \" + op.key() +\n                            \" not updating quota for this entity \" + quotaAlteration.entity())));\n            } else {\n                alterations.put(op.key(), op.value());\n            }\n        });\n        if (outputResults.containsKey(quotaAlteration.entity())) {\n            outputResults.put(quotaAlteration.entity(), ApiError.fromThrowable(\n                    new InvalidRequestException(\"Ignoring duplicate entity \" + quotaAlteration.entity())));\n        } else {\n            alterClientQuotaEntity(quotaAlteration.entity(), alterations, outputRecords, outputResults);\n        }\n    });\n\n    return ControllerResult.atomicOf(outputRecords, outputResults);\n}",
        "summary_tokens": [
            "determine",
            "the",
            "result",
            "of",
            "applying",
            "a",
            "batch",
            "of",
            "client",
            "quota",
            "alteration"
        ]
    },
    {
        "id": 2222,
        "code": "public void replay(ClientQuotaRecord record) {\n    Map<String, String> entityMap = new HashMap<>(2);\n    record.entity().forEach(entityData -> entityMap.put(entityData.entityType(), entityData.entityName()));\n    ClientQuotaEntity entity = new ClientQuotaEntity(entityMap);\n    TimelineHashMap<String, Double> quotas = clientQuotaData.get(entity);\n    if (quotas == null) {\n        quotas = new TimelineHashMap<>(snapshotRegistry, 0);\n        clientQuotaData.put(entity, quotas);\n    }\n    if (record.remove()) {\n        quotas.remove(record.key());\n        if (quotas.size() == 0) {\n            clientQuotaData.remove(entity);\n        }\n    } else {\n        quotas.put(record.key(), record.value());\n    }\n}",
        "summary_tokens": [
            "apply",
            "a",
            "quota",
            "record",
            "to",
            "the",
            "in",
            "memory",
            "state"
        ]
    },
    {
        "id": 2223,
        "code": "public void activate() {\n    heartbeatManager = new BrokerHeartbeatManager(logContext, time, sessionTimeoutNs);\n    for (BrokerRegistration registration : brokerRegistrations.values()) {\n        heartbeatManager.touch(registration.id(), registration.fenced(), -1);\n    }\n}",
        "summary_tokens": [
            "transition",
            "this",
            "cluster",
            "control",
            "manager",
            "to",
            "active"
        ]
    },
    {
        "id": 2224,
        "code": "public void deactivate() {\n    heartbeatManager = null;\n}",
        "summary_tokens": [
            "transition",
            "this",
            "cluster",
            "control",
            "manager",
            "to",
            "standby"
        ]
    },
    {
        "id": 2225,
        "code": "public ControllerResult<BrokerRegistrationReply> registerBroker(\n        BrokerRegistrationRequestData request,\n        long brokerEpoch,\n        FinalizedControllerFeatures finalizedFeatures) {\n    if (heartbeatManager == null) {\n        throw new RuntimeException(\"ClusterControlManager is not active.\");\n    }\n    if (!clusterId.equals(request.clusterId())) {\n        throw new InconsistentClusterIdException(\"Expected cluster ID \" + clusterId +\n            \", but got cluster ID \" + request.clusterId());\n    }\n    int brokerId = request.brokerId();\n    BrokerRegistration existing = brokerRegistrations.get(brokerId);\n    if (existing != null) {\n        if (heartbeatManager.hasValidSession(brokerId)) {\n            if (!existing.incarnationId().equals(request.incarnationId())) {\n                throw new DuplicateBrokerRegistrationException(\"Another broker is \" +\n                    \"registered with that broker id.\");\n            }\n        } else {\n            if (!existing.incarnationId().equals(request.incarnationId())) {\n                    \n                heartbeatManager.remove(brokerId);\n            }\n        }\n    }\n\n    RegisterBrokerRecord record = new RegisterBrokerRecord().setBrokerId(brokerId).\n        setIncarnationId(request.incarnationId()).\n        setBrokerEpoch(brokerEpoch).\n        setRack(request.rack());\n    for (BrokerRegistrationRequestData.Listener listener : request.listeners()) {\n        record.endPoints().add(new BrokerEndpoint().\n            setHost(listener.host()).\n            setName(listener.name()).\n            setPort(listener.port()).\n            setSecurityProtocol(listener.securityProtocol()));\n    }\n    for (BrokerRegistrationRequestData.Feature feature : request.features()) {\n        record.features().add(processRegistrationFeature(brokerId, finalizedFeatures, feature));\n    }\n    if (request.features().find(MetadataVersion.FEATURE_NAME) == null) {\n            \n            \n        record.features().add(processRegistrationFeature(brokerId, finalizedFeatures,\n                new BrokerRegistrationRequestData.Feature().\n                        setName(MetadataVersion.FEATURE_NAME).\n                        setMinSupportedVersion(MetadataVersion.MINIMUM_KRAFT_VERSION.featureLevel()).\n                        setMaxSupportedVersion(MetadataVersion.MINIMUM_KRAFT_VERSION.featureLevel())));\n    }\n\n    heartbeatManager.register(brokerId, record.fenced());\n\n    List<ApiMessageAndVersion> records = new ArrayList<>();\n    records.add(new ApiMessageAndVersion(record, featureControl.metadataVersion().\n        registerBrokerRecordVersion()));\n    return ControllerResult.atomicOf(records, new BrokerRegistrationReply(brokerEpoch));\n}",
        "summary_tokens": [
            "process",
            "an",
            "incoming",
            "broker",
            "registration",
            "request"
        ]
    },
    {
        "id": 2226,
        "code": "public boolean unfenced(int brokerId) {\n    BrokerRegistration registration = brokerRegistrations.get(brokerId);\n    if (registration == null) return false;\n    return !registration.fenced();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "broker",
            "is",
            "unfenced",
            "returns",
            "false",
            "if",
            "it",
            "is",
            "not",
            "or",
            "if",
            "it",
            "does",
            "not",
            "exist"
        ]
    },
    {
        "id": 2227,
        "code": "public BrokerRegistration registration(int brokerId) {\n    return brokerRegistrations.get(brokerId);\n}",
        "summary_tokens": [
            "get",
            "a",
            "broker",
            "registration",
            "if",
            "it",
            "exists"
        ]
    },
    {
        "id": 2228,
        "code": "public boolean inControlledShutdown(int brokerId) {\n    BrokerRegistration registration = brokerRegistrations.get(brokerId);\n    if (registration == null) return false;\n    return registration.inControlledShutdown();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "broker",
            "is",
            "in",
            "controlled",
            "shutdown",
            "state",
            "returns",
            "false",
            "if",
            "it",
            "is",
            "not",
            "or",
            "if",
            "it",
            "does",
            "not",
            "exist"
        ]
    },
    {
        "id": 2229,
        "code": "public boolean active(int brokerId) {\n    BrokerRegistration registration = brokerRegistrations.get(brokerId);\n    if (registration == null) return false;\n    return !registration.inControlledShutdown() && !registration.fenced();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "broker",
            "is",
            "active"
        ]
    },
    {
        "id": 2230,
        "code": "ControllerResult<Map<ConfigResource, ApiError>> incrementalAlterConfigs(\n        Map<ConfigResource, Map<String, Entry<OpType, String>>> configChanges,\n        boolean newlyCreatedResource) {\n    List<ApiMessageAndVersion> outputRecords = new ArrayList<>();\n    Map<ConfigResource, ApiError> outputResults = new HashMap<>();\n    for (Entry<ConfigResource, Map<String, Entry<OpType, String>>> resourceEntry :\n            configChanges.entrySet()) {\n        incrementalAlterConfigResource(resourceEntry.getKey(),\n            resourceEntry.getValue(),\n            newlyCreatedResource,\n            outputRecords,\n            outputResults);\n    }\n    return ControllerResult.atomicOf(outputRecords, outputResults);\n}",
        "summary_tokens": [
            "determine",
            "the",
            "result",
            "of",
            "applying",
            "a",
            "batch",
            "of",
            "incremental",
            "configuration",
            "changes"
        ]
    },
    {
        "id": 2231,
        "code": "ControllerResult<Map<ConfigResource, ApiError>> legacyAlterConfigs(\n    Map<ConfigResource, Map<String, String>> newConfigs,\n    boolean newlyCreatedResource\n) {\n    List<ApiMessageAndVersion> outputRecords = new ArrayList<>();\n    Map<ConfigResource, ApiError> outputResults = new HashMap<>();\n    for (Entry<ConfigResource, Map<String, String>> resourceEntry :\n        newConfigs.entrySet()) {\n        legacyAlterConfigResource(resourceEntry.getKey(),\n            resourceEntry.getValue(),\n            newlyCreatedResource,\n            outputRecords,\n            outputResults);\n    }\n    return ControllerResult.atomicOf(outputRecords, outputResults);\n}",
        "summary_tokens": [
            "determine",
            "the",
            "result",
            "of",
            "applying",
            "a",
            "batch",
            "of",
            "legacy",
            "configuration",
            "changes"
        ]
    },
    {
        "id": 2232,
        "code": "public void replay(ConfigRecord record) {\n    Type type = Type.forId(record.resourceType());\n    ConfigResource configResource = new ConfigResource(type, record.resourceName());\n    TimelineHashMap<String, String> configs = configData.get(configResource);\n    if (configs == null) {\n        configs = new TimelineHashMap<>(snapshotRegistry, 0);\n        configData.put(configResource, configs);\n    }\n    if (record.value() == null) {\n        configs.remove(record.name());\n    } else {\n        configs.put(record.name(), record.value());\n    }\n    if (configs.isEmpty()) {\n        configData.remove(configResource);\n    }\n    if (configSchema.isSensitive(record)) {\n        log.info(\"{}: set configuration {} to {}\", configResource, record.name(), Password.HIDDEN);\n    } else {\n        log.info(\"{}: set configuration {} to {}\", configResource, record.name(), record.value());\n    }\n}",
        "summary_tokens": [
            "apply",
            "a",
            "configuration",
            "record",
            "to",
            "the",
            "in",
            "memory",
            "state"
        ]
    },
    {
        "id": 2233,
        "code": "default boolean isActive() {\n    return curClaimEpoch() != -1;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "controller",
            "is",
            "currently",
            "active"
        ]
    },
    {
        "id": 2234,
        "code": "void completeUpTo(long offset) {\n    Iterator<Entry<Long, List<DeferredEvent>>> iter = pending.entrySet().iterator();\n    while (iter.hasNext()) {\n        Entry<Long, List<DeferredEvent>> entry = iter.next();\n        if (entry.getKey() > offset) {\n            break;\n        }\n        for (DeferredEvent event : entry.getValue()) {\n            event.complete(null);\n        }\n        iter.remove();\n    }\n}",
        "summary_tokens": [
            "complete",
            "some",
            "purgatory",
            "entries"
        ]
    },
    {
        "id": 2235,
        "code": "void failAll(Exception exception) {\n    Iterator<Entry<Long, List<DeferredEvent>>> iter = pending.entrySet().iterator();\n    while (iter.hasNext()) {\n        Entry<Long, List<DeferredEvent>> entry = iter.next();\n        for (DeferredEvent event : entry.getValue()) {\n            event.complete(exception);\n        }\n        iter.remove();\n    }\n}",
        "summary_tokens": [
            "fail",
            "all",
            "the",
            "pending",
            "purgatory",
            "entries"
        ]
    },
    {
        "id": 2236,
        "code": "void add(long offset, DeferredEvent event) {\n    if (!pending.isEmpty()) {\n        long lastKey = pending.lastKey();\n        if (offset < lastKey) {\n            throw new RuntimeException(\"There is already a purgatory event with \" +\n                \"offset \" + lastKey + \".  We should not add one with an offset of \" +\n                offset + \" which \" + \"is lower than that.\");\n        }\n    }\n    List<DeferredEvent> events = pending.get(offset);\n    if (events == null) {\n        events = new ArrayList<>();\n        pending.put(offset, events);\n    }\n    events.add(event);\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "purgatory",
            "event"
        ]
    },
    {
        "id": 2237,
        "code": "OptionalLong highestPendingOffset() {\n    if (pending.isEmpty()) {\n        return OptionalLong.empty();\n    } else {\n        return OptionalLong.of(pending.lastKey());\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "offset",
            "of",
            "the",
            "highest",
            "pending",
            "event",
            "or",
            "empty",
            "if",
            "there",
            "are",
            "no",
            "pending",
            "events"
        ]
    },
    {
        "id": 2238,
        "code": "private ApiError updateMetadataVersion(\n    short newVersionLevel,\n    boolean allowUnsafeDowngrade,\n    Consumer<ApiMessageAndVersion> recordConsumer\n) {\n    MetadataVersion currentVersion = metadataVersion();\n    final MetadataVersion newVersion;\n    try {\n        newVersion = MetadataVersion.fromFeatureLevel(newVersionLevel);\n    } catch (IllegalArgumentException e) {\n        return invalidMetadataVersion(newVersionLevel, \"Unknown metadata.version.\");\n    }\n\n        \n        \n    if (newVersion.isLessThan(minimumBootstrapVersion)) {\n        return invalidMetadataVersion(newVersionLevel, \"Unable to set a metadata.version less than \" +\n                minimumBootstrapVersion);\n    }\n    if (newVersion.isLessThan(currentVersion)) {\n            \n        boolean metadataChanged = MetadataVersion.checkIfMetadataChanged(currentVersion, newVersion);\n        if (!metadataChanged) {\n            log.info(\"Downgrading metadata.version from {} to {}.\", currentVersion, newVersion);\n        } else if (allowUnsafeDowngrade) {\n            log.info(\"Downgrading metadata.version unsafely from {} to {}.\", currentVersion, newVersion);\n        } else {\n            return invalidMetadataVersion(newVersionLevel, \"Refusing to perform the requested \" +\n                    \"downgrade because it might delete metadata information. Retry using \" +\n                    \"UNSAFE_DOWNGRADE if you want to force the downgrade to proceed.\");\n        }\n    } else {\n        log.info(\"Upgrading metadata.version from {} to {}.\", currentVersion, newVersion);\n    }\n\n    recordConsumer.accept(new ApiMessageAndVersion(\n        new FeatureLevelRecord()\n            .setName(MetadataVersion.FEATURE_NAME)\n            .setFeatureLevel(newVersionLevel), FEATURE_LEVEL_RECORD.lowestSupportedVersion()));\n    return ApiError.NONE;\n}",
        "summary_tokens": [
            "perform",
            "some",
            "additional",
            "validation",
            "for",
            "metadata"
        ]
    },
    {
        "id": 2239,
        "code": "ElectionResult electLeader() {\n    if (election == Election.PREFERRED) {\n        return electPreferredLeader();\n    }\n\n    return electAnyLeader();\n}",
        "summary_tokens": [
            "perform",
            "leader",
            "election",
            "based",
            "on",
            "the",
            "partition",
            "state",
            "and",
            "leader",
            "election",
            "type"
        ]
    },
    {
        "id": 2240,
        "code": "private ElectionResult electPreferredLeader() {\n    int preferredReplica = targetReplicas.get(0);\n    if (isValidNewLeader(preferredReplica)) {\n        return new ElectionResult(preferredReplica, false);\n    }\n\n    if (isValidNewLeader(partition.leader)) {\n            \n        return new ElectionResult(partition.leader, false);\n    }\n\n    Optional<Integer> onlineLeader = targetReplicas.stream()\n        .skip(1)\n        .filter(this::isValidNewLeader)\n        .findFirst();\n    if (onlineLeader.isPresent()) {\n        return new ElectionResult(onlineLeader.get(), false);\n    }\n\n    return new ElectionResult(NO_LEADER, false);\n}",
        "summary_tokens": [
            "assumes",
            "that",
            "the",
            "election",
            "type",
            "is",
            "election"
        ]
    },
    {
        "id": 2241,
        "code": "private ElectionResult electAnyLeader() {\n    if (isValidNewLeader(partition.leader)) {\n            \n        return new ElectionResult(partition.leader, false);\n    }\n\n    Optional<Integer> onlineLeader = targetReplicas.stream()\n        .filter(this::isValidNewLeader)\n        .findFirst();\n    if (onlineLeader.isPresent()) {\n        return new ElectionResult(onlineLeader.get(), false);\n    }\n\n    if (election == Election.UNCLEAN) {\n            \n        Optional<Integer> uncleanLeader = targetReplicas.stream()\n            .filter(replica -> isAcceptableLeader.apply(replica))\n            .findFirst();\n        if (uncleanLeader.isPresent()) {\n            return new ElectionResult(uncleanLeader.get(), true);\n        }\n    }\n\n    return new ElectionResult(NO_LEADER, false);\n}",
        "summary_tokens": [
            "assumes",
            "that",
            "the",
            "election",
            "type",
            "is",
            "either",
            "election"
        ]
    },
    {
        "id": 2242,
        "code": "void triggerLeaderEpochBumpIfNeeded(PartitionChangeRecord record) {\n    if (record.leader() == NO_LEADER_CHANGE) {\n        if (!Replicas.contains(targetIsr, partition.isr) ||\n                !Replicas.contains(targetReplicas, partition.replicas)) {\n            record.setLeader(partition.leader);\n        }\n    }\n}",
        "summary_tokens": [
            "trigger",
            "a",
            "leader",
            "epoch",
            "bump",
            "if",
            "one",
            "is",
            "needed"
        ]
    },
    {
        "id": 2243,
        "code": "private void replay(ApiMessage message, Optional<OffsetAndEpoch> snapshotId, long batchLastOffset) {\n    logReplayTracker.replay(message);\n    MetadataRecordType type = MetadataRecordType.fromId(message.apiKey());\n    switch (type) {\n        case REGISTER_BROKER_RECORD:\n            clusterControl.replay((RegisterBrokerRecord) message, batchLastOffset);\n            break;\n        case UNREGISTER_BROKER_RECORD:\n            clusterControl.replay((UnregisterBrokerRecord) message);\n            break;\n        case TOPIC_RECORD:\n            replicationControl.replay((TopicRecord) message);\n            break;\n        case PARTITION_RECORD:\n            replicationControl.replay((PartitionRecord) message);\n            break;\n        case CONFIG_RECORD:\n            configurationControl.replay((ConfigRecord) message);\n            break;\n        case PARTITION_CHANGE_RECORD:\n            replicationControl.replay((PartitionChangeRecord) message);\n            break;\n        case FENCE_BROKER_RECORD:\n            clusterControl.replay((FenceBrokerRecord) message);\n            break;\n        case UNFENCE_BROKER_RECORD:\n            clusterControl.replay((UnfenceBrokerRecord) message);\n            break;\n        case REMOVE_TOPIC_RECORD:\n            replicationControl.replay((RemoveTopicRecord) message);\n            break;\n        case FEATURE_LEVEL_RECORD:\n            featureControl.replay((FeatureLevelRecord) message);\n            handleFeatureControlChange();\n            break;\n        case CLIENT_QUOTA_RECORD:\n            clientQuotaControlManager.replay((ClientQuotaRecord) message);\n            break;\n        case PRODUCER_IDS_RECORD:\n            producerIdControlManager.replay((ProducerIdsRecord) message);\n            break;\n        case BROKER_REGISTRATION_CHANGE_RECORD:\n            clusterControl.replay((BrokerRegistrationChangeRecord) message);\n            break;\n        case ACCESS_CONTROL_ENTRY_RECORD:\n            aclControlManager.replay((AccessControlEntryRecord) message, snapshotId);\n            break;\n        case REMOVE_ACCESS_CONTROL_ENTRY_RECORD:\n            aclControlManager.replay((RemoveAccessControlEntryRecord) message, snapshotId);\n            break;\n        case NO_OP_RECORD:\n                \n            break;\n        default:\n            throw new RuntimeException(\"Unhandled record type \" + type);\n    }\n}",
        "summary_tokens": [
            "apply",
            "the",
            "metadata",
            "record",
            "to",
            "its",
            "corresponding",
            "in",
            "memory",
            "state",
            "s"
        ]
    },
    {
        "id": 2244,
        "code": "private void resetToEmptyState() {\n    snapshotGeneratorManager.cancel();\n    snapshotRegistry.reset();\n\n    newBytesSinceLastSnapshot = 0;\n    updateLastCommittedState(-1, -1, -1);\n}",
        "summary_tokens": [
            "clear",
            "all",
            "data",
            "structures",
            "and",
            "reset",
            "all",
            "kraft",
            "state"
        ]
    },
    {
        "id": 2245,
        "code": "public Optional<String> reasonNotSupported(String featureName, short level) {\n    VersionRange localRange = localSupportedFeatures.getOrDefault(featureName, DISABLED);\n    if (!localRange.contains(level)) {\n        if (localRange.equals(DISABLED)) {\n            return Optional.of(\"Local controller \" + nodeId + \" does not support this feature.\");\n        } else {\n            return Optional.of(\"Local controller \" + nodeId + \" only supports versions \" + localRange);\n        }\n    }\n    List<String> missing = new ArrayList<>();\n    for (int id : quorumNodeIds) {\n        if (nodeId == id) {\n            continue; \n        }\n        NodeApiVersions nodeVersions = apiVersions.get(Integer.toString(id));\n        if (nodeVersions == null) {\n            missing.add(Integer.toString(id));\n            continue;\n        }\n        SupportedVersionRange supportedRange = nodeVersions.supportedFeatures().get(featureName);\n        VersionRange range = supportedRange == null ? DISABLED :\n                VersionRange.of(supportedRange.min(), supportedRange.max());\n        if (!range.contains(level)) {\n            if (range.equals(DISABLED)) {\n                return Optional.of(\"Controller \" + id + \" does not support this feature.\");\n            } else {\n                return Optional.of(\"Controller \" + id + \" only supports versions \" + range);\n            }\n        }\n    }\n    if (!missing.isEmpty()) {\n        log.info(\"Unable to get feature level information for controller(s): \" + String.join(\", \", missing));\n    }\n    return Optional.empty();\n}",
        "summary_tokens": [
            "return",
            "the",
            "reason",
            "a",
            "specific",
            "feature",
            "level",
            "is",
            "not",
            "supported",
            "or",
            "optional"
        ]
    },
    {
        "id": 2246,
        "code": "static Map<String, String> translateCreationConfigs(CreateableTopicConfigCollection collection) {\n    HashMap<String, String> result = new HashMap<>();\n    collection.forEach(config -> result.put(config.name(), config.value()));\n    return Collections.unmodifiableMap(result);\n}",
        "summary_tokens": [
            "translate",
            "a",
            "createable",
            "topic",
            "config",
            "collection",
            "to",
            "a",
            "map",
            "from",
            "string",
            "to",
            "string"
        ]
    },
    {
        "id": 2247,
        "code": "private Errors validateAlterPartitionData(\n    int brokerId,\n    TopicControlInfo topic,\n    int partitionId,\n    PartitionRegistration partition,\n    short requestApiVersion,\n    AlterPartitionRequestData.PartitionData partitionData\n) {\n    if (partition == null) {\n        log.info(\"Rejecting AlterPartition request for unknown partition {}-{}.\",\n                topic.name, partitionId);\n\n        return UNKNOWN_TOPIC_OR_PARTITION;\n    }\n\n        \n        \n        \n    if (partitionData.leaderEpoch() > partition.leaderEpoch) {\n        log.debug(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current leader epoch is {}, which is greater than the local value {}.\",\n            brokerId, topic.name, partitionId, partition.leaderEpoch, partitionData.leaderEpoch());\n        return NOT_CONTROLLER;\n    }\n    if (partitionData.partitionEpoch() > partition.partitionEpoch) {\n        log.debug(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current partition epoch is {}, which is greater than the local value {}.\",\n            brokerId, topic.name, partitionId, partition.partitionEpoch, partitionData.partitionEpoch());\n        return NOT_CONTROLLER;\n    }\n    if (partitionData.leaderEpoch() < partition.leaderEpoch) {\n        log.debug(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current leader epoch is {}, not {}.\", brokerId, topic.name,\n                partitionId, partition.leaderEpoch, partitionData.leaderEpoch());\n\n        return FENCED_LEADER_EPOCH;\n    }\n    if (brokerId != partition.leader) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current leader is {}.\", brokerId, topic.name,\n                partitionId, partition.leader);\n\n        return INVALID_REQUEST;\n    }\n    if (partitionData.partitionEpoch() < partition.partitionEpoch) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current partition epoch is {}, not {}.\", brokerId,\n                topic.name, partitionId, partition.partitionEpoch,\n                partitionData.partitionEpoch());\n\n        return INVALID_UPDATE_VERSION;\n    }\n    int[] newIsr = Replicas.toArray(partitionData.newIsr());\n    if (!Replicas.validateIsr(partition.replicas, newIsr)) {\n        log.error(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"it specified an invalid ISR {}.\", brokerId,\n                topic.name, partitionId, partitionData.newIsr());\n\n        return INVALID_REQUEST;\n    }\n    if (!Replicas.contains(newIsr, partition.leader)) {\n            \n        log.error(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"it specified an invalid ISR {} that doesn't include itself.\",\n                brokerId, topic.name, partitionId, partitionData.newIsr());\n\n        return INVALID_REQUEST;\n    }\n    LeaderRecoveryState leaderRecoveryState = LeaderRecoveryState.of(partitionData.leaderRecoveryState());\n    if (leaderRecoveryState == LeaderRecoveryState.RECOVERING && newIsr.length > 1) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the ISR {} had more than one replica while the leader was still \" +\n                \"recovering from an unclean leader election {}.\",\n                brokerId, topic.name, partitionId, partitionData.newIsr(),\n                leaderRecoveryState);\n\n        return INVALID_REQUEST;\n    }\n    if (partition.leaderRecoveryState == LeaderRecoveryState.RECOVERED &&\n            leaderRecoveryState == LeaderRecoveryState.RECOVERING) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the leader recovery state cannot change from RECOVERED to RECOVERING.\",\n                brokerId, topic.name, partitionId);\n\n        return INVALID_REQUEST;\n    }\n\n    List<IneligibleReplica> ineligibleReplicas = ineligibleReplicasForIsr(newIsr);\n    if (!ineligibleReplicas.isEmpty()) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"it specified ineligible replicas {} in the new ISR {}.\",\n                brokerId, topic.name, partitionId, ineligibleReplicas, partitionData.newIsr());\n\n        if (requestApiVersion > 1) {\n            return INELIGIBLE_REPLICA;\n        } else {\n            return OPERATION_NOT_ATTEMPTED;\n        }\n    }\n\n    return Errors.NONE;\n}",
        "summary_tokens": [
            "validate",
            "the",
            "partition",
            "information",
            "included",
            "in",
            "the",
            "alter",
            "partition",
            "request"
        ]
    },
    {
        "id": 2248,
        "code": "void handleBrokerFenced(int brokerId, List<ApiMessageAndVersion> records) {\n    BrokerRegistration brokerRegistration = clusterControl.brokerRegistrations().get(brokerId);\n    if (brokerRegistration == null) {\n        throw new RuntimeException(\"Can't find broker registration for broker \" + brokerId);\n    }\n    generateLeaderAndIsrUpdates(\"handleBrokerFenced\", brokerId, NO_LEADER, records,\n        brokersToIsrs.partitionsWithBrokerInIsr(brokerId));\n    if (featureControl.metadataVersion().isBrokerRegistrationChangeRecordSupported()) {\n        records.add(new ApiMessageAndVersion(new BrokerRegistrationChangeRecord().\n                setBrokerId(brokerId).setBrokerEpoch(brokerRegistration.epoch()).\n                setFenced(BrokerRegistrationFencingChange.FENCE.value()),\n                (short) 0));\n    } else {\n        records.add(new ApiMessageAndVersion(new FenceBrokerRecord().\n                setId(brokerId).setEpoch(brokerRegistration.epoch()),\n                (short) 0));\n    }\n}",
        "summary_tokens": [
            "generate",
            "the",
            "appropriate",
            "records",
            "to",
            "handle",
            "a",
            "broker",
            "being",
            "fenced"
        ]
    },
    {
        "id": 2249,
        "code": "void handleBrokerUnregistered(int brokerId, long brokerEpoch,\n                              List<ApiMessageAndVersion> records) {\n    generateLeaderAndIsrUpdates(\"handleBrokerUnregistered\", brokerId, NO_LEADER, records,\n        brokersToIsrs.partitionsWithBrokerInIsr(brokerId));\n    records.add(new ApiMessageAndVersion(new UnregisterBrokerRecord().\n        setBrokerId(brokerId).setBrokerEpoch(brokerEpoch),\n        (short) 0));\n}",
        "summary_tokens": [
            "generate",
            "the",
            "appropriate",
            "records",
            "to",
            "handle",
            "a",
            "broker",
            "being",
            "unregistered"
        ]
    },
    {
        "id": 2250,
        "code": "void handleBrokerUnfenced(int brokerId, long brokerEpoch, List<ApiMessageAndVersion> records) {\n    if (featureControl.metadataVersion().isBrokerRegistrationChangeRecordSupported()) {\n        records.add(new ApiMessageAndVersion(new BrokerRegistrationChangeRecord().\n            setBrokerId(brokerId).setBrokerEpoch(brokerEpoch).\n            setFenced(BrokerRegistrationFencingChange.UNFENCE.value()),\n            (short) 0));\n    } else {\n        records.add(new ApiMessageAndVersion(new UnfenceBrokerRecord().setId(brokerId).\n            setEpoch(brokerEpoch), (short) 0));\n    }\n    generateLeaderAndIsrUpdates(\"handleBrokerUnfenced\", NO_LEADER, brokerId, records,\n        brokersToIsrs.partitionsWithNoLeader());\n}",
        "summary_tokens": [
            "generate",
            "the",
            "appropriate",
            "records",
            "to",
            "handle",
            "a",
            "broker",
            "becoming",
            "unfenced"
        ]
    },
    {
        "id": 2251,
        "code": "void handleBrokerInControlledShutdown(int brokerId, long brokerEpoch, List<ApiMessageAndVersion> records) {\n    if (featureControl.metadataVersion().isInControlledShutdownStateSupported()\n            && !clusterControl.inControlledShutdown(brokerId)) {\n        records.add(new ApiMessageAndVersion(new BrokerRegistrationChangeRecord().\n            setBrokerId(brokerId).setBrokerEpoch(brokerEpoch).\n            setInControlledShutdown(BrokerRegistrationInControlledShutdownChange.IN_CONTROLLED_SHUTDOWN.value()),\n            (short) 1));\n    }\n    generateLeaderAndIsrUpdates(\"enterControlledShutdown[\" + brokerId + \"]\",\n        brokerId, NO_LEADER, records, brokersToIsrs.partitionsWithBrokerInIsr(brokerId));\n}",
        "summary_tokens": [
            "generate",
            "the",
            "appropriate",
            "records",
            "to",
            "handle",
            "a",
            "broker",
            "starting",
            "a",
            "controlled",
            "shutdown"
        ]
    },
    {
        "id": 2252,
        "code": "ControllerResult<Boolean> maybeBalancePartitionLeaders() {\n    List<ApiMessageAndVersion> records = new ArrayList<>();\n\n    boolean rescheduleImmidiately = false;\n    for (TopicIdPartition topicPartition : imbalancedPartitions) {\n        if (records.size() >= maxElectionsPerImbalance) {\n            rescheduleImmidiately = true;\n            break;\n        }\n\n        TopicControlInfo topic = topics.get(topicPartition.topicId());\n        if (topic == null) {\n            log.error(\"Skipping unknown imbalanced topic {}\", topicPartition);\n            continue;\n        }\n\n        PartitionRegistration partition = topic.parts.get(topicPartition.partitionId());\n        if (partition == null) {\n            log.error(\"Skipping unknown imbalanced partition {}\", topicPartition);\n            continue;\n        }\n\n            \n        PartitionChangeBuilder builder = new PartitionChangeBuilder(\n            partition,\n            topicPartition.topicId(),\n            topicPartition.partitionId(),\n            clusterControl::active,\n            featureControl.metadataVersion().isLeaderRecoverySupported()\n        );\n        builder.setElection(PartitionChangeBuilder.Election.PREFERRED);\n        builder.build().ifPresent(records::add);\n    }\n\n    return ControllerResult.of(records, rescheduleImmidiately);\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "elect",
            "a",
            "preferred",
            "leader",
            "for",
            "all",
            "topic",
            "partitions",
            "which",
            "have",
            "a",
            "leader",
            "that",
            "is",
            "not",
            "the",
            "preferred",
            "replica"
        ]
    },
    {
        "id": 2253,
        "code": "void generateLeaderAndIsrUpdates(String context,\n                                 int brokerToRemove,\n                                 int brokerToAdd,\n                                 List<ApiMessageAndVersion> records,\n                                 Iterator<TopicIdPartition> iterator) {\n    int oldSize = records.size();\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    Function<Integer, Boolean> isAcceptableLeader =\n        r -> (r != brokerToRemove) && (r == brokerToAdd || clusterControl.active(r));\n\n    while (iterator.hasNext()) {\n        TopicIdPartition topicIdPart = iterator.next();\n        TopicControlInfo topic = topics.get(topicIdPart.topicId());\n        if (topic == null) {\n            throw new RuntimeException(\"Topic ID \" + topicIdPart.topicId() +\n                \" existed in isrMembers, but not in the topics map.\");\n        }\n        PartitionRegistration partition = topic.parts.get(topicIdPart.partitionId());\n        if (partition == null) {\n            throw new RuntimeException(\"Partition \" + topicIdPart +\n                \" existed in isrMembers, but not in the partitions map.\");\n        }\n        PartitionChangeBuilder builder = new PartitionChangeBuilder(partition,\n            topicIdPart.topicId(),\n            topicIdPart.partitionId(),\n            isAcceptableLeader,\n            featureControl.metadataVersion().isLeaderRecoverySupported());\n        if (configurationControl.uncleanLeaderElectionEnabledForTopic(topic.name)) {\n            builder.setElection(PartitionChangeBuilder.Election.UNCLEAN);\n        }\n\n            \n            \n        builder.setTargetIsr(Replicas.toList(\n            Replicas.copyWithout(partition.isr, brokerToRemove)));\n\n        builder.build().ifPresent(records::add);\n    }\n    if (records.size() != oldSize) {\n        if (log.isDebugEnabled()) {\n            StringBuilder bld = new StringBuilder();\n            String prefix = \"\";\n            for (ListIterator<ApiMessageAndVersion> iter = records.listIterator(oldSize);\n                 iter.hasNext(); ) {\n                ApiMessageAndVersion apiMessageAndVersion = iter.next();\n                PartitionChangeRecord record = (PartitionChangeRecord) apiMessageAndVersion.message();\n                bld.append(prefix).append(topics.get(record.topicId()).name).append(\"-\").\n                    append(record.partitionId());\n                prefix = \", \";\n            }\n            log.debug(\"{}: changing partition(s): {}\", context, bld.toString());\n        } else if (log.isInfoEnabled()) {\n            log.info(\"{}: changing {} partition(s)\", context, records.size() - oldSize);\n        }\n    }\n}",
        "summary_tokens": [
            "iterate",
            "over",
            "a",
            "sequence",
            "of",
            "partitions",
            "and",
            "generate",
            "isr",
            "changes",
            "and",
            "or",
            "leader",
            "changes",
            "if",
            "necessary"
        ]
    },
    {
        "id": 2254,
        "code": "Optional<ApiMessageAndVersion> changePartitionReassignment(TopicIdPartition tp,\n                                                           PartitionRegistration part,\n                                                           ReassignablePartition target) {\n        \n    validateManualPartitionAssignment(target.replicas(), OptionalInt.empty());\n\n    List<Integer> currentReplicas = Replicas.toList(part.replicas);\n    PartitionReassignmentReplicas reassignment =\n        new PartitionReassignmentReplicas(currentReplicas, target.replicas());\n    PartitionChangeBuilder builder = new PartitionChangeBuilder(part,\n        tp.topicId(),\n        tp.partitionId(),\n        clusterControl::active,\n        featureControl.metadataVersion().isLeaderRecoverySupported());\n    if (!reassignment.merged().equals(currentReplicas)) {\n        builder.setTargetReplicas(reassignment.merged());\n    }\n    if (!reassignment.removing().isEmpty()) {\n        builder.setTargetRemoving(reassignment.removing());\n    }\n    if (!reassignment.adding().isEmpty()) {\n        builder.setTargetAdding(reassignment.adding());\n    }\n    return builder.build();\n}",
        "summary_tokens": [
            "apply",
            "a",
            "given",
            "partition",
            "reassignment"
        ]
    },
    {
        "id": 2255,
        "code": "long lastContainedLogOffset() {\n    return writer.lastContainedLogOffset();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "last",
            "offset",
            "from",
            "the",
            "log",
            "that",
            "will",
            "be",
            "included",
            "in",
            "the",
            "snapshot"
        ]
    },
    {
        "id": 2256,
        "code": "private boolean generateBatch() throws Exception {\n    if (batch == null) {\n        while (!batchIterator.hasNext()) {\n            if (section != null) {\n                log.info(\"Generated {} record(s) for the {} section of snapshot {}.\",\n                         numRecords, section.name(), writer.snapshotId());\n                section = null;\n                numRecords = 0;\n            }\n            if (!sectionIterator.hasNext()) {\n                writer.freeze();\n                return true;\n            }\n            section = sectionIterator.next();\n            log.info(\"Generating records for the {} section of snapshot {}.\",\n                     section.name(), writer.snapshotId());\n            batchIterator = section.iterator();\n        }\n        batch = batchIterator.next();\n    }\n\n    writer.append(batch);\n    numRecords += batch.size();\n    batch = null;\n    return false;\n}",
        "summary_tokens": [
            "generate",
            "and",
            "write",
            "the",
            "next",
            "batch",
            "of",
            "records"
        ]
    },
    {
        "id": 2257,
        "code": "OptionalLong generateBatches() throws Exception {\n    for (int numBatches = 0; numBatches < maxBatchesPerGenerateCall; numBatches++) {\n        if (generateBatch()) {\n            return OptionalLong.empty();\n        }\n    }\n    return OptionalLong.of(0);\n}",
        "summary_tokens": [
            "generate",
            "the",
            "next",
            "few",
            "batches",
            "of",
            "records"
        ]
    },
    {
        "id": 2258,
        "code": "public Map<Uuid, Optional<StandardAcl>> changes() {\n    return changes;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "map",
            "of",
            "deltas",
            "from",
            "acl",
            "id",
            "to",
            "optional",
            "standard",
            "acl"
        ]
    },
    {
        "id": 2259,
        "code": "public void replay(RemoveAccessControlEntryRecord record) {\n    if (image.acls().containsKey(record.id())) {\n        changes.put(record.id(), Optional.empty());\n    } else if (changes.containsKey(record.id())) {\n        changes.remove(record.id());\n    } else {\n        throw new IllegalStateException(\"Failed to find existing ACL with ID \" + record.id() + \" in either image or changes\");\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "replays",
            "a",
            "remove",
            "access",
            "control",
            "entry",
            "record",
            "record"
        ]
    },
    {
        "id": 2260,
        "code": "public void finishSnapshot() {\n    getOrCreateFeaturesDelta().finishSnapshot();\n    getOrCreateClusterDelta().finishSnapshot();\n    getOrCreateTopicsDelta().finishSnapshot();\n    getOrCreateConfigsDelta().finishSnapshot();\n    getOrCreateClientQuotasDelta().finishSnapshot();\n    getOrCreateProducerIdsDelta().finishSnapshot();\n    getOrCreateAclsDelta().finishSnapshot();\n}",
        "summary_tokens": [
            "create",
            "removal",
            "deltas",
            "for",
            "anything",
            "which",
            "was",
            "in",
            "the",
            "base",
            "image",
            "but",
            "which",
            "was",
            "not",
            "referenced",
            "in",
            "the",
            "snapshot",
            "records",
            "we",
            "just",
            "applied"
        ]
    },
    {
        "id": 2261,
        "code": "public LocalReplicaChanges localChanges(int brokerId) {\n    Set<TopicPartition> deletes = new HashSet<>();\n    Map<TopicPartition, LocalReplicaChanges.PartitionInfo> leaders = new HashMap<>();\n    Map<TopicPartition, LocalReplicaChanges.PartitionInfo> followers = new HashMap<>();\n\n    for (Entry<Integer, PartitionRegistration> entry : partitionChanges.entrySet()) {\n        if (!Replicas.contains(entry.getValue().replicas, brokerId)) {\n            PartitionRegistration prevPartition = image.partitions().get(entry.getKey());\n            if (prevPartition != null && Replicas.contains(prevPartition.replicas, brokerId)) {\n                deletes.add(new TopicPartition(name(), entry.getKey()));\n            }\n        } else if (entry.getValue().leader == brokerId) {\n            PartitionRegistration prevPartition = image.partitions().get(entry.getKey());\n            if (prevPartition == null || prevPartition.partitionEpoch != entry.getValue().partitionEpoch) {\n                leaders.put(\n                    new TopicPartition(name(), entry.getKey()),\n                    new LocalReplicaChanges.PartitionInfo(id(), entry.getValue())\n                );\n            }\n        } else if (\n            entry.getValue().leader != brokerId &&\n            Replicas.contains(entry.getValue().replicas, brokerId)\n        ) {\n            PartitionRegistration prevPartition = image.partitions().get(entry.getKey());\n            if (prevPartition == null || prevPartition.partitionEpoch != entry.getValue().partitionEpoch) {\n                followers.put(\n                    new TopicPartition(name(), entry.getKey()),\n                    new LocalReplicaChanges.PartitionInfo(id(), entry.getValue())\n                );\n            }\n        }\n    }\n\n    return new LocalReplicaChanges(deletes, leaders, followers);\n}",
        "summary_tokens": [
            "find",
            "the",
            "partitions",
            "that",
            "have",
            "change",
            "based",
            "on",
            "the",
            "replica",
            "given"
        ]
    },
    {
        "id": 2262,
        "code": "public boolean topicWasDeleted(String topicName) {\n    TopicImage topicImage = image.getTopic(topicName);\n    if (topicImage == null) {\n        return false;\n    }\n    return deletedTopicIds.contains(topicImage.id());\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "topic",
            "with",
            "the",
            "given",
            "name",
            "was",
            "deleted"
        ]
    },
    {
        "id": 2263,
        "code": "public LocalReplicaChanges localChanges(int brokerId) {\n    Set<TopicPartition> deletes = new HashSet<>();\n    Map<TopicPartition, LocalReplicaChanges.PartitionInfo> leaders = new HashMap<>();\n    Map<TopicPartition, LocalReplicaChanges.PartitionInfo> followers = new HashMap<>();\n\n    for (TopicDelta delta : changedTopics.values()) {\n        LocalReplicaChanges changes = delta.localChanges(brokerId);\n\n        deletes.addAll(changes.deletes());\n        leaders.putAll(changes.leaders());\n        followers.putAll(changes.followers());\n    }\n\n        \n    deletedTopicIds().forEach(topicId -> {\n        TopicImage topicImage = image().getTopic(topicId);\n        topicImage.partitions().forEach((partitionId, prevPartition) -> {\n            if (Replicas.contains(prevPartition.replicas, brokerId)) {\n                deletes.add(new TopicPartition(topicImage.name(), partitionId));\n            }\n        });\n    });\n\n    return new LocalReplicaChanges(deletes, leaders, followers);\n}",
        "summary_tokens": [
            "find",
            "the",
            "topic",
            "partitions",
            "that",
            "have",
            "change",
            "based",
            "on",
            "the",
            "replica",
            "given"
        ]
    },
    {
        "id": 2264,
        "code": "public Map<String, Uuid> topicNameToIdView() {\n    return new TranslatedValueMapView<>(topicsByName, image -> image.id());\n}",
        "summary_tokens": [
            "expose",
            "a",
            "view",
            "of",
            "this",
            "topics",
            "image",
            "as",
            "a",
            "map",
            "from",
            "topic",
            "names",
            "to",
            "ids"
        ]
    },
    {
        "id": 2265,
        "code": "public Map<Uuid, String> topicIdToNameView() {\n    return new TranslatedValueMapView<>(topicsById, image -> image.name());\n}",
        "summary_tokens": [
            "expose",
            "a",
            "view",
            "of",
            "this",
            "topics",
            "image",
            "as",
            "a",
            "map",
            "from",
            "ids",
            "to",
            "names"
        ]
    },
    {
        "id": 2266,
        "code": "public static ConfigEntry.ConfigType translateConfigType(ConfigDef.Type type) {\n    switch (type) {\n        case BOOLEAN:\n            return ConfigEntry.ConfigType.BOOLEAN;\n        case STRING:\n            return ConfigEntry.ConfigType.STRING;\n        case INT:\n            return ConfigEntry.ConfigType.INT;\n        case SHORT:\n            return ConfigEntry.ConfigType.SHORT;\n        case LONG:\n            return ConfigEntry.ConfigType.LONG;\n        case DOUBLE:\n            return ConfigEntry.ConfigType.DOUBLE;\n        case LIST:\n            return ConfigEntry.ConfigType.LIST;\n        case CLASS:\n            return ConfigEntry.ConfigType.CLASS;\n        case PASSWORD:\n            return ConfigEntry.ConfigType.PASSWORD;\n        default:\n            return ConfigEntry.ConfigType.UNKNOWN;\n    }\n}",
        "summary_tokens": [
            "translate",
            "a",
            "config",
            "def"
        ]
    },
    {
        "id": 2267,
        "code": "public static DescribeConfigsResponse.ConfigSource translateConfigSource(ConfigEntry.ConfigSource configSource) {\n    DescribeConfigsResponse.ConfigSource result = TRANSLATE_CONFIG_SOURCE_MAP.get(configSource);\n    if (result != null) return result;\n    return DescribeConfigsResponse.ConfigSource.UNKNOWN;\n}",
        "summary_tokens": [
            "translate",
            "a",
            "config",
            "entry"
        ]
    },
    {
        "id": 2268,
        "code": "public boolean isSplittable(ConfigResource.Type type, String key) {\n    ConfigDef configDef = configDefs.get(type);\n    if (configDef == null) return false;\n    ConfigDef.ConfigKey configKey = configDef.configKeys().get(key);\n    if (configKey == null) return false;\n    return configKey.type == ConfigDef.Type.LIST;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "configuration",
            "key",
            "specified",
            "is",
            "splittable",
            "only",
            "lists",
            "are",
            "splittable"
        ]
    },
    {
        "id": 2269,
        "code": "public boolean isSensitive(ConfigResource.Type type, String key) {\n    ConfigDef configDef = configDefs.get(type);\n    if (configDef == null) return true;\n    ConfigDef.ConfigKey configKey = configDef.configKeys().get(key);\n    if (configKey == null) return true;\n    return configKey.type.isSensitive();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "configuration",
            "key",
            "specified",
            "is",
            "sensitive",
            "or",
            "if",
            "we",
            "don",
            "t",
            "know",
            "whether",
            "it",
            "is",
            "sensitive"
        ]
    },
    {
        "id": 2270,
        "code": "public String getDefault(ConfigResource.Type type, String key) {\n    ConfigDef configDef = configDefs.get(type);\n    if (configDef == null) return null;\n    ConfigDef.ConfigKey configKey = configDef.configKeys().get(key);\n    if (configKey == null || !configKey.hasDefault()) {\n        return null;\n    }\n    return ConfigDef.convertToString(configKey.defaultValue, configKey.type);\n}",
        "summary_tokens": [
            "get",
            "the",
            "default",
            "value",
            "of",
            "the",
            "configuration",
            "key",
            "or",
            "null",
            "if",
            "no",
            "default",
            "is",
            "specified"
        ]
    },
    {
        "id": 2271,
        "code": "public boolean isReassigning() {\n    return removingReplicas.length > 0 || addingReplicas.length > 0;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "this",
            "partition",
            "is",
            "reassigning"
        ]
    },
    {
        "id": 2272,
        "code": "public static List<Integer> toList(int[] array) {\n    if (array == null) return null;\n    ArrayList<Integer> list = new ArrayList<>(array.length);\n    for (int i = 0; i < array.length; i++) {\n        list.add(array[i]);\n    }\n    return list;\n}",
        "summary_tokens": [
            "convert",
            "an",
            "array",
            "of",
            "integers",
            "to",
            "a",
            "list",
            "of",
            "ints"
        ]
    },
    {
        "id": 2273,
        "code": "public static int[] toArray(List<Integer> list) {\n    if (list == null) return null;\n    int[] array = new int[list.size()];\n    for (int i = 0; i < list.size(); i++) {\n        array[i] = list.get(i);\n    }\n    return array;\n}",
        "summary_tokens": [
            "convert",
            "a",
            "list",
            "of",
            "integers",
            "to",
            "an",
            "array",
            "of",
            "ints"
        ]
    },
    {
        "id": 2274,
        "code": "public static int[] clone(int[] array) {\n    int[] clone = new int[array.length];\n    System.arraycopy(array, 0, clone, 0, array.length);\n    return clone;\n}",
        "summary_tokens": [
            "copy",
            "an",
            "array",
            "of",
            "ints"
        ]
    },
    {
        "id": 2275,
        "code": "public static boolean validate(int[] replicas) {\n    if (replicas.length == 0) return true;\n    int[] sortedReplicas = clone(replicas);\n    Arrays.sort(sortedReplicas);\n    int prev = sortedReplicas[0];\n    if (prev < 0) return false;\n    for (int i = 1; i < sortedReplicas.length; i++) {\n        int replica = sortedReplicas[i];\n        if (prev == replica) return false;\n        prev = replica;\n    }\n    return true;\n}",
        "summary_tokens": [
            "check",
            "that",
            "a",
            "replica",
            "set",
            "is",
            "valid"
        ]
    },
    {
        "id": 2276,
        "code": "public static boolean validateIsr(int[] replicas, int[] isr) {\n    if (isr.length == 0) return true;\n    if (replicas.length == 0) return false;\n    int[] sortedReplicas = clone(replicas);\n    Arrays.sort(sortedReplicas);\n    int[] sortedIsr = clone(isr);\n    Arrays.sort(sortedIsr);\n    int j = 0;\n    if (sortedIsr[0] < 0) return false;\n    int prevIsr = -1;\n    for (int i = 0; i < sortedIsr.length; i++) {\n        int curIsr = sortedIsr[i];\n        if (prevIsr == curIsr) return false;\n        prevIsr = curIsr;\n        while (true) {\n            if (j == sortedReplicas.length) return false;\n            int curReplica = sortedReplicas[j++];\n            if (curReplica == curIsr) break;\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "check",
            "that",
            "an",
            "isr",
            "set",
            "is",
            "valid"
        ]
    },
    {
        "id": 2277,
        "code": "public static boolean contains(List<Integer> a, int[] b) {\n    List<Integer> aSorted = new ArrayList<>(a);\n    aSorted.sort(Integer::compareTo);\n    List<Integer> bSorted = Replicas.toList(b);\n    bSorted.sort(Integer::compareTo);\n    int i = 0;\n    for (int replica : bSorted) {\n        while (true) {\n            if (i >= aSorted.size()) return false;\n            int replica2 = aSorted.get(i++);\n            if (replica2 == replica) break;\n            if (replica2 > replica) return false;\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "first",
            "list",
            "of",
            "integers",
            "contains",
            "the",
            "second"
        ]
    },
    {
        "id": 2278,
        "code": "public static int[] copyWithout(int[] replicas, int[] values) {\n    int size = 0;\n    for (int i = 0; i < replicas.length; i++) {\n        if (!Replicas.contains(values, replicas[i])) {\n            size++;\n        }\n    }\n    int[] result = new int[size];\n    int j = 0;\n    for (int i = 0; i < replicas.length; i++) {\n        int replica = replicas[i];\n        if (!Replicas.contains(values, replica)) {\n            result[j++] = replica;\n        }\n    }\n    return result;\n}",
        "summary_tokens": [
            "copy",
            "a",
            "replica",
            "array",
            "without",
            "any",
            "occurrences",
            "of",
            "the",
            "given",
            "values"
        ]
    },
    {
        "id": 2279,
        "code": "public static int[] copyWith(int[] replicas, int value) {\n    int[] newReplicas = new int[replicas.length + 1];\n    System.arraycopy(replicas, 0, newReplicas, 0, replicas.length);\n    newReplicas[newReplicas.length - 1] = value;\n    return newReplicas;\n}",
        "summary_tokens": [
            "copy",
            "a",
            "replica",
            "array",
            "with",
            "the",
            "given",
            "value"
        ]
    },
    {
        "id": 2280,
        "code": "public static Set<Integer> toSet(int[] replicas) {\n    Set<Integer> result = new HashSet<>();\n    for (int replica : replicas) {\n        result.add(replica);\n    }\n    return result;\n}",
        "summary_tokens": [
            "convert",
            "a",
            "replica",
            "array",
            "to",
            "a",
            "set"
        ]
    },
    {
        "id": 2281,
        "code": "public boolean contains(short version) {\n    return version >= min && version <= max;\n}",
        "summary_tokens": [
            "check",
            "if",
            "a",
            "given",
            "version",
            "is",
            "fully",
            "contained",
            "within",
            "this",
            "range"
        ]
    },
    {
        "id": 2282,
        "code": "public boolean intersects(VersionRange other) {\n    return other.min <= max && other.max >= min;\n}",
        "summary_tokens": [
            "check",
            "if",
            "a",
            "given",
            "version",
            "range",
            "has",
            "overlap",
            "with",
            "this",
            "one"
        ]
    },
    {
        "id": 2283,
        "code": "default List<? extends CompletionStage<AclDeleteResult>> deleteAcls(\n        AuthorizableRequestContext requestContext,\n        List<AclBindingFilter> filters) {\n    List<CompletableFuture<AclDeleteResult>> futures = new ArrayList<>(filters.size());\n    AclMutator aclMutator = aclMutatorOrException();\n    filters.forEach(b -> futures.add(new CompletableFuture<>()));\n    ControllerRequestContext context = new ControllerRequestContext(\n        requestContext, OptionalLong.empty());\n    aclMutator.deleteAcls(context, filters).whenComplete((results, throwable) -> {\n        if (throwable == null && results.size() != futures.size()) {\n            throwable = new UnknownServerException(\"Invalid size \" +\n                \"of result set from controller. Expected \" + futures.size() +\n                \"; got \" + results.size());\n        }\n        if (throwable == null) {\n            for (int i = 0; i < futures.size(); i++) {\n                futures.get(i).complete(results.get(i));\n            }\n        } else {\n            for (CompletableFuture<AclDeleteResult> future : futures) {\n                ApiException e = (throwable instanceof ApiException) ? (ApiException) throwable :\n                    ApiError.fromThrowable(throwable).exception();\n                future.complete(new AclDeleteResult(e));\n            }\n        }\n    });\n    return futures;\n}",
        "summary_tokens": [
            "delete",
            "acls",
            "based",
            "on",
            "filters"
        ]
    },
    {
        "id": 2284,
        "code": "public int compareTo(StandardAcl other) {\n    int result;\n    result = resourceType.compareTo(other.resourceType);\n    if (result != 0) return result;\n    result = other.resourceName.compareTo(resourceName); \n    if (result != 0) return result;\n    result = patternType.compareTo(other.patternType);\n    if (result != 0) return result;\n    result = operation.compareTo(other.operation);\n    if (result != 0) return result;\n    result = principal.compareTo(other.principal);\n    if (result != 0) return result;\n    result = host.compareTo(other.host);\n    if (result != 0) return result;\n    result = permissionType.compareTo(other.permissionType);\n    return result;\n}",
        "summary_tokens": [
            "compare",
            "two",
            "standard",
            "acl",
            "objects"
        ]
    },
    {
        "id": 2285,
        "code": "public AuthorizationResult authorize(\n    AuthorizableRequestContext requestContext,\n    Action action\n) {\n    KafkaPrincipal principal = baseKafkaPrincipal(requestContext);\n    final MatchingRule rule;\n\n        \n    if (superUsers.contains(principal.toString())) {\n        rule = SuperUserRule.INSTANCE;\n    } else if (!loadingComplete) {\n        throw new AuthorizerNotReadyException();\n    } else {\n        MatchingAclRule aclRule = findAclRule(\n            matchingPrincipals(requestContext),\n            requestContext.clientAddress().getHostAddress(),\n            action\n        );\n\n        if (aclRule != null) {\n            rule = aclRule;\n        } else {\n                \n            rule = defaultRule;\n        }\n    }\n\n    logAuditMessage(principal, requestContext, action, rule);\n    return rule.result();\n}",
        "summary_tokens": [
            "authorize",
            "an",
            "action",
            "based",
            "on",
            "the",
            "current",
            "set",
            "of",
            "acls"
        ]
    },
    {
        "id": 2286,
        "code": "static AuthorizationResult findResult(Action action,\n                                      Set<KafkaPrincipal> matchingPrincipals,\n                                      String host,\n                                      StandardAcl acl) {\n        \n    if (!matchingPrincipals.contains(acl.kafkaPrincipal())) {\n        return null;\n    }\n        \n    if (!acl.host().equals(WILDCARD) && !acl.host().equals(host)) {\n        return null;\n    }\n        \n        \n        \n        \n        \n        \n        \n    if (acl.operation() != ALL) {\n        if (acl.permissionType().equals(ALLOW)) {\n            switch (action.operation()) {\n                case DESCRIBE:\n                    if (!IMPLIES_DESCRIBE.contains(acl.operation())) return null;\n                    break;\n                case DESCRIBE_CONFIGS:\n                    if (!IMPLIES_DESCRIBE_CONFIGS.contains(acl.operation())) return null;\n                    break;\n                default:\n                    if (action.operation() != acl.operation()) {\n                        return null;\n                    }\n                    break;\n            }\n        } else if (action.operation() != acl.operation()) {\n            return null;\n        }\n    }\n\n    return acl.permissionType().equals(ALLOW) ? ALLOWED : DENIED;\n}",
        "summary_tokens": [
            "determine",
            "what",
            "the",
            "result",
            "of",
            "applying",
            "an",
            "acl",
            "to",
            "the",
            "given",
            "action",
            "and",
            "request",
            "context",
            "should",
            "be"
        ]
    },
    {
        "id": 2287,
        "code": "static int expectedSizeToCapacity(int expectedSize) {\n    long minCapacity = (long) Math.ceil((float) expectedSize / MAX_LOAD_FACTOR);\n    return Math.max(MIN_CAPACITY,\n            (int) Math.min(MAX_CAPACITY, roundUpToPowerOfTwo(minCapacity)));\n}",
        "summary_tokens": [
            "calculate",
            "the",
            "capacity",
            "we",
            "should",
            "provision",
            "given",
            "the",
            "expected",
            "size"
        ]
    },
    {
        "id": 2288,
        "code": "final private void rehash(int newSize) {\n    Object[] prevElements = elements;\n    elements = new Object[newSize];\n    List<Object> ready = new ArrayList<>();\n    for (int slot = 0; slot < prevElements.length; slot++) {\n        unpackSlot(ready, prevElements, slot);\n        for (Object object : ready) {\n            int newSlot = findSlot(object, elements.length);\n            Object cur = elements[newSlot];\n            if (cur == null) {\n                elements[newSlot] = object;\n            } else if (cur instanceof Object[]) {\n                Object[] curArray = (Object[]) cur;\n                Object[] newArray = new Object[curArray.length + 1];\n                System.arraycopy(curArray, 0, newArray, 0, curArray.length);\n                newArray[curArray.length] = object;\n                elements[newSlot] = newArray;\n            } else {\n                elements[newSlot] = new Object[]{cur, object};\n            }\n        }\n        ready.clear();\n    }\n}",
        "summary_tokens": [
            "expand",
            "the",
            "hash",
            "table",
            "to",
            "a",
            "new",
            "size"
        ]
    },
    {
        "id": 2289,
        "code": "static int findSlot(Object object, int numElements) {\n        \n        \n        \n        \n    int objectHashCode = object.hashCode();\n    int log2size = 32 - Integer.numberOfLeadingZeros(numElements);\n    int shift = 65 - log2size;\n    return (int) ((objectHashCode * -7046029254386353131L) >>> shift);\n}",
        "summary_tokens": [
            "find",
            "the",
            "slot",
            "in",
            "the",
            "array",
            "that",
            "an",
            "element",
            "should",
            "go",
            "into"
        ]
    },
    {
        "id": 2290,
        "code": "static <T> void unpackSlot(List<T> out, Object[] elements, int slot) {\n    Object value = elements[slot];\n    if (value == null) {\n        return;\n    } else if (value instanceof Object[]) {\n        Object[] array = (Object[]) value;\n        for (Object object : array) {\n            out.add((T) object);\n        }\n    } else {\n        out.add((T) value);\n    }\n}",
        "summary_tokens": [
            "copy",
            "any",
            "elements",
            "in",
            "the",
            "given",
            "slot",
            "into",
            "the",
            "output",
            "list"
        ]
    },
    {
        "id": 2291,
        "code": "public Iterator<Snapshot> iterator(Snapshot snapshot) {\n    return new SnapshotIterator(snapshot);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "snapshot",
            "iterator",
            "that",
            "iterates",
            "from",
            "the",
            "snapshots",
            "with",
            "the",
            "lowest",
            "epoch",
            "to",
            "those",
            "with",
            "the",
            "highest",
            "starting",
            "at",
            "the",
            "given",
            "snapshot"
        ]
    },
    {
        "id": 2292,
        "code": "public Iterator<Snapshot> reverseIterator() {\n    return new ReverseSnapshotIterator();\n}",
        "summary_tokens": [
            "returns",
            "a",
            "reverse",
            "snapshot",
            "iterator",
            "that",
            "iterates",
            "from",
            "the",
            "snapshots",
            "with",
            "the",
            "highest",
            "epoch",
            "to",
            "those",
            "with",
            "the",
            "lowest"
        ]
    },
    {
        "id": 2293,
        "code": "public List<Long> epochsList() {\n    List<Long> result = new ArrayList<>();\n    for (Iterator<Snapshot> iterator = iterator(); iterator.hasNext(); ) {\n        result.add(iterator.next().epoch());\n    }\n    return result;\n}",
        "summary_tokens": [
            "returns",
            "a",
            "sorted",
            "list",
            "of",
            "snapshot",
            "epochs"
        ]
    },
    {
        "id": 2294,
        "code": "public Snapshot getSnapshot(long epoch) {\n    Snapshot snapshot = snapshots.get(epoch);\n    if (snapshot == null) {\n        throw new RuntimeException(\"No in-memory snapshot for epoch \" + epoch + \". Snapshot \" +\n            \"epochs are: \" + epochsList().stream().map(e -> e.toString()).\n                collect(Collectors.joining(\", \")));\n    }\n    return snapshot;\n}",
        "summary_tokens": [
            "gets",
            "the",
            "snapshot",
            "for",
            "a",
            "specific",
            "epoch"
        ]
    },
    {
        "id": 2295,
        "code": "public Snapshot getOrCreateSnapshot(long epoch) {\n    Snapshot last = head.prev();\n    if (last.epoch() > epoch) {\n        throw new RuntimeException(\"Can't create a new in-memory snapshot at epoch \" + epoch +\n            \" because there is already a snapshot with epoch \" + last.epoch());\n    } else if (last.epoch() == epoch) {\n        return last;\n    }\n    Snapshot snapshot = new Snapshot(epoch);\n    last.appendNext(snapshot);\n    snapshots.put(epoch, snapshot);\n    log.debug(\"Creating in-memory snapshot {}\", epoch);\n    return snapshot;\n}",
        "summary_tokens": [
            "creates",
            "a",
            "new",
            "snapshot",
            "at",
            "the",
            "given",
            "epoch"
        ]
    },
    {
        "id": 2296,
        "code": "public void revertToSnapshot(long targetEpoch) {\n    Snapshot target = getSnapshot(targetEpoch);\n    Iterator<Snapshot> iterator = iterator(target);\n    iterator.next();\n    while (iterator.hasNext()) {\n        Snapshot snapshot = iterator.next();\n        log.debug(\"Deleting in-memory snapshot {} because we are reverting to {}\",\n            snapshot.epoch(), targetEpoch);\n        iterator.remove();\n    }\n    target.handleRevert();\n}",
        "summary_tokens": [
            "reverts",
            "the",
            "state",
            "of",
            "all",
            "data",
            "structures",
            "to",
            "the",
            "state",
            "at",
            "the",
            "given",
            "epoch"
        ]
    },
    {
        "id": 2297,
        "code": "public void deleteSnapshot(Snapshot snapshot) {\n    Snapshot prev = snapshot.prev();\n    if (prev != head) {\n        prev.mergeFrom(snapshot);\n    } else {\n        snapshot.erase();\n    }\n    log.debug(\"Deleting snapshot {}\", snapshot.epoch());\n    snapshots.remove(snapshot.epoch(), snapshot);\n}",
        "summary_tokens": [
            "deletes",
            "the",
            "given",
            "snapshot"
        ]
    },
    {
        "id": 2298,
        "code": "public void deleteSnapshotsUpTo(long targetEpoch) {\n    for (Iterator<Snapshot> iterator = iterator(); iterator.hasNext(); ) {\n        Snapshot snapshot = iterator.next();\n        if (snapshot.epoch() >= targetEpoch) {\n            return;\n        }\n        iterator.remove();\n    }\n}",
        "summary_tokens": [
            "deletes",
            "all",
            "the",
            "snapshots",
            "up",
            "to",
            "the",
            "given",
            "epoch"
        ]
    },
    {
        "id": 2299,
        "code": "public long latestEpoch() {\n    return head.prev().epoch();\n}",
        "summary_tokens": [
            "return",
            "the",
            "latest",
            "epoch"
        ]
    },
    {
        "id": 2300,
        "code": "public void register(Revertable revertable) {\n    revertables.add(revertable);\n}",
        "summary_tokens": [
            "associate",
            "with",
            "this",
            "registry"
        ]
    },
    {
        "id": 2301,
        "code": "public void reset() {\n    deleteSnapshotsUpTo(LATEST_EPOCH);\n\n    for (Revertable revertable : revertables) {\n        revertable.reset();\n    }\n}",
        "summary_tokens": [
            "delete",
            "all",
            "snapshots",
            "and",
            "resets",
            "all",
            "of",
            "the",
            "revertable",
            "object",
            "registered"
        ]
    },
    {
        "id": 2302,
        "code": "public void testValidateNewAcl() {\n    AclControlManager.validateNewAcl(new AclBinding(\n        new ResourcePattern(TOPIC, \"*\", LITERAL),\n        new AccessControlEntry(\"User:*\", \"*\", ALTER, ALLOW)));\n    assertEquals(\"Invalid patternType UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(TOPIC, \"*\", PatternType.UNKNOWN),\n                new AccessControlEntry(\"User:*\", \"*\", ALTER, ALLOW)))).\n            getMessage());\n    assertEquals(\"Invalid resourceType UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(ResourceType.UNKNOWN, \"*\", LITERAL),\n                new AccessControlEntry(\"User:*\", \"*\", ALTER, ALLOW)))).\n            getMessage());\n    assertEquals(\"Invalid operation UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(TOPIC, \"*\", LITERAL),\n                new AccessControlEntry(\"User:*\", \"*\", AclOperation.UNKNOWN, ALLOW)))).\n            getMessage());\n    assertEquals(\"Invalid permissionType UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(TOPIC, \"*\", LITERAL),\n                new AccessControlEntry(\"User:*\", \"*\", ALTER, AclPermissionType.UNKNOWN)))).\n            getMessage());\n}",
        "summary_tokens": [
            "verify",
            "that",
            "validate",
            "new",
            "acl",
            "catches",
            "invalid",
            "acls"
        ]
    },
    {
        "id": 2303,
        "code": "public void testValidateFilter() {\n    AclControlManager.validateFilter(new AclBindingFilter(\n        new ResourcePatternFilter(ResourceType.ANY, \"*\", LITERAL),\n        new AccessControlEntryFilter(\"User:*\", \"*\", AclOperation.ANY, AclPermissionType.ANY)));\n    assertEquals(\"Unknown patternFilter.\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateFilter(new AclBindingFilter(\n                new ResourcePatternFilter(ResourceType.ANY, \"*\", PatternType.UNKNOWN),\n                new AccessControlEntryFilter(\"User:*\", \"*\", AclOperation.ANY, AclPermissionType.ANY)))).\n            getMessage());\n    assertEquals(\"Unknown entryFilter.\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateFilter(new AclBindingFilter(\n                new ResourcePatternFilter(ResourceType.ANY, \"*\", MATCH),\n                new AccessControlEntryFilter(\"User:*\", \"*\", AclOperation.ANY, AclPermissionType.UNKNOWN)))).\n            getMessage());\n}",
        "summary_tokens": [
            "verify",
            "that",
            "validate",
            "filter",
            "catches",
            "invalid",
            "filters"
        ]
    },
    {
        "id": 2304,
        "code": "public void testCreateAndClose() throws Throwable {\n    MockControllerMetrics metrics = new MockControllerMetrics();\n    try (\n        LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty());\n        QuorumControllerTestEnv controlEnv =\n            new QuorumControllerTestEnv(logEnv, builder -> builder.setMetrics(metrics))\n    ) {\n    }\n    assertTrue(metrics.isClosed(), \"metrics were not closed\");\n}",
        "summary_tokens": [
            "test",
            "creating",
            "a",
            "new",
            "quorum",
            "controller",
            "and",
            "closing",
            "it"
        ]
    },
    {
        "id": 2305,
        "code": "public void testConfigurationOperations() throws Throwable {\n    try (\n        LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty());\n        QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> {\n            b.setConfigSchema(SCHEMA);\n        })\n    ) {\n        controlEnv.activeController().registerBroker(ANONYMOUS_CONTEXT,\n            new BrokerRegistrationRequestData().\n            setFeatures(brokerFeatures(MetadataVersion.IBP_3_0_IV1, MetadataVersion.IBP_3_3_IV3)).\n            setBrokerId(0).\n            setClusterId(logEnv.clusterId())).get();\n        testConfigurationOperations(controlEnv.activeController());\n    }\n}",
        "summary_tokens": [
            "test",
            "setting",
            "some",
            "configuration",
            "values",
            "and",
            "reading",
            "them",
            "back"
        ]
    },
    {
        "id": 2306,
        "code": "public void testDelayedConfigurationOperations() throws Throwable {\n    try (\n        LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty());\n        QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> {\n            b.setConfigSchema(SCHEMA);\n        })\n    ) {\n        controlEnv.activeController().registerBroker(ANONYMOUS_CONTEXT,\n            new BrokerRegistrationRequestData().\n                setFeatures(brokerFeatures(MetadataVersion.IBP_3_0_IV1, MetadataVersion.IBP_3_3_IV3)).\n                setBrokerId(0).\n                setClusterId(logEnv.clusterId())).get();\n        testDelayedConfigurationOperations(logEnv, controlEnv.activeController());\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "an",
            "incremental",
            "alter",
            "configs",
            "operation",
            "doesn",
            "t",
            "complete",
            "until",
            "the",
            "records",
            "can",
            "be",
            "written",
            "to",
            "the",
            "metadata",
            "log"
        ]
    },
    {
        "id": 2307,
        "code": "private void checkSnapshotSubcontent(\n    List<ApiMessageAndVersion> expected,\n    Iterator<Batch<ApiMessageAndVersion>> iterator\n) throws Exception {\n    RecordTestUtils.deepSortRecords(expected);\n\n    List<ApiMessageAndVersion> actual = StreamSupport\n        .stream(Spliterators.spliteratorUnknownSize(iterator, Spliterator.ORDERED), false)\n        .flatMap(batch ->  batch.records().stream())\n        .collect(Collectors.toList());\n\n    RecordTestUtils.deepSortRecords(actual);\n\n    int expectedIndex = 0;\n    for (ApiMessageAndVersion current : actual) {\n        while (expectedIndex < expected.size() && !expected.get(expectedIndex).equals(current)) {\n            expectedIndex += 1;\n        }\n\n        if (expectedIndex >= expected.size()) {\n            fail(\"Failed to find record \" + current + \" in the expected record set: \" + expected);\n        }\n\n        expectedIndex += 1;\n    }\n}",
        "summary_tokens": [
            "this",
            "function",
            "checks",
            "that",
            "the",
            "iterator",
            "is",
            "a",
            "subset",
            "of",
            "the",
            "expected",
            "list"
        ]
    },
    {
        "id": 2308,
        "code": "public void testTimeouts() throws Throwable {\n    try (LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty())) {\n        try (QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> {\n            b.setConfigSchema(SCHEMA);\n        })) {\n            QuorumController controller = controlEnv.activeController();\n            CountDownLatch countDownLatch = controller.pause();\n            long now = controller.time().nanoseconds();\n            ControllerRequestContext context0 = new ControllerRequestContext(\n                new RequestHeaderData(), KafkaPrincipal.ANONYMOUS, OptionalLong.of(now));\n            CompletableFuture<CreateTopicsResponseData> createFuture =\n                controller.createTopics(context0, new CreateTopicsRequestData().setTimeoutMs(0).\n                    setTopics(new CreatableTopicCollection(Collections.singleton(\n                        new CreatableTopic().setName(\"foo\")).iterator())),\n                    Collections.emptySet());\n            CompletableFuture<Map<Uuid, ApiError>> deleteFuture =\n                controller.deleteTopics(context0, Collections.singletonList(Uuid.ZERO_UUID));\n            CompletableFuture<Map<String, ResultOrError<Uuid>>> findTopicIdsFuture =\n                controller.findTopicIds(context0, Collections.singletonList(\"foo\"));\n            CompletableFuture<Map<Uuid, ResultOrError<String>>> findTopicNamesFuture =\n                controller.findTopicNames(context0, Collections.singletonList(Uuid.ZERO_UUID));\n            CompletableFuture<List<CreatePartitionsTopicResult>> createPartitionsFuture =\n                controller.createPartitions(context0, Collections.singletonList(\n                    new CreatePartitionsTopic()), false);\n            CompletableFuture<ElectLeadersResponseData> electLeadersFuture =\n                controller.electLeaders(context0, new ElectLeadersRequestData().setTimeoutMs(0).\n                    setTopicPartitions(null));\n            CompletableFuture<AlterPartitionReassignmentsResponseData> alterReassignmentsFuture =\n                controller.alterPartitionReassignments(context0,\n                    new AlterPartitionReassignmentsRequestData().setTimeoutMs(0).\n                        setTopics(Collections.singletonList(new ReassignableTopic())));\n            CompletableFuture<ListPartitionReassignmentsResponseData> listReassignmentsFuture =\n                controller.listPartitionReassignments(context0,\n                    new ListPartitionReassignmentsRequestData().setTopics(null).setTimeoutMs(0));\n            while (controller.time().nanoseconds() == now) {\n                Thread.sleep(0, 10);\n            }\n            countDownLatch.countDown();\n            assertYieldsTimeout(createFuture);\n            assertYieldsTimeout(deleteFuture);\n            assertYieldsTimeout(findTopicIdsFuture);\n            assertYieldsTimeout(findTopicNamesFuture);\n            assertYieldsTimeout(createPartitionsFuture);\n            assertYieldsTimeout(electLeadersFuture);\n            assertYieldsTimeout(alterReassignmentsFuture);\n            assertYieldsTimeout(listReassignmentsFuture);\n        }\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "certain",
            "controller",
            "operations",
            "time",
            "out",
            "if",
            "they",
            "stay",
            "on",
            "the",
            "controller",
            "queue",
            "for",
            "too",
            "long"
        ]
    },
    {
        "id": 2309,
        "code": "public void testEarlyControllerResults() throws Throwable {\n    try (LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty())) {\n        try (QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> {\n            b.setConfigSchema(SCHEMA);\n        })) {\n            QuorumController controller = controlEnv.activeController();\n            CountDownLatch countDownLatch = controller.pause();\n            CompletableFuture<CreateTopicsResponseData> createFuture =\n                controller.createTopics(ANONYMOUS_CONTEXT, new CreateTopicsRequestData().\n                    setTimeoutMs(120000), Collections.emptySet());\n            CompletableFuture<Map<Uuid, ApiError>> deleteFuture =\n                controller.deleteTopics(ANONYMOUS_CONTEXT, Collections.emptyList());\n            CompletableFuture<Map<String, ResultOrError<Uuid>>> findTopicIdsFuture =\n                controller.findTopicIds(ANONYMOUS_CONTEXT, Collections.emptyList());\n            CompletableFuture<Map<Uuid, ResultOrError<String>>> findTopicNamesFuture =\n                controller.findTopicNames(ANONYMOUS_CONTEXT, Collections.emptyList());\n            CompletableFuture<List<CreatePartitionsTopicResult>> createPartitionsFuture =\n                controller.createPartitions(ANONYMOUS_CONTEXT, Collections.emptyList(), false);\n            CompletableFuture<ElectLeadersResponseData> electLeadersFuture =\n                controller.electLeaders(ANONYMOUS_CONTEXT, new ElectLeadersRequestData());\n            CompletableFuture<AlterPartitionReassignmentsResponseData> alterReassignmentsFuture =\n                controller.alterPartitionReassignments(ANONYMOUS_CONTEXT,\n                    new AlterPartitionReassignmentsRequestData());\n            createFuture.get();\n            deleteFuture.get();\n            findTopicIdsFuture.get();\n            findTopicNamesFuture.get();\n            createPartitionsFuture.get();\n            electLeadersFuture.get();\n            alterReassignmentsFuture.get();\n            countDownLatch.countDown();\n        }\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "certain",
            "controller",
            "operations",
            "finish",
            "immediately",
            "without",
            "putting",
            "an",
            "event",
            "on",
            "the",
            "controller",
            "queue",
            "if",
            "there",
            "is",
            "nothing",
            "to",
            "do"
        ]
    },
    {
        "id": 2310,
        "code": "public void testParsingMalformedFrameVersionVarint() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(64);\n    buffer.clear();\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.position(0);\n    buffer.limit(64);\n    assertStartsWith(\"Error while reading frame version\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "parse",
            "an",
            "event",
            "which",
            "has",
            "a",
            "malformed",
            "frame",
            "version",
            "type",
            "varint"
        ]
    },
    {
        "id": 2311,
        "code": "public void testParsingMalformedMessageTypeVarint() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(64);\n    buffer.clear();\n    buffer.put((byte) 0x01);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.position(0);\n    buffer.limit(64);\n    assertStartsWith(\"Error while reading type\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "parse",
            "an",
            "event",
            "which",
            "has",
            "a",
            "malformed",
            "message",
            "type",
            "varint"
        ]
    },
    {
        "id": 2312,
        "code": "public void testParsingMalformedMessageVersionVarint() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(64);\n    buffer.clear();\n    buffer.put((byte) 0x01);\n    buffer.put((byte) 0x08);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.position(0);\n    buffer.limit(64);\n    assertStartsWith(\"Error while reading version\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "parse",
            "an",
            "event",
            "which",
            "has",
            "a",
            "malformed",
            "message",
            "version",
            "varint"
        ]
    },
    {
        "id": 2313,
        "code": "public void testParsingVersionTooLarge() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(64);\n    buffer.clear();\n    buffer.put((byte) 0x01); \n    buffer.put((byte) 0x08); \n    buffer.put((byte) 0xff); \n    buffer.put((byte) 0xff); \n    buffer.put((byte) 0xff); \n    buffer.put((byte) 0x7f); \n    buffer.put((byte) 0x80);\n    buffer.position(0);\n    buffer.limit(64);\n    assertStartsWith(\"Value for version was too large\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "parse",
            "an",
            "event",
            "which",
            "has",
            "a",
            "version",
            "short"
        ]
    },
    {
        "id": 2314,
        "code": "public void testParsingUnsupportedApiKey() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(64);\n    buffer.put((byte) 0x01); \n    buffer.put((byte) 0xff); \n    buffer.put((byte) 0x7f); \n    buffer.put((byte) 0x00); \n    buffer.put((byte) 0x80);\n    buffer.position(0);\n    buffer.limit(64);\n    assertStartsWith(\"Unknown metadata id \",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getCause().getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "parse",
            "an",
            "event",
            "which",
            "has",
            "a",
            "unsupported",
            "version"
        ]
    },
    {
        "id": 2315,
        "code": "public void testParsingMalformedMessage() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(4);\n    buffer.put((byte) 0x01); \n    buffer.put((byte) 0x00); \n    buffer.put((byte) 0x00); \n    buffer.put((byte) 0x80); \n    buffer.position(0);\n    buffer.limit(4);\n    assertStartsWith(\"Failed to deserialize record with type\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "parse",
            "an",
            "event",
            "which",
            "has",
            "a",
            "malformed",
            "message",
            "body"
        ]
    },
    {
        "id": 2316,
        "code": "public void testParsingRecordWithGarbageAtEnd() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    RegisterBrokerRecord message = new RegisterBrokerRecord().setBrokerId(1).setBrokerEpoch(2);\n\n    ObjectSerializationCache cache = new ObjectSerializationCache();\n    ApiMessageAndVersion messageAndVersion = new ApiMessageAndVersion(message, (short) 0);\n    int size = serde.recordSize(messageAndVersion, cache);\n    ByteBuffer buffer = ByteBuffer.allocate(size + 1);\n\n    serde.write(messageAndVersion, cache, new ByteBufferAccessor(buffer));\n    buffer.clear();\n    assertStartsWith(\"Found 1 byte(s) of garbage after\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), size + 1)).getMessage());\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "parse",
            "an",
            "event",
            "which",
            "has",
            "a",
            "malformed",
            "message",
            "version",
            "varint"
        ]
    },
    {
        "id": 2317,
        "code": "public static void replayAll(\n    MetadataDelta delta,\n    long highestOffset,\n    int highestEpoch,\n    List<ApiMessageAndVersion> recordsAndVersions\n) {\n    for (ApiMessageAndVersion recordAndVersion : recordsAndVersions) {\n        ApiMessage record = recordAndVersion.message();\n        delta.replay(highestOffset, highestEpoch, record);\n    }\n}",
        "summary_tokens": [
            "replay",
            "a",
            "list",
            "of",
            "records",
            "to",
            "the",
            "metadata",
            "delta"
        ]
    },
    {
        "id": 2318,
        "code": "public static void replayAllBatches(\n    MetadataDelta delta,\n    long highestOffset,\n    int highestEpoch,\n    List<List<ApiMessageAndVersion>> batches\n) {\n    for (List<ApiMessageAndVersion> batch : batches) {\n        replayAll(delta, highestOffset, highestEpoch, batch);\n    }\n}",
        "summary_tokens": [
            "replay",
            "a",
            "list",
            "of",
            "record",
            "batches",
            "to",
            "the",
            "metadata",
            "delta"
        ]
    },
    {
        "id": 2319,
        "code": "public static <T> Set<T> iteratorToSet(Iterator<T> iterator) {\n    HashSet<T> set = new HashSet<>();\n    while (iterator.hasNext()) {\n        set.add(iterator.next());\n    }\n    return set;\n}",
        "summary_tokens": [
            "materialize",
            "the",
            "output",
            "of",
            "an",
            "iterator",
            "into",
            "a",
            "set"
        ]
    },
    {
        "id": 2320,
        "code": "public static void assertBatchIteratorContains(List<List<ApiMessageAndVersion>> batches,\n                                               Iterator<List<ApiMessageAndVersion>> iterator) throws Exception {\n    List<List<ApiMessageAndVersion>> actual = new ArrayList<>();\n    while (iterator.hasNext()) {\n        actual.add(new ArrayList<>(iterator.next()));\n    }\n    deepSortRecords(actual);\n    List<List<ApiMessageAndVersion>> expected = new ArrayList<>();\n    for (List<ApiMessageAndVersion> batch : batches) {\n        expected.add(new ArrayList<>(batch));\n    }\n    deepSortRecords(expected);\n    assertEquals(expected, actual);\n}",
        "summary_tokens": [
            "assert",
            "that",
            "a",
            "batch",
            "iterator",
            "yields",
            "a",
            "given",
            "set",
            "of",
            "record",
            "batches"
        ]
    },
    {
        "id": 2321,
        "code": "public static void deepSortRecords(Object o) throws Exception {\n    if (o == null) {\n        return;\n    } else if (o instanceof List) {\n        List<?> list = (List<?>) o;\n        for (Object entry : list) {\n            if (entry != null) {\n                if (Number.class.isAssignableFrom(entry.getClass())) {\n                    return;\n                }\n                deepSortRecords(entry);\n            }\n        }\n        list.sort(Comparator.comparing(Object::toString));\n    } else if (o instanceof ImplicitLinkedHashCollection) {\n        ImplicitLinkedHashCollection<?> coll = (ImplicitLinkedHashCollection<?>) o;\n        for (Object entry : coll) {\n            deepSortRecords(entry);\n        }\n        coll.sort(Comparator.comparing(Object::toString));\n    } else if (o instanceof Message || o instanceof ApiMessageAndVersion) {\n        for (Field field : o.getClass().getDeclaredFields()) {\n            field.setAccessible(true);\n            deepSortRecords(field.get(o));\n        }\n    }\n}",
        "summary_tokens": [
            "sort",
            "the",
            "contents",
            "of",
            "an",
            "object",
            "which",
            "contains",
            "records"
        ]
    },
    {
        "id": 2322,
        "code": "public static BatchReader<ApiMessageAndVersion> mockBatchReader(\n    long lastOffset,\n    long appendTimestamp,\n    List<ApiMessageAndVersion> records\n) {\n    List<Batch<ApiMessageAndVersion>> batches = new ArrayList<>();\n    long offset = lastOffset - records.size() + 1;\n    Iterator<ApiMessageAndVersion> iterator = records.iterator();\n    List<ApiMessageAndVersion> curRecords = new ArrayList<>();\n    assertTrue(iterator.hasNext()); \n    while (true) {\n        if (!iterator.hasNext() || curRecords.size() >= 2) {\n            batches.add(Batch.data(offset, 0, appendTimestamp, sizeInBytes(curRecords), curRecords));\n            if (!iterator.hasNext()) {\n                break;\n            }\n            offset += curRecords.size();\n            curRecords = new ArrayList<>();\n        }\n        curRecords.add(iterator.next());\n    }\n    return MemoryBatchReader.of(batches, __ -> { });\n}",
        "summary_tokens": [
            "create",
            "a",
            "batch",
            "reader",
            "for",
            "testing"
        ]
    },
    {
        "id": 2323,
        "code": "public void testStartWithEarlyStartListeners() throws Exception {\n    StandardAuthorizer authorizer = new StandardAuthorizer();\n    authorizer.configure(Collections.singletonMap(SUPER_USERS_CONFIG, \"User:superman\"));\n    Map<Endpoint, ? extends CompletionStage<Void>> futures2 = authorizer.\n        start(new AuthorizerTestServerInfo(Arrays.asList(PLAINTEXT, CONTROLLER)));\n    assertEquals(new HashSet<>(Arrays.asList(PLAINTEXT, CONTROLLER)), futures2.keySet());\n    assertFalse(futures2.get(PLAINTEXT).toCompletableFuture().isDone());\n    assertTrue(futures2.get(CONTROLLER).toCompletableFuture().isDone());\n}",
        "summary_tokens": [
            "test",
            "that",
            "standard",
            "authorizer",
            "start",
            "returns",
            "a",
            "completed",
            "future",
            "for",
            "early",
            "start",
            "listeners"
        ]
    },
    {
        "id": 2324,
        "code": "public void testAuthorizationPriorToCompleteInitialLoad() throws Exception {\n    StandardAuthorizer authorizer = new StandardAuthorizer();\n    authorizer.configure(Collections.singletonMap(SUPER_USERS_CONFIG, \"User:superman\"));\n    assertThrows(AuthorizerNotReadyException.class, () ->\n        authorizer.authorize(new MockAuthorizableRequestContext.Builder().\n                setPrincipal(new KafkaPrincipal(USER_TYPE, \"bob\")).build(),\n            Arrays.asList(newAction(READ, TOPIC, \"green1\"),\n                newAction(READ, TOPIC, \"green2\"))));\n    assertEquals(Arrays.asList(ALLOWED, ALLOWED),\n        authorizer.authorize(new MockAuthorizableRequestContext.Builder().\n                setPrincipal(new KafkaPrincipal(USER_TYPE, \"superman\")).build(),\n            Arrays.asList(newAction(READ, TOPIC, \"green1\"),\n                newAction(WRITE, GROUP, \"wheel\"))));\n}",
        "summary_tokens": [
            "test",
            "attempts",
            "to",
            "authorize",
            "prior",
            "to",
            "complete",
            "initial",
            "load"
        ]
    },
    {
        "id": 2325,
        "code": "public void testBrokerList() {\n    assertEquals(0, BrokerList.EMPTY.size());\n    assertEquals(-1, BrokerList.EMPTY.next(1));\n    BrokerList brokers = new BrokerList().add(0).add(1).add(2).add(3);\n    assertEquals(4, brokers.size());\n    assertEquals(0, brokers.next(0));\n    assertEquals(1, brokers.next(0));\n    assertEquals(2, brokers.next(0));\n    assertEquals(3, brokers.next(0));\n    assertEquals(-1, brokers.next(0));\n    assertEquals(-1, brokers.next(0));\n    assertEquals(1, brokers.next(1));\n    assertEquals(2, brokers.next(1));\n    assertEquals(3, brokers.next(1));\n    assertEquals(0, brokers.next(1));\n    assertEquals(-1, brokers.next(1));\n}",
        "summary_tokens": [
            "test",
            "that",
            "the",
            "broker",
            "list",
            "class",
            "works",
            "as",
            "expected"
        ]
    },
    {
        "id": 2326,
        "code": "public void testAvoidFencedReplicaIfPossibleOnSingleRack() {\n    MockRandom random = new MockRandom();\n    RackList rackList = new RackList(random, Arrays.asList(\n        new UsableBroker(3, Optional.empty(), false),\n        new UsableBroker(1, Optional.empty(), true),\n        new UsableBroker(0, Optional.empty(), false),\n        new UsableBroker(4, Optional.empty(), false),\n        new UsableBroker(2, Optional.empty(), false)).iterator());\n    assertEquals(5, rackList.numTotalBrokers());\n    assertEquals(4, rackList.numUnfencedBrokers());\n    assertEquals(Collections.singletonList(Optional.empty()), rackList.rackNames());\n    assertThrows(InvalidReplicationFactorException.class, () -> rackList.place(0));\n    assertThrows(InvalidReplicationFactorException.class, () -> rackList.place(-1));\n    assertEquals(Arrays.asList(3, 4, 0, 2), rackList.place(4));\n    assertEquals(Arrays.asList(4, 0, 2, 3), rackList.place(4));\n    assertEquals(Arrays.asList(0, 2, 3, 4), rackList.place(4));\n    assertEquals(Arrays.asList(2, 3, 4, 0), rackList.place(4));\n    assertEquals(Arrays.asList(0, 4, 3, 2), rackList.place(4));\n}",
        "summary_tokens": [
            "test",
            "that",
            "we",
            "perform",
            "striped",
            "replica",
            "placement",
            "as",
            "expected",
            "and",
            "don",
            "t",
            "use",
            "the",
            "fenced",
            "replica",
            "if",
            "we",
            "don",
            "t",
            "have",
            "to"
        ]
    },
    {
        "id": 2327,
        "code": "public void testMultiPartitionTopicPlacementOnSingleUnfencedBroker() {\n    MockRandom random = new MockRandom();\n    StripedReplicaPlacer placer = new StripedReplicaPlacer(random);\n    assertEquals(Arrays.asList(Arrays.asList(0),\n            Arrays.asList(0),\n            Arrays.asList(0)),\n            place(placer, 0, 3, (short) 1, Arrays.asList(\n                    new UsableBroker(0, Optional.empty(), false),\n                    new UsableBroker(1, Optional.empty(), true))));\n}",
        "summary_tokens": [
            "test",
            "that",
            "we",
            "perform",
            "striped",
            "replica",
            "placement",
            "as",
            "expected",
            "for",
            "a",
            "multi",
            "partition",
            "topic",
            "on",
            "a",
            "single",
            "unfenced",
            "broker"
        ]
    },
    {
        "id": 2328,
        "code": "public void testPlacementOnFencedReplicaOnSingleRack() {\n    MockRandom random = new MockRandom();\n    RackList rackList = new RackList(random, Arrays.asList(\n        new UsableBroker(3, Optional.empty(), false),\n        new UsableBroker(1, Optional.empty(), true),\n        new UsableBroker(2, Optional.empty(), false)).iterator());\n    assertEquals(3, rackList.numTotalBrokers());\n    assertEquals(2, rackList.numUnfencedBrokers());\n    assertEquals(Collections.singletonList(Optional.empty()), rackList.rackNames());\n    assertEquals(Arrays.asList(3, 2, 1), rackList.place(3));\n    assertEquals(Arrays.asList(2, 3, 1), rackList.place(3));\n    assertEquals(Arrays.asList(3, 2, 1), rackList.place(3));\n    assertEquals(Arrays.asList(2, 3, 1), rackList.place(3));\n}",
        "summary_tokens": [
            "test",
            "that",
            "we",
            "will",
            "place",
            "on",
            "the",
            "fenced",
            "replica",
            "if",
            "we",
            "need",
            "to"
        ]
    },
    {
        "id": 2329,
        "code": "public CompletableFuture<Void> shutdown(int timeoutMs) {\n    CompletableFuture<Void> shutdownFuture = new CompletableFuture<>();\n    try {\n        close();\n        shutdownFuture.complete(null);\n    } catch (Throwable t) {\n        shutdownFuture.completeExceptionally(t);\n    }\n    return shutdownFuture;\n}",
        "summary_tokens": [
            "shutdown",
            "the",
            "log",
            "manager"
        ]
    },
    {
        "id": 2330,
        "code": "public void testCreateAndClose() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(1, Optional.empty())) {\n        env.close();\n        assertEquals(null, env.firstError.get());\n    }\n}",
        "summary_tokens": [
            "test",
            "creating",
            "a",
            "local",
            "log",
            "manager",
            "and",
            "closing",
            "it"
        ]
    },
    {
        "id": 2331,
        "code": "public void testClaimsLeadership() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(1, Optional.empty())) {\n        assertEquals(new LeaderAndEpoch(OptionalInt.of(0), 1), env.waitForLeader());\n        env.close();\n        assertEquals(null, env.firstError.get());\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "the",
            "local",
            "log",
            "manager",
            "will",
            "claim",
            "leadership"
        ]
    },
    {
        "id": 2332,
        "code": "public void testPassLeadership() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(3, Optional.empty())) {\n        LeaderAndEpoch first = env.waitForLeader();\n        LeaderAndEpoch cur = first;\n        do {\n            int currentLeaderId = cur.leaderId().orElseThrow(() ->\n                new AssertionError(\"Current leader is undefined\")\n            );\n            env.logManagers().get(currentLeaderId).resign(cur.epoch());\n\n            LeaderAndEpoch next = env.waitForLeader();\n            while (next.epoch() == cur.epoch()) {\n                Thread.sleep(1);\n                next = env.waitForLeader();\n            }\n            long expectedNextEpoch = cur.epoch() + 2;\n            assertEquals(expectedNextEpoch, next.epoch(), \"Expected next epoch to be \" + expectedNextEpoch +\n                \", but found  \" + next);\n            cur = next;\n        } while (cur.leaderId().equals(first.leaderId()));\n        env.close();\n        assertEquals(null, env.firstError.get());\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "we",
            "can",
            "pass",
            "leadership",
            "back",
            "and",
            "forth",
            "between",
            "log",
            "managers"
        ]
    },
    {
        "id": 2333,
        "code": "public void testCommits() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(3, Optional.empty())) {\n        LeaderAndEpoch leaderInfo = env.waitForLeader();\n        int leaderId = leaderInfo.leaderId().orElseThrow(() ->\n            new AssertionError(\"Current leader is undefined\")\n        );\n\n        LocalLogManager activeLogManager = env.logManagers().get(leaderId);\n        int epoch = activeLogManager.leaderAndEpoch().epoch();\n        List<ApiMessageAndVersion> messages = Arrays.asList(\n            new ApiMessageAndVersion(new RegisterBrokerRecord().setBrokerId(0), (short) 0),\n            new ApiMessageAndVersion(new RegisterBrokerRecord().setBrokerId(1), (short) 0),\n            new ApiMessageAndVersion(new RegisterBrokerRecord().setBrokerId(2), (short) 0));\n        assertEquals(3, activeLogManager.scheduleAppend(epoch, messages));\n        for (LocalLogManager logManager : env.logManagers()) {\n            waitForLastCommittedOffset(3, logManager);\n        }\n        List<MockMetaLogManagerListener> listeners = env.logManagers().stream().\n            map(m -> (MockMetaLogManagerListener) m.listeners().get(0)).\n            collect(Collectors.toList());\n        env.close();\n        for (MockMetaLogManagerListener listener : listeners) {\n            List<String> events = listener.serializedEvents();\n            assertEquals(SHUTDOWN, events.get(events.size() - 1));\n            int foundIndex = 0;\n            for (String event : events) {\n                if (event.startsWith(COMMIT)) {\n                    assertEquals(messages.get(foundIndex).message().toString(),\n                        event.substring(COMMIT.length() + 1));\n                    foundIndex++;\n                }\n            }\n            assertEquals(messages.size(), foundIndex);\n        }\n    }\n}",
        "summary_tokens": [
            "test",
            "that",
            "all",
            "the",
            "log",
            "managers",
            "see",
            "all",
            "the",
            "commits"
        ]
    },
    {
        "id": 2334,
        "code": "public void appendInitialRecords(List<ApiMessageAndVersion> records) {\n    int initialLeaderEpoch = 1;\n    shared.append(new LeaderChangeBatch(\n        new LeaderAndEpoch(OptionalInt.empty(), initialLeaderEpoch + 1)));\n    shared.append(new LocalRecordBatch(initialLeaderEpoch + 1, 0, records));\n    shared.append(new LeaderChangeBatch(\n        new LeaderAndEpoch(OptionalInt.of(0), initialLeaderEpoch + 2)));\n}",
        "summary_tokens": [
            "append",
            "some",
            "records",
            "to",
            "the",
            "log"
        ]
    },
    {
        "id": 2335,
        "code": "private static void assertIteratorYields(Iterator<? extends Object> iter,\n                                         Object... expected) {\n    IdentityHashMap<Object, Boolean> remaining = new IdentityHashMap<>();\n    for (Object object : expected) {\n        remaining.put(object, true);\n    }\n    List<Object> extraObjects = new ArrayList<>();\n    int i = 0;\n    while (iter.hasNext()) {\n        Object object = iter.next();\n        assertNotNull(object);\n        if (remaining.remove(object) == null) {\n            extraObjects.add(object);\n        }\n    }\n    if (!extraObjects.isEmpty() || !remaining.isEmpty()) {\n        throw new RuntimeException(\"Found extra object(s): [\" + String.join(\", \",\n            extraObjects.stream().map(e -> e.toString()).collect(Collectors.toList())) +\n            \"] and didn't find object(s): [\" + String.join(\", \",\n            remaining.keySet().stream().map(e -> e.toString()).collect(Collectors.toList())) + \"]\");\n    }\n}",
        "summary_tokens": [
            "assert",
            "that",
            "the",
            "given",
            "iterator",
            "contains",
            "the",
            "given",
            "elements",
            "in",
            "any",
            "order"
        ]
    },
    {
        "id": 2336,
        "code": "public long lastOffset() {\n    return lastOffset;\n}",
        "summary_tokens": [
            "the",
            "offset",
            "of",
            "the",
            "last",
            "record",
            "in",
            "the",
            "batch"
        ]
    },
    {
        "id": 2337,
        "code": "public long baseOffset() {\n    return baseOffset;\n}",
        "summary_tokens": [
            "the",
            "offset",
            "of",
            "the",
            "first",
            "record",
            "in",
            "the",
            "batch"
        ]
    },
    {
        "id": 2338,
        "code": "public long appendTimestamp() {\n    return appendTimestamp;\n}",
        "summary_tokens": [
            "the",
            "append",
            "timestamp",
            "in",
            "milliseconds",
            "of",
            "the",
            "batch"
        ]
    },
    {
        "id": 2339,
        "code": "public List<T> records() {\n    return records;\n}",
        "summary_tokens": [
            "the",
            "list",
            "of",
            "records",
            "in",
            "the",
            "batch"
        ]
    },
    {
        "id": 2340,
        "code": "public int epoch() {\n    return epoch;\n}",
        "summary_tokens": [
            "the",
            "epoch",
            "of",
            "the",
            "leader",
            "that",
            "appended",
            "the",
            "record",
            "batch"
        ]
    },
    {
        "id": 2341,
        "code": "public int sizeInBytes() {\n    return sizeInBytes;\n}",
        "summary_tokens": [
            "the",
            "number",
            "of",
            "bytes",
            "used",
            "by",
            "this",
            "batch"
        ]
    },
    {
        "id": 2342,
        "code": "public static <T> Batch<T> control(\n    long baseOffset,\n    int epoch,\n    long appendTimestamp,\n    int sizeInBytes,\n    long lastOffset\n) {\n    return new Batch<>(\n        baseOffset,\n        epoch,\n        appendTimestamp,\n        sizeInBytes,\n        lastOffset,\n        Collections.emptyList()\n    );\n}",
        "summary_tokens": [
            "create",
            "a",
            "control",
            "batch",
            "without",
            "any",
            "data",
            "records"
        ]
    },
    {
        "id": 2343,
        "code": "public static <T> Batch<T> data(\n    long baseOffset,\n    int epoch,\n    long appendTimestamp,\n    int sizeInBytes,\n    List<T> records\n) {\n    if (records.isEmpty()) {\n        throw new IllegalArgumentException(\n            String.format(\n                \"Batch must contain at least one record; baseOffset = %s; epoch = %s\",\n                baseOffset,\n                epoch\n            )\n        );\n    }\n\n    return new Batch<>(\n        baseOffset,\n        epoch,\n        appendTimestamp,\n        sizeInBytes,\n        baseOffset + records.size() - 1,\n        records\n    );\n}",
        "summary_tokens": [
            "create",
            "a",
            "data",
            "batch",
            "with",
            "the",
            "given",
            "base",
            "offset",
            "epoch",
            "and",
            "records"
        ]
    },
    {
        "id": 2344,
        "code": "public boolean isBackingOff() {\n    return isBackingOff;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "candidate",
            "is",
            "backing",
            "off",
            "for",
            "the",
            "next",
            "election"
        ]
    },
    {
        "id": 2345,
        "code": "public boolean isVoteGranted() {\n    return numGranted() >= majoritySize();\n}",
        "summary_tokens": [
            "check",
            "whether",
            "we",
            "have",
            "received",
            "enough",
            "votes",
            "to",
            "conclude",
            "the",
            "election",
            "and",
            "become",
            "leader"
        ]
    },
    {
        "id": 2346,
        "code": "public boolean isVoteRejected() {\n    return numGranted() + numUnrecorded() < majoritySize();\n}",
        "summary_tokens": [
            "check",
            "if",
            "we",
            "have",
            "received",
            "enough",
            "rejections",
            "that",
            "it",
            "is",
            "no",
            "longer",
            "possible",
            "to",
            "reach",
            "a",
            "majority",
            "of",
            "grants"
        ]
    },
    {
        "id": 2347,
        "code": "public boolean recordGrantedVote(int remoteNodeId) {\n    State state = voteStates.get(remoteNodeId);\n    if (state == null) {\n        throw new IllegalArgumentException(\"Attempt to grant vote to non-voter \" + remoteNodeId);\n    } else if (state == State.REJECTED) {\n        throw new IllegalArgumentException(\"Attempt to grant vote from node \" + remoteNodeId +\n            \" which previously rejected our request\");\n    }\n    return voteStates.put(remoteNodeId, State.GRANTED) == State.UNRECORDED;\n}",
        "summary_tokens": [
            "record",
            "a",
            "granted",
            "vote",
            "from",
            "one",
            "of",
            "the",
            "voters"
        ]
    },
    {
        "id": 2348,
        "code": "public boolean recordRejectedVote(int remoteNodeId) {\n    State state = voteStates.get(remoteNodeId);\n    if (state == null) {\n        throw new IllegalArgumentException(\"Attempt to reject vote to non-voter \" + remoteNodeId);\n    } else if (state == State.GRANTED) {\n        throw new IllegalArgumentException(\"Attempt to reject vote from node \" + remoteNodeId +\n            \" which previously granted our request\");\n    }\n\n    return voteStates.put(remoteNodeId, State.REJECTED) == State.UNRECORDED;\n}",
        "summary_tokens": [
            "record",
            "a",
            "rejected",
            "vote",
            "from",
            "one",
            "of",
            "the",
            "voters"
        ]
    },
    {
        "id": 2349,
        "code": "public void startBackingOff(long currentTimeMs, long backoffDurationMs) {\n    this.backoffTimer.update(currentTimeMs);\n    this.backoffTimer.reset(backoffDurationMs);\n    this.isBackingOff = true;\n}",
        "summary_tokens": [
            "record",
            "the",
            "current",
            "election",
            "has",
            "failed",
            "since",
            "we",
            "ve",
            "either",
            "received",
            "sufficient",
            "rejecting",
            "voters",
            "or",
            "election",
            "timed",
            "out"
        ]
    },
    {
        "id": 2350,
        "code": "public Set<Integer> unrecordedVoters() {\n    return votersInState(State.UNRECORDED);\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "voters",
            "which",
            "have",
            "not",
            "been",
            "counted",
            "as",
            "granted",
            "or",
            "rejected",
            "yet"
        ]
    },
    {
        "id": 2351,
        "code": "public Set<Integer> grantingVoters() {\n    return votersInState(State.GRANTED);\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "voters",
            "that",
            "have",
            "granted",
            "our",
            "vote",
            "requests"
        ]
    },
    {
        "id": 2352,
        "code": "public Set<Integer> rejectingVoters() {\n    return votersInState(State.REJECTED);\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "voters",
            "that",
            "have",
            "rejected",
            "our",
            "candidacy"
        ]
    },
    {
        "id": 2353,
        "code": "public ElectionState readElectionState() {\n    if (!stateFile.exists()) {\n        return null;\n    }\n\n    QuorumStateData data = readStateFromFile(stateFile);\n\n    return new ElectionState(data.leaderEpoch(),\n        data.leaderId() == UNKNOWN_LEADER_ID ? OptionalInt.empty() :\n            OptionalInt.of(data.leaderId()),\n        data.votedId() == NOT_VOTED ? OptionalInt.empty() :\n            OptionalInt.of(data.votedId()),\n        data.currentVoters()\n            .stream().map(Voter::voterId).collect(Collectors.toSet()));\n}",
        "summary_tokens": [
            "reads",
            "the",
            "election",
            "state",
            "from",
            "local",
            "file"
        ]
    },
    {
        "id": 2354,
        "code": "public void clear() {\n    deleteFileIfExists(stateFile);\n    deleteFileIfExists(new File(stateFile.getAbsolutePath() + \".tmp\"));\n}",
        "summary_tokens": [
            "clear",
            "state",
            "store",
            "by",
            "deleting",
            "the",
            "local",
            "quorum",
            "state",
            "file"
        ]
    },
    {
        "id": 2355,
        "code": "private VoteResponseData handleVoteRequest(\n    RaftRequest.Inbound requestMetadata\n) {\n    VoteRequestData request = (VoteRequestData) requestMetadata.data;\n\n    if (!hasValidClusterId(request.clusterId())) {\n        return new VoteResponseData().setErrorCode(Errors.INCONSISTENT_CLUSTER_ID.code());\n    }\n\n    if (!hasValidTopicPartition(request, log.topicPartition())) {\n            \n        return new VoteResponseData().setErrorCode(Errors.INVALID_REQUEST.code());\n    }\n\n    VoteRequestData.PartitionData partitionRequest =\n        request.topics().get(0).partitions().get(0);\n\n    int candidateId = partitionRequest.candidateId();\n    int candidateEpoch = partitionRequest.candidateEpoch();\n\n    int lastEpoch = partitionRequest.lastOffsetEpoch();\n    long lastEpochEndOffset = partitionRequest.lastOffset();\n    if (lastEpochEndOffset < 0 || lastEpoch < 0 || lastEpoch >= candidateEpoch) {\n        return buildVoteResponse(Errors.INVALID_REQUEST, false);\n    }\n\n    Optional<Errors> errorOpt = validateVoterOnlyRequest(candidateId, candidateEpoch);\n    if (errorOpt.isPresent()) {\n        return buildVoteResponse(errorOpt.get(), false);\n    }\n\n    if (candidateEpoch > quorum.epoch()) {\n        transitionToUnattached(candidateEpoch);\n    }\n\n    OffsetAndEpoch lastEpochEndOffsetAndEpoch = new OffsetAndEpoch(lastEpochEndOffset, lastEpoch);\n    boolean voteGranted = quorum.canGrantVote(candidateId, lastEpochEndOffsetAndEpoch.compareTo(endOffset()) >= 0);\n\n    if (voteGranted && quorum.isUnattached()) {\n        transitionToVoted(candidateId, candidateEpoch);\n    }\n\n    logger.info(\"Vote request {} with epoch {} is {}\", request, candidateEpoch, voteGranted ? \"granted\" : \"rejected\");\n    return buildVoteResponse(Errors.NONE, voteGranted);\n}",
        "summary_tokens": [
            "handle",
            "a",
            "vote",
            "request"
        ]
    },
    {
        "id": 2356,
        "code": "private BeginQuorumEpochResponseData handleBeginQuorumEpochRequest(\n    RaftRequest.Inbound requestMetadata,\n    long currentTimeMs\n) {\n    BeginQuorumEpochRequestData request = (BeginQuorumEpochRequestData) requestMetadata.data;\n\n    if (!hasValidClusterId(request.clusterId())) {\n        return new BeginQuorumEpochResponseData().setErrorCode(Errors.INCONSISTENT_CLUSTER_ID.code());\n    }\n\n    if (!hasValidTopicPartition(request, log.topicPartition())) {\n            \n        return new BeginQuorumEpochResponseData().setErrorCode(Errors.INVALID_REQUEST.code());\n    }\n\n    BeginQuorumEpochRequestData.PartitionData partitionRequest =\n        request.topics().get(0).partitions().get(0);\n\n    int requestLeaderId = partitionRequest.leaderId();\n    int requestEpoch = partitionRequest.leaderEpoch();\n\n    Optional<Errors> errorOpt = validateVoterOnlyRequest(requestLeaderId, requestEpoch);\n    if (errorOpt.isPresent()) {\n        return buildBeginQuorumEpochResponse(errorOpt.get());\n    }\n\n    maybeTransition(OptionalInt.of(requestLeaderId), requestEpoch, currentTimeMs);\n    return buildBeginQuorumEpochResponse(Errors.NONE);\n}",
        "summary_tokens": [
            "handle",
            "a",
            "begin",
            "epoch",
            "request"
        ]
    },
    {
        "id": 2357,
        "code": "private EndQuorumEpochResponseData handleEndQuorumEpochRequest(\n    RaftRequest.Inbound requestMetadata,\n    long currentTimeMs\n) {\n    EndQuorumEpochRequestData request = (EndQuorumEpochRequestData) requestMetadata.data;\n\n    if (!hasValidClusterId(request.clusterId())) {\n        return new EndQuorumEpochResponseData().setErrorCode(Errors.INCONSISTENT_CLUSTER_ID.code());\n    }\n\n    if (!hasValidTopicPartition(request, log.topicPartition())) {\n            \n        return new EndQuorumEpochResponseData().setErrorCode(Errors.INVALID_REQUEST.code());\n    }\n\n    EndQuorumEpochRequestData.PartitionData partitionRequest =\n        request.topics().get(0).partitions().get(0);\n\n    int requestEpoch = partitionRequest.leaderEpoch();\n    int requestLeaderId = partitionRequest.leaderId();\n\n    Optional<Errors> errorOpt = validateVoterOnlyRequest(requestLeaderId, requestEpoch);\n    if (errorOpt.isPresent()) {\n        return buildEndQuorumEpochResponse(errorOpt.get());\n    }\n    maybeTransition(OptionalInt.of(requestLeaderId), requestEpoch, currentTimeMs);\n\n    if (quorum.isFollower()) {\n        FollowerState state = quorum.followerStateOrThrow();\n        if (state.leaderId() == requestLeaderId) {\n            List<Integer> preferredSuccessors = partitionRequest.preferredSuccessors();\n            long electionBackoffMs = endEpochElectionBackoff(preferredSuccessors);\n            logger.debug(\"Overriding follower fetch timeout to {} after receiving \" +\n                \"EndQuorumEpoch request from leader {} in epoch {}\", electionBackoffMs,\n                requestLeaderId, requestEpoch);\n            state.overrideFetchTimeout(currentTimeMs, electionBackoffMs);\n        }\n    }\n    return buildEndQuorumEpochResponse(Errors.NONE);\n}",
        "summary_tokens": [
            "handle",
            "an",
            "end",
            "epoch",
            "request"
        ]
    },
    {
        "id": 2358,
        "code": "private CompletableFuture<FetchResponseData> handleFetchRequest(\n    RaftRequest.Inbound requestMetadata,\n    long currentTimeMs\n) {\n    FetchRequestData request = (FetchRequestData) requestMetadata.data;\n\n    if (!hasValidClusterId(request.clusterId())) {\n        return completedFuture(new FetchResponseData().setErrorCode(Errors.INCONSISTENT_CLUSTER_ID.code()));\n    }\n\n    if (!hasValidTopicPartition(request, log.topicPartition(), log.topicId())) {\n            \n        return completedFuture(new FetchResponseData().setErrorCode(Errors.INVALID_REQUEST.code()));\n    }\n        \n    request.topics().get(0).setTopic(log.topicPartition().topic());\n\n    FetchRequestData.FetchPartition fetchPartition = request.topics().get(0).partitions().get(0);\n    if (request.maxWaitMs() < 0\n        || fetchPartition.fetchOffset() < 0\n        || fetchPartition.lastFetchedEpoch() < 0\n        || fetchPartition.lastFetchedEpoch() > fetchPartition.currentLeaderEpoch()) {\n        return completedFuture(buildEmptyFetchResponse(\n            Errors.INVALID_REQUEST, Optional.empty()));\n    }\n\n    FetchResponseData response = tryCompleteFetchRequest(request.replicaId(), fetchPartition, currentTimeMs);\n    FetchResponseData.PartitionData partitionResponse =\n        response.responses().get(0).partitions().get(0);\n\n    if (partitionResponse.errorCode() != Errors.NONE.code()\n        || FetchResponse.recordsSize(partitionResponse) > 0\n        || request.maxWaitMs() == 0) {\n        return completedFuture(response);\n    }\n\n    CompletableFuture<Long> future = fetchPurgatory.await(\n        fetchPartition.fetchOffset(),\n        request.maxWaitMs());\n\n    return future.handle((completionTimeMs, exception) -> {\n        if (exception != null) {\n            Throwable cause = exception instanceof ExecutionException ?\n                exception.getCause() : exception;\n\n                \n                \n                \n            Errors error = Errors.forException(cause);\n            if (error != Errors.REQUEST_TIMED_OUT) {\n                logger.debug(\"Failed to handle fetch from {} at {} due to {}\",\n                    request.replicaId(), fetchPartition.fetchOffset(), error);\n                return buildEmptyFetchResponse(error, Optional.empty());\n            }\n        }\n\n            \n        logger.trace(\"Completing delayed fetch from {} starting at offset {} at {}\",\n            request.replicaId(), fetchPartition.fetchOffset(), completionTimeMs);\n\n        return tryCompleteFetchRequest(request.replicaId(), fetchPartition, time.milliseconds());\n    });\n}",
        "summary_tokens": [
            "handle",
            "a",
            "fetch",
            "request"
        ]
    },
    {
        "id": 2359,
        "code": "private FetchSnapshotResponseData handleFetchSnapshotRequest(\n    RaftRequest.Inbound requestMetadata\n) {\n    FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n\n    if (!hasValidClusterId(data.clusterId())) {\n        return new FetchSnapshotResponseData().setErrorCode(Errors.INCONSISTENT_CLUSTER_ID.code());\n    }\n\n    if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n        return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n    }\n\n    Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n        .forTopicPartition(data, log.topicPartition());\n    if (!partitionSnapshotOpt.isPresent()) {\n            \n        TopicPartition unknownTopicPartition = new TopicPartition(\n            data.topics().get(0).name(),\n            data.topics().get(0).partitions().get(0).partition()\n        );\n\n        return FetchSnapshotResponse.singleton(\n            unknownTopicPartition,\n            responsePartitionSnapshot -> responsePartitionSnapshot\n                .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code())\n        );\n    }\n\n    FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n    Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n            partitionSnapshot.currentLeaderEpoch()\n    );\n    if (leaderValidation.isPresent()) {\n        return FetchSnapshotResponse.singleton(\n            log.topicPartition(),\n            responsePartitionSnapshot -> addQuorumLeader(responsePartitionSnapshot)\n                .setErrorCode(leaderValidation.get().code())\n        );\n    }\n\n    OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n        partitionSnapshot.snapshotId().endOffset(),\n        partitionSnapshot.snapshotId().epoch()\n    );\n    Optional<RawSnapshotReader> snapshotOpt = log.readSnapshot(snapshotId);\n    if (!snapshotOpt.isPresent()) {\n        return FetchSnapshotResponse.singleton(\n            log.topicPartition(),\n            responsePartitionSnapshot -> addQuorumLeader(responsePartitionSnapshot)\n                .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code())\n        );\n    }\n\n    RawSnapshotReader snapshot = snapshotOpt.get();\n    long snapshotSize = snapshot.sizeInBytes();\n    if (partitionSnapshot.position() < 0 || partitionSnapshot.position() >= snapshotSize) {\n        return FetchSnapshotResponse.singleton(\n            log.topicPartition(),\n            responsePartitionSnapshot -> addQuorumLeader(responsePartitionSnapshot)\n                .setErrorCode(Errors.POSITION_OUT_OF_RANGE.code())\n        );\n    }\n\n    if (partitionSnapshot.position() > Integer.MAX_VALUE) {\n        throw new IllegalStateException(\n            String.format(\n                \"Trying to fetch a snapshot with size (%d) and a position (%d) larger than %d\",\n                snapshotSize,\n                partitionSnapshot.position(),\n                Integer.MAX_VALUE\n            )\n        );\n    }\n\n    int maxSnapshotSize;\n    try {\n        maxSnapshotSize = Math.toIntExact(snapshotSize);\n    } catch (ArithmeticException e) {\n        maxSnapshotSize = Integer.MAX_VALUE;\n    }\n\n    UnalignedRecords records = snapshot.slice(partitionSnapshot.position(), Math.min(data.maxBytes(), maxSnapshotSize));\n\n    return FetchSnapshotResponse.singleton(\n        log.topicPartition(),\n        responsePartitionSnapshot -> {\n            addQuorumLeader(responsePartitionSnapshot)\n                .snapshotId()\n                .setEndOffset(snapshotId.offset)\n                .setEpoch(snapshotId.epoch);\n\n            return responsePartitionSnapshot\n                .setSize(snapshotSize)\n                .setPosition(partitionSnapshot.position())\n                .setUnalignedRecords(records);\n        }\n    );\n}",
        "summary_tokens": [
            "handle",
            "a",
            "fetch",
            "snapshot",
            "request",
            "similar",
            "to",
            "the",
            "fetch",
            "request",
            "but",
            "we",
            "use",
            "unaligned",
            "records",
            "in",
            "response",
            "because",
            "the",
            "records",
            "are",
            "not",
            "necessarily",
            "offset",
            "aligned"
        ]
    },
    {
        "id": 2360,
        "code": "private Optional<Boolean> maybeHandleCommonResponse(\n    Errors error,\n    OptionalInt leaderId,\n    int epoch,\n    long currentTimeMs\n) {\n    if (epoch < quorum.epoch() || error == Errors.UNKNOWN_LEADER_EPOCH) {\n            \n        return Optional.of(true);\n    } else if (epoch > quorum.epoch()\n        || error == Errors.FENCED_LEADER_EPOCH\n        || error == Errors.NOT_LEADER_OR_FOLLOWER) {\n\n            \n            \n        maybeTransition(leaderId, epoch, currentTimeMs);\n        return Optional.of(true);\n    } else if (epoch == quorum.epoch()\n        && leaderId.isPresent()\n        && !quorum.hasLeader()) {\n\n            \n            \n            \n            \n            \n        transitionToFollower(epoch, leaderId.getAsInt(), currentTimeMs);\n        if (error == Errors.NONE) {\n            return Optional.empty();\n        } else {\n            return Optional.of(true);\n        }\n    } else if (error == Errors.BROKER_NOT_AVAILABLE) {\n        return Optional.of(false);\n    } else if (error == Errors.INCONSISTENT_GROUP_PROTOCOL) {\n            \n            \n            \n            \n        throw new IllegalStateException(\"Received error indicating inconsistent voter sets\");\n    } else if (error == Errors.INVALID_REQUEST) {\n        throw new IllegalStateException(\"Received unexpected invalid request error\");\n    }\n\n    return Optional.empty();\n}",
        "summary_tokens": [
            "handle",
            "response",
            "errors",
            "that",
            "are",
            "common",
            "across",
            "request",
            "types"
        ]
    },
    {
        "id": 2361,
        "code": "private Optional<Errors> validateVoterOnlyRequest(int remoteNodeId, int requestEpoch) {\n    if (requestEpoch < quorum.epoch()) {\n        return Optional.of(Errors.FENCED_LEADER_EPOCH);\n    } else if (remoteNodeId < 0) {\n        return Optional.of(Errors.INVALID_REQUEST);\n    } else if (quorum.isObserver() || !quorum.isVoter(remoteNodeId)) {\n        return Optional.of(Errors.INCONSISTENT_VOTER_SET);\n    } else {\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "validate",
            "a",
            "request",
            "which",
            "is",
            "only",
            "valid",
            "between",
            "voters"
        ]
    },
    {
        "id": 2362,
        "code": "private Optional<Errors> validateLeaderOnlyRequest(int requestEpoch) {\n    if (requestEpoch < quorum.epoch()) {\n        return Optional.of(Errors.FENCED_LEADER_EPOCH);\n    } else if (requestEpoch > quorum.epoch()) {\n        return Optional.of(Errors.UNKNOWN_LEADER_EPOCH);\n    } else if (!quorum.isLeader()) {\n            \n            \n            \n        return Optional.of(Errors.NOT_LEADER_OR_FOLLOWER);\n    } else if (shutdown.get() != null) {\n        return Optional.of(Errors.BROKER_NOT_AVAILABLE);\n    } else {\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "validate",
            "a",
            "request",
            "which",
            "is",
            "intended",
            "for",
            "the",
            "current",
            "quorum",
            "leader"
        ]
    },
    {
        "id": 2363,
        "code": "private long maybeSendRequest(\n    long currentTimeMs,\n    int destinationId,\n    Supplier<ApiMessage> requestSupplier\n)  {\n    ConnectionState connection = requestManager.getOrCreate(destinationId);\n\n    if (connection.isBackingOff(currentTimeMs)) {\n        long remainingBackoffMs = connection.remainingBackoffMs(currentTimeMs);\n        logger.debug(\"Connection for {} is backing off for {} ms\", destinationId, remainingBackoffMs);\n        return remainingBackoffMs;\n    }\n\n    if (connection.isReady(currentTimeMs)) {\n        int correlationId = channel.newCorrelationId();\n        ApiMessage request = requestSupplier.get();\n\n        RaftRequest.Outbound requestMessage = new RaftRequest.Outbound(\n            correlationId,\n            request,\n            destinationId,\n            currentTimeMs\n        );\n\n        requestMessage.completion.whenComplete((response, exception) -> {\n            if (exception != null) {\n                ApiKeys api = ApiKeys.forId(request.apiKey());\n                Errors error = Errors.forException(exception);\n                ApiMessage errorResponse = RaftUtil.errorResponse(api, error);\n\n                response = new RaftResponse.Inbound(\n                    correlationId,\n                    errorResponse,\n                    destinationId\n                );\n            }\n\n            messageQueue.add(response);\n        });\n\n        channel.send(requestMessage);\n        logger.trace(\"Sent outbound request: {}\", requestMessage);\n        connection.onRequestSent(correlationId, currentTimeMs);\n        return Long.MAX_VALUE;\n    }\n\n    return connection.remainingRequestTimeMs(currentTimeMs);\n}",
        "summary_tokens": [
            "attempt",
            "to",
            "send",
            "a",
            "request"
        ]
    },
    {
        "id": 2364,
        "code": "public void handle(RaftRequest.Inbound request) {\n    messageQueue.add(Objects.requireNonNull(request));\n}",
        "summary_tokens": [
            "handle",
            "an",
            "inbound",
            "request"
        ]
    },
    {
        "id": 2365,
        "code": "public void poll() {\n    pollListeners();\n\n    long currentTimeMs = time.milliseconds();\n    if (maybeCompleteShutdown(currentTimeMs)) {\n        return;\n    }\n\n    long pollStateTimeoutMs = pollCurrentState(currentTimeMs);\n    long cleaningTimeoutMs = snapshotCleaner.maybeClean(currentTimeMs);\n    long pollTimeoutMs = Math.min(pollStateTimeoutMs, cleaningTimeoutMs);\n\n    kafkaRaftMetrics.updatePollStart(currentTimeMs);\n\n    RaftMessage message = messageQueue.poll(pollTimeoutMs);\n\n    currentTimeMs = time.milliseconds();\n    kafkaRaftMetrics.updatePollEnd(currentTimeMs);\n\n    if (message != null) {\n        handleInboundMessage(message, currentTimeMs);\n    }\n}",
        "summary_tokens": [
            "poll",
            "for",
            "new",
            "events"
        ]
    },
    {
        "id": 2366,
        "code": "public boolean updateLocalState(\n    LogOffsetMetadata endOffsetMetadata\n) {\n    ReplicaState state = getOrCreateReplicaState(localId);\n    state.endOffset.ifPresent(currentEndOffset -> {\n        if (currentEndOffset.offset > endOffsetMetadata.offset) {\n            throw new IllegalStateException(\"Detected non-monotonic update of local \" +\n                \"end offset: \" + currentEndOffset.offset + \" -> \" + endOffsetMetadata.offset);\n        }\n    });\n    state.updateLeaderState(endOffsetMetadata);\n    return maybeUpdateHighWatermark();\n}",
        "summary_tokens": [
            "update",
            "the",
            "local",
            "replica",
            "state"
        ]
    },
    {
        "id": 2367,
        "code": "public boolean updateReplicaState(\n    int replicaId,\n    long currentTimeMs,\n    LogOffsetMetadata fetchOffsetMetadata\n) {\n        \n        \n    if (replicaId < 0) {\n        return false;\n    } else if (replicaId == localId) {\n        throw new IllegalStateException(\"Remote replica ID \" + replicaId + \" matches the local leader ID\");\n    }\n\n    ReplicaState state = getOrCreateReplicaState(replicaId);\n\n    state.endOffset.ifPresent(currentEndOffset -> {\n        if (currentEndOffset.offset > fetchOffsetMetadata.offset) {\n            log.warn(\"Detected non-monotonic update of fetch offset from nodeId {}: {} -> {}\",\n                state.nodeId, currentEndOffset.offset, fetchOffsetMetadata.offset);\n        }\n    });\n\n    Optional<LogOffsetMetadata> leaderEndOffsetOpt =\n        voterStates.get(localId).endOffset;\n\n    state.updateFollowerState(\n        currentTimeMs,\n        fetchOffsetMetadata,\n        leaderEndOffsetOpt\n    );\n\n    return isVoter(state.nodeId) && maybeUpdateHighWatermark();\n}",
        "summary_tokens": [
            "update",
            "the",
            "replica",
            "state",
            "in",
            "terms",
            "of",
            "fetch",
            "time",
            "and",
            "log",
            "end",
            "offsets"
        ]
    },
    {
        "id": 2368,
        "code": "public void transitionToUnattached(int epoch) {\n    int currentEpoch = state.epoch();\n    if (epoch <= currentEpoch) {\n        throw new IllegalStateException(\"Cannot transition to Unattached with epoch= \" + epoch +\n            \" from current state \" + state);\n    }\n\n    final long electionTimeoutMs;\n    if (isObserver()) {\n        electionTimeoutMs = Long.MAX_VALUE;\n    } else if (isCandidate()) {\n        electionTimeoutMs = candidateStateOrThrow().remainingElectionTimeMs(time.milliseconds());\n    } else if (isVoted()) {\n        electionTimeoutMs = votedStateOrThrow().remainingElectionTimeMs(time.milliseconds());\n    } else if (isUnattached()) {\n        electionTimeoutMs = unattachedStateOrThrow().remainingElectionTimeMs(time.milliseconds());\n    } else {\n        electionTimeoutMs = randomElectionTimeoutMs();\n    }\n\n    transitionTo(new UnattachedState(\n        time,\n        epoch,\n        voters,\n        state.highWatermark(),\n        electionTimeoutMs,\n        logContext\n    ));\n}",
        "summary_tokens": [
            "transition",
            "to",
            "the",
            "unattached",
            "state"
        ]
    },
    {
        "id": 2369,
        "code": "public void transitionToVoted(\n    int epoch,\n    int candidateId\n) {\n    if (localId.isPresent() && candidateId == localId.getAsInt()) {\n        throw new IllegalStateException(\"Cannot transition to Voted with votedId=\" + candidateId +\n            \" and epoch=\" + epoch + \" since it matches the local broker.id\");\n    } else if (isObserver()) {\n        throw new IllegalStateException(\"Cannot transition to Voted with votedId=\" + candidateId +\n            \" and epoch=\" + epoch + \" since the local broker.id=\" + localId + \" is not a voter\");\n    } else if (!isVoter(candidateId)) {\n        throw new IllegalStateException(\"Cannot transition to Voted with voterId=\" + candidateId +\n            \" and epoch=\" + epoch + \" since it is not one of the voters \" + voters);\n    }\n\n    int currentEpoch = state.epoch();\n    if (epoch < currentEpoch) {\n        throw new IllegalStateException(\"Cannot transition to Voted with votedId=\" + candidateId +\n            \" and epoch=\" + epoch + \" since the current epoch \" + currentEpoch + \" is larger\");\n    } else if (epoch == currentEpoch && !isUnattached()) {\n        throw new IllegalStateException(\"Cannot transition to Voted with votedId=\" + candidateId +\n            \" and epoch=\" + epoch + \" from the current state \" + state);\n    }\n\n        \n        \n\n    transitionTo(new VotedState(\n        time,\n        epoch,\n        candidateId,\n        voters,\n        state.highWatermark(),\n        randomElectionTimeoutMs(),\n        logContext\n    ));\n}",
        "summary_tokens": [
            "grant",
            "a",
            "vote",
            "to",
            "a",
            "candidate",
            "and",
            "become",
            "a",
            "follower",
            "for",
            "this",
            "epoch"
        ]
    },
    {
        "id": 2370,
        "code": "public void transitionToFollower(\n    int epoch,\n    int leaderId\n) {\n    if (localId.isPresent() && leaderId == localId.getAsInt()) {\n        throw new IllegalStateException(\"Cannot transition to Follower with leaderId=\" + leaderId +\n            \" and epoch=\" + epoch + \" since it matches the local broker.id=\" + localId);\n    } else if (!isVoter(leaderId)) {\n        throw new IllegalStateException(\"Cannot transition to Follower with leaderId=\" + leaderId +\n            \" and epoch=\" + epoch + \" since it is not one of the voters \" + voters);\n    }\n\n    int currentEpoch = state.epoch();\n    if (epoch < currentEpoch) {\n        throw new IllegalStateException(\"Cannot transition to Follower with leaderId=\" + leaderId +\n            \" and epoch=\" + epoch + \" since the current epoch \" + currentEpoch + \" is larger\");\n    } else if (epoch == currentEpoch\n        && (isFollower() || isLeader())) {\n        throw new IllegalStateException(\"Cannot transition to Follower with leaderId=\" + leaderId +\n            \" and epoch=\" + epoch + \" from state \" + state);\n    }\n\n    transitionTo(new FollowerState(\n        time,\n        epoch,\n        leaderId,\n        voters,\n        state.highWatermark(),\n        fetchTimeoutMs,\n        logContext\n    ));\n}",
        "summary_tokens": [
            "become",
            "a",
            "follower",
            "of",
            "an",
            "elected",
            "leader",
            "so",
            "that",
            "we",
            "can",
            "begin",
            "fetching"
        ]
    },
    {
        "id": 2371,
        "code": "public int handleSnapshotCalls() {\n    return handleSnapshotCalls;\n}",
        "summary_tokens": [
            "use",
            "handle",
            "snapshot",
            "calls",
            "to",
            "verify",
            "leader",
            "is",
            "never",
            "asked",
            "to",
            "load",
            "snapshot"
        ]
    },
    {
        "id": 2372,
        "code": "default ValidOffsetAndEpoch validateOffsetAndEpoch(long offset, int epoch) {\n    if (startOffset() == 0 && offset == 0) {\n        return ValidOffsetAndEpoch.valid(new OffsetAndEpoch(0, 0));\n    }\n\n    Optional<OffsetAndEpoch> earliestSnapshotId = earliestSnapshotId();\n    if (earliestSnapshotId.isPresent() &&\n        ((offset < startOffset()) ||\n         (offset == startOffset() && epoch != earliestSnapshotId.get().epoch) ||\n         (epoch < earliestSnapshotId.get().epoch))\n    ) {\n            \n        OffsetAndEpoch latestSnapshotId = latestSnapshotId().orElseThrow(() -> new IllegalStateException(\n            String.format(\n                \"Log start offset (%s) is greater than zero but latest snapshot was not found\",\n                startOffset()\n            )\n        ));\n\n        return ValidOffsetAndEpoch.snapshot(latestSnapshotId);\n    } else {\n        OffsetAndEpoch endOffsetAndEpoch = endOffsetForEpoch(epoch);\n\n        if (endOffsetAndEpoch.epoch != epoch || endOffsetAndEpoch.offset < offset) {\n            return ValidOffsetAndEpoch.diverging(endOffsetAndEpoch);\n        } else {\n            return ValidOffsetAndEpoch.valid(new OffsetAndEpoch(offset, epoch));\n        }\n    }\n}",
        "summary_tokens": [
            "validate",
            "the",
            "given",
            "offset",
            "and",
            "epoch",
            "against",
            "the",
            "log",
            "and",
            "oldest",
            "snapshot"
        ]
    },
    {
        "id": 2373,
        "code": "default long truncateToEndOffset(OffsetAndEpoch endOffset) {\n    final long truncationOffset;\n    int leaderEpoch = endOffset.epoch;\n    if (leaderEpoch == 0) {\n        truncationOffset = Math.min(endOffset.offset, endOffset().offset);\n    } else {\n        OffsetAndEpoch localEndOffset = endOffsetForEpoch(leaderEpoch);\n        if (localEndOffset.epoch == leaderEpoch) {\n            truncationOffset = Math.min(localEndOffset.offset, endOffset.offset);\n        } else {\n            truncationOffset = localEndOffset.offset;\n        }\n    }\n\n    truncateTo(truncationOffset);\n    return truncationOffset;\n}",
        "summary_tokens": [
            "truncate",
            "to",
            "an",
            "offset",
            "and",
            "epoch"
        ]
    },
    {
        "id": 2374,
        "code": "public Set<Integer> unackedVoters() {\n    return unackedVoters;\n}",
        "summary_tokens": [
            "get",
            "the",
            "set",
            "of",
            "voters",
            "which",
            "have",
            "yet",
            "to",
            "acknowledge",
            "the",
            "resignation"
        ]
    },
    {
        "id": 2375,
        "code": "public void acknowledgeResignation(int voterId) {\n    if (!voters.contains(voterId)) {\n        throw new IllegalArgumentException(\"Attempt to acknowledge delivery of `EndQuorumEpoch` \" +\n            \"by a non-voter \" + voterId);\n    }\n    unackedVoters.remove(voterId);\n}",
        "summary_tokens": [
            "invoked",
            "after",
            "receiving",
            "a",
            "successful",
            "end",
            "quorum",
            "epoch",
            "response"
        ]
    },
    {
        "id": 2376,
        "code": "public boolean hasElectionTimeoutExpired(long currentTimeMs) {\n    electionTimer.update(currentTimeMs);\n    return electionTimer.isExpired();\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "timeout",
            "has",
            "expired"
        ]
    },
    {
        "id": 2377,
        "code": "public long remainingElectionTimeMs(long currentTimeMs) {\n    electionTimer.update(currentTimeMs);\n    return electionTimer.remainingMs();\n}",
        "summary_tokens": [
            "check",
            "the",
            "time",
            "remaining",
            "until",
            "the",
            "timeout",
            "expires"
        ]
    },
    {
        "id": 2378,
        "code": "public long append(int epoch, List<T> records) {\n    return append(epoch, records, false);\n}",
        "summary_tokens": [
            "append",
            "a",
            "list",
            "of",
            "records",
            "into",
            "as",
            "many",
            "batches",
            "as",
            "necessary"
        ]
    },
    {
        "id": 2379,
        "code": "public long appendAtomic(int epoch, List<T> records) {\n    return append(epoch, records, true);\n}",
        "summary_tokens": [
            "append",
            "a",
            "list",
            "of",
            "records",
            "into",
            "an",
            "atomic",
            "batch"
        ]
    },
    {
        "id": 2380,
        "code": "private void appendControlMessage(Function<ByteBuffer, MemoryRecords> valueCreator) {\n    appendLock.lock();\n    try {\n        ByteBuffer buffer = memoryPool.tryAllocate(256);\n        if (buffer != null) {\n            try {\n                forceDrain();\n                completed.add(\n                    new CompletedBatch<>(\n                        nextOffset,\n                        1,\n                        valueCreator.apply(buffer),\n                        memoryPool,\n                        buffer\n                    )\n                );\n                nextOffset += 1;\n            } catch (Exception e) {\n                    \n                memoryPool.release(buffer);\n                throw e;\n            }\n        } else {\n            throw new IllegalStateException(\"Could not allocate buffer for the control record\");\n        }\n    } finally {\n        appendLock.unlock();\n    }\n}",
        "summary_tokens": [
            "append",
            "a",
            "control",
            "batch",
            "from",
            "a",
            "supplied",
            "memory",
            "record"
        ]
    },
    {
        "id": 2381,
        "code": "public void appendLeaderChangeMessage(\n    LeaderChangeMessage leaderChangeMessage,\n    long currentTimestamp\n) {\n    appendControlMessage(buffer -> {\n        return MemoryRecords.withLeaderChangeMessage(\n            this.nextOffset,\n            currentTimestamp,\n            this.epoch,\n            buffer,\n            leaderChangeMessage\n        );\n    });\n}",
        "summary_tokens": [
            "append",
            "a",
            "leader",
            "change",
            "message",
            "record",
            "to",
            "the",
            "batch"
        ]
    },
    {
        "id": 2382,
        "code": "public void appendSnapshotHeaderRecord(\n    SnapshotHeaderRecord snapshotHeaderRecord,\n    long currentTimestamp\n) {\n    appendControlMessage(buffer -> {\n        return MemoryRecords.withSnapshotHeaderRecord(\n            this.nextOffset,\n            currentTimestamp,\n            this.epoch,\n            buffer,\n            snapshotHeaderRecord\n        );\n    });\n}",
        "summary_tokens": [
            "append",
            "a",
            "snapshot",
            "header",
            "record",
            "record",
            "to",
            "the",
            "batch"
        ]
    },
    {
        "id": 2383,
        "code": "public void appendSnapshotFooterRecord(\n    SnapshotFooterRecord snapshotFooterRecord,\n    long currentTimestamp\n) {\n    appendControlMessage(buffer -> {\n        return MemoryRecords.withSnapshotFooterRecord(\n            this.nextOffset,\n            currentTimestamp,\n            this.epoch,\n            buffer,\n            snapshotFooterRecord\n        );\n    });\n}",
        "summary_tokens": [
            "append",
            "a",
            "snapshot",
            "footer",
            "record",
            "record",
            "to",
            "the",
            "batch"
        ]
    },
    {
        "id": 2384,
        "code": "public boolean needsDrain(long currentTimeMs) {\n    return timeUntilDrain(currentTimeMs) <= 0;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "there",
            "are",
            "any",
            "batches",
            "which",
            "need",
            "to",
            "be",
            "drained",
            "now"
        ]
    },
    {
        "id": 2385,
        "code": "public long timeUntilDrain(long currentTimeMs) {\n    if (drainStatus == DrainStatus.FINISHED) {\n        return 0;\n    } else {\n        return lingerTimer.remainingMs(currentTimeMs);\n    }\n}",
        "summary_tokens": [
            "check",
            "the",
            "time",
            "remaining",
            "until",
            "the",
            "next",
            "needed",
            "drain"
        ]
    },
    {
        "id": 2386,
        "code": "public int epoch() {\n    return epoch;\n}",
        "summary_tokens": [
            "get",
            "the",
            "leader",
            "epoch",
            "which",
            "is",
            "constant",
            "for",
            "each",
            "instance"
        ]
    },
    {
        "id": 2387,
        "code": "public int numCompletedBatches() {\n    return completed.size();\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "completed",
            "batches",
            "which",
            "are",
            "ready",
            "to",
            "be",
            "drained"
        ]
    },
    {
        "id": 2388,
        "code": "public long appendRecord(T record, ObjectSerializationCache serializationCache) {\n    if (!isOpenForAppends) {\n        throw new IllegalStateException(\"Cannot append new records after the batch has been built\");\n    }\n\n    if (nextOffset - baseOffset > Integer.MAX_VALUE) {\n        throw new IllegalArgumentException(\"Cannot include more than \" + Integer.MAX_VALUE +\n            \" records in a single batch\");\n    }\n\n    long offset = nextOffset++;\n    int recordSizeInBytes = writeRecord(\n        offset,\n        record,\n        serializationCache\n    );\n    unflushedBytes += recordSizeInBytes;\n    records.add(record);\n    return offset;\n}",
        "summary_tokens": [
            "append",
            "a",
            "record",
            "to",
            "this",
            "batch"
        ]
    },
    {
        "id": 2389,
        "code": "public OptionalInt bytesNeeded(Collection<T> records, ObjectSerializationCache serializationCache) {\n    int bytesNeeded = bytesNeededForRecords(\n        records,\n        serializationCache\n    );\n\n    if (!isOpenForAppends) {\n        return OptionalInt.of(batchHeaderSizeInBytes() + bytesNeeded);\n    }\n\n    int approxUnusedSizeInBytes = maxBytes - approximateSizeInBytes();\n    if (approxUnusedSizeInBytes >= bytesNeeded) {\n        return OptionalInt.empty();\n    } else if (unflushedBytes > 0) {\n        recordOutput.flush();\n        unflushedBytes = 0;\n        int unusedSizeInBytes = maxBytes - flushedSizeInBytes();\n        if (unusedSizeInBytes >= bytesNeeded) {\n            return OptionalInt.empty();\n        }\n    }\n\n    return OptionalInt.of(batchHeaderSizeInBytes() + bytesNeeded);\n}",
        "summary_tokens": [
            "check",
            "whether",
            "the",
            "batch",
            "has",
            "enough",
            "room",
            "for",
            "all",
            "the",
            "record",
            "values"
        ]
    },
    {
        "id": 2390,
        "code": "public int approximateSizeInBytes() {\n    return flushedSizeInBytes() + unflushedBytes;\n}",
        "summary_tokens": [
            "get",
            "an",
            "estimate",
            "of",
            "the",
            "current",
            "size",
            "of",
            "the",
            "appended",
            "data"
        ]
    },
    {
        "id": 2391,
        "code": "public long baseOffset() {\n    return baseOffset;\n}",
        "summary_tokens": [
            "get",
            "the",
            "base",
            "offset",
            "of",
            "this",
            "batch"
        ]
    },
    {
        "id": 2392,
        "code": "public long lastOffset() {\n    return nextOffset - 1;\n}",
        "summary_tokens": [
            "return",
            "the",
            "offset",
            "of",
            "the",
            "last",
            "appended",
            "record"
        ]
    },
    {
        "id": 2393,
        "code": "public int numRecords() {\n    return (int) (nextOffset - baseOffset);\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "records",
            "appended",
            "to",
            "the",
            "batch"
        ]
    },
    {
        "id": 2394,
        "code": "public boolean nonEmpty() {\n    return numRecords() > 0;\n}",
        "summary_tokens": [
            "check",
            "whether",
            "there",
            "has",
            "been",
            "at",
            "least",
            "one",
            "record",
            "appended",
            "to",
            "the",
            "batch"
        ]
    },
    {
        "id": 2395,
        "code": "public ByteBuffer initialBuffer() {\n    return initialBuffer;\n}",
        "summary_tokens": [
            "return",
            "the",
            "reference",
            "to",
            "the",
            "initial",
            "buffer",
            "passed",
            "through",
            "the",
            "constructor"
        ]
    },
    {
        "id": 2396,
        "code": "public List<T> records() {\n    return records;\n}",
        "summary_tokens": [
            "get",
            "a",
            "list",
            "of",
            "the",
            "records",
            "appended",
            "to",
            "the",
            "batch"
        ]
    },
    {
        "id": 2397,
        "code": "public static FileRawSnapshotReader open(Path logDir, OffsetAndEpoch snapshotId) {\n    FileRecords fileRecords;\n    Path filePath = Snapshots.snapshotPath(logDir, snapshotId);\n    try {\n        fileRecords = FileRecords.open(\n            filePath.toFile(),\n            false, \n            true, \n            0, \n            false \n        );\n    } catch (IOException e) {\n        throw new UncheckedIOException(\n            String.format(\"Unable to Opens a snapshot file %s\", filePath.toAbsolutePath()), e\n        );\n    }\n\n    return new FileRawSnapshotReader(fileRecords, snapshotId);\n}",
        "summary_tokens": [
            "opens",
            "a",
            "snapshot",
            "for",
            "reading"
        ]
    },
    {
        "id": 2398,
        "code": "public static FileRawSnapshotWriter create(\n    Path logDir,\n    OffsetAndEpoch snapshotId,\n    Optional<ReplicatedLog> replicatedLog\n) {\n    Path path = Snapshots.createTempFile(logDir, snapshotId);\n\n    try {\n        return new FileRawSnapshotWriter(\n            path,\n            FileChannel.open(path, StandardOpenOption.WRITE, StandardOpenOption.APPEND),\n            snapshotId,\n            replicatedLog\n        );\n    } catch (IOException e) {\n        throw new UncheckedIOException(\n            String.format(\n                \"Error creating snapshot writer. path = %s, snapshotId %s.\",\n                path,\n                snapshotId\n            ),\n            e\n        );\n    }\n}",
        "summary_tokens": [
            "create",
            "a",
            "snapshot",
            "writer",
            "for",
            "topic",
            "partition",
            "log",
            "dir",
            "and",
            "snapshot",
            "id"
        ]
    },
    {
        "id": 2399,
        "code": "private Optional<Batch<T>> nextBatch() {\n    while (iterator.hasNext()) {\n        Batch<T> batch = iterator.next();\n\n        if (!lastContainedLogTimestamp.isPresent()) {\n                \n                \n            lastContainedLogTimestamp = OptionalLong.of(batch.appendTimestamp());\n        }\n\n        if (!batch.records().isEmpty()) {\n            return Optional.of(batch);\n        }\n    }\n\n    return Optional.empty();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "next",
            "non",
            "control",
            "batch"
        ]
    },
    {
        "id": 2400,
        "code": "private void initializeSnapshotWithHeader() {\n    if (snapshot.sizeInBytes() != 0) {\n        String message = String.format(\n            \"Initializing writer with a non-empty snapshot: id = '%s'.\",\n            snapshot.snapshotId()\n        );\n        throw new IllegalStateException(message);\n    }\n\n    SnapshotHeaderRecord headerRecord = new SnapshotHeaderRecord()\n        .setVersion(ControlRecordUtils.SNAPSHOT_HEADER_CURRENT_VERSION)\n        .setLastContainedLogTimestamp(lastContainedLogTimestamp);\n    accumulator.appendSnapshotHeaderRecord(headerRecord, time.milliseconds());\n    accumulator.forceDrain();\n}",
        "summary_tokens": [
            "adds",
            "a",
            "snapshot",
            "header",
            "record",
            "to",
            "snapshot"
        ]
    },
    {
        "id": 2401,
        "code": "private void finalizeSnapshotWithFooter() {\n    SnapshotFooterRecord footerRecord = new SnapshotFooterRecord()\n        .setVersion(ControlRecordUtils.SNAPSHOT_FOOTER_CURRENT_VERSION);\n    accumulator.appendSnapshotFooterRecord(footerRecord, time.milliseconds());\n    accumulator.forceDrain();\n}",
        "summary_tokens": [
            "adds",
            "a",
            "snapshot",
            "footer",
            "record",
            "to",
            "the",
            "snapshot"
        ]
    },
    {
        "id": 2402,
        "code": "public static <T> Optional<SnapshotWriter<T>> createWithHeader(\n    Supplier<Optional<RawSnapshotWriter>> supplier,\n    int maxBatchSize,\n    MemoryPool memoryPool,\n    Time snapshotTime,\n    long lastContainedLogTimestamp,\n    CompressionType compressionType,\n    RecordSerde<T> serde\n) {\n    return supplier.get().map(snapshot -> {\n        RecordsSnapshotWriter<T> writer = new RecordsSnapshotWriter<>(\n                snapshot,\n                maxBatchSize,\n                memoryPool,\n                snapshotTime,\n                lastContainedLogTimestamp,\n                compressionType,\n                serde);\n        writer.initializeSnapshotWithHeader();\n\n        return writer;\n    });\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "this",
            "class",
            "and",
            "initialize",
            "the",
            "underlying",
            "snapshot",
            "with",
            "snapshot",
            "header",
            "record"
        ]
    },
    {
        "id": 2403,
        "code": "public static boolean deleteIfExists(Path logDir, OffsetAndEpoch snapshotId) {\n    Path immutablePath = snapshotPath(logDir, snapshotId);\n    Path deletedPath = deleteRename(immutablePath, snapshotId);\n    try {\n        boolean deleted = Files.deleteIfExists(immutablePath) | Files.deleteIfExists(deletedPath);\n        if (deleted) {\n            log.info(\"Deleted snapshot files for snapshot {}.\", snapshotId);\n        } else {\n            log.info(\"Did not delete snapshot files for snapshot {} since they did not exist.\", snapshotId);\n        }\n        return deleted;\n    } catch (IOException e) {\n        log.error(\"Error deleting snapshot files {} and {}\", immutablePath, deletedPath, e);\n        return false;\n    }\n}",
        "summary_tokens": [
            "delete",
            "the",
            "snapshot",
            "from",
            "the",
            "filesystem"
        ]
    },
    {
        "id": 2404,
        "code": "public static void markForDelete(Path logDir, OffsetAndEpoch snapshotId) {\n    Path immutablePath = snapshotPath(logDir, snapshotId);\n    Path deletedPath = deleteRename(immutablePath, snapshotId);\n    try {\n        Utils.atomicMoveWithFallback(immutablePath, deletedPath, false);\n    } catch (IOException e) {\n        throw new UncheckedIOException(\n            String.format(\n                \"Error renaming snapshot file from %s to %s.\",\n                immutablePath,\n                deletedPath\n            ),\n            e\n        );\n    }\n}",
        "summary_tokens": [
            "mark",
            "a",
            "snapshot",
            "for",
            "deletion",
            "by",
            "renaming",
            "with",
            "the",
            "deleted",
            "suffix"
        ]
    },
    {
        "id": 2405,
        "code": "public void reopen() {\n    batches.removeIf(batch -> batch.firstOffset() >= lastFlushedOffset);\n    epochStartOffsets.removeIf(epochStartOffset -> epochStartOffset.startOffset >= lastFlushedOffset);\n    highWatermark = new LogOffsetMetadata(0L, Optional.empty());\n}",
        "summary_tokens": [
            "reopening",
            "the",
            "log",
            "causes",
            "all",
            "unflushed",
            "data",
            "to",
            "be",
            "lost"
        ]
    },
    {
        "id": 2406,
        "code": "default void prepend(Event event) {\n    enqueue(EventInsertionType.PREPEND, null, NoDeadlineFunction.INSTANCE, event);\n}",
        "summary_tokens": [
            "add",
            "an",
            "element",
            "to",
            "the",
            "front",
            "of",
            "the",
            "queue"
        ]
    },
    {
        "id": 2407,
        "code": "default void append(Event event) {\n    enqueue(EventInsertionType.APPEND, null, NoDeadlineFunction.INSTANCE, event);\n}",
        "summary_tokens": [
            "add",
            "an",
            "element",
            "to",
            "the",
            "end",
            "of",
            "the",
            "queue"
        ]
    },
    {
        "id": 2408,
        "code": "default void appendWithDeadline(long deadlineNs, Event event) {\n    enqueue(EventInsertionType.APPEND, null, new DeadlineFunction(deadlineNs), event);\n}",
        "summary_tokens": [
            "add",
            "an",
            "event",
            "to",
            "the",
            "end",
            "of",
            "the",
            "queue"
        ]
    },
    {
        "id": 2409,
        "code": "default void scheduleDeferred(String tag,\n                              Function<OptionalLong, OptionalLong> deadlineNsCalculator,\n                              Event event) {\n    enqueue(EventInsertionType.DEFERRED, tag, deadlineNsCalculator, event);\n}",
        "summary_tokens": [
            "schedule",
            "an",
            "event",
            "to",
            "be",
            "run",
            "at",
            "a",
            "specific",
            "time"
        ]
    },
    {
        "id": 2410,
        "code": "default void beginShutdown(String source, Event cleanupEvent) {\n    beginShutdown(source, cleanupEvent, 0, TimeUnit.SECONDS);\n}",
        "summary_tokens": [
            "asynchronously",
            "shut",
            "down",
            "the",
            "event",
            "queue",
            "with",
            "no",
            "unnecessary",
            "delay"
        ]
    },
    {
        "id": 2411,
        "code": "default void wakeup() { }",
        "summary_tokens": [
            "this",
            "method",
            "is",
            "used",
            "during",
            "unit",
            "tests",
            "where",
            "mock",
            "time",
            "is",
            "in",
            "use"
        ]
    },
    {
        "id": 2412,
        "code": "public int assignedBrokerId() {\n    return assignedBrokerId;\n}",
        "summary_tokens": [
            "get",
            "the",
            "id",
            "of",
            "the",
            "broker",
            "that",
            "this",
            "block",
            "was",
            "assigned",
            "to"
        ]
    },
    {
        "id": 2413,
        "code": "public long firstProducerId() {\n    return firstProducerId;\n}",
        "summary_tokens": [
            "get",
            "the",
            "first",
            "id",
            "inclusive",
            "to",
            "be",
            "assigned",
            "from",
            "this",
            "block"
        ]
    },
    {
        "id": 2414,
        "code": "public int size() {\n    return blockSize;\n}",
        "summary_tokens": [
            "get",
            "the",
            "number",
            "of",
            "ids",
            "contained",
            "in",
            "this",
            "block"
        ]
    },
    {
        "id": 2415,
        "code": "public long lastProducerId() {\n    return firstProducerId + blockSize - 1;\n}",
        "summary_tokens": [
            "get",
            "the",
            "last",
            "id",
            "inclusive",
            "to",
            "be",
            "assigned",
            "from",
            "this",
            "block"
        ]
    },
    {
        "id": 2416,
        "code": "public long nextBlockFirstId() {\n    return firstProducerId + blockSize;\n}",
        "summary_tokens": [
            "get",
            "the",
            "first",
            "id",
            "of",
            "the",
            "next",
            "block",
            "following",
            "this",
            "one"
        ]
    },
    {
        "id": 2417,
        "code": "public static MetricsRegistry defaultRegistry() {\n    return INSTANCE.metricsRegistry;\n}",
        "summary_tokens": [
            "convenience",
            "method",
            "to",
            "replace",
            "com"
        ]
    },
    {
        "id": 2418,
        "code": "public static void printMetrics(Map<MetricName, ? extends Metric> metrics) {\n    if (metrics != null && !metrics.isEmpty()) {\n        int maxLengthOfDisplayName = 0;\n        TreeMap<String, Object> sortedMetrics = new TreeMap<>();\n        for (Metric metric : metrics.values()) {\n            MetricName mName = metric.metricName();\n            String mergedName = mName.group() + \":\" + mName.name() + \":\" + mName.tags();\n            maxLengthOfDisplayName = maxLengthOfDisplayName < mergedName.length() ? mergedName.length() : maxLengthOfDisplayName;\n            sortedMetrics.put(mergedName, metric.metricValue());\n        }\n        String doubleOutputFormat = \"%-\" + maxLengthOfDisplayName + \"s : %.3f\";\n        String defaultOutputFormat = \"%-\" + maxLengthOfDisplayName + \"s : %s\";\n        System.out.println(String.format(\"\\n%-\" + maxLengthOfDisplayName + \"s   %s\", \"Metric Name\", \"Value\"));\n\n        for (Map.Entry<String, Object> entry : sortedMetrics.entrySet()) {\n            String outputFormat;\n            if (entry.getValue() instanceof Double)\n                outputFormat = doubleOutputFormat;\n            else\n                outputFormat = defaultOutputFormat;\n            System.out.println(String.format(outputFormat, entry.getKey(), entry.getValue()));\n        }\n    }\n}",
        "summary_tokens": [
            "print",
            "out",
            "the",
            "metrics",
            "in",
            "alphabetical",
            "order",
            "metrics",
            "the",
            "metrics",
            "to",
            "be",
            "printed",
            "out"
        ]
    },
    {
        "id": 2419,
        "code": "public void testHandleFault() {\n    AtomicInteger counter = new AtomicInteger(0);\n    LoggingFaultHandler handler = new LoggingFaultHandler(\"test\", () -> {\n        counter.incrementAndGet();\n    });\n    handler.handleFault(\"uh oh\");\n    assertEquals(1, counter.get());\n    handler.handleFault(\"uh oh\", new RuntimeException(\"yikes\"));\n    assertEquals(2, counter.get());\n}",
        "summary_tokens": [
            "test",
            "handling",
            "faults",
            "with",
            "and",
            "without",
            "exceptions"
        ]
    },
    {
        "id": 2420,
        "code": "public void testHandleExceptionInAction() {\n    LoggingFaultHandler handler = new LoggingFaultHandler(\"test\", () -> {\n        throw new RuntimeException(\"action failed\");\n    });\n    handler.handleFault(\"uh oh\"); \n    handler.handleFault(\"uh oh\", new RuntimeException(\"yikes\")); \n}",
        "summary_tokens": [
            "test",
            "handling",
            "an",
            "exception",
            "in",
            "the",
            "action",
            "callback"
        ]
    },
    {
        "id": 2421,
        "code": "public static List<String> getEffectivePaths(List<String> paths) {\n    List<String> effectivePaths = new ArrayList<>();\n    for (String path : paths) {\n        if (!path.isEmpty()) {\n            effectivePaths.add(path);\n        }\n    }\n    if (effectivePaths.isEmpty()) {\n        effectivePaths.add(\".\");\n    }\n    return effectivePaths;\n}",
        "summary_tokens": [
            "convert",
            "a",
            "list",
            "of",
            "paths",
            "into",
            "the",
            "effective",
            "list",
            "of",
            "paths",
            "which",
            "should",
            "be",
            "used"
        ]
    },
    {
        "id": 2422,
        "code": "public static void completeCommand(String commandPrefix, List<Candidate> candidates) {\n    String command = Commands.TYPES.ceilingKey(commandPrefix);\n    while (command != null && command.startsWith(commandPrefix)) {\n        candidates.add(new Candidate(command));\n        command = Commands.TYPES.higherKey(command);\n    }\n}",
        "summary_tokens": [
            "generate",
            "a",
            "list",
            "of",
            "potential",
            "completions",
            "for",
            "a",
            "prefix",
            "of",
            "a",
            "command",
            "name"
        ]
    },
    {
        "id": 2423,
        "code": "public static List<String> splitPath(String path) {\n    List<String> results = new ArrayList<>();\n    String[] components = path.split(\"/\");\n    for (int i = 0; i < components.length; i++) {\n        if (!components[i].isEmpty()) {\n            results.add(components[i]);\n        }\n    }\n    return results;\n}",
        "summary_tokens": [
            "convert",
            "a",
            "path",
            "to",
            "a",
            "list",
            "of",
            "path",
            "components"
        ]
    },
    {
        "id": 2424,
        "code": "public static void completePath(MetadataNodeManager nodeManager,\n                                String pathPrefix,\n                                List<Candidate> candidates) throws Exception {\n    nodeManager.visit(data -> {\n        String absolutePath = pathPrefix.startsWith(\"/\") ?\n            pathPrefix : data.workingDirectory() + \"/\" + pathPrefix;\n        List<String> pathComponents = stripDotPathComponents(splitPath(absolutePath));\n        DirectoryNode directory = data.root();\n        int numDirectories = pathPrefix.endsWith(\"/\") ?\n            pathComponents.size() : pathComponents.size() - 1;\n        for (int i = 0; i < numDirectories; i++) {\n            MetadataNode node = directory.child(pathComponents.get(i));\n            if (!(node instanceof DirectoryNode)) {\n                return;\n            }\n            directory = (DirectoryNode) node;\n        }\n        String lastComponent = \"\";\n        if (numDirectories >= 0 && numDirectories < pathComponents.size()) {\n            lastComponent = pathComponents.get(numDirectories);\n        }\n        Entry<String, MetadataNode> candidate =\n            directory.children().ceilingEntry(lastComponent);\n        String effectivePrefix;\n        int lastSlash = pathPrefix.lastIndexOf('/');\n        if (lastSlash < 0) {\n            effectivePrefix = \"\";\n        } else {\n            effectivePrefix = pathPrefix.substring(0, lastSlash + 1);\n        }\n        while (candidate != null && candidate.getKey().startsWith(lastComponent)) {\n            StringBuilder candidateBuilder = new StringBuilder();\n            candidateBuilder.append(effectivePrefix).append(candidate.getKey());\n            boolean complete = true;\n            if (candidate.getValue() instanceof DirectoryNode) {\n                candidateBuilder.append(\"/\");\n                complete = false;\n            }\n            candidates.add(new Candidate(candidateBuilder.toString(),\n                candidateBuilder.toString(), null, null, null, null, complete));\n            candidate = directory.children().higherEntry(candidate.getKey());\n        }\n    });\n}",
        "summary_tokens": [
            "generate",
            "a",
            "list",
            "of",
            "potential",
            "completions",
            "for",
            "a",
            "path"
        ]
    },
    {
        "id": 2425,
        "code": "public Handler parseCommand(List<String> arguments) {\n    List<String> trimmedArguments = new ArrayList<>(arguments);\n    while (true) {\n        if (trimmedArguments.isEmpty()) {\n            return new NoOpCommandHandler();\n        }\n        String last = trimmedArguments.get(trimmedArguments.size() - 1);\n        if (!last.isEmpty()) {\n            break;\n        }\n        trimmedArguments.remove(trimmedArguments.size() - 1);\n    }\n    Namespace namespace;\n    try {\n        namespace = parser.parseArgs(trimmedArguments.toArray(new String[0]));\n    } catch (HelpScreenException e) {\n        return new NoOpCommandHandler();\n    } catch (ArgumentParserException e) {\n        return new ErroneousCommandHandler(e.getMessage());\n    }\n    String command = namespace.get(\"command\");\n    if (!command.equals(trimmedArguments.get(0))) {\n        return new ErroneousCommandHandler(\"invalid choice: '\" +\n            trimmedArguments.get(0) + \"': did you mean '\" + command + \"'?\");\n    }\n    Type type = TYPES.get(command);\n    if (type == null) {\n        return new ErroneousCommandHandler(\"Unknown command specified: \" + command);\n    } else {\n        return type.createHandler(namespace);\n    }\n}",
        "summary_tokens": [
            "handle",
            "the",
            "given",
            "command"
        ]
    },
    {
        "id": 2426,
        "code": "    private static boolean isRegularExpressionSpecialCharacter(char ch) {\n        switch (ch) {\n            case '$':\n            case '(':\n            case ')':\n            case '+':\n            case '.':\n            case '[':\n            case ']':\n            case '^':\n            case '{':\n            case '|':\n                return true;\n            default:\n                break;\n        }\n        return false;\n    }\n\n    \n    private static boolean isGlobSpecialCharacter(char ch) {\n        switch (ch) {\n            case '*':\n            case '?':\n            case '\\\\':\n            case '{':\n            case '}':\n                return true;\n            default:\n                break;\n        }\n        return false;\n    }\n\n    \n    static String toRegularExpression(String glob) {\n        StringBuilder output = new StringBuilder(\"^\");\n        boolean literal = true;\n        boolean processingGroup = false;\n\n        for (int i = 0; i < glob.length(); ) {\n            char c = glob.charAt(i++);\n            switch (c) {\n                case '?':\n                    literal = false;\n                    output.append(\".\");\n                    break;\n                case '*':\n                    literal = false;\n                    output.append(\".*\");\n                    break;\n                case '\\\\':\n                    if (i == glob.length()) {\n                        output.append(c);\n                    } else {\n                        char next = glob.charAt(i);\n                        i++;\n                        if (isGlobSpecialCharacter(next) ||\n                                isRegularExpressionSpecialCharacter(next)) {\n                            output.append('\\\\');\n                        }\n                        output.append(next);\n                    }\n                    break;\n                case '{':\n                    if (processingGroup) {\n                        throw new RuntimeException(\"Can't nest glob groups.\");\n                    }\n                    literal = false;\n                    output.append(\"(?:(?:\");\n                    processingGroup = true;\n                    break;\n                case ',':\n                    if (processingGroup) {\n                        literal = false;\n                        output.append(\")|(?:\");\n                    } else {\n                        output.append(c);\n                    }\n                    break;\n                case '}':\n                    if (processingGroup) {\n                        literal = false;\n                        output.append(\"))\");\n                        processingGroup = false;\n                    } else {\n                        output.append(c);\n                    }\n                    break;\n                \n                default:\n                    if (isRegularExpressionSpecialCharacter(c)) {\n                        output.append('\\\\');\n                    }\n                    output.append(c);\n            }\n        }\n        if (processingGroup) {\n            throw new RuntimeException(\"Unterminated glob group.\");\n        }\n        if (literal) {\n            return null;\n        }\n        output.append('$');\n        return output.toString();\n    }\n\n    private final String component;\n    private final Pattern pattern;\n\n    public GlobComponent(String component) {\n        this.component = component;\n        Pattern newPattern = null;\n        try {\n            String regularExpression = toRegularExpression(component);\n            if (regularExpression != null) {\n                newPattern = Pattern.compile(regularExpression);\n            }\n        } catch (RuntimeException e) {\n            log.debug(\"Invalid glob pattern: \" + e.getMessage());\n        }\n        this.pattern = newPattern;\n    }\n\n    public String component() {\n        return component;\n    }\n\n    public boolean literal() {\n        return pattern == null;\n    }\n\n    public boolean matches(String nodeName) {\n        if (pattern == null) {\n            return component.equals(nodeName);\n        } else {\n            return pattern.matcher(nodeName).matches();\n        }\n    }\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "character",
            "is",
            "a",
            "special",
            "character",
            "for",
            "regular",
            "expressions"
        ]
    },
    {
        "id": 2427,
        "code": "private static boolean isGlobSpecialCharacter(char ch) {\n    switch (ch) {\n        case '*':\n        case '?':\n        case '\\\\':\n        case '{':\n        case '}':\n            return true;\n        default:\n            break;\n    }\n    return false;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "character",
            "is",
            "a",
            "special",
            "character",
            "for",
            "globs"
        ]
    },
    {
        "id": 2428,
        "code": "static String toRegularExpression(String glob) {\n    StringBuilder output = new StringBuilder(\"^\");\n    boolean literal = true;\n    boolean processingGroup = false;\n\n    for (int i = 0; i < glob.length(); ) {\n        char c = glob.charAt(i++);\n        switch (c) {\n            case '?':\n                literal = false;\n                output.append(\".\");\n                break;\n            case '*':\n                literal = false;\n                output.append(\".*\");\n                break;\n            case '\\\\':\n                if (i == glob.length()) {\n                    output.append(c);\n                } else {\n                    char next = glob.charAt(i);\n                    i++;\n                    if (isGlobSpecialCharacter(next) ||\n                            isRegularExpressionSpecialCharacter(next)) {\n                        output.append('\\\\');\n                    }\n                    output.append(next);\n                }\n                break;\n            case '{':\n                if (processingGroup) {\n                    throw new RuntimeException(\"Can't nest glob groups.\");\n                }\n                literal = false;\n                output.append(\"(?:(?:\");\n                processingGroup = true;\n                break;\n            case ',':\n                if (processingGroup) {\n                    literal = false;\n                    output.append(\")|(?:\");\n                } else {\n                    output.append(c);\n                }\n                break;\n            case '}':\n                if (processingGroup) {\n                    literal = false;\n                    output.append(\"))\");\n                    processingGroup = false;\n                } else {\n                    output.append(c);\n                }\n                break;\n                \n            default:\n                if (isRegularExpressionSpecialCharacter(c)) {\n                    output.append('\\\\');\n                }\n                output.append(c);\n        }\n    }\n    if (processingGroup) {\n        throw new RuntimeException(\"Unterminated glob group.\");\n    }\n    if (literal) {\n        return null;\n    }\n    output.append('$');\n    return output.toString();\n}",
        "summary_tokens": [
            "converts",
            "a",
            "glob",
            "string",
            "to",
            "a",
            "regular",
            "expression",
            "string"
        ]
    },
    {
        "id": 2429,
        "code": "public Path logSegment() {\n    return logSegment;\n}",
        "summary_tokens": [
            "log",
            "segment",
            "file",
            "of",
            "this",
            "segment"
        ]
    },
    {
        "id": 2430,
        "code": "public Path timeIndex() {\n    return timeIndex;\n}",
        "summary_tokens": [
            "time",
            "index",
            "file",
            "of",
            "this",
            "segment"
        ]
    },
    {
        "id": 2431,
        "code": "public Optional<Path> transactionIndex() {\n    return transactionIndex;\n}",
        "summary_tokens": [
            "transaction",
            "index",
            "file",
            "of",
            "this",
            "segment",
            "if",
            "it",
            "exists"
        ]
    },
    {
        "id": 2432,
        "code": "public Path producerSnapshotIndex() {\n    return producerSnapshotIndex;\n}",
        "summary_tokens": [
            "producer",
            "snapshot",
            "file",
            "until",
            "this",
            "segment"
        ]
    },
    {
        "id": 2433,
        "code": "public ByteBuffer leaderEpochIndex() {\n    return leaderEpochIndex;\n}",
        "summary_tokens": [
            "leader",
            "epoch",
            "index",
            "until",
            "this",
            "segment"
        ]
    },
    {
        "id": 2434,
        "code": "public long eventTimestampMs() {\n    return eventTimestampMs;\n}",
        "summary_tokens": [
            "epoch",
            "time",
            "in",
            "milli",
            "seconds",
            "at",
            "which",
            "this",
            "event",
            "is",
            "occurred"
        ]
    },
    {
        "id": 2435,
        "code": "public int brokerId() {\n    return brokerId;\n}",
        "summary_tokens": [
            "broker",
            "id",
            "from",
            "which",
            "this",
            "event",
            "is",
            "generated"
        ]
    },
    {
        "id": 2436,
        "code": "public TopicIdPartition topicIdPartition() {\n    return topicIdPartition;\n}",
        "summary_tokens": [
            "topic",
            "id",
            "partition",
            "of",
            "this",
            "remote",
            "log",
            "segment"
        ]
    },
    {
        "id": 2437,
        "code": "public Uuid id() {\n    return id;\n}",
        "summary_tokens": [
            "universally",
            "unique",
            "id",
            "of",
            "this",
            "remote",
            "log",
            "segment"
        ]
    },
    {
        "id": 2438,
        "code": "public RemoteLogSegmentId remoteLogSegmentId() {\n    return remoteLogSegmentId;\n}",
        "summary_tokens": [
            "unique",
            "id",
            "of",
            "this",
            "segment"
        ]
    },
    {
        "id": 2439,
        "code": "public long startOffset() {\n    return startOffset;\n}",
        "summary_tokens": [
            "start",
            "offset",
            "of",
            "this",
            "segment",
            "inclusive"
        ]
    },
    {
        "id": 2440,
        "code": "public long endOffset() {\n    return endOffset;\n}",
        "summary_tokens": [
            "end",
            "offset",
            "of",
            "this",
            "segment",
            "inclusive"
        ]
    },
    {
        "id": 2441,
        "code": "public int segmentSizeInBytes() {\n    return segmentSizeInBytes;\n}",
        "summary_tokens": [
            "total",
            "size",
            "of",
            "this",
            "segment",
            "in",
            "bytes"
        ]
    },
    {
        "id": 2442,
        "code": "public long maxTimestampMs() {\n    return maxTimestampMs;\n}",
        "summary_tokens": [
            "maximum",
            "timestamp",
            "in",
            "milli",
            "seconds",
            "of",
            "a",
            "record",
            "within",
            "this",
            "segment"
        ]
    },
    {
        "id": 2443,
        "code": "public NavigableMap<Integer, Long> segmentLeaderEpochs() {\n    return segmentLeaderEpochs;\n}",
        "summary_tokens": [
            "map",
            "of",
            "leader",
            "epoch",
            "vs",
            "offset",
            "for",
            "the",
            "records",
            "available",
            "in",
            "this",
            "segment"
        ]
    },
    {
        "id": 2444,
        "code": "public RemoteLogSegmentState state() {\n    return state;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "current",
            "state",
            "of",
            "this",
            "remote",
            "log",
            "segment"
        ]
    },
    {
        "id": 2445,
        "code": "public RemoteLogSegmentMetadata createWithUpdates(RemoteLogSegmentMetadataUpdate rlsmUpdate) {\n    if (!remoteLogSegmentId.equals(rlsmUpdate.remoteLogSegmentId())) {\n        throw new IllegalArgumentException(\"Given rlsmUpdate does not have this instance's remoteLogSegmentId.\");\n    }\n\n    return new RemoteLogSegmentMetadata(remoteLogSegmentId, startOffset,\n            endOffset, maxTimestampMs, rlsmUpdate.brokerId(), rlsmUpdate.eventTimestampMs(),\n            segmentSizeInBytes, rlsmUpdate.state(), segmentLeaderEpochs);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "new",
            "remote",
            "log",
            "segment",
            "metadata",
            "applying",
            "the",
            "given",
            "rlsm",
            "update",
            "on",
            "this",
            "instance"
        ]
    },
    {
        "id": 2446,
        "code": "public RemoteLogSegmentId remoteLogSegmentId() {\n    return remoteLogSegmentId;\n}",
        "summary_tokens": [
            "universally",
            "unique",
            "id",
            "of",
            "this",
            "remote",
            "log",
            "segment"
        ]
    },
    {
        "id": 2447,
        "code": "public RemoteLogSegmentState state() {\n    return state;\n}",
        "summary_tokens": [
            "it",
            "represents",
            "the",
            "state",
            "of",
            "the",
            "remote",
            "log",
            "segment"
        ]
    },
    {
        "id": 2448,
        "code": "public TopicIdPartition topicIdPartition() {\n    return topicIdPartition;\n}",
        "summary_tokens": [
            "topic",
            "id",
            "partition",
            "for",
            "which",
            "this",
            "event",
            "is",
            "meant",
            "for"
        ]
    },
    {
        "id": 2449,
        "code": "public RemotePartitionDeleteState state() {\n    return state;\n}",
        "summary_tokens": [
            "it",
            "represents",
            "the",
            "state",
            "of",
            "the",
            "remote",
            "partition"
        ]
    },
    {
        "id": 2450,
        "code": "public void waitTillConsumptionCatchesUp(RecordMetadata recordMetadata,\n                                         long timeoutMs) throws TimeoutException {\n    final int partition = recordMetadata.partition();\n    final long consumeCheckIntervalMs = Math.min(CONSUME_RECHECK_INTERVAL_MS, timeoutMs);\n\n        \n    if (!consumerTask.isPartitionAssigned(partition)) {\n        throw new KafkaException(\"This consumer is not subscribed to the target partition \" + partition + \" on which message is produced.\");\n    }\n\n    final long offset = recordMetadata.offset();\n    long startTimeMs = time.milliseconds();\n    while (true) {\n        long receivedOffset = consumerTask.receivedOffsetForPartition(partition).orElse(-1L);\n        if (receivedOffset >= offset) {\n            return;\n        }\n\n        log.debug(\"Committed offset [{}] for partition [{}], but the target offset: [{}],  Sleeping for [{}] to retry again\",\n                  offset, partition, receivedOffset, consumeCheckIntervalMs);\n\n        if (time.milliseconds() - startTimeMs > timeoutMs) {\n            log.warn(\"Committed offset for partition:[{}] is : [{}], but the target offset: [{}] \",\n                     partition, receivedOffset, offset);\n            throw new TimeoutException(\"Timed out in catching up with the expected offset by consumer.\");\n        }\n\n        time.sleep(consumeCheckIntervalMs);\n    }\n}",
        "summary_tokens": [
            "waits",
            "if",
            "necessary",
            "for",
            "the",
            "consumption",
            "to",
            "reach",
            "the",
            "offset",
            "of",
            "the",
            "given",
            "record",
            "metadata"
        ]
    },
    {
        "id": 2451,
        "code": "public void flushToFile(int metadataPartition,\n                        Long metadataPartitionOffset) throws IOException {\n    List<RemoteLogSegmentMetadataSnapshot> snapshots = new ArrayList<>(idToSegmentMetadata.size());\n    for (RemoteLogLeaderEpochState state : leaderEpochEntries.values()) {\n            \n            \n        for (RemoteLogSegmentId id : state.unreferencedSegmentIds()) {\n            snapshots.add(RemoteLogSegmentMetadataSnapshot.create(idToSegmentMetadata.get(id)));\n        }\n            \n            \n        for (RemoteLogSegmentId id : state.referencedSegmentIds()) {\n            snapshots.add(RemoteLogSegmentMetadataSnapshot.create(idToSegmentMetadata.get(id)));\n        }\n    }\n\n    snapshotFile.write(new RemoteLogMetadataSnapshotFile.Snapshot(metadataPartition, metadataPartitionOffset, snapshots));\n}",
        "summary_tokens": [
            "flushes",
            "the",
            "in",
            "memory",
            "state",
            "to",
            "the",
            "snapshot",
            "file"
        ]
    },
    {
        "id": 2452,
        "code": "public CompletableFuture<RecordMetadata> publishMessage(RemoteLogMetadata remoteLogMetadata) {\n    CompletableFuture<RecordMetadata> future = new CompletableFuture<>();\n\n    TopicIdPartition topicIdPartition = remoteLogMetadata.topicIdPartition();\n    int metadataPartitionNum = topicPartitioner.metadataPartition(topicIdPartition);\n    log.debug(\"Publishing metadata message of partition:[{}] into metadata topic partition:[{}] with payload: [{}]\",\n              topicIdPartition, metadataPartitionNum, remoteLogMetadata);\n    if (metadataPartitionNum >= rlmmConfig.metadataTopicPartitionsCount()) {\n            \n        throw new KafkaException(\"Chosen partition no \" + metadataPartitionNum +\n                                         \" must be less than the partition count: \" + rlmmConfig.metadataTopicPartitionsCount());\n    }\n\n    try {\n        Callback callback = new Callback() {\n            @Override\n            public void onCompletion(RecordMetadata metadata,\n                                     Exception exception) {\n                if (exception != null) {\n                    future.completeExceptionally(exception);\n                } else {\n                    future.complete(metadata);\n                }\n            }\n        };\n        producer.send(new ProducerRecord<>(rlmmConfig.remoteLogMetadataTopicName(), metadataPartitionNum, null,\n                                           serde.serialize(remoteLogMetadata)), callback);\n    } catch (Exception ex) {\n        future.completeExceptionally(ex);\n    }\n\n    return future;\n}",
        "summary_tokens": [
            "returns",
            "completable",
            "future",
            "which",
            "will",
            "complete",
            "only",
            "after",
            "publishing",
            "of",
            "the",
            "given",
            "remote",
            "log",
            "metadata",
            "is",
            "considered",
            "complete"
        ]
    },
    {
        "id": 2453,
        "code": "Iterator<RemoteLogSegmentMetadata> listAllRemoteLogSegments(Map<RemoteLogSegmentId, RemoteLogSegmentMetadata> idToSegmentMetadata)\n        throws RemoteResourceNotFoundException {\n        \n    int size = offsetToId.size() + unreferencedSegmentIds.size();\n    if (size == 0) {\n        return Collections.emptyIterator();\n    }\n\n    ArrayList<RemoteLogSegmentMetadata> metadataList = new ArrayList<>(size);\n    collectConvertedIdToMetadata(offsetToId.values(), idToSegmentMetadata, metadataList);\n\n    if (!unreferencedSegmentIds.isEmpty()) {\n        collectConvertedIdToMetadata(unreferencedSegmentIds, idToSegmentMetadata, metadataList);\n\n            \n        metadataList.sort(Comparator.comparingLong(RemoteLogSegmentMetadata::startOffset));\n    }\n\n    return metadataList.iterator();\n}",
        "summary_tokens": [
            "returns",
            "all",
            "the",
            "segments",
            "associated",
            "with",
            "this",
            "leader",
            "epoch",
            "sorted",
            "by",
            "start",
            "offset",
            "in",
            "ascending",
            "order"
        ]
    },
    {
        "id": 2454,
        "code": "RemoteLogSegmentId floorEntry(long offset) {\n    Map.Entry<Long, RemoteLogSegmentId> entry = offsetToId.floorEntry(offset);\n\n    return entry == null ? null : entry.getValue();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "remote",
            "log",
            "segment",
            "id",
            "of",
            "a",
            "segment",
            "for",
            "the",
            "given",
            "offset",
            "if",
            "there",
            "exists",
            "a",
            "mapping",
            "associated",
            "with",
            "the",
            "greatest",
            "offset",
            "less",
            "than",
            "or",
            "equal",
            "to",
            "the",
            "given",
            "offset",
            "or",
            "null",
            "if",
            "there",
            "is",
            "no",
            "such",
            "mapping"
        ]
    },
    {
        "id": 2455,
        "code": "public Optional<RemoteLogSegmentMetadata> remoteLogSegmentMetadata(int leaderEpoch, long offset) {\n    RemoteLogLeaderEpochState remoteLogLeaderEpochState = leaderEpochEntries.get(leaderEpoch);\n\n    if (remoteLogLeaderEpochState == null) {\n        return Optional.empty();\n    }\n\n        \n    RemoteLogSegmentId remoteLogSegmentId = remoteLogLeaderEpochState.floorEntry(offset);\n    if (remoteLogSegmentId == null) {\n            \n        return Optional.empty();\n    }\n\n    RemoteLogSegmentMetadata metadata = idToSegmentMetadata.get(remoteLogSegmentId);\n        \n        \n        \n        \n    Map.Entry<Integer, Long> nextEntry = metadata.segmentLeaderEpochs().higherEntry(leaderEpoch);\n    long epochEndOffset = (nextEntry != null) ? nextEntry.getValue() - 1 : metadata.endOffset();\n\n        \n    return offset > epochEndOffset ? Optional.empty() : Optional.of(metadata);\n}",
        "summary_tokens": [
            "returns",
            "remote",
            "log",
            "segment",
            "metadata",
            "if",
            "it",
            "exists",
            "for",
            "the",
            "given",
            "leader",
            "epoch",
            "containing",
            "the",
            "offset",
            "and",
            "with",
            "remote",
            "log",
            "segment",
            "state",
            "copy",
            "segment",
            "finished",
            "state",
            "else",
            "returns",
            "optional",
            "empty"
        ]
    },
    {
        "id": 2456,
        "code": "public Iterator<RemoteLogSegmentMetadata> listAllRemoteLogSegments() {\n        \n    return Collections.unmodifiableCollection(idToSegmentMetadata.values()).iterator();\n}",
        "summary_tokens": [
            "returns",
            "all",
            "the",
            "segments",
            "stored",
            "in",
            "this",
            "cache"
        ]
    },
    {
        "id": 2457,
        "code": "public Iterator<RemoteLogSegmentMetadata> listRemoteLogSegments(int leaderEpoch)\n        throws RemoteResourceNotFoundException {\n    RemoteLogLeaderEpochState remoteLogLeaderEpochState = leaderEpochEntries.get(leaderEpoch);\n    if (remoteLogLeaderEpochState == null) {\n        return Collections.emptyIterator();\n    }\n\n    return remoteLogLeaderEpochState.listAllRemoteLogSegments(idToSegmentMetadata);\n}",
        "summary_tokens": [
            "returns",
            "all",
            "the",
            "segments",
            "mapped",
            "to",
            "the",
            "leader",
            "epoch",
            "that",
            "exist",
            "in",
            "this",
            "cache",
            "sorted",
            "by",
            "remote",
            "log",
            "segment",
            "metadata",
            "start",
            "offset"
        ]
    },
    {
        "id": 2458,
        "code": "public Optional<Long> highestOffsetForEpoch(int leaderEpoch) {\n    RemoteLogLeaderEpochState entry = leaderEpochEntries.get(leaderEpoch);\n    return entry != null ? Optional.ofNullable(entry.highestLogOffset()) : Optional.empty();\n}",
        "summary_tokens": [
            "returns",
            "the",
            "highest",
            "offset",
            "of",
            "a",
            "segment",
            "for",
            "the",
            "given",
            "leader",
            "epoch",
            "if",
            "exists",
            "else",
            "it",
            "returns",
            "empty"
        ]
    },
    {
        "id": 2459,
        "code": "public void addCopyInProgressSegment(RemoteLogSegmentMetadata remoteLogSegmentMetadata) {\n    log.debug(\"Adding to in-progress state: [{}]\", remoteLogSegmentMetadata);\n    Objects.requireNonNull(remoteLogSegmentMetadata, \"remoteLogSegmentMetadata can not be null\");\n\n        \n        \n    if (remoteLogSegmentMetadata.state() != RemoteLogSegmentState.COPY_SEGMENT_STARTED) {\n        throw new IllegalArgumentException(\n                \"Given remoteLogSegmentMetadata:\" + remoteLogSegmentMetadata + \" should have state as \" + RemoteLogSegmentState.COPY_SEGMENT_STARTED\n                + \" but it contains state as: \" + remoteLogSegmentMetadata.state());\n    }\n\n    RemoteLogSegmentId remoteLogSegmentId = remoteLogSegmentMetadata.remoteLogSegmentId();\n    RemoteLogSegmentMetadata existingMetadata = idToSegmentMetadata.get(remoteLogSegmentId);\n    checkStateTransition(existingMetadata != null ? existingMetadata.state() : null,\n            remoteLogSegmentMetadata.state());\n\n    for (Integer epoch : remoteLogSegmentMetadata.segmentLeaderEpochs().keySet()) {\n        leaderEpochEntries.computeIfAbsent(epoch, leaderEpoch -> new RemoteLogLeaderEpochState())\n                .handleSegmentWithCopySegmentStartedState(remoteLogSegmentId);\n    }\n\n    idToSegmentMetadata.put(remoteLogSegmentId, remoteLogSegmentMetadata);\n}",
        "summary_tokens": [
            "this",
            "method",
            "tracks",
            "the",
            "given",
            "remote",
            "segment",
            "as",
            "not",
            "yet",
            "available",
            "for",
            "reads"
        ]
    },
    {
        "id": 2460,
        "code": "public synchronized void write(Snapshot snapshot) throws IOException {\n    Path newMetadataSnapshotFilePath = new File(metadataStoreFile.getAbsolutePath() + \".tmp\").toPath();\n    try (FileChannel fileChannel = FileChannel.open(newMetadataSnapshotFilePath,\n                                                    StandardOpenOption.CREATE, StandardOpenOption.READ, StandardOpenOption.WRITE)) {\n\n            \n        ByteBuffer headerBuffer = ByteBuffer.allocate(HEADER_SIZE);\n\n            \n        headerBuffer.putShort(snapshot.version());\n\n            \n        headerBuffer.putInt(snapshot.metadataPartition());\n\n            \n        headerBuffer.putLong(snapshot.metadataPartitionOffset());\n\n            \n        Collection<RemoteLogSegmentMetadataSnapshot> metadataSnapshots = snapshot.remoteLogSegmentMetadataSnapshots();\n        headerBuffer.putInt(metadataSnapshots.size());\n\n            \n        headerBuffer.flip();\n        fileChannel.write(headerBuffer);\n\n            \n        ByteBuffer lenBuffer = ByteBuffer.allocate(4);\n        for (RemoteLogSegmentMetadataSnapshot metadataSnapshot : metadataSnapshots) {\n            final byte[] serializedBytes = serde.serialize(metadataSnapshot);\n                \n\n                \n            lenBuffer.putInt(serializedBytes.length);\n            lenBuffer.flip();\n            fileChannel.write(lenBuffer);\n            lenBuffer.rewind();\n\n                \n            fileChannel.write(ByteBuffer.wrap(serializedBytes));\n        }\n\n        fileChannel.force(true);\n    }\n\n    Utils.atomicMoveWithFallback(newMetadataSnapshotFilePath, metadataStoreFile.toPath());\n}",
        "summary_tokens": [
            "writes",
            "the",
            "given",
            "snapshot",
            "replacing",
            "the",
            "earlier",
            "snapshot",
            "data"
        ]
    },
    {
        "id": 2461,
        "code": "public synchronized Optional<Snapshot> read() throws IOException {\n\n        \n    if (metadataStoreFile.length() == 0) {\n        return Optional.empty();\n    }\n\n    try (ReadableByteChannel channel = Channels.newChannel(new FileInputStream(metadataStoreFile))) {\n\n            \n            \n        ByteBuffer headerBuffer = ByteBuffer.allocate(HEADER_SIZE);\n        channel.read(headerBuffer);\n        headerBuffer.rewind();\n        short version = headerBuffer.getShort();\n        int metadataPartition = headerBuffer.getInt();\n        long metadataPartitionOffset = headerBuffer.getLong();\n        int metadataSnapshotsSize = headerBuffer.getInt();\n\n        List<RemoteLogSegmentMetadataSnapshot> result = new ArrayList<>(metadataSnapshotsSize);\n        ByteBuffer lenBuffer = ByteBuffer.allocate(4);\n        int lenBufferReadCt;\n        while ((lenBufferReadCt = channel.read(lenBuffer)) > 0) {\n            lenBuffer.rewind();\n\n            if (lenBufferReadCt != lenBuffer.capacity()) {\n                throw new IOException(\"Invalid amount of data read for the length of an entry, file may have been corrupted.\");\n            }\n\n                \n\n                \n            final int len = lenBuffer.getInt();\n            lenBuffer.rewind();\n\n                \n            ByteBuffer data = ByteBuffer.allocate(len);\n            final int read = channel.read(data);\n            if (read != len) {\n                throw new IOException(\"Invalid amount of data read, file may have been corrupted.\");\n            }\n\n                \n                \n            final RemoteLogSegmentMetadataSnapshot remoteLogSegmentMetadata =\n                    (RemoteLogSegmentMetadataSnapshot) serde.deserialize(data.array());\n            result.add(remoteLogSegmentMetadata);\n        }\n\n        if (metadataSnapshotsSize != result.size()) {\n            throw new IOException(\"Unexpected entries in the snapshot file. Expected size: \" + metadataSnapshotsSize\n                                          + \", but found: \" + result.size());\n        }\n\n        return Optional.of(new Snapshot(version, metadataPartition, metadataPartitionOffset, result));\n    }\n}",
        "summary_tokens": [
            "the",
            "snapshot",
            "if",
            "it",
            "exists"
        ]
    },
    {
        "id": 2462,
        "code": "public Uuid segmentId() {\n    return segmentId;\n}",
        "summary_tokens": [
            "unique",
            "id",
            "of",
            "this",
            "segment"
        ]
    },
    {
        "id": 2463,
        "code": "public long startOffset() {\n    return startOffset;\n}",
        "summary_tokens": [
            "start",
            "offset",
            "of",
            "this",
            "segment",
            "inclusive"
        ]
    },
    {
        "id": 2464,
        "code": "public long endOffset() {\n    return endOffset;\n}",
        "summary_tokens": [
            "end",
            "offset",
            "of",
            "this",
            "segment",
            "inclusive"
        ]
    },
    {
        "id": 2465,
        "code": "public int segmentSizeInBytes() {\n    return segmentSizeInBytes;\n}",
        "summary_tokens": [
            "total",
            "size",
            "of",
            "this",
            "segment",
            "in",
            "bytes"
        ]
    },
    {
        "id": 2466,
        "code": "public long maxTimestampMs() {\n    return maxTimestampMs;\n}",
        "summary_tokens": [
            "maximum",
            "timestamp",
            "in",
            "milli",
            "seconds",
            "of",
            "a",
            "record",
            "within",
            "this",
            "segment"
        ]
    },
    {
        "id": 2467,
        "code": "public NavigableMap<Integer, Long> segmentLeaderEpochs() {\n    return segmentLeaderEpochs;\n}",
        "summary_tokens": [
            "map",
            "of",
            "leader",
            "epoch",
            "vs",
            "offset",
            "for",
            "the",
            "records",
            "available",
            "in",
            "this",
            "segment"
        ]
    },
    {
        "id": 2468,
        "code": "public RemoteLogSegmentState state() {\n    return state;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "current",
            "state",
            "of",
            "this",
            "remote",
            "log",
            "segment"
        ]
    },
    {
        "id": 2469,
        "code": "private CompletableFuture<Void> storeRemoteLogMetadata(TopicIdPartition topicIdPartition,\n                                                       RemoteLogMetadata remoteLogMetadata)\n        throws RemoteStorageException {\n    log.debug(\"Storing metadata for partition: [{}] with context: [{}]\", topicIdPartition, remoteLogMetadata);\n\n    try {\n            \n        CompletableFuture<RecordMetadata> produceFuture = producerManager.publishMessage(remoteLogMetadata);\n\n            \n        return produceFuture.thenApplyAsync(recordMetadata -> {\n            try {\n                consumerManager.waitTillConsumptionCatchesUp(recordMetadata);\n            } catch (TimeoutException e) {\n                throw new KafkaException(e);\n            }\n            return null;\n        });\n    } catch (KafkaException e) {\n        if (e instanceof RetriableException) {\n            throw e;\n        } else {\n            throw new RemoteStorageException(e);\n        }\n    }\n}",
        "summary_tokens": [
            "returns",
            "completable",
            "future",
            "which",
            "will",
            "complete",
            "only",
            "after",
            "publishing",
            "of",
            "the",
            "given",
            "remote",
            "log",
            "metadata",
            "into",
            "the",
            "remote",
            "log",
            "metadata",
            "topic",
            "and",
            "the",
            "internal",
            "consumer",
            "is",
            "caught",
            "up",
            "until",
            "the",
            "produced",
            "record",
            "s",
            "offset"
        ]
    },
    {
        "id": 2470,
        "code": "private boolean createTopic(AdminClient adminClient, NewTopic topic) {\n    boolean topicCreated = false;\n    try {\n        adminClient.createTopics(Collections.singleton(topic)).all().get();\n        topicCreated = true;\n    } catch (Exception e) {\n        if (e.getCause() instanceof TopicExistsException) {\n            log.info(\"Topic [{}] already exists\", topic.name());\n            topicCreated = true;\n        } else {\n            log.error(\"Encountered error while creating remote log metadata topic.\", e);\n        }\n    }\n\n    return topicCreated;\n}",
        "summary_tokens": [
            "topic",
            "topic",
            "to",
            "be",
            "created"
        ]
    },
    {
        "id": 2471,
        "code": "default void initialize(TopicIdPartition topicIdPartition) {\n}",
        "summary_tokens": [
            "initialize",
            "the",
            "resources",
            "for",
            "this",
            "instance",
            "and",
            "register",
            "the",
            "given",
            "topic",
            "id",
            "partition"
        ]
    },
    {
        "id": 2472,
        "code": "public void testOneWord() {\n        \n    inputTopic.pipeInput(\"Hello\");\n        \n    assertThat(outputTopic.readKeyValue(), equalTo(new KeyValue<>(\"hello\", 1L)));\n        \n    assertThat(outputTopic.isEmpty(), is(true));\n}",
        "summary_tokens": [
            "simple",
            "test",
            "validating",
            "count",
            "of",
            "one",
            "word"
        ]
    },
    {
        "id": 2473,
        "code": "public void testCountListOfWords() {\n    final List<String> inputValues = Arrays.asList(\n            \"Apache   Kafka Streams   Example\",\n            \"Using  \\t\\t Kafka   Streams\\tTest Utils\",\n            \"Reading and Writing Kafka Topic\"\n    );\n    final Map<String, Long> expectedWordCounts = new HashMap<>();\n    expectedWordCounts.put(\"apache\", 1L);\n    expectedWordCounts.put(\"kafka\", 3L);\n    expectedWordCounts.put(\"streams\", 2L);\n    expectedWordCounts.put(\"example\", 1L);\n    expectedWordCounts.put(\"using\", 1L);\n    expectedWordCounts.put(\"test\", 1L);\n    expectedWordCounts.put(\"utils\", 1L);\n    expectedWordCounts.put(\"reading\", 1L);\n    expectedWordCounts.put(\"and\", 1L);\n    expectedWordCounts.put(\"writing\", 1L);\n    expectedWordCounts.put(\"topic\", 1L);\n\n    inputTopic.pipeValueList(inputValues);\n    final Map<String, Long> actualWordCounts = outputTopic.readKeyValuesToMap();\n    assertThat(actualWordCounts, equalTo(expectedWordCounts));\n}",
        "summary_tokens": [
            "test",
            "word",
            "count",
            "of",
            "sentence",
            "list"
        ]
    },
    {
        "id": 2474,
        "code": "default Admin getAdmin(final Map<String, Object> config) {\n    throw new UnsupportedOperationException(\"Implementations of KafkaClientSupplier should implement the getAdmin() method.\");\n}",
        "summary_tokens": [
            "create",
            "an",
            "admin",
            "which",
            "is",
            "used",
            "for",
            "internal",
            "topic",
            "management"
        ]
    },
    {
        "id": 2475,
        "code": "private boolean setState(final State newState) {\n    final State oldState;\n\n    synchronized (stateLock) {\n        oldState = state;\n\n        if (state == State.PENDING_SHUTDOWN && newState != State.NOT_RUNNING) {\n                \n                \n            return false;\n        } else if (state == State.NOT_RUNNING && (newState == State.PENDING_SHUTDOWN || newState == State.NOT_RUNNING)) {\n                \n                \n            return false;\n        } else if (state == State.REBALANCING && newState == State.REBALANCING) {\n                \n            return false;\n        } else if (state == State.ERROR && (newState == State.PENDING_ERROR || newState == State.ERROR)) {\n                \n            return false;\n        } else if (state == State.PENDING_ERROR && newState != State.ERROR) {\n                \n                \n            return false;\n        } else if (!state.isValidTransition(newState)) {\n            throw new IllegalStateException(\"Stream-client \" + clientId + \": Unexpected state transition from \" + oldState + \" to \" + newState);\n        } else {\n            log.info(\"State transition from {} to {}\", oldState, newState);\n        }\n        state = newState;\n        stateLock.notifyAll();\n    }\n\n        \n    if (stateListener != null) {\n        stateListener.onChange(newState, oldState);\n    }\n\n    return true;\n}",
        "summary_tokens": [
            "sets",
            "the",
            "state",
            "new",
            "state",
            "new",
            "state"
        ]
    },
    {
        "id": 2476,
        "code": "public State state() {\n    return state;\n}",
        "summary_tokens": [
            "return",
            "the",
            "current",
            "state",
            "of",
            "this",
            "kafka",
            "streams",
            "instance"
        ]
    },
    {
        "id": 2477,
        "code": "public void setStateListener(final KafkaStreams.StateListener listener) {\n    synchronized (stateLock) {\n        if (state.hasNotStarted()) {\n            stateListener = listener;\n        } else {\n            throw new IllegalStateException(\"Can only set StateListener before calling start(). Current state is: \" + state);\n        }\n    }\n}",
        "summary_tokens": [
            "an",
            "app",
            "can",
            "set",
            "a",
            "single",
            "kafka",
            "streams"
        ]
    },
    {
        "id": 2478,
        "code": "public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler userStreamsUncaughtExceptionHandler) {\n    synchronized (stateLock) {\n        if (state.hasNotStarted()) {\n            Objects.requireNonNull(userStreamsUncaughtExceptionHandler);\n            streamsUncaughtExceptionHandler =\n                (exception, skipThreadReplacement) ->\n                    handleStreamsUncaughtException(exception, userStreamsUncaughtExceptionHandler, skipThreadReplacement);\n            processStreamThread(thread -> thread.setStreamsUncaughtExceptionHandler(streamsUncaughtExceptionHandler));\n            if (globalStreamThread != null) {\n                globalStreamThread.setUncaughtExceptionHandler(\n                    exception -> handleStreamsUncaughtException(exception, userStreamsUncaughtExceptionHandler, false)\n                );\n            }\n            processStreamThread(thread -> thread.setUncaughtExceptionHandler((t, e) -> { }\n            ));\n\n            if (globalStreamThread != null) {\n                globalStreamThread.setUncaughtExceptionHandler((t, e) -> { }\n                );\n            }\n        } else {\n            throw new IllegalStateException(\"Can only set UncaughtExceptionHandler before calling start(). \" +\n                \"Current state is: \" + state);\n        }\n    }\n}",
        "summary_tokens": [
            "set",
            "the",
            "handler",
            "invoked",
            "when",
            "an",
            "internal",
            "streams",
            "config",
            "num",
            "stream",
            "threads",
            "config",
            "stream",
            "thread",
            "throws",
            "an",
            "unexpected",
            "exception"
        ]
    },
    {
        "id": 2479,
        "code": "public void setGlobalStateRestoreListener(final StateRestoreListener globalStateRestoreListener) {\n    synchronized (stateLock) {\n        if (state.hasNotStarted()) {\n            this.globalStateRestoreListener = globalStateRestoreListener;\n        } else {\n            throw new IllegalStateException(\"Can only set GlobalStateRestoreListener before calling start(). \" +\n                \"Current state is: \" + state);\n        }\n    }\n}",
        "summary_tokens": [
            "set",
            "the",
            "listener",
            "which",
            "is",
            "triggered",
            "whenever",
            "a",
            "state",
            "store",
            "is",
            "being",
            "restored",
            "in",
            "order",
            "to",
            "resume",
            "processing"
        ]
    },
    {
        "id": 2480,
        "code": "public Map<MetricName, ? extends Metric> metrics() {\n    final Map<MetricName, Metric> result = new LinkedHashMap<>();\n        \n    processStreamThread(thread -> {\n        result.putAll(thread.producerMetrics());\n        result.putAll(thread.consumerMetrics());\n            \n            \n            \n        result.putAll(thread.adminClientMetrics());\n    });\n        \n    if (globalStreamThread != null) {\n        result.putAll(globalStreamThread.consumerMetrics());\n    }\n        \n    result.putAll(metrics.metrics());\n    return Collections.unmodifiableMap(result);\n}",
        "summary_tokens": [
            "get",
            "read",
            "only",
            "handle",
            "on",
            "global",
            "metrics",
            "registry",
            "including",
            "streams",
            "client",
            "s",
            "own",
            "metrics",
            "plus",
            "its",
            "embedded",
            "producer",
            "consumer",
            "and",
            "admin",
            "clients",
            "metrics"
        ]
    },
    {
        "id": 2481,
        "code": "public Optional<String> addStreamThread() {\n    if (isRunningOrRebalancing()) {\n        final StreamThread streamThread;\n        synchronized (changeThreadCount) {\n            final int threadIdx = getNextThreadIndex();\n            final int numLiveThreads = getNumLiveStreamThreads();\n            final long cacheSizePerThread = getCacheSizePerThread(numLiveThreads + 1);\n            log.info(\"Adding StreamThread-{}, there will now be {} live threads and the new cache size per thread is {}\",\n                     threadIdx, numLiveThreads + 1, cacheSizePerThread);\n            resizeThreadCache(cacheSizePerThread);\n                \n                \n            streamThread = createAndAddStreamThread(cacheSizePerThread, threadIdx);\n        }\n\n        synchronized (stateLock) {\n            if (isRunningOrRebalancing()) {\n                streamThread.start();\n                return Optional.of(streamThread.getName());\n            } else {\n                log.warn(\"Terminating the new thread because the Kafka Streams client is in state {}\", state);\n                streamThread.shutdown();\n                threads.remove(streamThread);\n                final long cacheSizePerThread = getCacheSizePerThread(getNumLiveStreamThreads());\n                log.info(\"Resizing thread cache due to terminating added thread, new cache size per thread is {}\", cacheSizePerThread);\n                resizeThreadCache(cacheSizePerThread);\n                return Optional.empty();\n            }\n        }\n    } else {\n        log.warn(\"Cannot add a stream thread when Kafka Streams client is in state {}\", state);\n        return Optional.empty();\n    }\n}",
        "summary_tokens": [
            "adds",
            "and",
            "starts",
            "a",
            "stream",
            "thread",
            "in",
            "addition",
            "to",
            "the",
            "stream",
            "threads",
            "that",
            "are",
            "already",
            "running",
            "in",
            "this",
            "kafka",
            "streams",
            "client"
        ]
    },
    {
        "id": 2482,
        "code": "public Optional<String> removeStreamThread(final Duration timeout) {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(timeout, \"timeout\");\n    final long timeoutMs = validateMillisecondDuration(timeout, msgPrefix);\n    return removeStreamThread(timeoutMs);\n}",
        "summary_tokens": [
            "removes",
            "one",
            "stream",
            "thread",
            "out",
            "of",
            "the",
            "running",
            "stream",
            "threads",
            "from",
            "this",
            "kafka",
            "streams",
            "client"
        ]
    },
    {
        "id": 2483,
        "code": "private int getNumLiveStreamThreads() {\n    final AtomicInteger numLiveThreads = new AtomicInteger(0);\n\n    synchronized (threads) {\n        processStreamThread(thread -> {\n            if (thread.state() == StreamThread.State.DEAD) {\n                log.debug(\"Trimming thread {} from the threads list since it's state is {}\", thread.getName(), StreamThread.State.DEAD);\n                threads.remove(thread);\n            } else if (thread.state() == StreamThread.State.PENDING_SHUTDOWN) {\n                log.debug(\"Skipping thread {} from num live threads computation since it's state is {}\",\n                          thread.getName(), StreamThread.State.PENDING_SHUTDOWN);\n            } else {\n                numLiveThreads.incrementAndGet();\n            }\n        });\n        return numLiveThreads.get();\n    }\n}",
        "summary_tokens": [
            "takes",
            "a",
            "snapshot",
            "and",
            "counts",
            "the",
            "number",
            "of",
            "stream",
            "threads",
            "which",
            "are",
            "not",
            "in",
            "pending",
            "shutdown",
            "or",
            "dead"
        ]
    },
    {
        "id": 2484,
        "code": "public synchronized void start() throws IllegalStateException, StreamsException {\n    if (setState(State.REBALANCING)) {\n        log.debug(\"Starting Streams client\");\n\n        if (globalStreamThread != null) {\n            globalStreamThread.start();\n        }\n\n        final int numThreads = processStreamThread(StreamThread::start);\n\n        log.info(\"Started {} stream threads\", numThreads);\n\n        final Long cleanupDelay = applicationConfigs.getLong(StreamsConfig.STATE_CLEANUP_DELAY_MS_CONFIG);\n        stateDirCleaner.scheduleAtFixedRate(() -> {\n                \n            if (state == State.RUNNING) {\n                stateDirectory.cleanRemovedTasks(cleanupDelay);\n            }\n        }, cleanupDelay, cleanupDelay, TimeUnit.MILLISECONDS);\n\n        final long recordingDelay = 0;\n        final long recordingInterval = 1;\n        if (rocksDBMetricsRecordingService != null) {\n            rocksDBMetricsRecordingService.scheduleAtFixedRate(\n                streamsMetrics.rocksDBMetricsRecordingTrigger(),\n                recordingDelay,\n                recordingInterval,\n                TimeUnit.MINUTES\n            );\n        }\n    } else {\n        throw new IllegalStateException(\"The client is either already started or already stopped, cannot re-start\");\n    }\n}",
        "summary_tokens": [
            "start",
            "the",
            "kafka",
            "streams",
            "instance",
            "by",
            "starting",
            "all",
            "its",
            "threads"
        ]
    },
    {
        "id": 2485,
        "code": "public synchronized boolean close(final CloseOptions options) throws IllegalArgumentException {\n    Objects.requireNonNull(options, \"options cannot be null\");\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(options.timeout, \"timeout\");\n    final long timeoutMs = validateMillisecondDuration(options.timeout, msgPrefix);\n    if (timeoutMs < 0) {\n        throw new IllegalArgumentException(\"Timeout can't be negative.\");\n    }\n    log.debug(\"Stopping Streams client with timeoutMillis = {} ms.\", timeoutMs);\n    return close(timeoutMs, options.leaveGroup);\n}",
        "summary_tokens": [
            "shutdown",
            "this",
            "kafka",
            "streams",
            "by",
            "signaling",
            "all",
            "the",
            "threads",
            "to",
            "stop",
            "and",
            "then",
            "wait",
            "up",
            "to",
            "the",
            "timeout",
            "for",
            "the",
            "threads",
            "to",
            "join"
        ]
    },
    {
        "id": 2486,
        "code": "public void cleanUp() {\n    if (!(state.hasNotStarted() || state.hasCompletedShutdown())) {\n        throw new IllegalStateException(\"Cannot clean up while running.\");\n    }\n    stateDirectory.clean();\n}",
        "summary_tokens": [
            "do",
            "a",
            "clean",
            "up",
            "of",
            "the",
            "local",
            "state",
            "store",
            "directory",
            "streams",
            "config",
            "state",
            "dir",
            "config",
            "by",
            "deleting",
            "all",
            "data",
            "with",
            "regard",
            "to",
            "the",
            "streams",
            "config",
            "application",
            "id",
            "config",
            "application",
            "id"
        ]
    },
    {
        "id": 2487,
        "code": "public Collection<org.apache.kafka.streams.state.StreamsMetadata> allMetadata() {\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadata().stream().map(streamsMetadata ->\n            new org.apache.kafka.streams.state.StreamsMetadata(streamsMetadata.hostInfo(),\n                    streamsMetadata.stateStoreNames(),\n                    streamsMetadata.topicPartitions(),\n                    streamsMetadata.standbyStateStoreNames(),\n                    streamsMetadata.standbyTopicPartitions()))\n            .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "find",
            "all",
            "currently",
            "running",
            "kafka",
            "streams",
            "instances",
            "potentially",
            "remotely",
            "that",
            "use",
            "the",
            "same",
            "streams",
            "config",
            "application",
            "id",
            "config",
            "application",
            "id",
            "as",
            "this",
            "instance",
            "i"
        ]
    },
    {
        "id": 2488,
        "code": "public Collection<StreamsMetadata> metadataForAllStreamsClients() {\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadata();\n}",
        "summary_tokens": [
            "find",
            "all",
            "currently",
            "running",
            "kafka",
            "streams",
            "instances",
            "potentially",
            "remotely",
            "that",
            "use",
            "the",
            "same",
            "streams",
            "config",
            "application",
            "id",
            "config",
            "application",
            "id",
            "as",
            "this",
            "instance",
            "i"
        ]
    },
    {
        "id": 2489,
        "code": "public Collection<org.apache.kafka.streams.state.StreamsMetadata> allMetadataForStore(final String storeName) {\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadataForStore(storeName).stream().map(streamsMetadata ->\n            new org.apache.kafka.streams.state.StreamsMetadata(streamsMetadata.hostInfo(),\n                    streamsMetadata.stateStoreNames(),\n                    streamsMetadata.topicPartitions(),\n                    streamsMetadata.standbyStateStoreNames(),\n                    streamsMetadata.standbyTopicPartitions()))\n            .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "find",
            "all",
            "currently",
            "running",
            "kafka",
            "streams",
            "instances",
            "potentially",
            "remotely",
            "that",
            "ul",
            "li",
            "use",
            "the",
            "same",
            "streams",
            "config",
            "application",
            "id",
            "config",
            "application",
            "id",
            "as",
            "this",
            "instance",
            "i"
        ]
    },
    {
        "id": 2490,
        "code": "public Collection<StreamsMetadata> streamsMetadataForStore(final String storeName) {\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadataForStore(storeName);\n}",
        "summary_tokens": [
            "find",
            "all",
            "currently",
            "running",
            "kafka",
            "streams",
            "instances",
            "potentially",
            "remotely",
            "that",
            "ul",
            "li",
            "use",
            "the",
            "same",
            "streams",
            "config",
            "application",
            "id",
            "config",
            "application",
            "id",
            "as",
            "this",
            "instance",
            "i"
        ]
    },
    {
        "id": 2491,
        "code": "public <K> KeyQueryMetadata queryMetadataForKey(final String storeName,\n                                                final K key,\n                                                final StreamPartitioner<? super K, ?> partitioner) {\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getKeyQueryMetadataForKey(storeName, key, partitioner);\n}",
        "summary_tokens": [
            "finds",
            "the",
            "metadata",
            "containing",
            "the",
            "active",
            "hosts",
            "and",
            "standby",
            "hosts",
            "where",
            "the",
            "key",
            "being",
            "queried",
            "would",
            "reside"
        ]
    },
    {
        "id": 2492,
        "code": "public <T> T store(final StoreQueryParameters<T> storeQueryParameters) {\n    validateIsRunningOrRebalancing();\n    final String storeName = storeQueryParameters.storeName();\n    if (!topologyMetadata.hasStore(storeName)) {\n        throw new UnknownStateStoreException(\n            \"Cannot get state store \" + storeName + \" because no such store is registered in the topology.\"\n        );\n    }\n    return queryableStoreProvider.getStore(storeQueryParameters);\n}",
        "summary_tokens": [
            "get",
            "a",
            "facade",
            "wrapping",
            "the",
            "local",
            "state",
            "store",
            "instances",
            "with",
            "the",
            "provided",
            "store",
            "query",
            "parameters"
        ]
    },
    {
        "id": 2493,
        "code": "public void pause() {\n    if (topologyMetadata.hasNamedTopologies()) {\n        for (final NamedTopology namedTopology : topologyMetadata.getAllNamedTopologies()) {\n            topologyMetadata.pauseTopology(namedTopology.name());\n        }\n    } else {\n        topologyMetadata.pauseTopology(UNNAMED_TOPOLOGY);\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "pauses",
            "processing",
            "for",
            "the",
            "kafka",
            "streams",
            "instance"
        ]
    },
    {
        "id": 2494,
        "code": "public boolean isPaused() {\n    if (topologyMetadata.hasNamedTopologies()) {\n        return topologyMetadata.getAllNamedTopologies().stream()\n            .map(NamedTopology::name)\n            .allMatch(topologyMetadata::isPaused);\n    } else {\n        return topologyMetadata.isPaused(UNNAMED_TOPOLOGY);\n    }\n}",
        "summary_tokens": [
            "true",
            "when",
            "the",
            "kafka",
            "streams",
            "instance",
            "has",
            "its",
            "processing",
            "paused"
        ]
    },
    {
        "id": 2495,
        "code": "public void resume() {\n    if (topologyMetadata.hasNamedTopologies()) {\n        for (final NamedTopology namedTopology : topologyMetadata.getAllNamedTopologies()) {\n            topologyMetadata.resumeTopology(namedTopology.name());\n        }\n    } else {\n        topologyMetadata.resumeTopology(UNNAMED_TOPOLOGY);\n    }\n}",
        "summary_tokens": [
            "this",
            "method",
            "resumes",
            "processing",
            "for",
            "the",
            "kafka",
            "streams",
            "instance"
        ]
    },
    {
        "id": 2496,
        "code": "protected int processStreamThread(final Consumer<StreamThread> consumer) {\n    final List<StreamThread> copy = new ArrayList<>(threads);\n    for (final StreamThread thread : copy) consumer.accept(thread);\n\n    return copy.size();\n}",
        "summary_tokens": [
            "handle",
            "each",
            "stream",
            "thread",
            "in",
            "a",
            "snapshot",
            "of",
            "threads"
        ]
    },
    {
        "id": 2497,
        "code": "public Set<org.apache.kafka.streams.processor.ThreadMetadata> localThreadsMetadata() {\n    return metadataForLocalThreads().stream().map(threadMetadata -> new org.apache.kafka.streams.processor.ThreadMetadata(\n            threadMetadata.threadName(),\n            threadMetadata.threadState(),\n            threadMetadata.consumerClientId(),\n            threadMetadata.restoreConsumerClientId(),\n            threadMetadata.producerClientIds(),\n            threadMetadata.adminClientId(),\n            threadMetadata.activeTasks().stream().map(taskMetadata -> new org.apache.kafka.streams.processor.TaskMetadata(\n                    taskMetadata.taskId().toString(),\n                    taskMetadata.topicPartitions(),\n                    taskMetadata.committedOffsets(),\n                    taskMetadata.endOffsets(),\n                    taskMetadata.timeCurrentIdlingStarted())\n            ).collect(Collectors.toSet()),\n            threadMetadata.standbyTasks().stream().map(taskMetadata -> new org.apache.kafka.streams.processor.TaskMetadata(\n                    taskMetadata.taskId().toString(),\n                    taskMetadata.topicPartitions(),\n                    taskMetadata.committedOffsets(),\n                    taskMetadata.endOffsets(),\n                    taskMetadata.timeCurrentIdlingStarted())\n            ).collect(Collectors.toSet())))\n            .collect(Collectors.toSet());\n}",
        "summary_tokens": [
            "returns",
            "runtime",
            "information",
            "about",
            "the",
            "local",
            "threads",
            "of",
            "this",
            "kafka",
            "streams",
            "instance"
        ]
    },
    {
        "id": 2498,
        "code": "public Set<ThreadMetadata> metadataForLocalThreads() {\n    final Set<ThreadMetadata> threadMetadata = new HashSet<>();\n    processStreamThread(thread -> {\n        synchronized (thread.getStateLock()) {\n            if (thread.state() != StreamThread.State.DEAD) {\n                threadMetadata.add(thread.threadMetadata());\n            }\n        }\n    });\n    return threadMetadata;\n}",
        "summary_tokens": [
            "returns",
            "runtime",
            "information",
            "about",
            "the",
            "local",
            "threads",
            "of",
            "this",
            "kafka",
            "streams",
            "instance"
        ]
    },
    {
        "id": 2499,
        "code": "public Map<String, Map<Integer, LagInfo>> allLocalStorePartitionLags() {\n    final List<Task> allTasks = new ArrayList<>();\n    processStreamThread(thread -> allTasks.addAll(thread.allTasks().values()));\n    return allLocalStorePartitionLags(allTasks);\n}",
        "summary_tokens": [
            "returns",
            "lag",
            "info",
            "for",
            "all",
            "store",
            "partitions",
            "active",
            "or",
            "standby",
            "local",
            "to",
            "this",
            "streams",
            "instance"
        ]
    },
    {
        "id": 2500,
        "code": "public <R> StateQueryResult<R> query(final StateQueryRequest<R> request) {\n    final String storeName = request.getStoreName();\n    if (!topologyMetadata.hasStore(storeName)) {\n        throw new UnknownStateStoreException(\n            \"Cannot get state store \"\n                + storeName\n                + \" because no such store is registered in the topology.\"\n        );\n    }\n    if (state().hasNotStarted()) {\n        throw new StreamsNotStartedException(\n            \"KafkaStreams has not been started, you can retry after calling start().\"\n        );\n    }\n    if (state().isShuttingDown() || state.hasCompletedShutdown()) {\n        throw new StreamsStoppedException(\n            \"KafkaStreams has been stopped (\" + state + \").\"\n                + \" This instance can no longer serve queries.\"\n        );\n    }\n    final StateQueryResult<R> result = new StateQueryResult<>();\n\n    final Map<String, StateStore> globalStateStores = topologyMetadata.globalStateStores();\n    if (globalStateStores.containsKey(storeName)) {\n            \n        result.setGlobalResult(\n            QueryResult.forFailure(\n                FailureReason.UNKNOWN_QUERY_TYPE,\n                \"Global stores do not yet support the KafkaStreams#query API. Use KafkaStreams#store instead.\"\n            )\n        );\n    } else {\n        for (final StreamThread thread : threads) {\n            final Map<TaskId, Task> tasks = thread.allTasks();\n            for (final Entry<TaskId, Task> entry : tasks.entrySet()) {\n\n                final TaskId taskId = entry.getKey();\n                final int partition = taskId.partition();\n                if (request.isAllPartitions()\n                    || request.getPartitions().contains(partition)) {\n                    final Task task = entry.getValue();\n                    final StateStore store = task.getStore(storeName);\n                    if (store != null) {\n                        final StreamThread.State state = thread.state();\n                        final boolean active = task.isActive();\n                        if (request.isRequireActive()\n                            && (state != StreamThread.State.RUNNING\n                            || !active)) {\n                            result.addResult(\n                                partition,\n                                QueryResult.forFailure(\n                                    FailureReason.NOT_ACTIVE,\n                                    \"Query requires a running active task,\"\n                                        + \" but partition was in state \"\n                                        + state + \" and was \"\n                                        + (active ? \"active\" : \"not active\") + \".\"\n                                )\n                            );\n                        } else {\n                            final QueryResult<R> r = store.query(\n                                request.getQuery(),\n                                request.isRequireActive()\n                                    ? PositionBound.unbounded()\n                                    : request.getPositionBound(),\n                                new QueryConfig(request.executionInfoEnabled())\n                            );\n                            result.addResult(partition, r);\n                        }\n\n\n                            \n                            \n                        if (!request.isAllPartitions()\n                            && result.getPartitionResults().keySet().containsAll(request.getPartitions())) {\n                            return result;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    if (!request.isAllPartitions()) {\n        for (final Integer partition : request.getPartitions()) {\n            if (!result.getPartitionResults().containsKey(partition)) {\n                result.addResult(partition, QueryResult.forFailure(\n                    FailureReason.NOT_PRESENT,\n                    \"The requested partition was not present at the time of the query.\"\n                ));\n            }\n        }\n    }\n\n    return result;\n}",
        "summary_tokens": [
            "run",
            "an",
            "interactive",
            "query",
            "against",
            "a",
            "state",
            "store"
        ]
    },
    {
        "id": 2501,
        "code": "public HostInfo getActiveHost() {\n    return activeHost;\n}",
        "summary_tokens": [
            "get",
            "the",
            "active",
            "kafka",
            "streams",
            "instance",
            "for",
            "given",
            "key"
        ]
    },
    {
        "id": 2502,
        "code": "public Set<HostInfo> getStandbyHosts() {\n    return standbyHosts;\n}",
        "summary_tokens": [
            "get",
            "the",
            "kafka",
            "streams",
            "instances",
            "that",
            "host",
            "the",
            "key",
            "as",
            "standbys"
        ]
    },
    {
        "id": 2503,
        "code": "public int getPartition() {\n    return partition;\n}",
        "summary_tokens": [
            "get",
            "the",
            "store",
            "partition",
            "corresponding",
            "to",
            "the",
            "key"
        ]
    },
    {
        "id": 2504,
        "code": "public HostInfo activeHost() {\n    return activeHost;\n}",
        "summary_tokens": [
            "get",
            "the",
            "active",
            "kafka",
            "streams",
            "instance",
            "for",
            "given",
            "key"
        ]
    },
    {
        "id": 2505,
        "code": "public Set<HostInfo> standbyHosts() {\n    return standbyHosts;\n}",
        "summary_tokens": [
            "get",
            "the",
            "kafka",
            "streams",
            "instances",
            "that",
            "host",
            "the",
            "key",
            "as",
            "standbys"
        ]
    },
    {
        "id": 2506,
        "code": "public int partition() {\n    return partition;\n}",
        "summary_tokens": [
            "get",
            "the",
            "store",
            "partition",
            "corresponding",
            "to",
            "the",
            "key"
        ]
    },
    {
        "id": 2507,
        "code": "public static <K, V> KeyValue<K, V> pair(final K key, final V value) {\n    return new KeyValue<>(key, value);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "key",
            "value",
            "pair"
        ]
    },
    {
        "id": 2508,
        "code": "public long currentOffsetPosition() {\n    return this.currentOffsetPosition;\n}",
        "summary_tokens": [
            "get",
            "the",
            "current",
            "maximum",
            "offset",
            "on",
            "the",
            "store",
            "partition",
            "s",
            "changelog",
            "topic",
            "that",
            "has",
            "been",
            "successfully",
            "written",
            "into",
            "the",
            "store",
            "partition",
            "s",
            "state",
            "store"
        ]
    },
    {
        "id": 2509,
        "code": "public long endOffsetPosition() {\n    return this.endOffsetPosition;\n}",
        "summary_tokens": [
            "get",
            "the",
            "end",
            "offset",
            "position",
            "for",
            "this",
            "store",
            "partition",
            "s",
            "changelog",
            "topic",
            "on",
            "the",
            "kafka",
            "brokers"
        ]
    },
    {
        "id": 2510,
        "code": "public long offsetLag() {\n    return this.offsetLag;\n}",
        "summary_tokens": [
            "get",
            "the",
            "measured",
            "lag",
            "between",
            "current",
            "and",
            "end",
            "offset",
            "positions",
            "for",
            "this",
            "store",
            "partition",
            "replica"
        ]
    },
    {
        "id": 2511,
        "code": "public StoreQueryParameters<T> withPartition(final Integer partition) {\n    return new StoreQueryParameters<>(storeName, queryableStoreType, partition, staleStores);\n}",
        "summary_tokens": [
            "set",
            "a",
            "specific",
            "partition",
            "that",
            "should",
            "be",
            "queried",
            "exclusively"
        ]
    },
    {
        "id": 2512,
        "code": "public StoreQueryParameters<T> enableStaleStores() {\n    return new StoreQueryParameters<>(storeName, queryableStoreType, partition, true);\n}",
        "summary_tokens": [
            "enable",
            "querying",
            "of",
            "stale",
            "state",
            "stores",
            "i"
        ]
    },
    {
        "id": 2513,
        "code": "public String storeName() {\n    return storeName;\n}",
        "summary_tokens": [
            "get",
            "the",
            "name",
            "of",
            "the",
            "state",
            "store",
            "that",
            "should",
            "be",
            "queried"
        ]
    },
    {
        "id": 2514,
        "code": "public QueryableStoreType<T> queryableStoreType() {\n    return queryableStoreType;\n}",
        "summary_tokens": [
            "get",
            "the",
            "queryable",
            "store",
            "type",
            "for",
            "which",
            "key",
            "is",
            "queried",
            "by",
            "the",
            "user"
        ]
    },
    {
        "id": 2515,
        "code": "public Integer partition() {\n    return partition;\n}",
        "summary_tokens": [
            "get",
            "the",
            "store",
            "partition",
            "that",
            "will",
            "be",
            "queried"
        ]
    },
    {
        "id": 2516,
        "code": "public boolean staleStoresEnabled() {\n    return staleStores;\n}",
        "summary_tokens": [
            "get",
            "the",
            "flag",
            "stale",
            "stores"
        ]
    },
    {
        "id": 2517,
        "code": "public synchronized <K, V> KStream<K, V> stream(final Pattern topicPattern,\n                                                final Consumed<K, V> consumed) {\n    Objects.requireNonNull(topicPattern, \"topicPattern can't be null\");\n    Objects.requireNonNull(consumed, \"consumed can't be null\");\n    return internalStreamsBuilder.stream(topicPattern, new ConsumedInternal<>(consumed));\n}",
        "summary_tokens": [
            "create",
            "a",
            "kstream",
            "from",
            "the",
            "specified",
            "topic",
            "pattern"
        ]
    },
    {
        "id": 2518,
        "code": "public synchronized <K, V> KTable<K, V> table(final String topic,\n                                              final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized) {\n    Objects.requireNonNull(topic, \"topic can't be null\");\n    Objects.requireNonNull(materialized, \"materialized can't be null\");\n\n    final MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>> materializedInternal =\n        new MaterializedInternal<>(materialized, internalStreamsBuilder, topic + \"-\");\n\n    final ConsumedInternal<K, V> consumedInternal =\n            new ConsumedInternal<>(Consumed.with(materializedInternal.keySerde(), materializedInternal.valueSerde()));\n\n    return internalStreamsBuilder.table(topic, consumedInternal, materializedInternal);\n}",
        "summary_tokens": [
            "create",
            "a",
            "ktable",
            "for",
            "the",
            "specified",
            "topic"
        ]
    },
    {
        "id": 2519,
        "code": "public synchronized <K, V> GlobalKTable<K, V> globalTable(final String topic,\n                                                          final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized) {\n    Objects.requireNonNull(topic, \"topic can't be null\");\n    Objects.requireNonNull(materialized, \"materialized can't be null\");\n    final MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>> materializedInternal =\n        new MaterializedInternal<>(materialized, internalStreamsBuilder, topic + \"-\");\n\n    return internalStreamsBuilder.globalTable(topic,\n                                              new ConsumedInternal<>(Consumed.with(materializedInternal.keySerde(),\n                                                                                   materializedInternal.valueSerde())),\n                                              materializedInternal);\n}",
        "summary_tokens": [
            "create",
            "a",
            "global",
            "ktable",
            "for",
            "the",
            "specified",
            "topic"
        ]
    },
    {
        "id": 2520,
        "code": "public synchronized StreamsBuilder addStateStore(final StoreBuilder<?> builder) {\n    Objects.requireNonNull(builder, \"builder can't be null\");\n    internalStreamsBuilder.addStateStore(builder);\n    return this;\n}",
        "summary_tokens": [
            "adds",
            "a",
            "state",
            "store",
            "to",
            "the",
            "underlying",
            "topology"
        ]
    },
    {
        "id": 2521,
        "code": "public synchronized <KIn, VIn> StreamsBuilder addGlobalStore(final StoreBuilder<?> storeBuilder,\n                                                             final String topic,\n                                                             final Consumed<KIn, VIn> consumed,\n                                                             final ProcessorSupplier<KIn, VIn, Void, Void> stateUpdateSupplier) {\n    Objects.requireNonNull(storeBuilder, \"storeBuilder can't be null\");\n    Objects.requireNonNull(consumed, \"consumed can't be null\");\n    internalStreamsBuilder.addGlobalStore(\n        storeBuilder,\n        topic,\n        new ConsumedInternal<>(consumed),\n        stateUpdateSupplier\n    );\n    return this;\n}",
        "summary_tokens": [
            "adds",
            "a",
            "global",
            "state",
            "store",
            "to",
            "the",
            "topology"
        ]
    },
    {
        "id": 2522,
        "code": "public synchronized Topology build(final Properties props) {\n    final boolean optimizeTopology =\n        props != null &&\n        StreamsConfig.OPTIMIZE.equals(props.getProperty(StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG));\n\n    internalStreamsBuilder.buildAndOptimizeTopology(optimizeTopology);\n    return topology;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "topology",
            "that",
            "represents",
            "the",
            "specified",
            "processing",
            "logic",
            "and",
            "accepts",
            "a",
            "properties",
            "instance",
            "used",
            "to",
            "indicate",
            "whether",
            "to",
            "optimize",
            "topology",
            "or",
            "not"
        ]
    },
    {
        "id": 2523,
        "code": "public static String consumerPrefix(final String consumerProp) {\n    return CONSUMER_PREFIX + consumerProp;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "property",
            "with",
            "consumer",
            "prefix"
        ]
    },
    {
        "id": 2524,
        "code": "public static String mainConsumerPrefix(final String consumerProp) {\n    return MAIN_CONSUMER_PREFIX + consumerProp;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "property",
            "with",
            "main",
            "consumer",
            "prefix"
        ]
    },
    {
        "id": 2525,
        "code": "public static String restoreConsumerPrefix(final String consumerProp) {\n    return RESTORE_CONSUMER_PREFIX + consumerProp;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "property",
            "with",
            "restore",
            "consumer",
            "prefix"
        ]
    },
    {
        "id": 2526,
        "code": "public static String clientTagPrefix(final String clientTagKey) {\n    return CLIENT_TAG_PREFIX + clientTagKey;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "client",
            "tag",
            "key",
            "with",
            "client",
            "tag",
            "prefix"
        ]
    },
    {
        "id": 2527,
        "code": "public static String globalConsumerPrefix(final String consumerProp) {\n    return GLOBAL_CONSUMER_PREFIX + consumerProp;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "property",
            "with",
            "global",
            "consumer",
            "prefix"
        ]
    },
    {
        "id": 2528,
        "code": "public static String producerPrefix(final String producerProp) {\n    return PRODUCER_PREFIX + producerProp;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "property",
            "with",
            "producer",
            "prefix"
        ]
    },
    {
        "id": 2529,
        "code": "public static String adminClientPrefix(final String adminClientProp) {\n    return ADMIN_CLIENT_PREFIX + adminClientProp;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "property",
            "with",
            "admin",
            "client",
            "prefix"
        ]
    },
    {
        "id": 2530,
        "code": "public static String topicPrefix(final String topicProp) {\n    return TOPIC_PREFIX + topicProp;\n}",
        "summary_tokens": [
            "prefix",
            "a",
            "property",
            "with",
            "topic",
            "prefix",
            "used",
            "to",
            "provide",
            "default",
            "topic",
            "configs",
            "to",
            "be",
            "applied",
            "when",
            "creating",
            "internal",
            "topics"
        ]
    },
    {
        "id": 2531,
        "code": "public static ConfigDef configDef() {\n    return new ConfigDef(CONFIG);\n}",
        "summary_tokens": [
            "return",
            "a",
            "copy",
            "of",
            "the",
            "config",
            "definition"
        ]
    },
    {
        "id": 2532,
        "code": "public Map<String, Object> getMainConsumerConfigs(final String groupId, final String clientId, final int threadIdx) {\n    final Map<String, Object> consumerProps = getCommonConsumerConfigs();\n\n        \n    final Map<String, Object> mainConsumerProps = originalsWithPrefix(MAIN_CONSUMER_PREFIX);\n    for (final Map.Entry<String, Object> entry: mainConsumerProps.entrySet()) {\n        consumerProps.put(entry.getKey(), entry.getValue());\n    }\n\n        \n    consumerProps.put(APPLICATION_ID_CONFIG, groupId);\n\n        \n    consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n    consumerProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId);\n    final String groupInstanceId = (String) consumerProps.get(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG);\n        \n    if (groupInstanceId != null) {\n        consumerProps.put(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG, groupInstanceId + \"-\" + threadIdx);\n    }\n\n        \n    consumerProps.put(UPGRADE_FROM_CONFIG, getString(UPGRADE_FROM_CONFIG));\n    consumerProps.put(REPLICATION_FACTOR_CONFIG, getInt(REPLICATION_FACTOR_CONFIG));\n    consumerProps.put(APPLICATION_SERVER_CONFIG, getString(APPLICATION_SERVER_CONFIG));\n    consumerProps.put(NUM_STANDBY_REPLICAS_CONFIG, getInt(NUM_STANDBY_REPLICAS_CONFIG));\n    consumerProps.put(ACCEPTABLE_RECOVERY_LAG_CONFIG, getLong(ACCEPTABLE_RECOVERY_LAG_CONFIG));\n    consumerProps.put(MAX_WARMUP_REPLICAS_CONFIG, getInt(MAX_WARMUP_REPLICAS_CONFIG));\n    consumerProps.put(PROBING_REBALANCE_INTERVAL_MS_CONFIG, getLong(PROBING_REBALANCE_INTERVAL_MS_CONFIG));\n    consumerProps.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, StreamsPartitionAssignor.class.getName());\n    consumerProps.put(WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG, getLong(WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG));\n    consumerProps.put(RACK_AWARE_ASSIGNMENT_TAGS_CONFIG, getList(RACK_AWARE_ASSIGNMENT_TAGS_CONFIG));\n\n        \n    consumerProps.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, \"false\");\n\n        \n    final Map<String, Object> topicProps = originalsWithPrefix(TOPIC_PREFIX, false);\n    final Map<String, Object> producerProps = getClientPropsWithPrefix(PRODUCER_PREFIX, ProducerConfig.configNames());\n\n    if (topicProps.containsKey(topicPrefix(TopicConfig.SEGMENT_BYTES_CONFIG)) &&\n        producerProps.containsKey(ProducerConfig.BATCH_SIZE_CONFIG)) {\n        final int segmentSize = Integer.parseInt(topicProps.get(topicPrefix(TopicConfig.SEGMENT_BYTES_CONFIG)).toString());\n        final int batchSize = Integer.parseInt(producerProps.get(ProducerConfig.BATCH_SIZE_CONFIG).toString());\n\n        if (segmentSize < batchSize) {\n            throw new IllegalArgumentException(String.format(\"Specified topic segment size %d is is smaller than the configured producer batch size %d, this will cause produced batch not able to be appended to the topic\",\n                    segmentSize,\n                    batchSize));\n        }\n    }\n\n    consumerProps.putAll(topicProps);\n\n    return consumerProps;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configs",
            "to",
            "the",
            "kafka",
            "consumer",
            "main",
            "consumer"
        ]
    },
    {
        "id": 2533,
        "code": "public Map<String, Object> getRestoreConsumerConfigs(final String clientId) {\n    final Map<String, Object> baseConsumerProps = getCommonConsumerConfigs();\n\n        \n    final Map<String, Object> restoreConsumerProps = originalsWithPrefix(RESTORE_CONSUMER_PREFIX);\n    for (final Map.Entry<String, Object> entry: restoreConsumerProps.entrySet()) {\n        baseConsumerProps.put(entry.getKey(), entry.getValue());\n    }\n\n        \n    baseConsumerProps.remove(ConsumerConfig.GROUP_ID_CONFIG);\n        \n    baseConsumerProps.remove(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG);\n\n        \n    baseConsumerProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId);\n    baseConsumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"none\");\n\n    return baseConsumerProps;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configs",
            "for",
            "the",
            "kafka",
            "consumer",
            "restore",
            "consumer"
        ]
    },
    {
        "id": 2534,
        "code": "public Map<String, Object> getGlobalConsumerConfigs(final String clientId) {\n    final Map<String, Object> baseConsumerProps = getCommonConsumerConfigs();\n\n        \n    final Map<String, Object> globalConsumerProps = originalsWithPrefix(GLOBAL_CONSUMER_PREFIX);\n    for (final Map.Entry<String, Object> entry: globalConsumerProps.entrySet()) {\n        baseConsumerProps.put(entry.getKey(), entry.getValue());\n    }\n\n        \n    baseConsumerProps.remove(ConsumerConfig.GROUP_ID_CONFIG);\n        \n    baseConsumerProps.remove(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG);\n\n        \n    baseConsumerProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId + \"-global-consumer\");\n    baseConsumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"none\");\n\n    return baseConsumerProps;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configs",
            "for",
            "the",
            "kafka",
            "consumer",
            "global",
            "consumer"
        ]
    },
    {
        "id": 2535,
        "code": "public Map<String, Object> getProducerConfigs(final String clientId) {\n    final Map<String, Object> clientProvidedProps = getClientPropsWithPrefix(PRODUCER_PREFIX, ProducerConfig.configNames());\n\n    checkIfUnexpectedUserSpecifiedConsumerConfig(clientProvidedProps, NON_CONFIGURABLE_PRODUCER_EOS_CONFIGS);\n\n        \n    final Map<String, Object> props = new HashMap<>(eosEnabled ? PRODUCER_EOS_OVERRIDES : PRODUCER_DEFAULT_OVERRIDES);\n    props.putAll(getClientCustomProps());\n    props.putAll(clientProvidedProps);\n\n        \n    if (StreamsConfigUtils.processingMode(this) == StreamsConfigUtils.ProcessingMode.EXACTLY_ONCE_ALPHA) {\n        props.put(\"internal.auto.downgrade.txn.commit\", true);\n    }\n\n    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, originals().get(BOOTSTRAP_SERVERS_CONFIG));\n        \n    props.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId);\n\n    return props;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configs",
            "for",
            "the",
            "kafka",
            "producer",
            "producer"
        ]
    },
    {
        "id": 2536,
        "code": "public Map<String, Object> getAdminConfigs(final String clientId) {\n    final Map<String, Object> clientProvidedProps = getClientPropsWithPrefix(ADMIN_CLIENT_PREFIX, AdminClientConfig.configNames());\n\n    final Map<String, Object> props = new HashMap<>();\n    props.putAll(getClientCustomProps());\n    props.putAll(clientProvidedProps);\n\n        \n    props.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId);\n\n    return props;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configs",
            "for",
            "the",
            "admin",
            "admin",
            "client"
        ]
    },
    {
        "id": 2537,
        "code": "public Map<String, String> getClientTags() {\n    return originalsWithPrefix(CLIENT_TAG_PREFIX).entrySet().stream().collect(\n        Collectors.toMap(\n            Map.Entry::getKey,\n            tagEntry -> Objects.toString(tagEntry.getValue())\n        )\n    );\n}",
        "summary_tokens": [
            "get",
            "the",
            "configured",
            "client",
            "tags",
            "set",
            "with",
            "client",
            "tag",
            "prefix",
            "prefix"
        ]
    },
    {
        "id": 2538,
        "code": "private Map<String, Object> getClientCustomProps() {\n    final Map<String, Object> props = originals();\n    props.keySet().removeAll(CONFIG.names());\n    props.keySet().removeAll(ConsumerConfig.configNames());\n    props.keySet().removeAll(ProducerConfig.configNames());\n    props.keySet().removeAll(AdminClientConfig.configNames());\n    props.keySet().removeAll(originalsWithPrefix(CONSUMER_PREFIX, false).keySet());\n    props.keySet().removeAll(originalsWithPrefix(PRODUCER_PREFIX, false).keySet());\n    props.keySet().removeAll(originalsWithPrefix(ADMIN_CLIENT_PREFIX, false).keySet());\n    return props;\n}",
        "summary_tokens": [
            "get",
            "a",
            "map",
            "of",
            "custom",
            "configs",
            "by",
            "removing",
            "from",
            "the",
            "originals",
            "all",
            "the",
            "streams",
            "consumer",
            "producer",
            "and",
            "admin",
            "client",
            "configs"
        ]
    },
    {
        "id": 2539,
        "code": "public Serde defaultKeySerde() {\n    final Object keySerdeConfigSetting = get(DEFAULT_KEY_SERDE_CLASS_CONFIG);\n    if (keySerdeConfigSetting ==  null) {\n        throw new ConfigException(\"Please specify a key serde or set one through StreamsConfig#DEFAULT_KEY_SERDE_CLASS_CONFIG\");\n    }\n    try {\n        final Serde<?> serde = getConfiguredInstance(DEFAULT_KEY_SERDE_CLASS_CONFIG, Serde.class);\n        serde.configure(originals(), true);\n        return serde;\n    } catch (final Exception e) {\n        throw new StreamsException(\n            String.format(\"Failed to configure key serde %s\", keySerdeConfigSetting), e);\n    }\n}",
        "summary_tokens": [
            "return",
            "an",
            "serde",
            "configure",
            "map",
            "boolean",
            "configured",
            "instance",
            "of",
            "default",
            "key",
            "serde",
            "class",
            "config",
            "key",
            "serde",
            "class"
        ]
    },
    {
        "id": 2540,
        "code": "public Serde defaultValueSerde() {\n    final Object valueSerdeConfigSetting = get(DEFAULT_VALUE_SERDE_CLASS_CONFIG);\n    if (valueSerdeConfigSetting == null) {\n        throw new ConfigException(\"Please specify a value serde or set one through StreamsConfig#DEFAULT_VALUE_SERDE_CLASS_CONFIG\");\n    }\n    try {\n        final Serde<?> serde = getConfiguredInstance(DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serde.class);\n        serde.configure(originals(), false);\n        return serde;\n    } catch (final Exception e) {\n        throw new StreamsException(\n            String.format(\"Failed to configure value serde %s\", valueSerdeConfigSetting), e);\n    }\n}",
        "summary_tokens": [
            "return",
            "an",
            "serde",
            "configure",
            "map",
            "boolean",
            "configured",
            "instance",
            "of",
            "default",
            "value",
            "serde",
            "class",
            "config",
            "value",
            "serde",
            "class"
        ]
    },
    {
        "id": 2541,
        "code": "private Map<String, Object> clientProps(final Set<String> configNames,\n                                        final Map<String, Object> originals) {\n        \n        \n    final Map<String, Object> parsed = new HashMap<>();\n    for (final String configName: configNames) {\n        if (originals.containsKey(configName)) {\n            parsed.put(configName, originals.get(configName));\n        }\n    }\n\n    return parsed;\n}",
        "summary_tokens": [
            "override",
            "any",
            "client",
            "properties",
            "in",
            "the",
            "original",
            "configs",
            "with",
            "overrides"
        ]
    },
    {
        "id": 2542,
        "code": "public synchronized Topology addSource(final AutoOffsetReset offsetReset,\n                                       final String name,\n                                       final TimestampExtractor timestampExtractor,\n                                       final Deserializer<?> keyDeserializer,\n                                       final Deserializer<?> valueDeserializer,\n                                       final Pattern topicPattern) {\n    internalTopologyBuilder.addSource(offsetReset, name, timestampExtractor, keyDeserializer, valueDeserializer, topicPattern);\n    return this;\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "source",
            "that",
            "consumes",
            "from",
            "topics",
            "matching",
            "the",
            "given",
            "pattern",
            "and",
            "forwards",
            "the",
            "records",
            "to",
            "child",
            "processor",
            "and",
            "or",
            "sink",
            "nodes"
        ]
    },
    {
        "id": 2543,
        "code": "public synchronized <K, V> Topology addSink(final String name,\n                                            final TopicNameExtractor<K, V> topicExtractor,\n                                            final Serializer<K> keySerializer,\n                                            final Serializer<V> valueSerializer,\n                                            final StreamPartitioner<? super K, ? super V> partitioner,\n                                            final String... parentNames) {\n    internalTopologyBuilder.addSink(name, topicExtractor, keySerializer, valueSerializer, partitioner, parentNames);\n    return this;\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "sink",
            "that",
            "forwards",
            "records",
            "from",
            "upstream",
            "parent",
            "processor",
            "and",
            "or",
            "source",
            "nodes",
            "to",
            "kafka",
            "topics",
            "based",
            "on",
            "topic",
            "extractor"
        ]
    },
    {
        "id": 2544,
        "code": "public synchronized <KIn, VIn, KOut, VOut> Topology addProcessor(final String name,\n                                                                 final ProcessorSupplier<KIn, VIn, KOut, VOut> supplier,\n                                                                 final String... parentNames) {\n    internalTopologyBuilder.addProcessor(name, supplier, parentNames);\n    final Set<StoreBuilder<?>> stores = supplier.stores();\n    if (stores != null) {\n        for (final StoreBuilder storeBuilder : stores) {\n            internalTopologyBuilder.addStateStore(storeBuilder, name);\n        }\n    }\n    return this;\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "processor",
            "node",
            "that",
            "receives",
            "and",
            "processes",
            "records",
            "output",
            "by",
            "one",
            "or",
            "more",
            "parent",
            "source",
            "or",
            "processor",
            "node"
        ]
    },
    {
        "id": 2545,
        "code": "public synchronized Topology addStateStore(final StoreBuilder<?> storeBuilder,\n                                           final String... processorNames) {\n    internalTopologyBuilder.addStateStore(storeBuilder, processorNames);\n    return this;\n}",
        "summary_tokens": [
            "adds",
            "a",
            "state",
            "store"
        ]
    },
    {
        "id": 2546,
        "code": "public synchronized <KIn, VIn> Topology addGlobalStore(final StoreBuilder<?> storeBuilder,\n                                                       final String sourceName,\n                                                       final TimestampExtractor timestampExtractor,\n                                                       final Deserializer<KIn> keyDeserializer,\n                                                       final Deserializer<VIn> valueDeserializer,\n                                                       final String topic,\n                                                       final String processorName,\n                                                       final ProcessorSupplier<KIn, VIn, Void, Void> stateUpdateSupplier) {\n    internalTopologyBuilder.addGlobalStore(\n        storeBuilder,\n        sourceName,\n        timestampExtractor,\n        keyDeserializer,\n        valueDeserializer,\n        topic,\n        processorName,\n        stateUpdateSupplier\n    );\n    return this;\n}",
        "summary_tokens": [
            "adds",
            "a",
            "global",
            "state",
            "store",
            "to",
            "the",
            "topology"
        ]
    },
    {
        "id": 2547,
        "code": "public synchronized Topology connectProcessorAndStateStores(final String processorName,\n                                                            final String... stateStoreNames) {\n    internalTopologyBuilder.connectProcessorAndStateStores(processorName, stateStoreNames);\n    return this;\n}",
        "summary_tokens": [
            "connects",
            "the",
            "processor",
            "and",
            "the",
            "state",
            "stores"
        ]
    },
    {
        "id": 2548,
        "code": "public synchronized TopologyDescription describe() {\n    return internalTopologyBuilder.describe();\n}",
        "summary_tokens": [
            "returns",
            "a",
            "description",
            "of",
            "the",
            "specified",
            "topology"
        ]
    },
    {
        "id": 2549,
        "code": "private boolean isTopologyOverride(final String config, final Properties topologyOverrides) {\n        \n        \n    return topologyName != null && topologyOverrides.containsKey(config);\n}",
        "summary_tokens": [
            "true",
            "if",
            "there",
            "is",
            "an",
            "override",
            "for",
            "this",
            "config",
            "in",
            "the",
            "properties",
            "of",
            "this",
            "named",
            "topology"
        ]
    },
    {
        "id": 2550,
        "code": "public Optional<TaskId> taskId() {\n    return Optional.ofNullable(taskId);\n}",
        "summary_tokens": [
            "the",
            "task",
            "id",
            "that",
            "this",
            "exception",
            "originated",
            "from",
            "or",
            "optional",
            "empty",
            "if",
            "the",
            "exception",
            "cannot",
            "be",
            "traced",
            "back",
            "to",
            "a",
            "particular",
            "task"
        ]
    },
    {
        "id": 2551,
        "code": "public static long validateMillisecondDuration(final Duration duration, final String messagePrefix) {\n    try {\n        if (duration == null) {\n            throw new IllegalArgumentException(messagePrefix + VALIDATE_MILLISECOND_NULL_SUFFIX);\n        }\n\n        return duration.toMillis();\n    } catch (final ArithmeticException e) {\n        throw new IllegalArgumentException(messagePrefix + VALIDATE_MILLISECOND_OVERFLOW_SUFFIX, e);\n    }\n}",
        "summary_tokens": [
            "validates",
            "that",
            "milliseconds",
            "from",
            "duration",
            "can",
            "be",
            "retrieved"
        ]
    },
    {
        "id": 2552,
        "code": "public static long validateMillisecondInstant(final Instant instant, final String messagePrefix) {\n    try {\n        if (instant == null) {\n            throw new IllegalArgumentException(messagePrefix + VALIDATE_MILLISECOND_NULL_SUFFIX);\n        }\n\n        return instant.toEpochMilli();\n    } catch (final ArithmeticException e) {\n        throw new IllegalArgumentException(messagePrefix + VALIDATE_MILLISECOND_OVERFLOW_SUFFIX, e);\n    }\n}",
        "summary_tokens": [
            "validates",
            "that",
            "milliseconds",
            "from",
            "instant",
            "can",
            "be",
            "retrieved"
        ]
    },
    {
        "id": 2553,
        "code": "public static String prepareMillisCheckFailMsgPrefix(final Object value, final String name) {\n    return format(MILLISECOND_VALIDATION_FAIL_MSG_FRMT, name, value);\n}",
        "summary_tokens": [
            "generates",
            "the",
            "prefix",
            "message",
            "for",
            "validate",
            "millisecond",
            "xxxxxx",
            "utility",
            "value",
            "object",
            "to",
            "be",
            "converted",
            "to",
            "milliseconds",
            "name",
            "object",
            "name",
            "error",
            "message",
            "prefix",
            "to",
            "use",
            "in",
            "exception"
        ]
    },
    {
        "id": 2554,
        "code": "public static <VR, V> void checkSupplier(final ValueTransformerSupplier<V, VR> supplier) {\n    if (supplier.get() == supplier.get()) {\n        final String supplierClass = supplier.getClass().getName();\n        throw new IllegalArgumentException(String.format(\"%s generates single reference.\" +\n                \" %s#get() must return a new object each time it is called.\", supplierClass, supplierClass));\n    }\n}",
        "summary_tokens": [
            "illegal",
            "argument",
            "exception",
            "if",
            "the",
            "same",
            "instance",
            "is",
            "obtained",
            "each",
            "time"
        ]
    },
    {
        "id": 2555,
        "code": "public static <K, V> Branched<K, V> as(final String name) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    return new Branched<>(name, null, null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "branched",
            "with",
            "provided",
            "branch",
            "name",
            "suffix"
        ]
    },
    {
        "id": 2556,
        "code": "public static <K, V> Branched<K, V> withFunction(\n        final Function<? super KStream<K, V>, ? extends KStream<K, V>> chain, final String name) {\n    Objects.requireNonNull(chain, \"chain function cannot be null\");\n    return new Branched<>(name, chain, null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "branched",
            "with",
            "provided",
            "chain",
            "function",
            "and",
            "branch",
            "name",
            "suffix"
        ]
    },
    {
        "id": 2557,
        "code": "public static <K, V> Branched<K, V> withConsumer(final Consumer<? super KStream<K, V>> chain,\n                                                 final String name) {\n    Objects.requireNonNull(chain, \"chain consumer cannot be null\");\n    return new Branched<>(name, null, chain);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "branched",
            "with",
            "provided",
            "chain",
            "consumer",
            "and",
            "branch",
            "name",
            "suffix"
        ]
    },
    {
        "id": 2558,
        "code": "public Branched<K, V> withName(final String name) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    return new Branched<>(name, chainFunction, chainConsumer);\n}",
        "summary_tokens": [
            "configure",
            "the",
            "instance",
            "of",
            "branched",
            "with",
            "a",
            "branch",
            "name",
            "suffix"
        ]
    },
    {
        "id": 2559,
        "code": "public static <K, V> Consumed<K, V> with(final Topology.AutoOffsetReset resetPolicy) {\n    return new Consumed<>(null, null, null, resetPolicy, null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "consumed",
            "with",
            "a",
            "org"
        ]
    },
    {
        "id": 2560,
        "code": "public static <K, V> Consumed<K, V> as(final String processorName) {\n    return new Consumed<>(null, null, null, null, processorName);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "consumed",
            "with",
            "provided",
            "processor",
            "name"
        ]
    },
    {
        "id": 2561,
        "code": "public Consumed<K, V> withKeySerde(final Serde<K> keySerde) {\n    this.keySerde = keySerde;\n    return this;\n}",
        "summary_tokens": [
            "configure",
            "the",
            "instance",
            "of",
            "consumed",
            "with",
            "a",
            "key",
            "serde"
        ]
    },
    {
        "id": 2562,
        "code": "public Consumed<K, V> withValueSerde(final Serde<V> valueSerde) {\n    this.valueSerde = valueSerde;\n    return this;\n}",
        "summary_tokens": [
            "configure",
            "the",
            "instance",
            "of",
            "consumed",
            "with",
            "a",
            "value",
            "serde"
        ]
    },
    {
        "id": 2563,
        "code": "public Consumed<K, V> withTimestampExtractor(final TimestampExtractor timestampExtractor) {\n    this.timestampExtractor = timestampExtractor;\n    return this;\n}",
        "summary_tokens": [
            "configure",
            "the",
            "instance",
            "of",
            "consumed",
            "with",
            "a",
            "timestamp",
            "extractor"
        ]
    },
    {
        "id": 2564,
        "code": "public Consumed<K, V> withOffsetResetPolicy(final Topology.AutoOffsetReset resetPolicy) {\n    this.resetPolicy = resetPolicy;\n    return this;\n}",
        "summary_tokens": [
            "configure",
            "the",
            "instance",
            "of",
            "consumed",
            "with",
            "a",
            "org"
        ]
    },
    {
        "id": 2565,
        "code": "public Consumed<K, V> withName(final String processorName) {\n    this.processorName = processorName;\n    return this;\n}",
        "summary_tokens": [
            "configure",
            "the",
            "instance",
            "of",
            "consumed",
            "with",
            "a",
            "processor",
            "name"
        ]
    },
    {
        "id": 2566,
        "code": "static EmitStrategy onWindowClose() {\n    return new WindowCloseStrategy();\n}",
        "summary_tokens": [
            "this",
            "strategy",
            "indicates",
            "that",
            "the",
            "aggregated",
            "result",
            "for",
            "a",
            "window",
            "will",
            "only",
            "be",
            "emitted",
            "when",
            "the",
            "window",
            "closes",
            "instead",
            "of",
            "when",
            "there",
            "s",
            "an",
            "update",
            "to",
            "the",
            "window"
        ]
    },
    {
        "id": 2567,
        "code": "static EmitStrategy onWindowUpdate() {\n    return new WindowUpdateStrategy();\n}",
        "summary_tokens": [
            "this",
            "strategy",
            "indicates",
            "that",
            "the",
            "aggregated",
            "result",
            "for",
            "a",
            "window",
            "will",
            "be",
            "emitted",
            "every",
            "time",
            "when",
            "there",
            "s",
            "an",
            "update",
            "to",
            "the",
            "window",
            "instead",
            "of",
            "when",
            "the",
            "window",
            "closes"
        ]
    },
    {
        "id": 2568,
        "code": "public static <K, V> Grouped<K, V> as(final String name) {\n    return new Grouped<>(name, null, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "grouped",
            "instance",
            "with",
            "the",
            "provided",
            "name",
            "used",
            "as",
            "part",
            "of",
            "the",
            "repartition",
            "topic",
            "if",
            "required"
        ]
    },
    {
        "id": 2569,
        "code": "public static <K, V> Grouped<K, V> keySerde(final Serde<K> keySerde) {\n    return new Grouped<>(null, keySerde, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "grouped",
            "instance",
            "with",
            "the",
            "provided",
            "key",
            "serde"
        ]
    },
    {
        "id": 2570,
        "code": "public static <K, V> Grouped<K, V> valueSerde(final Serde<V> valueSerde) {\n    return new Grouped<>(null, null, valueSerde);\n}",
        "summary_tokens": [
            "create",
            "a",
            "grouped",
            "instance",
            "with",
            "the",
            "provided",
            "value",
            "serde"
        ]
    },
    {
        "id": 2571,
        "code": "public static <K, V> Grouped<K, V> with(final Serde<K> keySerde,\n                                        final Serde<V> valueSerde) {\n    return new Grouped<>(null, keySerde, valueSerde);\n}",
        "summary_tokens": [
            "create",
            "a",
            "grouped",
            "instance",
            "with",
            "the",
            "provided",
            "key",
            "serde",
            "and",
            "value",
            "serde"
        ]
    },
    {
        "id": 2572,
        "code": "public Grouped<K, V> withName(final String name) {\n    return new Grouped<>(name, keySerde, valueSerde);\n}",
        "summary_tokens": [
            "perform",
            "the",
            "grouping",
            "operation",
            "with",
            "the",
            "name",
            "for",
            "a",
            "repartition",
            "topic",
            "if",
            "required"
        ]
    },
    {
        "id": 2573,
        "code": "public Grouped<K, V> withKeySerde(final Serde<K> keySerde) {\n    return new Grouped<>(name, keySerde, valueSerde);\n}",
        "summary_tokens": [
            "perform",
            "the",
            "grouping",
            "operation",
            "using",
            "the",
            "provided",
            "key",
            "serde",
            "for",
            "serializing",
            "the",
            "key"
        ]
    },
    {
        "id": 2574,
        "code": "public Grouped<K, V> withValueSerde(final Serde<V> valueSerde) {\n    return new Grouped<>(name, keySerde, valueSerde);\n}",
        "summary_tokens": [
            "perform",
            "the",
            "grouping",
            "operation",
            "using",
            "the",
            "provided",
            "value",
            "serde",
            "for",
            "serializing",
            "the",
            "value"
        ]
    },
    {
        "id": 2575,
        "code": "public static JoinWindows ofTimeDifferenceAndGrace(final Duration timeDifference, final Duration afterWindowEnd) {\n    final String timeDifferenceMsgPrefix = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, timeDifferenceMsgPrefix);\n\n    final String afterWindowEndMsgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, afterWindowEndMsgPrefix);\n\n    return new JoinWindows(timeDifferenceMs, timeDifferenceMs, afterWindowEndMs, true);\n}",
        "summary_tokens": [
            "specifies",
            "that",
            "records",
            "of",
            "the",
            "same",
            "key",
            "are",
            "joinable",
            "if",
            "their",
            "timestamps",
            "are",
            "within",
            "time",
            "difference",
            "i"
        ]
    },
    {
        "id": 2576,
        "code": "public static JoinWindows ofTimeDifferenceWithNoGrace(final Duration timeDifference) {\n    return ofTimeDifferenceAndGrace(timeDifference, Duration.ofMillis(NO_GRACE_PERIOD));\n}",
        "summary_tokens": [
            "specifies",
            "that",
            "records",
            "of",
            "the",
            "same",
            "key",
            "are",
            "joinable",
            "if",
            "their",
            "timestamps",
            "are",
            "within",
            "time",
            "difference",
            "i"
        ]
    },
    {
        "id": 2577,
        "code": "public static JoinWindows of(final Duration timeDifference) throws IllegalArgumentException {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, msgPrefix);\n    return new JoinWindows(timeDifferenceMs, timeDifferenceMs, Math.max(DEPRECATED_DEFAULT_24_HR_GRACE_PERIOD - timeDifferenceMs * 2, 0), false);\n}",
        "summary_tokens": [
            "specifies",
            "that",
            "records",
            "of",
            "the",
            "same",
            "key",
            "are",
            "joinable",
            "if",
            "their",
            "timestamps",
            "are",
            "within",
            "time",
            "difference",
            "i"
        ]
    },
    {
        "id": 2578,
        "code": "public JoinWindows before(final Duration timeDifference) throws IllegalArgumentException {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, msgPrefix);\n    return new JoinWindows(timeDifferenceMs, afterMs, graceMs, enableSpuriousResultFix);\n}",
        "summary_tokens": [
            "changes",
            "the",
            "start",
            "window",
            "boundary",
            "to",
            "time",
            "difference",
            "but",
            "keep",
            "the",
            "end",
            "window",
            "boundary",
            "as",
            "is"
        ]
    },
    {
        "id": 2579,
        "code": "public JoinWindows after(final Duration timeDifference) throws IllegalArgumentException {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, msgPrefix);\n    return new JoinWindows(beforeMs, timeDifferenceMs, graceMs, enableSpuriousResultFix);\n}",
        "summary_tokens": [
            "changes",
            "the",
            "end",
            "window",
            "boundary",
            "to",
            "time",
            "difference",
            "but",
            "keep",
            "the",
            "start",
            "window",
            "boundary",
            "as",
            "is"
        ]
    },
    {
        "id": 2580,
        "code": "public Map<Long, Window> windowsFor(final long timestamp) {\n    throw new UnsupportedOperationException(\"windowsFor() is not supported by JoinWindows.\");\n}",
        "summary_tokens": [
            "not",
            "supported",
            "by",
            "join",
            "windows"
        ]
    },
    {
        "id": 2581,
        "code": "public JoinWindows grace(final Duration afterWindowEnd) throws IllegalArgumentException {\n        \n    if (this.enableSpuriousResultFix) {\n        throw new IllegalStateException(\n            \"Cannot call grace() after setting grace value via ofTimeDifferenceAndGrace or ofTimeDifferenceWithNoGrace.\");\n    }\n\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, msgPrefix);\n    return new JoinWindows(beforeMs, afterMs, afterWindowEndMs, false);\n}",
        "summary_tokens": [
            "reject",
            "out",
            "of",
            "order",
            "events",
            "that",
            "are",
            "delayed",
            "more",
            "than",
            "after",
            "window",
            "end",
            "after",
            "the",
            "end",
            "of",
            "its",
            "window"
        ]
    },
    {
        "id": 2582,
        "code": "public static <K, V, VO> Joined<K, V, VO> with(final Serde<K> keySerde,\n                                               final Serde<V> valueSerde,\n                                               final Serde<VO> otherValueSerde,\n                                               final String name) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "joined",
            "with",
            "key",
            "value",
            "and",
            "other",
            "value",
            "serde",
            "instances"
        ]
    },
    {
        "id": 2583,
        "code": "public static <K, V, VO> Joined<K, V, VO> keySerde(final Serde<K> keySerde) {\n    return new Joined<>(keySerde, null, null, null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "joined",
            "with",
            "a",
            "key",
            "serde"
        ]
    },
    {
        "id": 2584,
        "code": "public static <K, V, VO> Joined<K, V, VO> valueSerde(final Serde<V> valueSerde) {\n    return new Joined<>(null, valueSerde, null, null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "joined",
            "with",
            "a",
            "value",
            "serde"
        ]
    },
    {
        "id": 2585,
        "code": "public static <K, V, VO> Joined<K, V, VO> otherValueSerde(final Serde<VO> otherValueSerde) {\n    return new Joined<>(null, null, otherValueSerde, null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "joined",
            "with",
            "an",
            "other",
            "value",
            "serde"
        ]
    },
    {
        "id": 2586,
        "code": "public static <K, V, VO> Joined<K, V, VO> as(final String name) {\n    return new Joined<>(null, null, null, name);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "joined",
            "with",
            "base",
            "name",
            "for",
            "all",
            "components",
            "of",
            "the",
            "join",
            "this",
            "may",
            "include",
            "any",
            "repartition",
            "topics",
            "created",
            "to",
            "complete",
            "the",
            "join"
        ]
    },
    {
        "id": 2587,
        "code": "public Joined<K, V, VO> withKeySerde(final Serde<K> keySerde) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}",
        "summary_tokens": [
            "set",
            "the",
            "key",
            "serde",
            "to",
            "be",
            "used"
        ]
    },
    {
        "id": 2588,
        "code": "public Joined<K, V, VO> withValueSerde(final Serde<V> valueSerde) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}",
        "summary_tokens": [
            "set",
            "the",
            "value",
            "serde",
            "to",
            "be",
            "used"
        ]
    },
    {
        "id": 2589,
        "code": "public Joined<K, V, VO> withOtherValueSerde(final Serde<VO> otherValueSerde) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}",
        "summary_tokens": [
            "set",
            "the",
            "other",
            "value",
            "serde",
            "to",
            "be",
            "used"
        ]
    },
    {
        "id": 2590,
        "code": "public Joined<K, V, VO> withName(final String name) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}",
        "summary_tokens": [
            "set",
            "the",
            "base",
            "name",
            "used",
            "for",
            "all",
            "components",
            "of",
            "the",
            "join",
            "this",
            "may",
            "include",
            "any",
            "repartition",
            "topics",
            "created",
            "to",
            "complete",
            "the",
            "join"
        ]
    },
    {
        "id": 2591,
        "code": "public static <K, V> Materialized<K, V, KeyValueStore<Bytes, byte[]>> as(final KeyValueBytesStoreSupplier supplier) {\n    Objects.requireNonNull(supplier, \"supplier can't be null\");\n    return new Materialized<>(supplier);\n}",
        "summary_tokens": [
            "materialize",
            "a",
            "key",
            "value",
            "store",
            "using",
            "the",
            "provided",
            "key",
            "value",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 2592,
        "code": "public static <K, V, S extends StateStore> Materialized<K, V, S> with(final Serde<K> keySerde,\n                                                                      final Serde<V> valueSerde) {\n    return new Materialized<K, V, S>((String) null).withKeySerde(keySerde).withValueSerde(valueSerde);\n}",
        "summary_tokens": [
            "materialize",
            "a",
            "state",
            "store",
            "with",
            "the",
            "provided",
            "key",
            "and",
            "value",
            "serde",
            "s"
        ]
    },
    {
        "id": 2593,
        "code": "public Materialized<K, V, S> withValueSerde(final Serde<V> valueSerde) {\n    this.valueSerde = valueSerde;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "value",
            "serde",
            "the",
            "materialized",
            "state",
            "store",
            "will",
            "use"
        ]
    },
    {
        "id": 2594,
        "code": "public Materialized<K, V, S> withKeySerde(final Serde<K> keySerde) {\n    this.keySerde = keySerde;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "key",
            "serde",
            "the",
            "materialize",
            "state",
            "store",
            "will",
            "use"
        ]
    },
    {
        "id": 2595,
        "code": "public Materialized<K, V, S> withLoggingEnabled(final Map<String, String> config) {\n    loggingEnabled = true;\n    this.topicConfig = config;\n    return this;\n}",
        "summary_tokens": [
            "indicates",
            "that",
            "a",
            "changelog",
            "should",
            "be",
            "created",
            "for",
            "the",
            "store"
        ]
    },
    {
        "id": 2596,
        "code": "public Materialized<K, V, S> withLoggingDisabled() {\n    loggingEnabled = false;\n    this.topicConfig.clear();\n    return this;\n}",
        "summary_tokens": [
            "disable",
            "change",
            "logging",
            "for",
            "the",
            "materialized",
            "state",
            "store"
        ]
    },
    {
        "id": 2597,
        "code": "public Materialized<K, V, S> withCachingEnabled() {\n    cachingEnabled = true;\n    return this;\n}",
        "summary_tokens": [
            "enable",
            "caching",
            "for",
            "the",
            "materialized",
            "state",
            "store"
        ]
    },
    {
        "id": 2598,
        "code": "public Materialized<K, V, S> withCachingDisabled() {\n    cachingEnabled = false;\n    return this;\n}",
        "summary_tokens": [
            "disable",
            "caching",
            "for",
            "the",
            "materialized",
            "state",
            "store"
        ]
    },
    {
        "id": 2599,
        "code": "public Materialized<K, V, S> withRetention(final Duration retention) throws IllegalArgumentException {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(retention, \"retention\");\n    final long retentionMs = validateMillisecondDuration(retention, msgPrefix);\n\n    if (retentionMs < 0) {\n        throw new IllegalArgumentException(\"Retention must not be negative.\");\n    }\n    this.retention = retention;\n    return this;\n}",
        "summary_tokens": [
            "configure",
            "retention",
            "period",
            "for",
            "window",
            "and",
            "session",
            "stores"
        ]
    },
    {
        "id": 2600,
        "code": "public Materialized<K, V, S> withStoreType(final StoreType storeType) throws IllegalArgumentException {\n    Objects.requireNonNull(storeType, \"store type can't be null\");\n    if (storeSupplier != null) {\n        throw new IllegalArgumentException(\"Cannot set store type when store supplier is pre-configured.\");\n    }\n    this.storeType = storeType;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "type",
            "of",
            "the",
            "materialized",
            "state",
            "store"
        ]
    },
    {
        "id": 2601,
        "code": "public static Named as(final String name) {\n    Objects.requireNonNull(name, \"name can't be null\");\n    return new Named(name);\n}",
        "summary_tokens": [
            "create",
            "a",
            "named",
            "instance",
            "with",
            "provided",
            "name"
        ]
    },
    {
        "id": 2602,
        "code": "private static boolean containsValidPattern(final String topic) {\n    for (int i = 0; i < topic.length(); ++i) {\n        final char c = topic.charAt(i);\n\n            \n        final boolean validLetterOrDigit = (c >= 'a' && c <= 'z') || (c >= '0' && c <= '9') || (c >= 'A' && c <= 'Z');\n        final boolean validChar = validLetterOrDigit || c == '.' || c == '_' || c == '-';\n        if (!validChar) {\n            return false;\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "valid",
            "characters",
            "for",
            "kafka",
            "topics",
            "are",
            "the",
            "ascii",
            "alphanumerics"
        ]
    },
    {
        "id": 2603,
        "code": "public static <K, V> Printed<K, V> toFile(final String filePath) {\n    Objects.requireNonNull(filePath, \"filePath can't be null\");\n    if (Utils.isBlank(filePath)) {\n        throw new TopologyException(\"filePath can't be an empty string\");\n    }\n    try {\n        return new Printed<>(Files.newOutputStream(Paths.get(filePath)));\n    } catch (final IOException e) {\n        throw new TopologyException(\"Unable to write stream to file at [\" + filePath + \"] \" + e.getMessage());\n    }\n}",
        "summary_tokens": [
            "print",
            "the",
            "records",
            "of",
            "a",
            "kstream",
            "to",
            "a",
            "file"
        ]
    },
    {
        "id": 2604,
        "code": "public static <K, V> Printed<K, V> toSysOut() {\n    return new Printed<>(System.out);\n}",
        "summary_tokens": [
            "print",
            "the",
            "records",
            "of",
            "a",
            "kstream",
            "to",
            "system",
            "out"
        ]
    },
    {
        "id": 2605,
        "code": "public Printed<K, V> withLabel(final String label) {\n    Objects.requireNonNull(label, \"label can't be null\");\n    this.label = label;\n    return this;\n}",
        "summary_tokens": [
            "print",
            "the",
            "records",
            "of",
            "a",
            "kstream",
            "with",
            "the",
            "provided",
            "label"
        ]
    },
    {
        "id": 2606,
        "code": "public Printed<K, V> withKeyValueMapper(final KeyValueMapper<? super K, ? super V, String> mapper) {\n    Objects.requireNonNull(mapper, \"mapper can't be null\");\n    this.mapper = mapper;\n    return this;\n}",
        "summary_tokens": [
            "print",
            "the",
            "records",
            "of",
            "a",
            "kstream",
            "with",
            "the",
            "provided",
            "key",
            "value",
            "mapper",
            "the",
            "provided",
            "key",
            "value",
            "mapper",
            "s",
            "mapped",
            "value",
            "type",
            "must",
            "be",
            "string"
        ]
    },
    {
        "id": 2607,
        "code": "public Printed<K, V> withName(final String processorName) {\n    this.processorName = processorName;\n    return this;\n}",
        "summary_tokens": [
            "print",
            "the",
            "records",
            "of",
            "a",
            "kstream",
            "with",
            "provided",
            "processor",
            "name"
        ]
    },
    {
        "id": 2608,
        "code": "public static <K, V> Produced<K, V> with(final Serde<K> keySerde,\n                                         final Serde<V> valueSerde,\n                                         final StreamPartitioner<? super K, ? super V> partitioner) {\n    return new Produced<>(keySerde, valueSerde, partitioner, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "produced",
            "instance",
            "with",
            "provided",
            "key",
            "serde",
            "value",
            "serde",
            "and",
            "partitioner"
        ]
    },
    {
        "id": 2609,
        "code": "public static <K, V> Produced<K, V> as(final String processorName) {\n    return new Produced<>(null, null, null, processorName);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "produced",
            "with",
            "provided",
            "processor",
            "name"
        ]
    },
    {
        "id": 2610,
        "code": "public static <K, V> Produced<K, V> keySerde(final Serde<K> keySerde) {\n    return new Produced<>(keySerde, null, null, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "produced",
            "instance",
            "with",
            "provided",
            "key",
            "serde"
        ]
    },
    {
        "id": 2611,
        "code": "public static <K, V> Produced<K, V> valueSerde(final Serde<V> valueSerde) {\n    return new Produced<>(null, valueSerde, null, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "produced",
            "instance",
            "with",
            "provided",
            "value",
            "serde"
        ]
    },
    {
        "id": 2612,
        "code": "public static <K, V> Produced<K, V> streamPartitioner(final StreamPartitioner<? super K, ? super V> partitioner) {\n    return new Produced<>(null, null, partitioner, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "produced",
            "instance",
            "with",
            "provided",
            "partitioner"
        ]
    },
    {
        "id": 2613,
        "code": "public Produced<K, V> withStreamPartitioner(final StreamPartitioner<? super K, ? super V> partitioner) {\n    this.partitioner = partitioner;\n    return this;\n}",
        "summary_tokens": [
            "produce",
            "records",
            "using",
            "the",
            "provided",
            "partitioner"
        ]
    },
    {
        "id": 2614,
        "code": "public Produced<K, V> withValueSerde(final Serde<V> valueSerde) {\n    this.valueSerde = valueSerde;\n    return this;\n}",
        "summary_tokens": [
            "produce",
            "records",
            "using",
            "the",
            "provided",
            "value",
            "serde"
        ]
    },
    {
        "id": 2615,
        "code": "public Produced<K, V> withKeySerde(final Serde<K> keySerde) {\n    this.keySerde = keySerde;\n    return this;\n}",
        "summary_tokens": [
            "produce",
            "records",
            "using",
            "the",
            "provided",
            "key",
            "serde"
        ]
    },
    {
        "id": 2616,
        "code": "public static <K, V> Repartitioned<K, V> as(final String name) {\n    return new Repartitioned<>(name, null, null, null, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "repartitioned",
            "instance",
            "with",
            "the",
            "provided",
            "name",
            "used",
            "as",
            "part",
            "of",
            "the",
            "repartition",
            "topic"
        ]
    },
    {
        "id": 2617,
        "code": "public static <K, V> Repartitioned<K, V> with(final Serde<K> keySerde,\n                                              final Serde<V> valueSerde) {\n    return new Repartitioned<>(null, keySerde, valueSerde, null, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "repartitioned",
            "instance",
            "with",
            "provided",
            "key",
            "serde",
            "and",
            "value",
            "serde"
        ]
    },
    {
        "id": 2618,
        "code": "public static <K, V> Repartitioned<K, V> streamPartitioner(final StreamPartitioner<K, V> partitioner) {\n    return new Repartitioned<>(null, null, null, null, partitioner);\n}",
        "summary_tokens": [
            "create",
            "a",
            "repartitioned",
            "instance",
            "with",
            "provided",
            "partitioner"
        ]
    },
    {
        "id": 2619,
        "code": "public static <K, V> Repartitioned<K, V> numberOfPartitions(final int numberOfPartitions) {\n    return new Repartitioned<>(null, null, null, numberOfPartitions, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "repartitioned",
            "instance",
            "with",
            "provided",
            "number",
            "of",
            "partitions",
            "for",
            "repartition",
            "topic"
        ]
    },
    {
        "id": 2620,
        "code": "public Repartitioned<K, V> withName(final String name) {\n    return new Repartitioned<>(name, keySerde, valueSerde, numberOfPartitions, partitioner);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "instance",
            "of",
            "repartitioned",
            "with",
            "the",
            "provided",
            "name",
            "used",
            "as",
            "part",
            "of",
            "repartition",
            "topic",
            "and",
            "processor",
            "name"
        ]
    },
    {
        "id": 2621,
        "code": "public Repartitioned<K, V> withNumberOfPartitions(final int numberOfPartitions) {\n    return new Repartitioned<>(name, keySerde, valueSerde, numberOfPartitions, partitioner);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "instance",
            "of",
            "repartitioned",
            "with",
            "the",
            "provided",
            "number",
            "of",
            "partitions",
            "for",
            "repartition",
            "topic"
        ]
    },
    {
        "id": 2622,
        "code": "public Repartitioned<K, V> withKeySerde(final Serde<K> keySerde) {\n    return new Repartitioned<>(name, keySerde, valueSerde, numberOfPartitions, partitioner);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "instance",
            "of",
            "repartitioned",
            "with",
            "the",
            "provided",
            "key",
            "serde"
        ]
    },
    {
        "id": 2623,
        "code": "public Repartitioned<K, V> withValueSerde(final Serde<V> valueSerde) {\n    return new Repartitioned<>(name, keySerde, valueSerde, numberOfPartitions, partitioner);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "instance",
            "of",
            "repartitioned",
            "with",
            "the",
            "provided",
            "value",
            "serde"
        ]
    },
    {
        "id": 2624,
        "code": "public Repartitioned<K, V> withStreamPartitioner(final StreamPartitioner<K, V> partitioner) {\n    return new Repartitioned<>(name, keySerde, valueSerde, numberOfPartitions, partitioner);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "instance",
            "of",
            "repartitioned",
            "with",
            "the",
            "provided",
            "partitioner"
        ]
    },
    {
        "id": 2625,
        "code": "public static SessionWindows ofInactivityGapWithNoGrace(final Duration inactivityGap) {\n    return ofInactivityGapAndGrace(inactivityGap, ofMillis(NO_GRACE_PERIOD));\n}",
        "summary_tokens": [
            "creates",
            "a",
            "new",
            "window",
            "specification",
            "with",
            "the",
            "specified",
            "inactivity",
            "gap"
        ]
    },
    {
        "id": 2626,
        "code": "public static SessionWindows ofInactivityGapAndGrace(final Duration inactivityGap, final Duration afterWindowEnd) {\n    final String inactivityGapMsgPrefix = prepareMillisCheckFailMsgPrefix(inactivityGap, \"inactivityGap\");\n    final long inactivityGapMs = validateMillisecondDuration(inactivityGap, inactivityGapMsgPrefix);\n\n    final String afterWindowEndMsgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, afterWindowEndMsgPrefix);\n\n    return new SessionWindows(inactivityGapMs, afterWindowEndMs, true);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "new",
            "window",
            "specification",
            "with",
            "the",
            "specified",
            "inactivity",
            "gap"
        ]
    },
    {
        "id": 2627,
        "code": "public static SessionWindows with(final Duration inactivityGap) {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(inactivityGap, \"inactivityGap\");\n    final long inactivityGapMs = validateMillisecondDuration(inactivityGap, msgPrefix);\n\n    return new SessionWindows(inactivityGapMs, Math.max(DEPRECATED_DEFAULT_24_HR_GRACE_PERIOD - inactivityGapMs, 0), false);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "window",
            "specification",
            "with",
            "the",
            "specified",
            "inactivity",
            "gap"
        ]
    },
    {
        "id": 2628,
        "code": "public SessionWindows grace(final Duration afterWindowEnd) throws IllegalArgumentException {\n    if (this.hasSetGrace) {\n        throw new IllegalStateException(\n            \"Cannot call grace() after setting grace value via ofInactivityGapAndGrace or ofInactivityGapWithNoGrace.\");\n    }\n\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, msgPrefix);\n\n    return new SessionWindows(gapMs, afterWindowEndMs, false);\n}",
        "summary_tokens": [
            "reject",
            "out",
            "of",
            "order",
            "events",
            "that",
            "arrive",
            "more",
            "than",
            "after",
            "window",
            "end",
            "after",
            "the",
            "end",
            "of",
            "its",
            "window"
        ]
    },
    {
        "id": 2629,
        "code": "public long inactivityGap() {\n    return gapMs;\n}",
        "summary_tokens": [
            "return",
            "the",
            "specified",
            "gap",
            "for",
            "the",
            "session",
            "windows",
            "in",
            "milliseconds"
        ]
    },
    {
        "id": 2630,
        "code": "public static SlidingWindows ofTimeDifferenceWithNoGrace(final Duration timeDifference) throws IllegalArgumentException {\n    return ofTimeDifferenceAndGrace(timeDifference, ofMillis(NO_GRACE_PERIOD));\n}",
        "summary_tokens": [
            "return",
            "a",
            "window",
            "definition",
            "with",
            "the",
            "window",
            "size",
            "based",
            "on",
            "the",
            "given",
            "maximum",
            "time",
            "difference",
            "inclusive",
            "between",
            "records",
            "in",
            "the",
            "same",
            "window",
            "and",
            "given",
            "window",
            "grace",
            "period"
        ]
    },
    {
        "id": 2631,
        "code": "public static SlidingWindows ofTimeDifferenceAndGrace(final Duration timeDifference, final Duration afterWindowEnd) throws IllegalArgumentException {\n    final String timeDifferenceMsgPrefix = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, timeDifferenceMsgPrefix);\n    final String afterWindowEndMsgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, afterWindowEndMsgPrefix);\n\n    return new SlidingWindows(timeDifferenceMs, afterWindowEndMs);\n}",
        "summary_tokens": [
            "return",
            "a",
            "window",
            "definition",
            "with",
            "the",
            "window",
            "size",
            "based",
            "on",
            "the",
            "given",
            "maximum",
            "time",
            "difference",
            "inclusive",
            "between",
            "records",
            "in",
            "the",
            "same",
            "window",
            "and",
            "given",
            "window",
            "grace",
            "period"
        ]
    },
    {
        "id": 2632,
        "code": "public static SlidingWindows withTimeDifferenceAndGrace(final Duration timeDifference, final Duration grace) throws IllegalArgumentException {\n    final String msgPrefixSize = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, msgPrefixSize);\n\n    final String msgPrefixGrace = prepareMillisCheckFailMsgPrefix(grace, \"grace\");\n    final long graceMs = validateMillisecondDuration(grace, msgPrefixGrace);\n\n    return new SlidingWindows(timeDifferenceMs, graceMs);\n}",
        "summary_tokens": [
            "return",
            "a",
            "window",
            "definition",
            "with",
            "the",
            "window",
            "size",
            "based",
            "on",
            "the",
            "given",
            "maximum",
            "time",
            "difference",
            "inclusive",
            "between",
            "records",
            "in",
            "the",
            "same",
            "window",
            "and",
            "given",
            "window",
            "grace",
            "period"
        ]
    },
    {
        "id": 2633,
        "code": "public static <K, V1, V2> StreamJoined<K, V1, V2> with(final Serde<K> keySerde,\n                                                       final Serde<V1> valueSerde,\n                                                       final Serde<V2> otherValueSerde\n) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        null,\n        null,\n        null,\n        null,\n        true,\n        new HashMap<>()\n    );\n}",
        "summary_tokens": [
            "creates",
            "a",
            "stream",
            "joined",
            "instance",
            "with",
            "the",
            "provided",
            "serdes",
            "to",
            "configure",
            "the",
            "stores",
            "for",
            "the",
            "join"
        ]
    },
    {
        "id": 2634,
        "code": "public static <K, V1, V2> StreamJoined<K, V1, V2> as(final String storeName) {\n    return new StreamJoined<>(\n        null,\n        null,\n        null,\n        null,\n        null,\n        null,\n        storeName,\n        true,\n        new HashMap<>()\n    );\n}",
        "summary_tokens": [
            "creates",
            "a",
            "stream",
            "joined",
            "instance",
            "using",
            "the",
            "provided",
            "name",
            "for",
            "the",
            "state",
            "stores",
            "and",
            "hence",
            "the",
            "changelog",
            "topics",
            "for",
            "the",
            "join",
            "stores"
        ]
    },
    {
        "id": 2635,
        "code": "public StreamJoined<K, V1, V2> withName(final String name) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}",
        "summary_tokens": [
            "set",
            "the",
            "name",
            "to",
            "use",
            "for",
            "the",
            "join",
            "processor",
            "and",
            "the",
            "repartition",
            "topic",
            "s",
            "if",
            "required"
        ]
    },
    {
        "id": 2636,
        "code": "public StreamJoined<K, V1, V2> withStoreName(final String storeName) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}",
        "summary_tokens": [
            "sets",
            "the",
            "base",
            "store",
            "name",
            "to",
            "use",
            "for",
            "both",
            "sides",
            "of",
            "the",
            "join"
        ]
    },
    {
        "id": 2637,
        "code": "public StreamJoined<K, V1, V2> withKeySerde(final Serde<K> keySerde) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}",
        "summary_tokens": [
            "configure",
            "with",
            "the",
            "provided",
            "serde",
            "serde",
            "k",
            "for",
            "the",
            "key",
            "key",
            "serde",
            "the",
            "serde",
            "to",
            "use",
            "for",
            "the",
            "key",
            "a",
            "new",
            "stream",
            "joined",
            "configured",
            "with",
            "the",
            "key",
            "serde"
        ]
    },
    {
        "id": 2638,
        "code": "public StreamJoined<K, V1, V2> withValueSerde(final Serde<V1> valueSerde) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}",
        "summary_tokens": [
            "configure",
            "with",
            "the",
            "provided",
            "serde",
            "serde",
            "v",
            "0",
            "for",
            "this",
            "value",
            "value",
            "serde",
            "the",
            "serde",
            "to",
            "use",
            "for",
            "this",
            "value",
            "calling",
            "or",
            "left",
            "side",
            "of",
            "the",
            "join",
            "a",
            "new",
            "stream",
            "joined",
            "configured",
            "with",
            "the",
            "value",
            "serde"
        ]
    },
    {
        "id": 2639,
        "code": "public StreamJoined<K, V1, V2> withOtherValueSerde(final Serde<V2> otherValueSerde) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}",
        "summary_tokens": [
            "configure",
            "with",
            "the",
            "provided",
            "serde",
            "serde",
            "v",
            "0",
            "for",
            "the",
            "other",
            "value",
            "other",
            "value",
            "serde",
            "the",
            "serde",
            "to",
            "use",
            "for",
            "the",
            "other",
            "value",
            "other",
            "or",
            "right",
            "side",
            "of",
            "the",
            "join",
            "a",
            "new",
            "stream",
            "joined",
            "configured",
            "with",
            "the",
            "other",
            "value",
            "serde"
        ]
    },
    {
        "id": 2640,
        "code": "public StreamJoined<K, V1, V2> withThisStoreSupplier(final WindowBytesStoreSupplier thisStoreSupplier) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}",
        "summary_tokens": [
            "configure",
            "with",
            "the",
            "provided",
            "window",
            "bytes",
            "store",
            "supplier",
            "for",
            "this",
            "store",
            "supplier"
        ]
    },
    {
        "id": 2641,
        "code": "public StreamJoined<K, V1, V2> withOtherStoreSupplier(final WindowBytesStoreSupplier otherStoreSupplier) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}",
        "summary_tokens": [
            "configure",
            "with",
            "the",
            "provided",
            "window",
            "bytes",
            "store",
            "supplier",
            "for",
            "the",
            "other",
            "store",
            "supplier"
        ]
    },
    {
        "id": 2642,
        "code": "public StreamJoined<K, V1, V2> withLoggingEnabled(final Map<String, String> config) {\n\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        true,\n        config\n    );\n}",
        "summary_tokens": [
            "configures",
            "logging",
            "for",
            "both",
            "state",
            "stores"
        ]
    },
    {
        "id": 2643,
        "code": "public StreamJoined<K, V1, V2> withLoggingDisabled() {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        false,\n        new HashMap<>()\n    );\n}",
        "summary_tokens": [
            "disable",
            "change",
            "logging",
            "for",
            "both",
            "state",
            "stores"
        ]
    },
    {
        "id": 2644,
        "code": "static Suppressed<Windowed> untilWindowCloses(final StrictBufferConfig bufferConfig) {\n    return new FinalResultsSuppressionBuilder<>(null, bufferConfig);\n}",
        "summary_tokens": [
            "configure",
            "the",
            "suppression",
            "to",
            "emit",
            "only",
            "the",
            "final",
            "results",
            "from",
            "the",
            "window"
        ]
    },
    {
        "id": 2645,
        "code": "static <K> Suppressed<K> untilTimeLimit(final Duration timeToWaitForMoreEvents, final BufferConfig bufferConfig) {\n    return new SuppressedInternal<>(null, timeToWaitForMoreEvents, bufferConfig, null, false);\n}",
        "summary_tokens": [
            "configure",
            "the",
            "suppression",
            "to",
            "wait",
            "time",
            "to",
            "wait",
            "for",
            "more",
            "events",
            "amount",
            "of",
            "time",
            "after",
            "receiving",
            "a",
            "record",
            "before",
            "emitting",
            "it",
            "further",
            "downstream"
        ]
    },
    {
        "id": 2646,
        "code": "public static <K, KO> TableJoined<K, KO> with(final StreamPartitioner<K, Void> partitioner,\n                                              final StreamPartitioner<KO, Void> otherPartitioner) {\n    return new TableJoined<>(partitioner, otherPartitioner, null);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "table",
            "joined",
            "with",
            "partitioner",
            "and",
            "other",
            "partitioner",
            "stream",
            "partitioner",
            "instances"
        ]
    },
    {
        "id": 2647,
        "code": "public static <K, KO> TableJoined<K, KO> as(final String name) {\n    return new TableJoined<>(null, null, name);\n}",
        "summary_tokens": [
            "create",
            "an",
            "instance",
            "of",
            "table",
            "joined",
            "with",
            "base",
            "name",
            "for",
            "all",
            "components",
            "of",
            "the",
            "join",
            "including",
            "internal",
            "topics",
            "created",
            "to",
            "complete",
            "the",
            "join"
        ]
    },
    {
        "id": 2648,
        "code": "public TableJoined<K, KO> withPartitioner(final StreamPartitioner<K, Void> partitioner) {\n    return new TableJoined<>(partitioner, otherPartitioner, name);\n}",
        "summary_tokens": [
            "set",
            "the",
            "custom",
            "stream",
            "partitioner",
            "to",
            "be",
            "used",
            "as",
            "part",
            "of",
            "computing",
            "the",
            "join"
        ]
    },
    {
        "id": 2649,
        "code": "public TableJoined<K, KO> withOtherPartitioner(final StreamPartitioner<KO, Void> otherPartitioner) {\n    return new TableJoined<>(partitioner, otherPartitioner, name);\n}",
        "summary_tokens": [
            "set",
            "the",
            "custom",
            "other",
            "stream",
            "partitioner",
            "to",
            "be",
            "used",
            "as",
            "part",
            "of",
            "computing",
            "the",
            "join"
        ]
    },
    {
        "id": 2650,
        "code": "public TableJoined<K, KO> withName(final String name) {\n    return new TableJoined<>(partitioner, otherPartitioner, name);\n}",
        "summary_tokens": [
            "set",
            "the",
            "base",
            "name",
            "used",
            "for",
            "all",
            "components",
            "of",
            "the",
            "join",
            "including",
            "internal",
            "topics",
            "created",
            "to",
            "complete",
            "the",
            "join"
        ]
    },
    {
        "id": 2651,
        "code": "public static TimeWindows ofSizeWithNoGrace(final Duration size) throws IllegalArgumentException {\n    return ofSizeAndGrace(size, ofMillis(NO_GRACE_PERIOD));\n}",
        "summary_tokens": [
            "return",
            "a",
            "window",
            "definition",
            "with",
            "the",
            "given",
            "window",
            "size",
            "and",
            "with",
            "the",
            "advance",
            "interval",
            "being",
            "equal",
            "to",
            "the",
            "window",
            "size"
        ]
    },
    {
        "id": 2652,
        "code": "public static TimeWindows ofSizeAndGrace(final Duration size, final Duration afterWindowEnd) throws IllegalArgumentException {\n    final String sizeMsgPrefix = prepareMillisCheckFailMsgPrefix(size, \"size\");\n    final long sizeMs = validateMillisecondDuration(size, sizeMsgPrefix);\n\n    final String afterWindowEndMsgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, afterWindowEndMsgPrefix);\n\n    return new TimeWindows(sizeMs, sizeMs, afterWindowEndMs, true);\n}",
        "summary_tokens": [
            "return",
            "a",
            "window",
            "definition",
            "with",
            "the",
            "given",
            "window",
            "size",
            "and",
            "with",
            "the",
            "advance",
            "interval",
            "being",
            "equal",
            "to",
            "the",
            "window",
            "size"
        ]
    },
    {
        "id": 2653,
        "code": "public static TimeWindows of(final Duration size) throws IllegalArgumentException {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(size, \"size\");\n    final long sizeMs = validateMillisecondDuration(size, msgPrefix);\n\n    return new TimeWindows(sizeMs, sizeMs, Math.max(DEPRECATED_DEFAULT_24_HR_GRACE_PERIOD - sizeMs, 0), false);\n}",
        "summary_tokens": [
            "return",
            "a",
            "window",
            "definition",
            "with",
            "the",
            "given",
            "window",
            "size",
            "and",
            "with",
            "the",
            "advance",
            "interval",
            "being",
            "equal",
            "to",
            "the",
            "window",
            "size"
        ]
    },
    {
        "id": 2654,
        "code": "public TimeWindows advanceBy(final Duration advance) {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(advance, \"advance\");\n    final long advanceMs = validateMillisecondDuration(advance, msgPrefix);\n    return new TimeWindows(sizeMs, advanceMs, graceMs, false);\n}",
        "summary_tokens": [
            "return",
            "a",
            "window",
            "definition",
            "with",
            "the",
            "original",
            "size",
            "but",
            "advance",
            "hop",
            "the",
            "window",
            "by",
            "the",
            "given",
            "interval",
            "which",
            "specifies",
            "by",
            "how",
            "much",
            "a",
            "window",
            "moves",
            "forward",
            "relative",
            "to",
            "the",
            "previous",
            "one"
        ]
    },
    {
        "id": 2655,
        "code": "public TimeWindows grace(final Duration afterWindowEnd) throws IllegalArgumentException {\n    if (this.hasSetGrace) {\n        throw new IllegalStateException(\n            \"Cannot call grace() after setting grace value via ofSizeAndGrace or ofSizeWithNoGrace.\");\n    }\n\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, msgPrefix);\n\n    return new TimeWindows(sizeMs, advanceMs, afterWindowEndMs, false);\n}",
        "summary_tokens": [
            "reject",
            "out",
            "of",
            "order",
            "events",
            "that",
            "arrive",
            "more",
            "than",
            "millis",
            "after",
            "window",
            "end",
            "after",
            "the",
            "end",
            "of",
            "its",
            "window"
        ]
    },
    {
        "id": 2656,
        "code": "public static UnlimitedWindows of() {\n    return new UnlimitedWindows(DEFAULT_START_TIMESTAMP_MS);\n}",
        "summary_tokens": [
            "return",
            "an",
            "unlimited",
            "window",
            "starting",
            "at",
            "timestamp",
            "zero"
        ]
    },
    {
        "id": 2657,
        "code": "public UnlimitedWindows startOn(final Instant start) throws IllegalArgumentException {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(start, \"start\");\n    final long startMs = ApiUtils.validateMillisecondInstant(start, msgPrefix);\n    if (startMs < 0) {\n        throw new IllegalArgumentException(\"Window start time (startMs) cannot be negative.\");\n    }\n    return new UnlimitedWindows(startMs);\n}",
        "summary_tokens": [
            "return",
            "a",
            "new",
            "unlimited",
            "window",
            "for",
            "the",
            "specified",
            "start",
            "timestamp"
        ]
    },
    {
        "id": 2658,
        "code": "public long size() {\n    return Long.MAX_VALUE;\n}",
        "summary_tokens": [
            "as",
            "unlimited",
            "windows",
            "have",
            "conceptually",
            "infinite",
            "size",
            "this",
            "methods",
            "just",
            "returns",
            "long",
            "max",
            "value"
        ]
    },
    {
        "id": 2659,
        "code": "public long start() {\n    return startMs;\n}",
        "summary_tokens": [
            "return",
            "the",
            "start",
            "timestamp",
            "of",
            "this",
            "window"
        ]
    },
    {
        "id": 2660,
        "code": "public long end() {\n    return endMs;\n}",
        "summary_tokens": [
            "return",
            "the",
            "end",
            "timestamp",
            "of",
            "this",
            "window"
        ]
    },
    {
        "id": 2661,
        "code": "public Instant startTime() {\n    return startTime;\n}",
        "summary_tokens": [
            "return",
            "the",
            "start",
            "time",
            "of",
            "this",
            "window"
        ]
    },
    {
        "id": 2662,
        "code": "public Instant endTime() {\n    return endTime;\n}",
        "summary_tokens": [
            "return",
            "the",
            "end",
            "time",
            "of",
            "this",
            "window"
        ]
    },
    {
        "id": 2663,
        "code": "public K key() {\n    return key;\n}",
        "summary_tokens": [
            "return",
            "the",
            "key",
            "of",
            "the",
            "window"
        ]
    },
    {
        "id": 2664,
        "code": "public Window window() {\n    return window;\n}",
        "summary_tokens": [
            "return",
            "the",
            "window",
            "containing",
            "the",
            "values",
            "associated",
            "with",
            "this",
            "key"
        ]
    },
    {
        "id": 2665,
        "code": "static public <T> Serde<Windowed<T>> timeWindowedSerdeFrom(final Class<T> type, final long windowSize) {\n    return new TimeWindowedSerde<>(Serdes.serdeFrom(type), windowSize);\n}",
        "summary_tokens": [
            "construct",
            "a",
            "time",
            "windowed",
            "serde",
            "object",
            "to",
            "deserialize",
            "changelog",
            "topic",
            "for",
            "the",
            "specified",
            "inner",
            "class",
            "type",
            "and",
            "window",
            "size"
        ]
    },
    {
        "id": 2666,
        "code": "static public <T> Serde<Windowed<T>> sessionWindowedSerdeFrom(final Class<T> type) {\n    return new SessionWindowedSerde<>(Serdes.serdeFrom(type));\n}",
        "summary_tokens": [
            "construct",
            "a",
            "session",
            "windowed",
            "serde",
            "object",
            "for",
            "the",
            "specified",
            "inner",
            "class",
            "type"
        ]
    },
    {
        "id": 2667,
        "code": "public byte[] serialize(final String topic, final Headers headers, final Change<T> data) {\n    final byte[] serializedKey;\n\n        \n    if (data.newValue != null) {\n        if (data.oldValue != null) {\n            throw new StreamsException(\"Both old and new values are not null (\" + data.oldValue\n                + \" : \" + data.newValue + \") in ChangeSerializer, which is not allowed.\");\n        }\n\n        serializedKey = inner.serialize(topic, headers, data.newValue);\n    } else {\n        if (data.oldValue == null) {\n            throw new StreamsException(\"Both old and new values are null in ChangeSerializer, which is not allowed.\");\n        }\n\n        serializedKey = inner.serialize(topic, headers, data.oldValue);\n    }\n\n    final ByteBuffer buf = ByteBuffer.allocate(serializedKey.length + NEWFLAG_SIZE);\n    buf.put(serializedKey);\n    buf.put((byte) (data.newValue != null ? 1 : 0));\n\n    return buf.array();\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "if",
            "both",
            "old",
            "and",
            "new",
            "values",
            "of",
            "data",
            "are",
            "null",
            "or",
            "if",
            "both",
            "values",
            "are",
            "not",
            "null"
        ]
    },
    {
        "id": 2668,
        "code": "public static Change<byte[]> decomposeLegacyFormattedArrayIntoChangeArrays(final byte[] data) {\n    if (data == null) {\n        return null;\n    }\n    final ByteBuffer buffer = ByteBuffer.wrap(data);\n    final byte[] oldBytes = getNullableSizePrefixedArray(buffer);\n    final byte[] newBytes = getNullableSizePrefixedArray(buffer);\n    return new Change<>(newBytes, oldBytes);\n}",
        "summary_tokens": [
            "we",
            "used",
            "to",
            "serialize",
            "a",
            "change",
            "into",
            "a",
            "single",
            "byte"
        ]
    },
    {
        "id": 2669,
        "code": "private String createRepartitionSource(final String repartitionTopicNamePrefix,\n                                       final OptimizableRepartitionNodeBuilder<K, V> optimizableRepartitionNodeBuilder) {\n\n    return KStreamImpl.createRepartitionedSource(builder,\n                                                 keySerde,\n                                                 valueSerde,\n                                                 repartitionTopicNamePrefix,\n                                                 null,\n                                                 optimizableRepartitionNodeBuilder);\n\n}",
        "summary_tokens": [
            "the",
            "new",
            "source",
            "name",
            "of",
            "the",
            "repartitioned",
            "source"
        ]
    },
    {
        "id": 2670,
        "code": "private <VR> ProcessorParameters<K, VR, ?, ?> unsafeCastProcessorParametersToCompletelyDifferentType(final ProcessorParameters<K, Change<V>, ?, ?> kObjectProcessorParameters) {\n    return (ProcessorParameters<K, VR, ?, ?>) kObjectProcessorParameters;\n}",
        "summary_tokens": [
            "we",
            "conflate",
            "v",
            "with",
            "change",
            "v",
            "in",
            "many",
            "places"
        ]
    },
    {
        "id": 2671,
        "code": "public boolean enableSendingOldValues(final boolean forceMaterialization) {\n        \n    throw new IllegalStateException(\"KTableRepartitionMap should always require sending old values.\");\n}",
        "summary_tokens": [
            "illegal",
            "state",
            "exception",
            "since",
            "this",
            "method",
            "should",
            "never",
            "be",
            "called"
        ]
    },
    {
        "id": 2672,
        "code": "public boolean overlap(final Window other) throws IllegalArgumentException {\n    if (getClass() != other.getClass()) {\n        throw new IllegalArgumentException(\"Cannot compare windows of different type. Other window has type \"\n            + other.getClass() + \".\");\n    }\n    final SessionWindow otherWindow = (SessionWindow) other;\n    return !(otherWindow.endMs < startMs || endMs < otherWindow.startMs);\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "given",
            "window",
            "overlaps",
            "with",
            "this",
            "window"
        ]
    },
    {
        "id": 2673,
        "code": "public boolean overlap(final Window other) throws IllegalArgumentException {\n    if (getClass() != other.getClass()) {\n        throw new IllegalArgumentException(\"Cannot compare windows of different type. Other window has type \"\n            + other.getClass() + \".\");\n    }\n    final TimeWindow otherWindow = (TimeWindow) other;\n    return startMs < otherWindow.endMs && otherWindow.startMs < endMs;\n}",
        "summary_tokens": [
            "check",
            "if",
            "the",
            "given",
            "window",
            "overlaps",
            "with",
            "this",
            "window"
        ]
    },
    {
        "id": 2674,
        "code": "public boolean overlap(final Window other) {\n    if (getClass() != other.getClass()) {\n        throw new IllegalArgumentException(\"Cannot compare windows of different type. Other window has type \"\n            + other.getClass() + \".\");\n    }\n    return true;\n}",
        "summary_tokens": [
            "returns",
            "true",
            "if",
            "the",
            "given",
            "window",
            "is",
            "of",
            "the",
            "same",
            "type",
            "because",
            "all",
            "unlimited",
            "windows",
            "overlap",
            "with",
            "each",
            "other",
            "due",
            "to",
            "their",
            "infinite",
            "size"
        ]
    },
    {
        "id": 2675,
        "code": "public Integer partition(final String topic, final Windowed<K> windowedKey, final V value, final int numPartitions) {\n        \n    final byte[] keyBytes = serializer.serializeBaseKey(topic, windowedKey);\n\n        \n        \n    return BuiltInPartitioner.partitionForKey(keyBytes, numPartitions);\n}",
        "summary_tokens": [
            "windowed",
            "stream",
            "partitioner",
            "determines",
            "the",
            "partition",
            "number",
            "for",
            "a",
            "record",
            "with",
            "the",
            "given",
            "windowed",
            "key",
            "and",
            "value",
            "and",
            "the",
            "current",
            "number",
            "of",
            "partitions"
        ]
    },
    {
        "id": 2676,
        "code": "public KTableKTableJoinMerger<K, VR> joinMerger() {\n    final KTableKTableJoinMerger<K, Change<VR>> merger =\n        mergeProcessorParameters().kTableKTableJoinMergerProcessorSupplier();\n        \n    return (KTableKTableJoinMerger<K, VR>) merger;\n}",
        "summary_tokens": [
            "the",
            "supplier",
            "which",
            "provides",
            "processor",
            "with",
            "ktable",
            "ktable",
            "join",
            "merge",
            "functionality"
        ]
    },
    {
        "id": 2677,
        "code": "",
        "summary_tokens": [
            "close",
            "this",
            "processor",
            "and",
            "clean",
            "up",
            "any",
            "resources"
        ]
    },
    {
        "id": 2678,
        "code": "protected final ProcessorContext context() {\n    return context;\n}",
        "summary_tokens": [
            "get",
            "the",
            "processor",
            "s",
            "context",
            "set",
            "during",
            "init",
            "processor",
            "context",
            "initialization"
        ]
    },
    {
        "id": 2679,
        "code": "default Set<StoreBuilder<?>> stores() {\n    return null;\n}",
        "summary_tokens": [
            "the",
            "state",
            "stores",
            "to",
            "be",
            "connected",
            "and",
            "added",
            "or",
            "null",
            "if",
            "no",
            "stores",
            "should",
            "be",
            "automatically",
            "connected",
            "and",
            "added"
        ]
    },
    {
        "id": 2680,
        "code": "public long extract(final ConsumerRecord<Object, Object> record, final long partitionTime) {\n    final long timestamp = record.timestamp();\n\n    if (timestamp < 0) {\n        return onInvalidTimestamp(record, timestamp, partitionTime);\n    }\n\n    return timestamp;\n}",
        "summary_tokens": [
            "extracts",
            "the",
            "embedded",
            "metadata",
            "timestamp",
            "from",
            "the",
            "given",
            "consumer",
            "record"
        ]
    },
    {
        "id": 2681,
        "code": "public long onInvalidTimestamp(final ConsumerRecord<Object, Object> record,\n                               final long recordTimestamp,\n                               final long partitionTime)\n        throws StreamsException {\n\n    final String message = \"Input record \" + record + \" has invalid (negative) timestamp. \" +\n        \"Possibly because a pre-0.10 producer client was used to write this record to Kafka without embedding \" +\n        \"a timestamp, or because the input topic was created before upgrading the Kafka cluster to 0.10+. \" +\n        \"Use a different TimestampExtractor to process this data.\";\n\n    log.error(message);\n    throw new StreamsException(message);\n}",
        "summary_tokens": [
            "raises",
            "an",
            "exception",
            "on",
            "every",
            "call"
        ]
    },
    {
        "id": 2682,
        "code": "public long onInvalidTimestamp(final ConsumerRecord<Object, Object> record,\n                               final long recordTimestamp,\n                               final long partitionTime) {\n    log.warn(\"Input record {} will be dropped because it has an invalid (negative) timestamp.\", record);\n    return recordTimestamp;\n}",
        "summary_tokens": [
            "writes",
            "a",
            "log",
            "warn",
            "message",
            "when",
            "the",
            "extracted",
            "timestamp",
            "is",
            "invalid",
            "negative",
            "but",
            "returns",
            "the",
            "invalid",
            "timestamp",
            "as",
            "is",
            "which",
            "ultimately",
            "causes",
            "the",
            "record",
            "to",
            "be",
            "skipped",
            "and",
            "not",
            "to",
            "be",
            "processed"
        ]
    },
    {
        "id": 2683,
        "code": "default void init(final StateStoreContext context, final StateStore root) {\n    init(StoreToProcessorContextAdapter.adapt(context), root);\n}",
        "summary_tokens": [
            "initializes",
            "this",
            "state",
            "store"
        ]
    },
    {
        "id": 2684,
        "code": "default Position getPosition() {\n    throw new UnsupportedOperationException(\n        \"getPosition is not implemented by this StateStore (\" + getClass() + \")\"\n    );\n}",
        "summary_tokens": [
            "returns",
            "the",
            "position",
            "the",
            "state",
            "store",
            "is",
            "at",
            "with",
            "respect",
            "to",
            "the",
            "input",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 2685,
        "code": "public String topologyName() {\n    return topologyName;\n}",
        "summary_tokens": [
            "experimental",
            "feature",
            "will",
            "return",
            "null"
        ]
    },
    {
        "id": 2686,
        "code": "public static TaskId parse(final String taskIdStr) {\n    try {\n        final int namedTopologyDelimiterIndex = taskIdStr.indexOf(NAMED_TOPOLOGY_DELIMITER);\n            \n        if (namedTopologyDelimiterIndex < 0) {\n            final int index = taskIdStr.indexOf('_');\n\n            final int topicGroupId = Integer.parseInt(taskIdStr.substring(0, index));\n            final int partition = Integer.parseInt(taskIdStr.substring(index + 1));\n\n            return new TaskId(topicGroupId, partition);\n        } else {\n            final int topicGroupIdIndex = namedTopologyDelimiterIndex + 2;\n            final int subtopologyPartitionDelimiterIndex = taskIdStr.indexOf('_', topicGroupIdIndex);\n\n            final String namedTopology = taskIdStr.substring(0, namedTopologyDelimiterIndex);\n            final int topicGroupId = Integer.parseInt(taskIdStr.substring(topicGroupIdIndex, subtopologyPartitionDelimiterIndex));\n            final int partition = Integer.parseInt(taskIdStr.substring(subtopologyPartitionDelimiterIndex + 1));\n\n            return new TaskId(topicGroupId, partition, namedTopology);\n        }\n    } catch (final Exception e) {\n        throw new TaskIdFormatException(taskIdStr);\n    }\n}",
        "summary_tokens": [
            "task",
            "id",
            "format",
            "exception",
            "if",
            "the",
            "task",
            "id",
            "str",
            "is",
            "not",
            "a",
            "valid",
            "task",
            "id"
        ]
    },
    {
        "id": 2687,
        "code": "public void writeTo(final DataOutputStream out, final int version) throws IOException {\n    writeTaskIdTo(this, out, version);\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "cannot",
            "write",
            "to",
            "output",
            "stream",
            "since",
            "0"
        ]
    },
    {
        "id": 2688,
        "code": "public static TaskId readFrom(final DataInputStream in, final int version) throws IOException {\n    return readTaskIdFrom(in, version);\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "cannot",
            "read",
            "from",
            "input",
            "stream",
            "since",
            "0"
        ]
    },
    {
        "id": 2689,
        "code": "public String taskId() {\n    return taskId;\n}",
        "summary_tokens": [
            "the",
            "basic",
            "task",
            "metadata",
            "such",
            "as",
            "subtopology",
            "and",
            "partition",
            "id"
        ]
    },
    {
        "id": 2690,
        "code": "public Map<TopicPartition, Long> committedOffsets() {\n    return committedOffsets;\n}",
        "summary_tokens": [
            "this",
            "function",
            "will",
            "return",
            "a",
            "map",
            "of",
            "topic",
            "partitions",
            "and",
            "the",
            "highest",
            "committed",
            "offset",
            "seen",
            "so",
            "far"
        ]
    },
    {
        "id": 2691,
        "code": "public Map<TopicPartition, Long> endOffsets() {\n    return endOffsets;\n}",
        "summary_tokens": [
            "this",
            "function",
            "will",
            "return",
            "a",
            "map",
            "of",
            "topic",
            "partitions",
            "and",
            "the",
            "highest",
            "offset",
            "seen",
            "so",
            "far",
            "in",
            "the",
            "topic"
        ]
    },
    {
        "id": 2692,
        "code": "public Optional<Long> timeCurrentIdlingStarted() {\n    return timeCurrentIdlingStarted;\n}",
        "summary_tokens": [
            "this",
            "function",
            "will",
            "return",
            "the",
            "time",
            "task",
            "idling",
            "started",
            "if",
            "the",
            "task",
            "is",
            "not",
            "currently",
            "idling",
            "it",
            "will",
            "return",
            "empty"
        ]
    },
    {
        "id": 2693,
        "code": "public static To child(final String childName) {\n    return new To(childName, -1);\n}",
        "summary_tokens": [
            "forward",
            "the",
            "key",
            "value",
            "pair",
            "to",
            "one",
            "of",
            "the",
            "downstream",
            "processors",
            "designated",
            "by",
            "the",
            "downstream",
            "processor",
            "name"
        ]
    },
    {
        "id": 2694,
        "code": "public static To all() {\n    return new To(null, -1);\n}",
        "summary_tokens": [
            "forward",
            "the",
            "key",
            "value",
            "pair",
            "to",
            "all",
            "downstream",
            "processors",
            "a",
            "new",
            "to",
            "instance",
            "configured",
            "for",
            "all",
            "downstream",
            "processor"
        ]
    },
    {
        "id": 2695,
        "code": "public To withTimestamp(final long timestamp) {\n    this.timestamp = timestamp;\n    return this;\n}",
        "summary_tokens": [
            "set",
            "the",
            "timestamp",
            "of",
            "the",
            "output",
            "record"
        ]
    },
    {
        "id": 2696,
        "code": "public int hashCode() {\n    throw new UnsupportedOperationException(\"To is unsafe for use in Hash collections\");\n}",
        "summary_tokens": [
            "equality",
            "is",
            "implemented",
            "in",
            "support",
            "of",
            "tests",
            "not",
            "for",
            "use",
            "in",
            "hash",
            "collections",
            "since",
            "this",
            "class",
            "is",
            "mutable"
        ]
    },
    {
        "id": 2697,
        "code": "public long onInvalidTimestamp(final ConsumerRecord<Object, Object> record,\n                               final long recordTimestamp,\n                               final long partitionTime)\n        throws StreamsException {\n    if (partitionTime < 0) {\n        throw new StreamsException(\"Could not infer new timestamp for input record \" + record\n                + \" because partition time is unknown.\");\n    }\n    return partitionTime;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "current",
            "stream",
            "time",
            "as",
            "new",
            "timestamp",
            "for",
            "the",
            "record"
        ]
    },
    {
        "id": 2698,
        "code": "public long extract(final ConsumerRecord<Object, Object> record, final long partitionTime) {\n    return System.currentTimeMillis();\n}",
        "summary_tokens": [
            "return",
            "the",
            "current",
            "wall",
            "clock",
            "time",
            "as",
            "timestamp"
        ]
    },
    {
        "id": 2699,
        "code": "protected final FixedKeyProcessorContext<KIn, VOut> context() {\n    return context;\n}",
        "summary_tokens": [
            "get",
            "the",
            "processor",
            "s",
            "context",
            "set",
            "during",
            "init",
            "fixed",
            "key",
            "processor",
            "context",
            "initialization"
        ]
    },
    {
        "id": 2700,
        "code": "protected final ProcessorContext<KOut, VOut> context() {\n    return context;\n}",
        "summary_tokens": [
            "get",
            "the",
            "processor",
            "s",
            "context",
            "set",
            "during",
            "init",
            "processor",
            "context",
            "initialization"
        ]
    },
    {
        "id": 2701,
        "code": "default void init(final FixedKeyProcessorContext<KIn, VOut> context) {}",
        "summary_tokens": [
            "initialize",
            "this",
            "processor",
            "with",
            "the",
            "given",
            "context"
        ]
    },
    {
        "id": 2702,
        "code": "default void close() {}",
        "summary_tokens": [
            "close",
            "this",
            "processor",
            "and",
            "clean",
            "up",
            "any",
            "resources"
        ]
    },
    {
        "id": 2703,
        "code": "public K key() {\n    return key;\n}",
        "summary_tokens": [
            "the",
            "key",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2704,
        "code": "public V value() {\n    return value;\n}",
        "summary_tokens": [
            "the",
            "value",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2705,
        "code": "public long timestamp() {\n    return timestamp;\n}",
        "summary_tokens": [
            "the",
            "timestamp",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2706,
        "code": "public Headers headers() {\n    return headers;\n}",
        "summary_tokens": [
            "the",
            "headers",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2707,
        "code": "public <NewV> FixedKeyRecord<K, NewV> withValue(final NewV value) {\n    return new FixedKeyRecord<>(key, value, timestamp, headers);\n}",
        "summary_tokens": [
            "a",
            "convenient",
            "way",
            "to",
            "produce",
            "a",
            "new",
            "record",
            "if",
            "you",
            "only",
            "need",
            "to",
            "change",
            "the",
            "value"
        ]
    },
    {
        "id": 2708,
        "code": "public FixedKeyRecord<K, V> withTimestamp(final long timestamp) {\n    return new FixedKeyRecord<>(key, value, timestamp, headers);\n}",
        "summary_tokens": [
            "a",
            "convenient",
            "way",
            "to",
            "produce",
            "a",
            "new",
            "record",
            "if",
            "you",
            "only",
            "need",
            "to",
            "change",
            "the",
            "timestamp"
        ]
    },
    {
        "id": 2709,
        "code": "public FixedKeyRecord<K, V> withHeaders(final Headers headers) {\n    return new FixedKeyRecord<>(key, value, timestamp, headers);\n}",
        "summary_tokens": [
            "a",
            "convenient",
            "way",
            "to",
            "produce",
            "a",
            "new",
            "record",
            "if",
            "you",
            "only",
            "need",
            "to",
            "change",
            "the",
            "headers"
        ]
    },
    {
        "id": 2710,
        "code": "public static <KIn, VIn> FixedKeyRecord<KIn, VIn> create(final Record<KIn, VIn> record) {\n    return new FixedKeyRecord<>(\n        record.key(),\n        record.value(),\n        record.timestamp(),\n        record.headers()\n    );\n}",
        "summary_tokens": [
            "only",
            "allowed",
            "way",
            "to",
            "create",
            "fixed",
            "key",
            "record",
            "s"
        ]
    },
    {
        "id": 2711,
        "code": "default void init(final ProcessorContext<KOut, VOut> context) {}",
        "summary_tokens": [
            "initialize",
            "this",
            "processor",
            "with",
            "the",
            "given",
            "context"
        ]
    },
    {
        "id": 2712,
        "code": "default void close() {}",
        "summary_tokens": [
            "close",
            "this",
            "processor",
            "and",
            "clean",
            "up",
            "any",
            "resources"
        ]
    },
    {
        "id": 2713,
        "code": "public K key() {\n    return key;\n}",
        "summary_tokens": [
            "the",
            "key",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2714,
        "code": "public V value() {\n    return value;\n}",
        "summary_tokens": [
            "the",
            "value",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2715,
        "code": "public long timestamp() {\n    return timestamp;\n}",
        "summary_tokens": [
            "the",
            "timestamp",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2716,
        "code": "public Headers headers() {\n    return headers;\n}",
        "summary_tokens": [
            "the",
            "headers",
            "of",
            "the",
            "record"
        ]
    },
    {
        "id": 2717,
        "code": "public <NewK> Record<NewK, V> withKey(final NewK key) {\n    return new Record<>(key, value, timestamp, headers);\n}",
        "summary_tokens": [
            "a",
            "convenient",
            "way",
            "to",
            "produce",
            "a",
            "new",
            "record",
            "if",
            "you",
            "only",
            "need",
            "to",
            "change",
            "the",
            "key"
        ]
    },
    {
        "id": 2718,
        "code": "public <NewV> Record<K, NewV> withValue(final NewV value) {\n    return new Record<>(key, value, timestamp, headers);\n}",
        "summary_tokens": [
            "a",
            "convenient",
            "way",
            "to",
            "produce",
            "a",
            "new",
            "record",
            "if",
            "you",
            "only",
            "need",
            "to",
            "change",
            "the",
            "value"
        ]
    },
    {
        "id": 2719,
        "code": "public Record<K, V> withTimestamp(final long timestamp) {\n    return new Record<>(key, value, timestamp, headers);\n}",
        "summary_tokens": [
            "a",
            "convenient",
            "way",
            "to",
            "produce",
            "a",
            "new",
            "record",
            "if",
            "you",
            "only",
            "need",
            "to",
            "change",
            "the",
            "timestamp"
        ]
    },
    {
        "id": 2720,
        "code": "public Record<K, V> withHeaders(final Headers headers) {\n    return new Record<>(key, value, timestamp, headers);\n}",
        "summary_tokens": [
            "a",
            "convenient",
            "way",
            "to",
            "produce",
            "a",
            "new",
            "record",
            "if",
            "you",
            "only",
            "need",
            "to",
            "change",
            "the",
            "headers"
        ]
    },
    {
        "id": 2721,
        "code": "public void maybeCheckpoint(final boolean enforceCheckpoint) {\n    final Map<TopicPartition, Long> offsetSnapshot = stateMgr.changelogOffsets();\n    if (StateManagerUtil.checkpointNeeded(enforceCheckpoint, offsetSnapshotSinceLastFlush, offsetSnapshot)) {\n            \n        stateMgr.flush();\n        stateMgr.checkpoint();\n        offsetSnapshotSinceLastFlush = new HashMap<>(offsetSnapshot);\n    }\n}",
        "summary_tokens": [
            "the",
            "following",
            "exceptions",
            "maybe",
            "thrown",
            "from",
            "the",
            "state",
            "manager",
            "flushing",
            "call"
        ]
    },
    {
        "id": 2722,
        "code": "public static Map<TopicPartition, Long> fetchCommittedOffsets(final Set<TopicPartition> partitions,\n                                                              final Consumer<byte[], byte[]> consumer) {\n    if (partitions.isEmpty()) {\n        return Collections.emptyMap();\n    }\n\n    final Map<TopicPartition, Long> committedOffsets;\n    try {\n            \n        committedOffsets = consumer.committed(partitions).entrySet().stream()\n            .collect(Collectors.toMap(Map.Entry::getKey, e -> e.getValue() == null ? 0L : e.getValue().offset()));\n    } catch (final TimeoutException timeoutException) {\n        LOG.warn(\"The committed offsets request timed out, try increasing the consumer client's default.api.timeout.ms\", timeoutException);\n        throw timeoutException;\n    } catch (final KafkaException fatal) {\n        LOG.warn(\"The committed offsets request failed.\", fatal);\n        throw new StreamsException(String.format(\"Failed to retrieve end offsets for %s\", partitions), fatal);\n    }\n\n    return committedOffsets;\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "if",
            "the",
            "consumer",
            "throws",
            "an",
            "exception",
            "org"
        ]
    },
    {
        "id": 2723,
        "code": "public static Map<TopicPartition, ListOffsetsResultInfo> getEndOffsets(final KafkaFuture<Map<TopicPartition, ListOffsetsResultInfo>> endOffsetsFuture) {\n    try {\n        return endOffsetsFuture.get();\n    } catch (final RuntimeException | InterruptedException | ExecutionException e) {\n        LOG.warn(\"The listOffsets request failed.\", e);\n        throw new StreamsException(\"Unable to obtain end offsets from kafka\", e);\n    }\n}",
        "summary_tokens": [
            "a",
            "helper",
            "method",
            "that",
            "wraps",
            "the",
            "future",
            "get",
            "call",
            "and",
            "rethrows",
            "any",
            "thrown",
            "exception",
            "as",
            "a",
            "streams",
            "exception",
            "streams",
            "exception",
            "if",
            "the",
            "admin",
            "client",
            "request",
            "throws",
            "an",
            "exception"
        ]
    },
    {
        "id": 2724,
        "code": "public static Map<TopicPartition, ListOffsetsResultInfo> fetchEndOffsets(final Collection<TopicPartition> partitions,\n                                                                         final Admin adminClient) {\n    if (partitions.isEmpty()) {\n        return Collections.emptyMap();\n    }\n    return getEndOffsets(fetchEndOffsetsFuture(partitions, adminClient));\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "if",
            "the",
            "admin",
            "client",
            "request",
            "throws",
            "an",
            "exception"
        ]
    },
    {
        "id": 2725,
        "code": "public Cancellable schedule(final Duration interval, final PunctuationType type, final Punctuator callback) {\n    throw new UnsupportedOperationException(\"this should not happen: schedule() not supported in global processor context.\");\n}",
        "summary_tokens": [
            "unsupported",
            "operation",
            "exception",
            "on",
            "every",
            "invocation"
        ]
    },
    {
        "id": 2726,
        "code": "public Map<TopicPartition, Long> initialize() {\n    final Set<String> storeNames = stateMgr.initialize();\n    final Map<String, String> storeNameToTopic = topology.storeToChangelogTopic();\n    for (final String storeName : storeNames) {\n        final String sourceTopic = storeNameToTopic.get(storeName);\n        final SourceNode<?, ?> source = topology.source(sourceTopic);\n        deserializers.put(\n            sourceTopic,\n            new RecordDeserializer(\n                source,\n                deserializationExceptionHandler,\n                logContext,\n                droppedRecordsSensor(\n                    Thread.currentThread().getName(),\n                    processorContext.taskId().toString(),\n                    processorContext.metrics()\n                )\n            )\n        );\n    }\n    initTopology();\n    processorContext.initialize();\n    return stateMgr.changelogOffsets();\n}",
        "summary_tokens": [
            "illegal",
            "state",
            "exception",
            "if",
            "store",
            "gets",
            "registered",
            "after",
            "initialized",
            "is",
            "already",
            "finished",
            "streams",
            "exception",
            "if",
            "the",
            "store",
            "s",
            "change",
            "log",
            "does",
            "not",
            "contain",
            "the",
            "partition"
        ]
    },
    {
        "id": 2727,
        "code": "public void setStateListener(final StreamThread.StateListener listener) {\n    stateListener = listener;\n}",
        "summary_tokens": [
            "set",
            "the",
            "stream",
            "thread"
        ]
    },
    {
        "id": 2728,
        "code": "public State state() {\n        \n    return state;\n}",
        "summary_tokens": [
            "the",
            "state",
            "this",
            "instance",
            "is",
            "in"
        ]
    },
    {
        "id": 2729,
        "code": "default <T extends StateStore> T getStateStore(final StoreBuilder<T> builder) {\n    return (T) getStateStore(builder.name());\n}",
        "summary_tokens": [
            "get",
            "a",
            "correctly",
            "typed",
            "state",
            "store",
            "given",
            "a",
            "handle",
            "on",
            "the",
            "original",
            "builder"
        ]
    },
    {
        "id": 2730,
        "code": "public ValidationResult validate(final Map<String, InternalTopicConfig> topicConfigs) {\n    log.info(\"Starting to validate internal topics {}.\", topicConfigs.keySet());\n\n    final long now = time.milliseconds();\n    final long deadline = now + retryTimeoutMs;\n\n    final ValidationResult validationResult = new ValidationResult();\n    final Set<String> topicDescriptionsStillToValidate = new HashSet<>(topicConfigs.keySet());\n    final Set<String> topicConfigsStillToValidate = new HashSet<>(topicConfigs.keySet());\n    while (!topicDescriptionsStillToValidate.isEmpty() || !topicConfigsStillToValidate.isEmpty()) {\n        Map<String, KafkaFuture<TopicDescription>> descriptionsForTopic = Collections.emptyMap();\n        if (!topicDescriptionsStillToValidate.isEmpty()) {\n            final DescribeTopicsResult describeTopicsResult = adminClient.describeTopics(topicDescriptionsStillToValidate);\n            descriptionsForTopic = describeTopicsResult.topicNameValues();\n        }\n        Map<String, KafkaFuture<Config>> configsForTopic = Collections.emptyMap();\n        if (!topicConfigsStillToValidate.isEmpty()) {\n            final DescribeConfigsResult describeConfigsResult = adminClient.describeConfigs(\n                topicConfigsStillToValidate.stream()\n                    .map(topic -> new ConfigResource(Type.TOPIC, topic))\n                    .collect(Collectors.toSet())\n            );\n            configsForTopic = describeConfigsResult.values().entrySet().stream()\n                .collect(Collectors.toMap(entry -> entry.getKey().name(), Map.Entry::getValue));\n        }\n\n        while (!descriptionsForTopic.isEmpty() || !configsForTopic.isEmpty()) {\n            if (!descriptionsForTopic.isEmpty()) {\n                doValidateTopic(\n                    validationResult,\n                    descriptionsForTopic,\n                    topicConfigs,\n                    topicDescriptionsStillToValidate,\n                    (streamsSide, brokerSide) -> validatePartitionCount(validationResult, streamsSide, brokerSide)\n                );\n            }\n            if (!configsForTopic.isEmpty()) {\n                doValidateTopic(\n                    validationResult,\n                    configsForTopic,\n                    topicConfigs,\n                    topicConfigsStillToValidate,\n                    (streamsSide, brokerSide) -> validateCleanupPolicy(validationResult, streamsSide, brokerSide)\n                );\n            }\n\n            maybeThrowTimeoutException(\n                Arrays.asList(topicDescriptionsStillToValidate, topicConfigsStillToValidate),\n                deadline,\n                String.format(\"Could not validate internal topics within %d milliseconds. \" +\n                    \"This can happen if the Kafka cluster is temporarily not available.\", retryTimeoutMs)\n            );\n\n            if (!descriptionsForTopic.isEmpty() || !configsForTopic.isEmpty()) {\n                Utils.sleep(100);\n            }\n        }\n\n        maybeSleep(\n            Arrays.asList(topicDescriptionsStillToValidate, topicConfigsStillToValidate),\n            deadline,\n            \"validated\"\n        );\n    }\n\n    log.info(\"Completed validation of internal topics {}.\", topicConfigs.keySet());\n    return validationResult;\n}",
        "summary_tokens": [
            "validates",
            "the",
            "internal",
            "topics",
            "passed"
        ]
    },
    {
        "id": 2731,
        "code": "public Set<String> makeReady(final Map<String, InternalTopicConfig> topics) {\n        \n        \n    log.debug(\"Starting to validate internal topics {} in partition assignor.\", topics);\n\n    long currentWallClockMs = time.milliseconds();\n    final long deadlineMs = currentWallClockMs + retryTimeoutMs;\n\n    Set<String> topicsNotReady = new HashSet<>(topics.keySet());\n    final Set<String> newlyCreatedTopics = new HashSet<>();\n\n    while (!topicsNotReady.isEmpty()) {\n        final Set<String> tempUnknownTopics = new HashSet<>();\n        topicsNotReady = validateTopics(topicsNotReady, topics, tempUnknownTopics);\n        newlyCreatedTopics.addAll(topicsNotReady);\n\n        if (!topicsNotReady.isEmpty()) {\n            final Set<NewTopic> newTopics = new HashSet<>();\n\n            for (final String topicName : topicsNotReady) {\n                if (tempUnknownTopics.contains(topicName)) {\n                        \n                        \n                    continue;\n                }\n                final InternalTopicConfig internalTopicConfig = Objects.requireNonNull(topics.get(topicName));\n                final Map<String, String> topicConfig = internalTopicConfig.getProperties(defaultTopicConfigs, windowChangeLogAdditionalRetention);\n\n                log.debug(\"Going to create topic {} with {} partitions and config {}.\",\n                    internalTopicConfig.name(),\n                    internalTopicConfig.numberOfPartitions(),\n                    topicConfig);\n\n                newTopics.add(\n                    new NewTopic(\n                        internalTopicConfig.name(),\n                        internalTopicConfig.numberOfPartitions(),\n                        Optional.of(replicationFactor))\n                        .configs(topicConfig));\n            }\n\n                \n                \n                \n            if (!newTopics.isEmpty()) {\n                final CreateTopicsResult createTopicsResult = adminClient.createTopics(newTopics);\n\n                for (final Map.Entry<String, KafkaFuture<Void>> createTopicResult : createTopicsResult.values().entrySet()) {\n                    final String topicName = createTopicResult.getKey();\n                    try {\n                        createTopicResult.getValue().get();\n                        topicsNotReady.remove(topicName);\n                    } catch (final InterruptedException fatalException) {\n                            \n                        Thread.currentThread().interrupt();\n                        log.error(INTERRUPTED_ERROR_MESSAGE, fatalException);\n                        throw new IllegalStateException(INTERRUPTED_ERROR_MESSAGE, fatalException);\n                    } catch (final ExecutionException executionException) {\n                        final Throwable cause = executionException.getCause();\n                        if (cause instanceof TopicExistsException) {\n                                \n                            log.info(\n                                    \"Could not create topic {}. Topic is probably marked for deletion (number of partitions is unknown).\\n\"\n                                            +\n                                            \"Will retry to create this topic in {} ms (to let broker finish async delete operation first).\\n\"\n                                            +\n                                            \"Error message was: {}\", topicName, retryBackOffMs,\n                                    cause.toString());\n                        } else {\n                            log.error(\"Unexpected error during topic creation for {}.\\n\" +\n                                    \"Error message was: {}\", topicName, cause.toString());\n\n                            if (cause instanceof UnsupportedVersionException) {\n                                final String errorMessage = cause.getMessage();\n                                if (errorMessage != null &&\n                                        errorMessage.startsWith(\"Creating topics with default partitions/replication factor are only supported in CreateTopicRequest version 4+\")) {\n\n                                    throw new StreamsException(String.format(\n                                            \"Could not create topic %s, because brokers don't support configuration replication.factor=-1.\"\n                                                    + \" You can change the replication.factor config or upgrade your brokers to version 2.4 or newer to avoid this error.\",\n                                            topicName)\n                                    );\n                                }\n                            } else {\n                                throw new StreamsException(\n                                        String.format(\"Could not create topic %s.\", topicName),\n                                        cause\n                                );\n                            }\n                        }\n                    } catch (final TimeoutException retriableException) {\n                        log.error(\"Creating topic {} timed out.\\n\" +\n                                \"Error message was: {}\", topicName, retriableException.toString());\n                    }\n                }\n            }\n        }\n\n        if (!topicsNotReady.isEmpty()) {\n            currentWallClockMs = time.milliseconds();\n\n            if (currentWallClockMs >= deadlineMs) {\n                final String timeoutError = String.format(\"Could not create topics within %d milliseconds. \" +\n                    \"This can happen if the Kafka cluster is temporarily not available.\", retryTimeoutMs);\n                log.error(timeoutError);\n                throw new TimeoutException(timeoutError);\n            }\n            log.info(\n                \"Topics {} could not be made ready. Will retry in {} milliseconds. Remaining time in milliseconds: {}\",\n                topicsNotReady,\n                retryBackOffMs,\n                deadlineMs - currentWallClockMs\n            );\n            Utils.sleep(retryBackOffMs);\n        }\n    }\n    log.debug(\"Completed validating internal topics and created {}\", newlyCreatedTopics);\n\n    return newlyCreatedTopics;\n}",
        "summary_tokens": [
            "prepares",
            "a",
            "set",
            "of",
            "given",
            "internal",
            "topics"
        ]
    },
    {
        "id": 2732,
        "code": "protected Map<String, Integer> getNumPartitions(final Set<String> topics,\n                                                final Set<String> tempUnknownTopics) {\n    log.debug(\"Trying to check if topics {} have been created with expected number of partitions.\", topics);\n\n    final DescribeTopicsResult describeTopicsResult = adminClient.describeTopics(topics);\n    final Map<String, KafkaFuture<TopicDescription>> futures = describeTopicsResult.topicNameValues();\n\n    final Map<String, Integer> existedTopicPartition = new HashMap<>();\n    for (final Map.Entry<String, KafkaFuture<TopicDescription>> topicFuture : futures.entrySet()) {\n        final String topicName = topicFuture.getKey();\n        try {\n            final TopicDescription topicDescription = topicFuture.getValue().get();\n            existedTopicPartition.put(topicName, topicDescription.partitions().size());\n        } catch (final InterruptedException fatalException) {\n                \n            Thread.currentThread().interrupt();\n            log.error(INTERRUPTED_ERROR_MESSAGE, fatalException);\n            throw new IllegalStateException(INTERRUPTED_ERROR_MESSAGE, fatalException);\n        } catch (final ExecutionException couldNotDescribeTopicException) {\n            final Throwable cause = couldNotDescribeTopicException.getCause();\n            if (cause instanceof UnknownTopicOrPartitionException) {\n                    \n                log.debug(\"Topic {} is unknown or not found, hence not existed yet.\\n\" +\n                    \"Error message was: {}\", topicName, cause.toString());\n            } else if (cause instanceof LeaderNotAvailableException) {\n                tempUnknownTopics.add(topicName);\n                log.debug(\"The leader of topic {} is not available.\\n\" +\n                    \"Error message was: {}\", topicName, cause.toString());\n            } else {\n                log.error(\"Unexpected error during topic description for {}.\\n\" +\n                    \"Error message was: {}\", topicName, cause.toString());\n                throw new StreamsException(String.format(\"Could not create topic %s.\", topicName), cause);\n            }\n        } catch (final TimeoutException retriableException) {\n            tempUnknownTopics.add(topicName);\n            log.debug(\"Describing topic {} (to get number of partitions) timed out.\\n\" +\n                \"Error message was: {}\", topicName, retriableException.toString());\n        }\n    }\n\n    return existedTopicPartition;\n}",
        "summary_tokens": [
            "try",
            "to",
            "get",
            "the",
            "number",
            "of",
            "partitions",
            "for",
            "the",
            "given",
            "topics",
            "return",
            "the",
            "number",
            "of",
            "partitions",
            "for",
            "topics",
            "that",
            "already",
            "exists"
        ]
    },
    {
        "id": 2733,
        "code": "private Set<String> validateTopics(final Set<String> topicsToValidate,\n                                   final Map<String, InternalTopicConfig> topicsMap,\n                                   final Set<String> tempUnknownTopics) {\n    if (!topicsMap.keySet().containsAll(topicsToValidate)) {\n        throw new IllegalStateException(\"The topics map \" + topicsMap.keySet() + \" does not contain all the topics \" +\n            topicsToValidate + \" trying to validate.\");\n    }\n\n    final Map<String, Integer> existedTopicPartition = getNumPartitions(topicsToValidate, tempUnknownTopics);\n\n    final Set<String> topicsToCreate = new HashSet<>();\n    for (final String topicName : topicsToValidate) {\n        final Optional<Integer> numberOfPartitions = topicsMap.get(topicName).numberOfPartitions();\n        if (!numberOfPartitions.isPresent()) {\n            log.error(\"Found undefined number of partitions for topic {}\", topicName);\n            throw new StreamsException(\"Topic \" + topicName + \" number of partitions not defined\");\n        }\n        if (existedTopicPartition.containsKey(topicName)) {\n            if (!existedTopicPartition.get(topicName).equals(numberOfPartitions.get())) {\n                final String errorMsg = String.format(\"Existing internal topic %s has invalid partitions: \" +\n                        \"expected: %d; actual: %d. \" +\n                        \"Use 'kafka.tools.StreamsResetter' tool to clean up invalid topics before processing.\",\n                    topicName, numberOfPartitions.get(), existedTopicPartition.get(topicName));\n                log.error(errorMsg);\n                throw new StreamsException(errorMsg);\n            }\n        } else {\n            topicsToCreate.add(topicName);\n        }\n    }\n\n    return topicsToCreate;\n}",
        "summary_tokens": [
            "check",
            "the",
            "existing",
            "topics",
            "to",
            "have",
            "correct",
            "number",
            "of",
            "partitions",
            "and",
            "return",
            "the",
            "remaining",
            "topics",
            "that",
            "needs",
            "to",
            "be",
            "created"
        ]
    },
    {
        "id": 2734,
        "code": "public void setup(final Map<String, InternalTopicConfig> topicConfigs) {\n    log.info(\"Starting to setup internal topics {}.\", topicConfigs.keySet());\n\n    final long now = time.milliseconds();\n    final long deadline = now + retryTimeoutMs;\n\n    final Map<String, Map<String, String>> streamsSideTopicConfigs = topicConfigs.values().stream()\n        .collect(Collectors.toMap(\n            InternalTopicConfig::name,\n            topicConfig -> topicConfig.getProperties(defaultTopicConfigs, windowChangeLogAdditionalRetention)\n        ));\n    final Set<String> createdTopics = new HashSet<>();\n    final Set<String> topicStillToCreate = new HashSet<>(topicConfigs.keySet());\n    while (!topicStillToCreate.isEmpty()) {\n        final Set<NewTopic> newTopics = topicStillToCreate.stream()\n            .map(topicName -> new NewTopic(\n                    topicName,\n                    topicConfigs.get(topicName).numberOfPartitions(),\n                    Optional.of(replicationFactor)\n                ).configs(streamsSideTopicConfigs.get(topicName))\n            ).collect(Collectors.toSet());\n\n        log.info(\"Going to create internal topics: \" + newTopics);\n        final CreateTopicsResult createTopicsResult = adminClient.createTopics(newTopics);\n\n        processCreateTopicResults(createTopicsResult, topicStillToCreate, createdTopics, deadline);\n\n        maybeSleep(Collections.singletonList(topicStillToCreate), deadline, \"created\");\n    }\n\n    log.info(\"Completed setup of internal topics {}.\", topicConfigs.keySet());\n}",
        "summary_tokens": [
            "sets",
            "up",
            "internal",
            "topics"
        ]
    },
    {
        "id": 2735,
        "code": "public synchronized ProcessorTopology buildTopology() {\n    final Set<String> nodeGroup = new HashSet<>();\n    for (final Set<String> value : nodeGroups().values()) {\n        nodeGroup.addAll(value);\n    }\n    nodeGroup.removeAll(globalNodeGroups());\n\n    initializeSubscription();\n    return build(nodeGroup);\n}",
        "summary_tokens": [
            "the",
            "full",
            "topology",
            "minus",
            "any",
            "global",
            "state"
        ]
    },
    {
        "id": 2736,
        "code": "public synchronized ProcessorTopology buildSubtopology(final int topicGroupId) {\n    final Set<String> nodeGroup = nodeGroups().get(topicGroupId);\n    return build(nodeGroup);\n}",
        "summary_tokens": [
            "topic",
            "group",
            "id",
            "group",
            "of",
            "topics",
            "corresponding",
            "to",
            "a",
            "single",
            "subtopology",
            "subset",
            "of",
            "the",
            "full",
            "topology"
        ]
    },
    {
        "id": 2737,
        "code": "public synchronized ProcessorTopology buildGlobalStateTopology() {\n    Objects.requireNonNull(applicationId, \"topology has not completed optimization\");\n\n    final Set<String> globalGroups = globalNodeGroups();\n    if (globalGroups.isEmpty()) {\n        return null;\n    }\n    return build(globalGroups);\n}",
        "summary_tokens": [
            "builds",
            "the",
            "topology",
            "for",
            "any",
            "global",
            "state",
            "stores",
            "processor",
            "topology",
            "of",
            "global",
            "state"
        ]
    },
    {
        "id": 2738,
        "code": "public Map<String, StateStore> globalStateStores() {\n    Objects.requireNonNull(applicationId, \"topology has not completed optimization\");\n\n    return Collections.unmodifiableMap(globalStateStores);\n}",
        "summary_tokens": [
            "get",
            "any",
            "global",
            "state",
            "store",
            "s",
            "that",
            "are",
            "part",
            "of",
            "the",
            "topology",
            "map",
            "containing",
            "all",
            "global",
            "state",
            "store",
            "s"
        ]
    },
    {
        "id": 2739,
        "code": "public synchronized Map<Subtopology, TopicsInfo> subtopologyToTopicsInfo() {\n    final Map<Subtopology, TopicsInfo> topicGroups = new LinkedHashMap<>();\n\n    if (nodeGroups == null) {\n        nodeGroups = makeNodeGroups();\n    }\n\n    for (final Map.Entry<Integer, Set<String>> entry : nodeGroups.entrySet()) {\n        final Set<String> sinkTopics = new HashSet<>();\n        final Set<String> sourceTopics = new HashSet<>();\n        final Map<String, InternalTopicConfig> repartitionTopics = new HashMap<>();\n        final Map<String, InternalTopicConfig> stateChangelogTopics = new HashMap<>();\n        for (final String node : entry.getValue()) {\n                \n            final List<String> topics = nodeToSourceTopics.get(node);\n            if (topics != null) {\n                    \n                for (final String topic : topics) {\n                        \n                    if (globalTopics.contains(topic)) {\n                        continue;\n                    }\n                    if (internalTopicNamesWithProperties.containsKey(topic)) {\n                            \n                        final String internalTopic = decorateTopic(topic);\n\n                        final RepartitionTopicConfig repartitionTopicConfig = buildRepartitionTopicConfig(\n                            internalTopic,\n                            internalTopicNamesWithProperties.get(topic).getNumberOfPartitions()\n                        );\n\n                        repartitionTopics.put(repartitionTopicConfig.name(), repartitionTopicConfig);\n                        sourceTopics.add(repartitionTopicConfig.name());\n                    } else {\n                        sourceTopics.add(topic);\n                    }\n                }\n            }\n\n                \n            final String topic = nodeToSinkTopic.get(node);\n            if (topic != null) {\n                if (internalTopicNamesWithProperties.containsKey(topic)) {\n                        \n                    sinkTopics.add(decorateTopic(topic));\n                } else {\n                    sinkTopics.add(topic);\n                }\n            }\n\n                \n                \n            for (final StateStoreFactory<?> stateFactory : stateFactories.values()) {\n                if (stateFactory.users().contains(node) && storeToChangelogTopic.containsKey(stateFactory.name())) {\n                    final String topicName = storeToChangelogTopic.get(stateFactory.name());\n                    if (!stateChangelogTopics.containsKey(topicName)) {\n                        final InternalTopicConfig internalTopicConfig =\n                            createChangelogTopicConfig(stateFactory, topicName);\n                        stateChangelogTopics.put(topicName, internalTopicConfig);\n                    }\n                }\n            }\n        }\n        if (!sourceTopics.isEmpty()) {\n            topicGroups.put(new Subtopology(entry.getKey(), topologyName), new TopicsInfo(\n                    Collections.unmodifiableSet(sinkTopics),\n                    Collections.unmodifiableSet(sourceTopics),\n                    Collections.unmodifiableMap(repartitionTopics),\n                    Collections.unmodifiableMap(stateChangelogTopics)));\n        }\n    }\n\n    return Collections.unmodifiableMap(topicGroups);\n}",
        "summary_tokens": [
            "returns",
            "the",
            "map",
            "of",
            "topic",
            "groups",
            "keyed",
            "by",
            "the",
            "group",
            "id"
        ]
    },
    {
        "id": 2740,
        "code": "public Map<String, List<String>> stateStoreNameToFullSourceTopicNames() {\n    final Map<String, List<String>> results = new HashMap<>();\n    for (final Map.Entry<String, Set<String>> entry : stateStoreNameToRawSourceTopicNames.entrySet()) {\n        results.put(entry.getKey(), maybeDecorateInternalSourceTopics(entry.getValue()));\n    }\n    return results;\n}",
        "summary_tokens": [
            "map",
            "from",
            "state",
            "store",
            "name",
            "to",
            "full",
            "names",
            "including",
            "application",
            "id",
            "topology",
            "name",
            "prefix",
            "of",
            "all",
            "source",
            "topics",
            "whose",
            "processors",
            "are",
            "connected",
            "to",
            "it"
        ]
    },
    {
        "id": 2741,
        "code": "public Collection<String> sourceTopicsForStore(final String storeName) {\n    return maybeDecorateInternalSourceTopics(stateStoreNameToRawSourceTopicNames.get(storeName));\n}",
        "summary_tokens": [
            "the",
            "full",
            "names",
            "including",
            "application",
            "id",
            "topology",
            "name",
            "prefix",
            "of",
            "all",
            "source",
            "topics",
            "whose",
            "processors",
            "are",
            "connected",
            "to",
            "the",
            "given",
            "state",
            "store"
        ]
    },
    {
        "id": 2742,
        "code": "public synchronized List<String> fullSourceTopicNames() {\n    if (fullSourceTopicNames == null) {\n        fullSourceTopicNames = maybeDecorateInternalSourceTopics(rawSourceTopicNames);\n        Collections.sort(fullSourceTopicNames);\n    }\n    return fullSourceTopicNames;\n}",
        "summary_tokens": [
            "names",
            "of",
            "all",
            "source",
            "topics",
            "including",
            "the",
            "application",
            "id",
            "named",
            "topology",
            "prefix",
            "for",
            "repartition",
            "sources"
        ]
    },
    {
        "id": 2743,
        "code": "public synchronized List<String> allSourcePatternStrings() {\n    return nodeToSourcePatterns.values().stream().map(Pattern::pattern).collect(Collectors.toList());\n}",
        "summary_tokens": [
            "a",
            "copy",
            "of",
            "the",
            "string",
            "representation",
            "of",
            "any",
            "pattern",
            "subscribed",
            "source",
            "nodes"
        ]
    },
    {
        "id": 2744,
        "code": "StampedRecord nextRecord(final RecordInfo info, final long wallClockTime) {\n    StampedRecord record = null;\n\n    final RecordQueue queue = nonEmptyQueuesByTime.poll();\n    info.queue = queue;\n\n    if (queue != null) {\n            \n        record = queue.poll(wallClockTime);\n\n        if (record != null) {\n            --totalBuffered;\n\n            if (queue.isEmpty()) {\n                    \n                allBuffered = false;\n            } else {\n                nonEmptyQueuesByTime.offer(queue);\n            }\n\n                \n            if (record.timestamp > streamTime) {\n                streamTime = record.timestamp;\n                recordLatenessSensor.record(0, wallClockTime);\n            } else {\n                recordLatenessSensor.record(streamTime - record.timestamp, wallClockTime);\n            }\n        }\n    }\n\n    return record;\n}",
        "summary_tokens": [
            "get",
            "the",
            "next",
            "record",
            "and",
            "queue"
        ]
    },
    {
        "id": 2745,
        "code": "int addRawRecords(final TopicPartition partition, final Iterable<ConsumerRecord<byte[], byte[]>> rawRecords) {\n    final RecordQueue recordQueue = partitionQueues.get(partition);\n\n    if (recordQueue == null) {\n        throw new IllegalStateException(\"Partition \" + partition + \" not found.\");\n    }\n\n    final int oldSize = recordQueue.size();\n    final int newSize = recordQueue.addRawRecords(rawRecords);\n\n        \n    if (oldSize == 0 && newSize > 0) {\n        nonEmptyQueuesByTime.offer(recordQueue);\n\n            \n            \n            \n        if (nonEmptyQueuesByTime.size() == this.partitionQueues.size()) {\n            allBuffered = true;\n        }\n    }\n\n    totalBuffered += newSize - oldSize;\n\n    return newSize;\n}",
        "summary_tokens": [
            "adds",
            "raw",
            "records",
            "to",
            "this",
            "partition",
            "group"
        ]
    },
    {
        "id": 2746,
        "code": "long streamTime() {\n    return streamTime;\n}",
        "summary_tokens": [
            "return",
            "the",
            "stream",
            "time",
            "of",
            "this",
            "partition",
            "group",
            "defined",
            "as",
            "the",
            "largest",
            "timestamp",
            "seen",
            "across",
            "all",
            "partitions"
        ]
    },
    {
        "id": 2747,
        "code": "int numBuffered(final TopicPartition partition) {\n    final RecordQueue recordQueue = partitionQueues.get(partition);\n\n    if (recordQueue == null) {\n        throw new IllegalStateException(\"Partition \" + partition + \" not found.\");\n    }\n\n    return recordQueue.size();\n}",
        "summary_tokens": [
            "illegal",
            "state",
            "exception",
            "if",
            "the",
            "record",
            "s",
            "partition",
            "does",
            "not",
            "belong",
            "to",
            "this",
            "partition",
            "group"
        ]
    },
    {
        "id": 2748,
        "code": "public Map<TaskId, Set<TopicPartition>> partitionGroups(final Map<Subtopology, Set<String>> topicGroups, final Cluster metadata) {\n    final Map<TaskId, Set<TopicPartition>> groups = new HashMap<>();\n\n    for (final Map.Entry<Subtopology, Set<String>> entry : topicGroups.entrySet()) {\n        final Subtopology subtopology = entry.getKey();\n        final Set<String> topicGroup = entry.getValue();\n\n        final int maxNumPartitions = maxNumPartitions(metadata, topicGroup);\n\n        for (int partitionId = 0; partitionId < maxNumPartitions; partitionId++) {\n            final Set<TopicPartition> group = new HashSet<>(topicGroup.size());\n\n            for (final String topic : topicGroup) {\n                final List<PartitionInfo> partitions = metadata.partitionsForTopic(topic);\n                if (partitionId < partitions.size()) {\n                    group.add(new TopicPartition(topic, partitionId));\n                }\n            }\n            groups.put(new TaskId(subtopology.nodeGroupId, partitionId, subtopology.namedTopology), Collections.unmodifiableSet(group));\n        }\n    }\n\n    return Collections.unmodifiableMap(groups);\n}",
        "summary_tokens": [
            "generate",
            "tasks",
            "with",
            "the",
            "assigned",
            "topic",
            "partitions"
        ]
    },
    {
        "id": 2749,
        "code": "protected int maxNumPartitions(final Cluster metadata, final Set<String> topics) {\n    int maxNumPartitions = 0;\n    for (final String topic : topics) {\n        final List<PartitionInfo> partitions = metadata.partitionsForTopic(topic);\n        if (partitions.isEmpty()) {\n            log.error(\"Empty partitions for topic {}\", topic);\n            throw new RuntimeException(\"Empty partitions for topic \" + topic);\n        }\n\n        final int numPartitions = partitions.size();\n        if (numPartitions > maxNumPartitions) {\n            maxNumPartitions = numPartitions;\n        }\n    }\n    return maxNumPartitions;\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "if",
            "no",
            "metadata",
            "can",
            "be",
            "received",
            "for",
            "a",
            "topic"
        ]
    },
    {
        "id": 2750,
        "code": "public <S extends StateStore> S  getStateStore(final String name) {\n    throwUnsupportedOperationExceptionIfStandby(\"getStateStore\");\n    if (currentNode() == null) {\n        throw new StreamsException(\"Accessing from an unknown node\");\n    }\n\n    final StateStore globalStore = stateManager.getGlobalStore(name);\n    if (globalStore != null) {\n        return (S) getReadOnlyStore(globalStore);\n    }\n\n    if (!currentNode().stateStores.contains(name)) {\n        throw new StreamsException(\"Processor \" + currentNode().name() + \" has no access to StateStore \" + name +\n            \" as the store is not connected to the processor. If you add stores manually via '.addStateStore()' \" +\n            \"make sure to connect the added store to the processor by providing the processor name to \" +\n            \"'.addStateStore()' or connect them via '.connectProcessorAndStateStores()'. \" +\n            \"DSL users need to provide the store name to '.process()', '.transform()', or '.transformValues()' \" +\n            \"to connect the store to the corresponding operator, or they can provide a StoreBuilder by implementing \" +\n            \"the stores() method on the Supplier itself. If you do not add stores manually, \" +\n            \"please file a bug report at https://issues.apache.org/jira/projects/KAFKA.\");\n    }\n\n    final StateStore store = stateManager.getStore(name);\n    return (S) getReadWriteStore(store);\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "if",
            "an",
            "attempt",
            "is",
            "made",
            "to",
            "access",
            "this",
            "state",
            "store",
            "from",
            "an",
            "unknown",
            "node",
            "unsupported",
            "operation",
            "exception",
            "if",
            "the",
            "current",
            "stream",
            "task",
            "type",
            "is",
            "standby"
        ]
    },
    {
        "id": 2751,
        "code": "public static long currentSystemTime(final ProcessorContext context) {\n    return context.currentSystemTimeMs();\n}",
        "summary_tokens": [
            "note",
            "that",
            "kip",
            "0",
            "would",
            "move",
            "current",
            "system",
            "time",
            "ms",
            "to",
            "processor",
            "context",
            "removing",
            "the",
            "need",
            "for",
            "this",
            "method"
        ]
    },
    {
        "id": 2752,
        "code": "public static StreamsMetricsImpl getMetricsImpl(final StateStoreContext context) {\n    return (StreamsMetricsImpl) context.metrics();\n}",
        "summary_tokens": [
            "should",
            "be",
            "removed",
            "as",
            "part",
            "of",
            "kafka",
            "0"
        ]
    },
    {
        "id": 2753,
        "code": "public void update(final ProcessorMetadata other) {\n    if (other == null) {\n        return;\n    }\n    for (final Map.Entry<String, Long> kv : other.metadata.entrySet()) {\n        final Long value = metadata.get(kv.getKey());\n        if (value == null || value < kv.getValue()) {\n            metadata.put(kv.getKey(), kv.getValue());\n        }\n    }\n}",
        "summary_tokens": [
            "merge",
            "with",
            "other",
            "metadata"
        ]
    },
    {
        "id": 2754,
        "code": "public boolean needsCommit() {\n    return needsCommit;\n}",
        "summary_tokens": [
            "whether",
            "metadata",
            "needs",
            "to",
            "be",
            "committed"
        ]
    },
    {
        "id": 2755,
        "code": "public String toString(final String indent) {\n    final StringBuilder sb = new StringBuilder(indent + name + \":\\n\");\n    if (stateStores != null && !stateStores.isEmpty()) {\n        sb.append(indent).append(\"\\tstates:\\t\\t[\");\n        for (final String store : stateStores) {\n            sb.append(store);\n            sb.append(\", \");\n        }\n        sb.setLength(sb.length() - 2);  \n        sb.append(\"]\\n\");\n    }\n    return sb.toString();\n}",
        "summary_tokens": [
            "a",
            "string",
            "representation",
            "of",
            "this",
            "node",
            "starting",
            "with",
            "the",
            "given",
            "indent",
            "useful",
            "for",
            "debugging"
        ]
    },
    {
        "id": 2756,
        "code": "public int hashCode() {\n    throw new UnsupportedOperationException(\"ProcessorRecordContext is unsafe for use in Hash collections\");\n}",
        "summary_tokens": [
            "equality",
            "is",
            "implemented",
            "in",
            "support",
            "of",
            "tests",
            "not",
            "for",
            "use",
            "in",
            "hash",
            "collections",
            "since",
            "this",
            "class",
            "is",
            "mutable"
        ]
    },
    {
        "id": 2757,
        "code": "public void flush() {\n    RuntimeException firstException = null;\n        \n    if (!stores.isEmpty()) {\n        log.debug(\"Flushing all stores registered in the state manager: {}\", stores);\n        for (final StateStoreMetadata metadata : stores.values()) {\n            final StateStore store = metadata.stateStore;\n            log.trace(\"Flushing store {}\", store.name());\n            try {\n                store.flush();\n            } catch (final RuntimeException exception) {\n                if (firstException == null) {\n                        \n                    if (exception instanceof StreamsException)\n                        firstException = exception;\n                    else\n                        firstException = new ProcessorStateException(\n                            format(\"%sFailed to flush state store %s\", logPrefix, store.name()), exception);\n                }\n                log.error(\"Failed to flush state store {}: \", store.name(), exception);\n            }\n        }\n    }\n\n    if (firstException != null) {\n        throw firstException;\n    }\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "recoverable",
            "error",
            "sending",
            "changelog",
            "records",
            "that",
            "would",
            "cause",
            "the",
            "task",
            "to",
            "be",
            "removed",
            "streams",
            "exception",
            "fatal",
            "error",
            "when",
            "flushing",
            "the",
            "state",
            "store",
            "for",
            "example",
            "sending",
            "changelog",
            "records",
            "failed",
            "or",
            "flushing",
            "state",
            "store",
            "get",
            "io",
            "errors",
            "such",
            "error",
            "should",
            "cause",
            "the",
            "thread",
            "to",
            "die"
        ]
    },
    {
        "id": 2758,
        "code": "public void close() throws ProcessorStateException {\n    log.debug(\"Closing its state manager and all the registered state stores: {}\", stores);\n\n    changelogReader.unregister(getAllChangelogTopicPartitions());\n\n    RuntimeException firstException = null;\n        \n        \n    if (!stores.isEmpty()) {\n        for (final Map.Entry<String, StateStoreMetadata> entry : stores.entrySet()) {\n            final StateStore store = entry.getValue().stateStore;\n            log.trace(\"Closing store {}\", store.name());\n            try {\n                store.close();\n            } catch (final RuntimeException exception) {\n                if (firstException == null) {\n                        \n                    if (exception instanceof StreamsException)\n                        firstException = exception;\n                    else\n                        firstException = new ProcessorStateException(\n                            format(\"%sFailed to close state store %s\", logPrefix, store.name()), exception);\n                }\n                log.error(\"Failed to close state store {}: \", store.name(), exception);\n            }\n        }\n\n        stores.clear();\n    }\n\n    if (firstException != null) {\n        throw firstException;\n    }\n}",
        "summary_tokens": [
            "state",
            "store",
            "close",
            "close",
            "all",
            "stores",
            "even",
            "in",
            "case",
            "of",
            "failure"
        ]
    },
    {
        "id": 2759,
        "code": "void recycle() {\n    log.debug(\"Recycling state for {} task {}.\", taskType, taskId);\n\n    final List<TopicPartition> allChangelogs = getAllChangelogTopicPartitions();\n    changelogReader.unregister(allChangelogs);\n}",
        "summary_tokens": [
            "alternative",
            "to",
            "close",
            "that",
            "just",
            "resets",
            "the",
            "changelogs",
            "without",
            "closing",
            "any",
            "of",
            "the",
            "underlying",
            "state",
            "or",
            "unregistering",
            "the",
            "stores",
            "themselves"
        ]
    },
    {
        "id": 2760,
        "code": "public String toString(final String indent) {\n    final Map<SourceNode<?, ?>, List<String>> sourceToTopics = new HashMap<>();\n    for (final Map.Entry<String, SourceNode<?, ?>> sourceNodeEntry : sourceNodesByTopic.entrySet()) {\n        final String topic = sourceNodeEntry.getKey();\n        final SourceNode<?, ?> source = sourceNodeEntry.getValue();\n        sourceToTopics.computeIfAbsent(source, s -> new ArrayList<>());\n        sourceToTopics.get(source).add(topic);\n    }\n\n    final StringBuilder sb = new StringBuilder(indent + \"ProcessorTopology:\\n\");\n\n        \n    for (final Map.Entry<SourceNode<?, ?>, List<String>> sourceNodeEntry : sourceToTopics.entrySet()) {\n        final SourceNode<?, ?> source = sourceNodeEntry.getKey();\n        final List<String> topics = sourceNodeEntry.getValue();\n        sb.append(source.toString(indent + \"\\t\"))\n            .append(topicsToString(indent + \"\\t\", topics))\n            .append(childrenToString(indent + \"\\t\", source.children()));\n    }\n    return sb.toString();\n}",
        "summary_tokens": [
            "produces",
            "a",
            "string",
            "representation",
            "containing",
            "useful",
            "information",
            "this",
            "topology"
        ]
    },
    {
        "id": 2761,
        "code": "boolean mayPunctuate(final long timestamp, final PunctuationType type, final ProcessorNodePunctuator processorNodePunctuator) {\n    synchronized (pq) {\n        boolean punctuated = false;\n        PunctuationSchedule top = pq.peek();\n        while (top != null && top.timestamp <= timestamp) {\n            final PunctuationSchedule sched = top;\n            pq.poll();\n\n            if (!sched.isCancelled()) {\n                processorNodePunctuator.punctuate(sched.node(), timestamp, type, sched.punctuator());\n                    \n                if (!sched.isCancelled()) {\n                    pq.add(sched.next(timestamp));\n                }\n                punctuated = true;\n            }\n\n\n            top = pq.peek();\n        }\n\n        return punctuated;\n    }\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "only"
        ]
    },
    {
        "id": 2762,
        "code": "public T root(final T id) {\n    T current = id;\n    T parent = ids.get(current);\n\n    if (parent == null) {\n        throw new NoSuchElementException(\"id: \" + id.toString());\n    }\n\n    while (!parent.equals(current)) {\n            \n        final T grandparent = ids.get(parent);\n        ids.put(current, grandparent);\n\n        current = parent;\n        parent = grandparent;\n    }\n    return current;\n}",
        "summary_tokens": [
            "no",
            "such",
            "element",
            "exception",
            "if",
            "the",
            "parent",
            "of",
            "this",
            "node",
            "is",
            "null"
        ]
    },
    {
        "id": 2763,
        "code": "public <K, V> void send(final String topic,\n                        final K key,\n                        final V value,\n                        final Headers headers,\n                        final Long timestamp,\n                        final Serializer<K> keySerializer,\n                        final Serializer<V> valueSerializer,\n                        final String processorNodeId,\n                        final InternalProcessorContext<Void, Void> context,\n                        final StreamPartitioner<? super K, ? super V> partitioner) {\n    final Integer partition;\n\n    if (partitioner != null) {\n        final List<PartitionInfo> partitions;\n        try {\n            partitions = streamsProducer.partitionsFor(topic);\n        } catch (final TimeoutException timeoutException) {\n            log.warn(\"Could not get partitions for topic {}, will retry\", topic);\n\n                \n            throw timeoutException;\n        } catch (final KafkaException fatal) {\n                \n                \n            throw new StreamsException(\"Could not determine the number of partitions for topic '\" + topic +\n                \"' for task \" + taskId + \" due to \" + fatal,\n                fatal\n            );\n        }\n        if (partitions.size() > 0) {\n            partition = partitioner.partition(topic, key, value, partitions.size());\n        } else {\n            throw new StreamsException(\"Could not get partition information for topic \" + topic + \" for task \" + taskId +\n                \". This can happen if the topic does not exist.\");\n        }\n    } else {\n        partition = null;\n    }\n\n    send(topic, key, value, headers, partition, timestamp, keySerializer, valueSerializer, processorNodeId, context);\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "fatal",
            "error",
            "that",
            "should",
            "cause",
            "the",
            "thread",
            "to",
            "die",
            "task",
            "migrated",
            "exception",
            "recoverable",
            "error",
            "that",
            "would",
            "cause",
            "the",
            "task",
            "to",
            "be",
            "removed"
        ]
    },
    {
        "id": 2764,
        "code": "public void flush() {\n    log.debug(\"Flushing record collector\");\n    streamsProducer.flush();\n    checkForException();\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "fatal",
            "error",
            "that",
            "should",
            "cause",
            "the",
            "thread",
            "to",
            "die",
            "task",
            "migrated",
            "exception",
            "recoverable",
            "error",
            "that",
            "would",
            "cause",
            "the",
            "task",
            "to",
            "be",
            "removed"
        ]
    },
    {
        "id": 2765,
        "code": "public void closeClean() {\n    log.info(\"Closing record collector clean\");\n\n    removeAllProducedSensors();\n\n        \n        \n        \n\n    checkForException();\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "fatal",
            "error",
            "that",
            "should",
            "cause",
            "the",
            "thread",
            "to",
            "die",
            "task",
            "migrated",
            "exception",
            "recoverable",
            "error",
            "that",
            "would",
            "cause",
            "the",
            "task",
            "to",
            "be",
            "removed"
        ]
    },
    {
        "id": 2766,
        "code": "public void closeDirty() {\n    log.info(\"Closing record collector dirty\");\n\n    if (eosEnabled) {\n            \n        streamsProducer.abortTransaction();\n    }\n\n    checkForException();\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "fatal",
            "error",
            "that",
            "should",
            "cause",
            "the",
            "thread",
            "to",
            "die",
            "task",
            "migrated",
            "exception",
            "recoverable",
            "error",
            "that",
            "would",
            "cause",
            "the",
            "task",
            "to",
            "be",
            "removed"
        ]
    },
    {
        "id": 2767,
        "code": "ConsumerRecord<Object, Object> deserialize(final ProcessorContext<?, ?> processorContext,\n                                           final ConsumerRecord<byte[], byte[]> rawRecord) {\n\n    try {\n        return new ConsumerRecord<>(\n            rawRecord.topic(),\n            rawRecord.partition(),\n            rawRecord.offset(),\n            rawRecord.timestamp(),\n            TimestampType.CREATE_TIME,\n            rawRecord.serializedKeySize(),\n            rawRecord.serializedValueSize(),\n            sourceNode.deserializeKey(rawRecord.topic(), rawRecord.headers(), rawRecord.key()),\n            sourceNode.deserializeValue(rawRecord.topic(), rawRecord.headers(), rawRecord.value()),\n            rawRecord.headers(),\n            Optional.empty()\n        );\n    } catch (final Exception deserializationException) {\n        final DeserializationExceptionHandler.DeserializationHandlerResponse response;\n        try {\n            response = deserializationExceptionHandler.handle(\n                (InternalProcessorContext<?, ?>) processorContext,\n                rawRecord,\n                deserializationException);\n        } catch (final Exception fatalUserException) {\n            log.error(\n                \"Deserialization error callback failed after deserialization error for record {}\",\n                rawRecord,\n                deserializationException);\n            throw new StreamsException(\"Fatal user code error in deserialization error callback\", fatalUserException);\n        }\n\n        if (response == DeserializationExceptionHandler.DeserializationHandlerResponse.FAIL) {\n            throw new StreamsException(\"Deserialization exception handler is set to fail upon\" +\n                \" a deserialization error. If you would rather have the streaming pipeline\" +\n                \" continue after a deserialization error, please set the \" +\n                DEFAULT_DESERIALIZATION_EXCEPTION_HANDLER_CLASS_CONFIG + \" appropriately.\",\n                deserializationException);\n        } else {\n            log.warn(\n                \"Skipping record due to deserialization error. topic=[{}] partition=[{}] offset=[{}]\",\n                rawRecord.topic(),\n                rawRecord.partition(),\n                rawRecord.offset(),\n                deserializationException\n            );\n            droppedRecordsSensor.record();\n            return null;\n        }\n    }\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "if",
            "a",
            "deserialization",
            "error",
            "occurs",
            "and",
            "the",
            "deserialization",
            "callback",
            "returns",
            "deserialization",
            "exception",
            "handler"
        ]
    },
    {
        "id": 2768,
        "code": "public SourceNode<?, ?> source() {\n    return source;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "corresponding",
            "source",
            "node",
            "in",
            "the",
            "topology"
        ]
    },
    {
        "id": 2769,
        "code": "public TopicPartition partition() {\n    return partition;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "partition",
            "with",
            "which",
            "this",
            "queue",
            "is",
            "associated"
        ]
    },
    {
        "id": 2770,
        "code": "int addRawRecords(final Iterable<ConsumerRecord<byte[], byte[]>> rawRecords) {\n    for (final ConsumerRecord<byte[], byte[]> rawRecord : rawRecords) {\n        fifoQueue.addLast(rawRecord);\n    }\n\n    updateHead();\n\n    return size();\n}",
        "summary_tokens": [
            "add",
            "a",
            "batch",
            "of",
            "consumer",
            "record",
            "into",
            "the",
            "queue"
        ]
    },
    {
        "id": 2771,
        "code": "public StampedRecord poll(final long wallClockTime) {\n    final StampedRecord recordToReturn = headRecord;\n\n    consumedSensor.record(headRecordSizeInBytes, wallClockTime);\n\n    headRecord = null;\n    headRecordSizeInBytes = 0L;\n    partitionTime = Math.max(partitionTime, recordToReturn.timestamp);\n\n    updateHead();\n\n    return recordToReturn;\n}",
        "summary_tokens": [
            "get",
            "the",
            "next",
            "stamped",
            "record",
            "from",
            "the",
            "queue"
        ]
    },
    {
        "id": 2772,
        "code": "public int size() {\n        \n    return fifoQueue.size() + (headRecord == null ? 0 : 1);\n}",
        "summary_tokens": [
            "returns",
            "the",
            "number",
            "of",
            "records",
            "in",
            "the",
            "queue"
        ]
    },
    {
        "id": 2773,
        "code": "public boolean isEmpty() {\n    return fifoQueue.isEmpty() && headRecord == null;\n}",
        "summary_tokens": [
            "tests",
            "if",
            "the",
            "queue",
            "is",
            "empty"
        ]
    },
    {
        "id": 2774,
        "code": "public long headRecordTimestamp() {\n    return headRecord == null ? UNKNOWN : headRecord.timestamp;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "head",
            "record",
            "s",
            "timestamp"
        ]
    },
    {
        "id": 2775,
        "code": "public void clear() {\n    fifoQueue.clear();\n    headRecord = null;\n    headRecordSizeInBytes = 0L;\n    partitionTime = UNKNOWN;\n}",
        "summary_tokens": [
            "clear",
            "the",
            "fifo",
            "queue",
            "of",
            "its",
            "elements"
        ]
    },
    {
        "id": 2776,
        "code": "long partitionTime() {\n    return partitionTime;\n}",
        "summary_tokens": [
            "the",
            "local",
            "partition",
            "time",
            "for",
            "this",
            "particular",
            "record",
            "queue"
        ]
    },
    {
        "id": 2777,
        "code": "public Map<String, String> getProperties(final Map<String, String> defaultProperties, final long additionalRetentionMs) {\n        \n    final Map<String, String> topicConfig = new HashMap<>(REPARTITION_TOPIC_DEFAULT_OVERRIDES);\n\n    topicConfig.putAll(defaultProperties);\n\n    topicConfig.putAll(topicConfigs);\n\n    return topicConfig;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configured",
            "properties",
            "for",
            "this",
            "topic"
        ]
    },
    {
        "id": 2778,
        "code": "private Map<String, InternalTopicConfig> computeRepartitionTopicConfig(final Cluster clusterMetadata) {\n    final Set<TopicsInfo> allTopicsInfo = new HashSet<>();\n    final Map<String, InternalTopicConfig> allRepartitionTopicConfigs = new HashMap<>();\n    for (final Map.Entry<String, Map<Subtopology, TopicsInfo>> topologyEntry : topologyMetadata.topologyToSubtopologyTopicsInfoMap().entrySet()) {\n        final String topologyName = topologyMetadata.hasNamedTopologies() ? topologyEntry.getKey() : null;\n\n        final Set<TopicsInfo> topicsInfoForTopology = new HashSet<>();\n        final Set<String> missingSourceTopicsForTopology = new HashSet<>();\n        final Map<String, InternalTopicConfig> repartitionTopicConfigsForTopology = new HashMap<>();\n\n        for (final Map.Entry<Subtopology, TopicsInfo> subtopologyEntry : topologyEntry.getValue().entrySet()) {\n            final TopicsInfo topicsInfo = subtopologyEntry.getValue();\n\n            topicsInfoForTopology.add(topicsInfo);\n            repartitionTopicConfigsForTopology.putAll(\n                topicsInfo.repartitionSourceTopics\n                    .values()\n                    .stream()\n                    .collect(Collectors.toMap(InternalTopicConfig::name, topicConfig -> topicConfig)));\n\n            final Set<String> missingSourceTopicsForSubtopology = computeMissingExternalSourceTopics(topicsInfo, clusterMetadata);\n            missingSourceTopicsForTopology.addAll(missingSourceTopicsForSubtopology);\n            if (!missingSourceTopicsForSubtopology.isEmpty()) {\n                final Subtopology subtopology = subtopologyEntry.getKey();\n                missingInputTopicsBySubtopology.put(subtopology, missingSourceTopicsForSubtopology);\n                log.error(\"Subtopology {} was missing source topics {} and will be excluded from the current assignment, \"\n                    + \"this can be due to the consumer client's metadata being stale or because they have \"\n                    + \"not been created yet. Please verify that you have created all input topics; if they \"\n                    + \"do exist, you just need to wait for the metadata to be updated, at which time a new \"\n                    + \"rebalance will be kicked off automatically and the topology will be retried at that time.\",\n                    subtopology.nodeGroupId, missingSourceTopicsForSubtopology);\n            }\n        }\n\n        if (missingSourceTopicsForTopology.isEmpty()) {\n            allRepartitionTopicConfigs.putAll(repartitionTopicConfigsForTopology);\n            allTopicsInfo.addAll(topicsInfoForTopology);\n        } else {\n            log.debug(\"Skipping repartition topic validation for entire topology {} due to missing source topics {}\",\n                topologyName, missingSourceTopicsForTopology);\n        }\n    }\n    setRepartitionSourceTopicPartitionCount(allRepartitionTopicConfigs, allTopicsInfo, clusterMetadata);\n\n    return allRepartitionTopicConfigs;\n}",
        "summary_tokens": [
            "cluster",
            "metadata",
            "cluster",
            "metadata",
            "eg",
            "which",
            "topics",
            "exist",
            "on",
            "the",
            "brokers"
        ]
    },
    {
        "id": 2779,
        "code": "private void setRepartitionSourceTopicPartitionCount(final Map<String, InternalTopicConfig> repartitionTopicMetadata,\n                                                     final Collection<TopicsInfo> topicGroups,\n                                                     final Cluster clusterMetadata) {\n    boolean partitionCountNeeded;\n    do {\n        partitionCountNeeded = false;\n        boolean progressMadeThisIteration = false;  \n\n        for (final TopicsInfo topicsInfo : topicGroups) {\n            for (final String repartitionSourceTopic : topicsInfo.repartitionSourceTopics.keySet()) {\n                final Optional<Integer> repartitionSourceTopicPartitionCount =\n                    repartitionTopicMetadata.get(repartitionSourceTopic).numberOfPartitions();\n\n                if (!repartitionSourceTopicPartitionCount.isPresent()) {\n                    final Integer numPartitions = computePartitionCount(\n                        repartitionTopicMetadata,\n                        topicGroups,\n                        clusterMetadata,\n                        repartitionSourceTopic\n                    );\n\n                    if (numPartitions == null) {\n                        partitionCountNeeded = true;\n                        log.trace(\"Unable to determine number of partitions for {}, another iteration is needed\",\n                            repartitionSourceTopic);\n                    } else {\n                        log.trace(\"Determined number of partitions for {} to be {}\", repartitionSourceTopic, numPartitions);\n                        repartitionTopicMetadata.get(repartitionSourceTopic).setNumberOfPartitions(numPartitions);\n                        progressMadeThisIteration = true;\n                    }\n                }\n            }\n        }\n        if (!progressMadeThisIteration && partitionCountNeeded) {\n            log.error(\"Unable to determine the number of partitions of all repartition topics, most likely a source topic is missing or pattern doesn't match any topics\\n\" +\n                \"topic groups: {}\\n\" +\n                \"cluster topics: {}.\", topicGroups, clusterMetadata.topics());\n            throw new TaskAssignmentException(\"Failed to compute number of partitions for all repartition topics, \" +\n                \"make sure all user input topics are created and all Pattern subscriptions match at least one topic in the cluster\");\n        }\n    } while (partitionCountNeeded);\n}",
        "summary_tokens": [
            "computes",
            "the",
            "number",
            "of",
            "partitions",
            "and",
            "sets",
            "it",
            "for",
            "each",
            "repartition",
            "topic",
            "in",
            "repartition",
            "topic",
            "metadata"
        ]
    },
    {
        "id": 2780,
        "code": "public void addChild(final ProcessorNode<Void, Void, ?, ?> child) {\n    throw new UnsupportedOperationException(\"sink node does not allow addChild\");\n}",
        "summary_tokens": [
            "unsupported",
            "operation",
            "exception",
            "if",
            "this",
            "method",
            "adds",
            "a",
            "child",
            "to",
            "a",
            "sink",
            "node"
        ]
    },
    {
        "id": 2781,
        "code": "public String toString(final String indent) {\n    final StringBuilder sb = new StringBuilder(super.toString(indent));\n    sb.append(indent).append(\"\\ttopic:\\t\\t\");\n    sb.append(topicExtractor);\n    sb.append(\"\\n\");\n    return sb.toString();\n}",
        "summary_tokens": [
            "a",
            "string",
            "representation",
            "of",
            "this",
            "node",
            "starting",
            "with",
            "the",
            "given",
            "indent",
            "useful",
            "for",
            "debugging"
        ]
    },
    {
        "id": 2782,
        "code": "public String toString() {\n    return toString(\"\");\n}",
        "summary_tokens": [
            "a",
            "string",
            "representation",
            "of",
            "this",
            "node",
            "useful",
            "for",
            "debugging"
        ]
    },
    {
        "id": 2783,
        "code": "public void initializeIfNeeded() {\n    if (state() == State.CREATED) {\n        StateManagerUtil.registerStateStores(log, logPrefix, topology, stateMgr, stateDirectory, processorContext);\n\n            \n            \n            \n        offsetSnapshotSinceLastFlush = Collections.emptyMap();\n\n            \n            \n        transitionTo(State.RESTORING);\n        transitionTo(State.RUNNING);\n\n        processorContext.initialize();\n\n        log.info(\"Initialized\");\n    } else if (state() == State.RESTORING) {\n        throw new IllegalStateException(\"Illegal state \" + state() + \" while initializing standby task \" + id);\n    }\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "fatal",
            "error",
            "should",
            "close",
            "the",
            "thread"
        ]
    },
    {
        "id": 2784,
        "code": "public Map<TopicPartition, OffsetAndMetadata> prepareCommit() {\n    switch (state()) {\n        case CREATED:\n            log.debug(\"Skipped preparing created task for commit\");\n\n            break;\n\n        case RUNNING:\n        case SUSPENDED:\n                \n            log.debug(\"Prepared {} task for committing\", state());\n\n            break;\n\n        default:\n            throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing standby task \" + id + \" for committing \");\n    }\n\n    return Collections.emptyMap();\n}",
        "summary_tokens": [
            "flush",
            "stores",
            "before",
            "a",
            "commit",
            "the",
            "following",
            "exceptions",
            "maybe",
            "thrown",
            "from",
            "the",
            "state",
            "manager",
            "flushing",
            "call"
        ]
    },
    {
        "id": 2785,
        "code": "public String toString(final String indent) {\n    final StringBuilder sb = new StringBuilder();\n    sb.append(indent);\n    sb.append(\"TaskId: \");\n    sb.append(id);\n    sb.append(\"\\n\");\n\n        \n    if (topology != null) {\n        sb.append(indent).append(topology.toString(indent + \"\\t\"));\n    }\n\n    return sb.toString();\n}",
        "summary_tokens": [
            "produces",
            "a",
            "string",
            "representation",
            "containing",
            "useful",
            "information",
            "about",
            "a",
            "task",
            "starting",
            "with",
            "the",
            "given",
            "indent"
        ]
    },
    {
        "id": 2786,
        "code": "private boolean lockStateDirectory() {\n    final File lockFile = new File(stateDir, LOCK_FILE_NAME);\n    try {\n        stateDirLockChannel = FileChannel.open(lockFile.toPath(), StandardOpenOption.CREATE, StandardOpenOption.WRITE);\n        stateDirLock = tryLock(stateDirLockChannel);\n    } catch (final IOException e) {\n        log.error(\"Unable to lock the state directory due to unexpected exception\", e);\n        throw new ProcessorStateException(String.format(\"Failed to lock the state directory [%s] during startup\",\n            stateDir.getAbsolutePath()), e);\n    }\n    return stateDirLock != null;\n}",
        "summary_tokens": [
            "true",
            "if",
            "the",
            "state",
            "directory",
            "was",
            "successfully",
            "locked"
        ]
    },
    {
        "id": 2787,
        "code": "public File getOrCreateDirectoryForTask(final TaskId taskId) {\n    final File taskParentDir = getTaskDirectoryParentName(taskId);\n    final File taskDir = new File(taskParentDir, StateManagerUtil.toTaskDirString(taskId));\n    if (hasPersistentStores) {\n        if (!taskDir.exists()) {\n            synchronized (taskDirCreationLock) {\n                    \n                    \n                    \n                    \n                if (!taskParentDir.exists() && !taskParentDir.mkdir()) {\n                    throw new ProcessorStateException(\n                        String.format(\"Parent [%s] of task directory [%s] doesn't exist and couldn't be created\",\n                            taskParentDir.getPath(), taskDir.getPath()));\n                }\n                if (!taskDir.exists() && !taskDir.mkdir()) {\n                    throw new ProcessorStateException(\n                        String.format(\"task directory [%s] doesn't exist and couldn't be created\", taskDir.getPath()));\n                }\n            }\n        } else if (!taskDir.isDirectory()) {\n            throw new ProcessorStateException(\n                String.format(\"state directory [%s] can't be created as there is an existing file with the same name\", taskDir.getPath()));\n        }\n    }\n    return taskDir;\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "the",
            "directory",
            "for",
            "the",
            "provided",
            "task",
            "id"
        ]
    },
    {
        "id": 2788,
        "code": "File checkpointFileFor(final TaskId taskId) {\n    return new File(getOrCreateDirectoryForTask(taskId), StateManagerUtil.CHECKPOINT_FILE_NAME);\n}",
        "summary_tokens": [
            "the",
            "file",
            "handle",
            "for",
            "the",
            "checkpoint",
            "in",
            "the",
            "given",
            "task",
            "s",
            "directory"
        ]
    },
    {
        "id": 2789,
        "code": "boolean directoryForTaskIsEmpty(final TaskId taskId) {\n    final File taskDir = getOrCreateDirectoryForTask(taskId);\n\n    return taskDirIsEmpty(taskDir);\n}",
        "summary_tokens": [
            "decide",
            "if",
            "the",
            "directory",
            "of",
            "the",
            "task",
            "is",
            "empty",
            "or",
            "not"
        ]
    },
    {
        "id": 2790,
        "code": "File globalStateDir() {\n    final File dir = new File(stateDir, \"global\");\n    if (hasPersistentStores) {\n        if (!dir.exists() && !dir.mkdir()) {\n            throw new ProcessorStateException(\n                String.format(\"global state directory [%s] doesn't exist and couldn't be created\", dir.getPath()));\n        } else if (dir.exists() && !dir.isDirectory()) {\n            throw new ProcessorStateException(\n                String.format(\"global state directory [%s] can't be created as there is an existing file with the same name\", dir.getPath()));\n        }\n    }\n    return dir;\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "the",
            "directory",
            "for",
            "the",
            "global",
            "stores"
        ]
    },
    {
        "id": 2791,
        "code": "synchronized boolean lock(final TaskId taskId) {\n    if (!hasPersistentStores) {\n        return true;\n    }\n\n    final Thread lockOwner = lockedTasksToOwner.get(taskId);\n    if (lockOwner != null) {\n        if (lockOwner.equals(Thread.currentThread())) {\n            log.trace(\"{} Found cached state dir lock for task {}\", logPrefix(), taskId);\n                \n            return true;\n        } else {\n                \n            return false;\n        }\n    } else if (!stateDir.exists()) {\n        log.error(\"Tried to lock task directory for {} but the state directory does not exist\", taskId);\n        throw new IllegalStateException(\"The state directory has been deleted\");\n    } else {\n        lockedTasksToOwner.put(taskId, Thread.currentThread());\n            \n        getOrCreateDirectoryForTask(taskId);\n        return true;\n    }\n}",
        "summary_tokens": [
            "get",
            "the",
            "lock",
            "for",
            "the",
            "task",
            "id",
            "s",
            "directory",
            "if",
            "it",
            "is",
            "available",
            "task",
            "id",
            "task",
            "id",
            "true",
            "if",
            "successful"
        ]
    },
    {
        "id": 2792,
        "code": "synchronized void unlock(final TaskId taskId) {\n    final Thread lockOwner = lockedTasksToOwner.get(taskId);\n    if (lockOwner != null && lockOwner.equals(Thread.currentThread())) {\n        lockedTasksToOwner.remove(taskId);\n        log.debug(\"{} Released state dir lock for task {}\", logPrefix(), taskId);\n    }\n}",
        "summary_tokens": [
            "unlock",
            "the",
            "state",
            "directory",
            "for",
            "the",
            "given",
            "task",
            "id"
        ]
    },
    {
        "id": 2793,
        "code": "public synchronized void cleanRemovedTasks(final long cleanupDelayMs) {\n    try {\n        cleanRemovedTasksCalledByCleanerThread(cleanupDelayMs);\n    } catch (final Exception cannotHappen) {\n        throw new IllegalStateException(\"Should have swallowed exception.\", cannotHappen);\n    }\n}",
        "summary_tokens": [
            "remove",
            "the",
            "directories",
            "for",
            "any",
            "task",
            "id",
            "s",
            "that",
            "are",
            "no",
            "longer",
            "owned",
            "by",
            "this",
            "stream",
            "thread",
            "and",
            "aren",
            "t",
            "locked",
            "by",
            "either",
            "another",
            "process",
            "or",
            "another",
            "stream",
            "thread",
            "cleanup",
            "delay",
            "ms",
            "only",
            "remove",
            "directories",
            "if",
            "they",
            "haven",
            "t",
            "been",
            "modified",
            "for",
            "at",
            "least",
            "this",
            "amount",
            "of",
            "time",
            "milliseconds"
        ]
    },
    {
        "id": 2794,
        "code": "private IOException maybeCleanEmptyNamedTopologyDirs(final boolean logExceptionAsWarn) {\n    if (!hasNamedTopologies) {\n        return null;\n    }\n\n    final AtomicReference<IOException> firstException = new AtomicReference<>(null);\n    final File[] namedTopologyDirs = stateDir.listFiles(pathname ->\n            pathname.isDirectory() && NAMED_TOPOLOGY_DIR_PATH_NAME.matcher(pathname.getName()).matches()\n    );\n    if (namedTopologyDirs != null) {\n        for (final File namedTopologyDir : namedTopologyDirs) {\n            final File[] contents = namedTopologyDir.listFiles();\n            if (contents != null && contents.length == 0) {\n                try {\n                    Utils.delete(namedTopologyDir);\n                } catch (final IOException exception) {\n                    if (logExceptionAsWarn) {\n                        log.warn(\n                            String.format(\"%sSwallowed the following exception during deletion of named topology directory %s\",\n                                logPrefix(), namedTopologyDir.getName()),\n                            exception\n                        );\n                    } else {\n                        log.error(\n                            String.format(\"%s Failed to delete named topology directory %s with exception:\",\n                                logPrefix(), namedTopologyDir.getName()),\n                            exception\n                        );\n                    }\n                    firstException.compareAndSet(null, exception);\n                }\n            }\n        }\n    }\n    return firstException.get();\n}",
        "summary_tokens": [
            "cleans",
            "up",
            "any",
            "leftover",
            "named",
            "topology",
            "directories",
            "that",
            "are",
            "empty",
            "if",
            "any",
            "exist",
            "log",
            "exception",
            "as",
            "warn",
            "if",
            "true",
            "an",
            "exception",
            "will",
            "be",
            "logged",
            "as",
            "a",
            "warning",
            "if",
            "false",
            "an",
            "exception",
            "will",
            "be",
            "logged",
            "as",
            "error",
            "the",
            "first",
            "ioexception",
            "to",
            "be",
            "encountered"
        ]
    },
    {
        "id": 2795,
        "code": "public void clearLocalStateForNamedTopology(final String topologyName) {\n    final File namedTopologyDir = new File(stateDir, getNamedTopologyDirName(topologyName));\n    if (!namedTopologyDir.exists() || !namedTopologyDir.isDirectory()) {\n        log.debug(\"Tried to clear out the local state for NamedTopology {} but none was found\", topologyName);\n    }\n    try {\n        Utils.delete(namedTopologyDir);\n    } catch (final IOException e) {\n        log.error(\"Hit an unexpected error while clearing local state for topology \" + topologyName, e);\n        throw new StreamsException(\"Unable to delete state for the named topology \" + topologyName,\n                                   e, new TaskId(-1, -1, topologyName)); \n    }\n}",
        "summary_tokens": [
            "clears",
            "out",
            "any",
            "local",
            "state",
            "found",
            "for",
            "the",
            "given",
            "named",
            "topology",
            "after",
            "it",
            "was",
            "removed"
        ]
    },
    {
        "id": 2796,
        "code": "List<TaskDirectory> listNonEmptyTaskDirectories() {\n    return listTaskDirectories(pathname -> {\n        if (!pathname.isDirectory() || !TASK_DIR_PATH_NAME.matcher(pathname.getName()).matches()) {\n            return false;\n        } else {\n            return !taskDirIsEmpty(pathname);\n        }\n    });\n}",
        "summary_tokens": [
            "list",
            "all",
            "of",
            "the",
            "task",
            "directories",
            "that",
            "are",
            "non",
            "empty",
            "the",
            "list",
            "of",
            "all",
            "the",
            "non",
            "empty",
            "local",
            "directories",
            "for",
            "stream",
            "tasks"
        ]
    },
    {
        "id": 2797,
        "code": "List<TaskDirectory> listAllTaskDirectories() {\n    return listTaskDirectories(pathname -> pathname.isDirectory() && TASK_DIR_PATH_NAME.matcher(pathname.getName()).matches());\n}",
        "summary_tokens": [
            "list",
            "all",
            "of",
            "the",
            "task",
            "directories",
            "along",
            "with",
            "their",
            "parent",
            "directory",
            "if",
            "they",
            "belong",
            "to",
            "a",
            "named",
            "topology",
            "the",
            "list",
            "of",
            "all",
            "the",
            "existing",
            "local",
            "directories",
            "for",
            "stream",
            "tasks"
        ]
    },
    {
        "id": 2798,
        "code": "static void registerStateStores(final Logger log,\n                                final String logPrefix,\n                                final ProcessorTopology topology,\n                                final ProcessorStateManager stateMgr,\n                                final StateDirectory stateDirectory,\n                                final InternalProcessorContext processorContext) {\n    if (topology.stateStores().isEmpty()) {\n        return;\n    }\n\n    final TaskId id = stateMgr.taskId();\n    if (!stateDirectory.lock(id)) {\n        throw new LockException(String.format(\"%sFailed to lock the state directory for task %s\", logPrefix, id));\n    }\n    log.debug(\"Acquired state directory lock\");\n\n    final boolean storeDirsEmpty = stateDirectory.directoryForTaskIsEmpty(id);\n\n    stateMgr.registerStateStores(topology.stateStores(), processorContext);\n    log.debug(\"Registered state stores\");\n\n        \n        \n        \n    stateMgr.initializeStoreOffsetsFromCheckpoint(storeDirsEmpty);\n    log.debug(\"Initialized state stores\");\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "if",
            "the",
            "store",
            "s",
            "changelog",
            "does",
            "not",
            "contain",
            "the",
            "partition"
        ]
    },
    {
        "id": 2799,
        "code": "static void closeStateManager(final Logger log,\n                              final String logPrefix,\n                              final boolean closeClean,\n                              final boolean eosEnabled,\n                              final ProcessorStateManager stateMgr,\n                              final StateDirectory stateDirectory,\n                              final TaskType taskType) {\n        \n    final boolean wipeStateStore = !closeClean && eosEnabled;\n\n    final TaskId id = stateMgr.taskId();\n    log.trace(\"Closing state manager for {} task {}\", taskType, id);\n\n    final AtomicReference<ProcessorStateException> firstException = new AtomicReference<>(null);\n    try {\n        if (stateDirectory.lock(id)) {\n            try {\n                stateMgr.close();\n            } catch (final ProcessorStateException e) {\n                firstException.compareAndSet(null, e);\n            } finally {\n                try {\n                    if (wipeStateStore) {\n                        log.debug(\"Wiping state stores for {} task {}\", taskType, id);\n                            \n                            \n                            \n                        Utils.delete(stateMgr.baseDir());\n                    }\n                } finally {\n                    stateDirectory.unlock(id);\n                }\n            }\n        }\n    } catch (final IOException e) {\n        final ProcessorStateException exception = new ProcessorStateException(\n            String.format(\"%sFatal error while trying to close the state manager for task %s\", logPrefix, id), e\n        );\n        firstException.compareAndSet(null, exception);\n    }\n\n    final ProcessorStateException exception = firstException.get();\n    if (exception != null) {\n        throw exception;\n    }\n}",
        "summary_tokens": [
            "processor",
            "state",
            "exception",
            "if",
            "there",
            "is",
            "an",
            "error",
            "while",
            "closing",
            "the",
            "state",
            "manager"
        ]
    },
    {
        "id": 2800,
        "code": "static TaskId parseTaskDirectoryName(final String taskIdStr, final String namedTopology) {\n    final int index = taskIdStr.indexOf('_');\n    if (index <= 0 || index + 1 >= taskIdStr.length()) {\n        throw new TaskIdFormatException(taskIdStr);\n    }\n\n    try {\n        final int topicGroupId = Integer.parseInt(taskIdStr.substring(0, index));\n        final int partition = Integer.parseInt(taskIdStr.substring(index + 1));\n\n        return new TaskId(topicGroupId, partition, namedTopology);\n    } catch (final Exception e) {\n        throw new TaskIdFormatException(taskIdStr);\n    }\n}",
        "summary_tokens": [
            "parse",
            "the",
            "task",
            "directory",
            "name",
            "of",
            "the",
            "form",
            "topic",
            "group",
            "id",
            "partition",
            "and",
            "construct",
            "the",
            "task",
            "id",
            "with",
            "the",
            "optional",
            "named",
            "topology",
            "may",
            "be",
            "null"
        ]
    },
    {
        "id": 2801,
        "code": "static String toTaskDirString(final TaskId taskId) {\n    return taskId.subtopology() + \"_\" + taskId.partition();\n}",
        "summary_tokens": [
            "the",
            "string",
            "representation",
            "of",
            "the",
            "subtopology",
            "and",
            "partition",
            "metadata",
            "ie",
            "the",
            "task",
            "id",
            "string",
            "without",
            "the",
            "named",
            "topology",
            "which",
            "defines",
            "the",
            "innermost",
            "task",
            "directory",
            "name",
            "of",
            "this",
            "task",
            "s",
            "state"
        ]
    },
    {
        "id": 2802,
        "code": "public void register(final TopicPartition partition, final ProcessorStateManager stateManager) {\n    final StateStoreMetadata storeMetadata = stateManager.storeMetadata(partition);\n    if (storeMetadata == null) {\n        throw new IllegalStateException(\"Cannot find the corresponding state store metadata for changelog \" +\n            partition);\n    }\n\n    final ChangelogMetadata changelogMetadata = new ChangelogMetadata(storeMetadata, stateManager);\n\n        \n    if (stateManager.taskType() == Task.TaskType.STANDBY && stateManager.changelogAsSource(partition)) {\n        changelogMetadata.restoreEndOffset = 0L;\n    }\n\n    if (changelogs.putIfAbsent(partition, changelogMetadata) != null) {\n        throw new IllegalStateException(\"There is already a changelog registered for \" + partition +\n            \", this should not happen: \" + changelogs);\n    }\n}",
        "summary_tokens": [
            "since",
            "it",
            "is",
            "shared",
            "for",
            "multiple",
            "tasks",
            "and",
            "hence",
            "multiple",
            "state",
            "managers",
            "the",
            "registration",
            "would",
            "take",
            "its",
            "corresponding",
            "state",
            "manager",
            "as",
            "well",
            "for",
            "restoring"
        ]
    },
    {
        "id": 2803,
        "code": "private boolean restoreChangelog(final ChangelogMetadata changelogMetadata) {\n    final ProcessorStateManager stateManager = changelogMetadata.stateManager;\n    final StateStoreMetadata storeMetadata = changelogMetadata.storeMetadata;\n    final TopicPartition partition = storeMetadata.changelogPartition();\n    final String storeName = storeMetadata.store().name();\n    final int numRecords = changelogMetadata.bufferedLimitIndex;\n\n    boolean madeProgress = false;\n\n    if (numRecords != 0) {\n        madeProgress = true;\n\n        final List<ConsumerRecord<byte[], byte[]>> records = changelogMetadata.bufferedRecords.subList(0, numRecords);\n        stateManager.restore(storeMetadata, records);\n\n            \n            \n            \n        if (numRecords < changelogMetadata.bufferedRecords.size()) {\n            records.clear();\n        } else {\n            changelogMetadata.bufferedRecords.clear();\n        }\n\n        final Long currentOffset = storeMetadata.offset();\n        log.trace(\"Restored {} records from changelog {} to store {}, end offset is {}, current offset is {}\",\n            partition, storeName, numRecords, recordEndOffset(changelogMetadata.restoreEndOffset), currentOffset);\n\n        changelogMetadata.bufferedLimitIndex = 0;\n        changelogMetadata.totalRestored += numRecords;\n\n            \n        if (changelogMetadata.stateManager.taskType() == Task.TaskType.ACTIVE) {\n            try {\n                stateRestoreListener.onBatchRestored(partition, storeName, currentOffset, numRecords);\n            } catch (final Exception e) {\n                throw new StreamsException(\"State restore listener failed on batch restored\", e);\n            }\n        }\n    }\n\n        \n    if (changelogMetadata.stateManager.taskType() == Task.TaskType.ACTIVE && hasRestoredToEnd(changelogMetadata)) {\n        madeProgress = true;\n\n        log.info(\"Finished restoring changelog {} to store {} with a total number of {} records\",\n            partition, storeName, changelogMetadata.totalRestored);\n\n        changelogMetadata.transitTo(ChangelogState.COMPLETED);\n        pauseChangelogsFromRestoreConsumer(Collections.singleton(partition));\n\n        try {\n            stateRestoreListener.onRestoreEnd(partition, storeName, changelogMetadata.totalRestored);\n        } catch (final Exception e) {\n            throw new StreamsException(\"State restore listener failed on restore completed\", e);\n        }\n    }\n\n    return madeProgress;\n}",
        "summary_tokens": [
            "restore",
            "a",
            "changelog",
            "with",
            "its",
            "buffered",
            "records",
            "if",
            "there",
            "s",
            "any",
            "for",
            "active",
            "changelogs",
            "also",
            "check",
            "if",
            "it",
            "has",
            "completed",
            "the",
            "restoration",
            "and",
            "can",
            "transit",
            "to",
            "completed",
            "state",
            "and",
            "trigger",
            "restore",
            "callbacks"
        ]
    },
    {
        "id": 2804,
        "code": "public void initializeIfNeeded() {\n    if (state() == State.CREATED) {\n        recordCollector.initialize();\n\n        StateManagerUtil.registerStateStores(log, logPrefix, topology, stateMgr, stateDirectory, processorContext);\n\n            \n            \n            \n        offsetSnapshotSinceLastFlush = Collections.emptyMap();\n\n        transitionTo(State.RESTORING);\n\n        log.info(\"Initialized\");\n    }\n}",
        "summary_tokens": [
            "lock",
            "exception",
            "could",
            "happen",
            "when",
            "multi",
            "threads",
            "within",
            "the",
            "single",
            "instance",
            "could",
            "retry",
            "timeout",
            "exception",
            "if",
            "initializing",
            "record",
            "collector",
            "timed",
            "out",
            "streams",
            "exception",
            "fatal",
            "error",
            "should",
            "close",
            "the",
            "thread"
        ]
    },
    {
        "id": 2805,
        "code": "public void completeRestoration(final java.util.function.Consumer<Set<TopicPartition>> offsetResetter) {\n    switch (state()) {\n        case RUNNING:\n            return;\n\n        case RESTORING:\n            resetOffsetsIfNeededAndInitializeMetadata(offsetResetter);\n            initializeTopology();\n            processorContext.initialize();\n\n            transitionTo(State.RUNNING);\n\n            log.info(\"Restored and ready to run\");\n\n            break;\n\n        case CREATED:\n        case SUSPENDED:\n        case CLOSED:\n            throw new IllegalStateException(\"Illegal state \" + state() + \" while completing restoration for active task \" + id);\n\n        default:\n            throw new IllegalStateException(\"Unknown state \" + state() + \" while completing restoration for active task \" + id);\n    }\n}",
        "summary_tokens": [
            "timeout",
            "exception",
            "if",
            "fetching",
            "committed",
            "offsets",
            "timed",
            "out"
        ]
    },
    {
        "id": 2806,
        "code": "public void resume() {\n    switch (state()) {\n        case CREATED:\n        case RUNNING:\n        case RESTORING:\n                \n            log.trace(\"Skip resuming since state is {}\", state());\n            break;\n\n        case SUSPENDED:\n                \n                \n\n                \n            try {\n                stateMgr.deleteCheckPointFileIfEOSEnabled();\n                log.debug(\"Deleted check point file upon resuming with EOS enabled\");\n            } catch (final IOException ioe) {\n                log.error(\"Encountered error while deleting the checkpoint file due to this exception\", ioe);\n            }\n\n            transitionTo(State.RESTORING);\n            log.info(\"Resumed to restoring state\");\n\n            break;\n\n        case CLOSED:\n            throw new IllegalStateException(\"Illegal state \" + state() + \" while resuming active task \" + id);\n\n        default:\n            throw new IllegalStateException(\"Unknown state \" + state() + \" while resuming active task \" + id);\n    }\n    timeCurrentIdlingStarted = Optional.empty();\n}",
        "summary_tokens": [
            "pre",
            "resume",
            "the",
            "task",
            "pre"
        ]
    },
    {
        "id": 2807,
        "code": "public Map<TopicPartition, OffsetAndMetadata> prepareCommit() {\n    switch (state()) {\n        case CREATED:\n        case RESTORING:\n        case RUNNING:\n        case SUSPENDED:\n                \n                \n                \n            if (commitNeeded) {\n                    \n                    \n                    \n                    \n                stateMgr.flushCache();\n                recordCollector.flush();\n                hasPendingTxCommit = eosEnabled;\n\n                log.debug(\"Prepared {} task for committing\", state());\n                return committableOffsetsAndMetadata();\n            } else {\n                log.debug(\"Skipped preparing {} task for commit since there is nothing to commit\", state());\n                return Collections.emptyMap();\n            }\n\n        case CLOSED:\n            throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n\n        default:\n            throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n    }\n}",
        "summary_tokens": [
            "streams",
            "exception",
            "fatal",
            "error",
            "that",
            "should",
            "cause",
            "the",
            "thread",
            "to",
            "die",
            "task",
            "migrated",
            "exception",
            "recoverable",
            "error",
            "that",
            "would",
            "cause",
            "the",
            "task",
            "to",
            "be",
            "removed",
            "offsets",
            "that",
            "should",
            "be",
            "committed",
            "for",
            "this",
            "task"
        ]
    },
    {
        "id": 2808,
        "code": "public void maybeCheckpoint(final boolean enforceCheckpoint) {\n        \n        \n    if (commitNeeded || enforceCheckpoint) {\n        stateMgr.updateChangelogOffsets(checkpointableOffsets());\n    }\n\n    super.maybeCheckpoint(enforceCheckpoint);\n}",
        "summary_tokens": [
            "the",
            "following",
            "exceptions",
            "maybe",
            "thrown",
            "from",
            "the",
            "state",
            "manager",
            "flushing",
            "call"
        ]
    },
    {
        "id": 2809,
        "code": "private void close(final boolean clean) {\n    switch (state()) {\n        case SUSPENDED:\n            TaskManager.executeAndMaybeSwallow(\n                clean,\n                partitionGroup::close,\n                \"partition group close\",\n                log\n            );\n\n                \n                \n            TaskManager.executeAndMaybeSwallow(\n                clean,\n                () -> StateManagerUtil.closeStateManager(\n                    log,\n                    logPrefix,\n                    clean,\n                    eosEnabled,\n                    stateMgr,\n                    stateDirectory,\n                    TaskType.ACTIVE\n                ),\n                \"state manager close\",\n                log);\n\n            TaskManager.executeAndMaybeSwallow(\n                clean,\n                clean ? recordCollector::closeClean : recordCollector::closeDirty,\n                \"record collector close\",\n                log\n            );\n\n            break;\n\n        case CLOSED:\n            log.trace(\"Skip closing since state is {}\", state());\n            return;\n\n        case CREATED:\n        case RESTORING:\n        case RUNNING:\n            throw new IllegalStateException(\"Illegal state \" + state() + \" while closing active task \" + id);\n\n        default:\n            throw new IllegalStateException(\"Unknown state \" + state() + \" while closing active task \" + id);\n    }\n\n    record = null;\n    closeTaskSensor.record();\n\n    transitionTo(State.CLOSED);\n}",
        "summary_tokens": [
            "you",
            "must",
            "commit",
            "a",
            "task",
            "and",
            "checkpoint",
            "the",
            "state",
            "manager",
            "before",
            "closing",
            "as",
            "this",
            "will",
            "release",
            "the",
            "state",
            "dir",
            "lock"
        ]
    },
    {
        "id": 2810,
        "code": "public boolean isProcessable(final long wallClockTime) {\n    if (state() == State.CLOSED) {\n            \n            \n            \n        log.info(\"Stream task {} is already in {} state, skip processing it.\", id(), state());\n\n        return false;\n    }\n\n    if (hasPendingTxCommit) {\n            \n            \n        return false;\n    }\n    final boolean readyToProcess = partitionGroup.readyToProcess(wallClockTime);\n    if (!readyToProcess) {\n        if (!timeCurrentIdlingStarted.isPresent()) {\n            timeCurrentIdlingStarted = Optional.of(wallClockTime);\n        }\n    } else {\n        timeCurrentIdlingStarted = Optional.empty();\n    }\n    return readyToProcess;\n}",
        "summary_tokens": [
            "an",
            "active",
            "task",
            "is",
            "processable",
            "if",
            "its",
            "buffer",
            "contains",
            "data",
            "for",
            "all",
            "of",
            "its",
            "input",
            "source",
            "topic",
            "partitions",
            "or",
            "if",
            "it",
            "is",
            "enforced",
            "to",
            "be",
            "processable"
        ]
    },
    {
        "id": 2811,
        "code": "public void punctuate(final ProcessorNode<?, ?, ?, ?> node,\n                      final long timestamp,\n                      final PunctuationType type,\n                      final Punctuator punctuator) {\n    if (processorContext.currentNode() != null) {\n        throw new IllegalStateException(String.format(\"%sCurrent node is not null\", logPrefix));\n    }\n\n        \n        \n    final ProcessorRecordContext recordContext = new ProcessorRecordContext(\n        timestamp,\n        -1L,\n        -1,\n        null,\n        new RecordHeaders()\n    );\n    updateProcessorContext(node, time.milliseconds(), recordContext);\n\n    if (log.isTraceEnabled()) {\n        log.trace(\"Punctuating processor {} with timestamp {} and punctuation type {}\", node.name(), timestamp, type);\n    }\n\n    try {\n        maybeMeasureLatency(() -> node.punctuate(timestamp, punctuator), time, punctuateLatencySensor);\n    } catch (final StreamsException e) {\n        throw e;\n    } catch (final RuntimeException e) {\n        throw new StreamsException(String.format(\"%sException caught while punctuating processor '%s'\", logPrefix, node.name()), e);\n    } finally {\n        processorContext.setCurrentNode(null);\n    }\n}",
        "summary_tokens": [
            "illegal",
            "state",
            "exception",
            "if",
            "the",
            "current",
            "node",
            "is",
            "not",
            "null",
            "task",
            "migrated",
            "exception",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "only"
        ]
    },
    {
        "id": 2812,
        "code": "private Map<TopicPartition, Long> checkpointableOffsets() {\n    final Map<TopicPartition, Long> checkpointableOffsets = new HashMap<>(recordCollector.offsets());\n    for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n        checkpointableOffsets.putIfAbsent(entry.getKey(), entry.getValue());\n    }\n\n    log.debug(\"Checkpointable offsets {}\", checkpointableOffsets);\n\n    return checkpointableOffsets;\n}",
        "summary_tokens": [
            "return",
            "all",
            "the",
            "checkpointable",
            "offsets",
            "written",
            "consumed",
            "to",
            "the",
            "state",
            "manager"
        ]
    },
    {
        "id": 2813,
        "code": "public void addRecords(final TopicPartition partition, final Iterable<ConsumerRecord<byte[], byte[]>> records) {\n    final int newQueueSize = partitionGroup.addRawRecords(partition, records);\n\n    if (log.isTraceEnabled()) {\n        log.trace(\"Added records into the buffered queue of partition {}, new queue size is {}\", partition, newQueueSize);\n    }\n\n        \n        \n    if (newQueueSize > maxBufferedSize) {\n        mainConsumer.pause(singleton(partition));\n    }\n}",
        "summary_tokens": [
            "adds",
            "records",
            "to",
            "queues"
        ]
    },
    {
        "id": 2814,
        "code": "private Cancellable schedule(final long startTime, final long interval, final PunctuationType type, final Punctuator punctuator) {\n    if (processorContext.currentNode() == null) {\n        throw new IllegalStateException(String.format(\"%sCurrent node is null\", logPrefix));\n    }\n\n    final PunctuationSchedule schedule = new PunctuationSchedule(processorContext.currentNode(), startTime, interval, punctuator);\n\n    switch (type) {\n        case STREAM_TIME:\n                \n                \n            return streamTimePunctuationQueue.schedule(schedule);\n        case WALL_CLOCK_TIME:\n                \n            return systemTimePunctuationQueue.schedule(schedule);\n        default:\n            throw new IllegalArgumentException(\"Unrecognized PunctuationType: \" + type);\n    }\n}",
        "summary_tokens": [
            "schedules",
            "a",
            "punctuation",
            "for",
            "the",
            "processor"
        ]
    },
    {
        "id": 2815,
        "code": "public boolean maybePunctuateStreamTime() {\n    final long streamTime = partitionGroup.streamTime();\n\n        \n        \n    if (streamTime == RecordQueue.UNKNOWN) {\n        return false;\n    } else {\n        final boolean punctuated = streamTimePunctuationQueue.mayPunctuate(streamTime, PunctuationType.STREAM_TIME, this);\n\n        if (punctuated) {\n            commitNeeded = true;\n        }\n\n        return punctuated;\n    }\n}",
        "summary_tokens": [
            "possibly",
            "trigger",
            "registered",
            "stream",
            "time",
            "punctuation",
            "functions",
            "if",
            "current",
            "partition",
            "group",
            "timestamp",
            "has",
            "reached",
            "the",
            "defined",
            "stamp",
            "note",
            "this",
            "is",
            "only",
            "called",
            "in",
            "the",
            "presence",
            "of",
            "new",
            "records"
        ]
    },
    {
        "id": 2816,
        "code": "public boolean maybePunctuateSystemTime() {\n    final long systemTime = time.milliseconds();\n\n    final boolean punctuated = systemTimePunctuationQueue.mayPunctuate(systemTime, PunctuationType.WALL_CLOCK_TIME, this);\n\n    if (punctuated) {\n        commitNeeded = true;\n    }\n\n    return punctuated;\n}",
        "summary_tokens": [
            "possibly",
            "trigger",
            "registered",
            "system",
            "time",
            "punctuation",
            "functions",
            "if",
            "current",
            "system",
            "timestamp",
            "has",
            "reached",
            "the",
            "defined",
            "stamp",
            "note",
            "this",
            "is",
            "called",
            "irrespective",
            "of",
            "the",
            "presence",
            "of",
            "new",
            "records"
        ]
    },
    {
        "id": 2817,
        "code": "void requestCommit() {\n    commitRequested = true;\n}",
        "summary_tokens": [
            "request",
            "committing",
            "the",
            "current",
            "task",
            "s",
            "state"
        ]
    },
    {
        "id": 2818,
        "code": "public boolean commitRequested() {\n    return commitRequested;\n}",
        "summary_tokens": [
            "whether",
            "or",
            "not",
            "a",
            "request",
            "has",
            "been",
            "made",
            "to",
            "commit",
            "the",
            "current",
            "state"
        ]
    },
    {
        "id": 2819,
        "code": "public String toString(final String indent) {\n    final StringBuilder sb = new StringBuilder();\n    sb.append(indent);\n    sb.append(\"TaskId: \");\n    sb.append(id);\n    sb.append(\"\\n\");\n\n        \n    if (topology != null) {\n        sb.append(indent).append(topology.toString(indent + \"\\t\"));\n    }\n\n        \n    final Set<TopicPartition> partitions = inputPartitions();\n    if (partitions != null && !partitions.isEmpty()) {\n        sb.append(indent).append(\"Partitions [\");\n        for (final TopicPartition topicPartition : partitions) {\n            sb.append(topicPartition).append(\", \");\n        }\n        sb.setLength(sb.length() - 2);\n        sb.append(\"]\\n\");\n    }\n    return sb.toString();\n}",
        "summary_tokens": [
            "produces",
            "a",
            "string",
            "representation",
            "containing",
            "useful",
            "information",
            "about",
            "a",
            "task",
            "starting",
            "with",
            "the",
            "given",
            "indent"
        ]
    },
    {
        "id": 2820,
        "code": "public void setStateListener(final StreamThread.StateListener listener) {\n    stateListener = listener;\n}",
        "summary_tokens": [
            "set",
            "the",
            "stream",
            "thread"
        ]
    },
    {
        "id": 2821,
        "code": "public State state() {\n        \n    return state;\n}",
        "summary_tokens": [
            "the",
            "state",
            "this",
            "instance",
            "is",
            "in"
        ]
    },
    {
        "id": 2822,
        "code": "public void run() {\n    log.info(\"Starting\");\n    if (setState(State.STARTING) == null) {\n        log.info(\"StreamThread already shutdown. Not running\");\n        return;\n    }\n    boolean cleanRun = false;\n    try {\n        cleanRun = runLoop();\n    } catch (final Throwable e) {\n        failedStreamThreadSensor.record();\n        requestLeaveGroupDuringShutdown();\n        streamsUncaughtExceptionHandler.accept(e, false);\n            \n    } finally {\n        completeShutdown(cleanRun);\n    }\n}",
        "summary_tokens": [
            "execute",
            "the",
            "stream",
            "processors"
        ]
    },
    {
        "id": 2823,
        "code": "boolean runLoop() {\n    subscribeConsumer();\n\n        \n        \n    while (isRunning() || taskManager.isRebalanceInProgress()) {\n        try {\n            checkForTopologyUpdates();\n                \n                \n            if (!isRunning() && topologyMetadata.isEmpty()) {\n                log.info(\"Shutting down thread with empty topology.\");\n                break;\n            }\n\n            maybeSendShutdown();\n            final long size = cacheResizeSize.getAndSet(-1L);\n            if (size != -1L) {\n                cacheResizer.accept(size);\n            }\n            runOnce();\n            if (nextProbingRebalanceMs.get() < time.milliseconds()) {\n                log.info(\"Triggering the followup rebalance scheduled for {} ms.\", nextProbingRebalanceMs.get());\n                mainConsumer.enforceRebalance(\"Scheduled probing rebalance\");\n                nextProbingRebalanceMs.set(Long.MAX_VALUE);\n            }\n        } catch (final TaskCorruptedException e) {\n            log.warn(\"Detected the states of tasks \" + e.corruptedTasks() + \" are corrupted. \" +\n                     \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n            try {\n                    \n                    \n                final boolean enforceRebalance = taskManager.handleCorruption(e.corruptedTasks());\n                if (enforceRebalance && eosEnabled) {\n                    log.info(\"Active task(s) got corrupted. Triggering a rebalance.\");\n                    mainConsumer.enforceRebalance(\"Active tasks corrupted\");\n                }\n            } catch (final TaskMigratedException taskMigrated) {\n                handleTaskMigrated(taskMigrated);\n            }\n        } catch (final TaskMigratedException e) {\n            handleTaskMigrated(e);\n        } catch (final UnsupportedVersionException e) {\n            final String errorMessage = e.getMessage();\n            if (errorMessage != null &&\n                errorMessage.startsWith(\"Broker unexpectedly doesn't support requireStable flag on version \")) {\n\n                log.error(\"Shutting down because the Kafka cluster seems to be on a too old version. \" +\n                          \"Setting {}=\\\"{}\\\"/\\\"{}\\\" requires broker version 2.5 or higher.\",\n                      StreamsConfig.PROCESSING_GUARANTEE_CONFIG,\n                      StreamsConfig.EXACTLY_ONCE_V2, StreamsConfig.EXACTLY_ONCE_BETA);\n            }\n            failedStreamThreadSensor.record();\n            this.streamsUncaughtExceptionHandler.accept(new StreamsException(e), false);\n            return false;\n        } catch (final StreamsException e) {\n            throw e;\n        } catch (final Exception e) {\n            throw new StreamsException(e);\n        }\n    }\n    return true;\n}",
        "summary_tokens": [
            "main",
            "event",
            "loop",
            "for",
            "polling",
            "and",
            "processing",
            "records",
            "through",
            "topologies"
        ]
    },
    {
        "id": 2824,
        "code": "public void setStreamsUncaughtExceptionHandler(final BiConsumer<Throwable, Boolean> streamsUncaughtExceptionHandler) {\n    this.streamsUncaughtExceptionHandler = streamsUncaughtExceptionHandler;\n}",
        "summary_tokens": [
            "sets",
            "the",
            "streams",
            "uncaught",
            "exception",
            "handler"
        ]
    },
    {
        "id": 2825,
        "code": "void runOnce() {\n    final long startMs = time.milliseconds();\n    now = startMs;\n\n    final long pollLatency = pollPhase();\n\n        \n        \n        \n        \n    if (!isRunning()) {\n        log.debug(\"Thread state is already {}, skipping the run once call after poll request\", state);\n        return;\n    }\n\n    initializeAndRestorePhase();\n\n        \n        \n    advanceNowAndComputeLatency();\n\n    int totalProcessed = 0;\n    long totalCommitLatency = 0L;\n    long totalProcessLatency = 0L;\n    long totalPunctuateLatency = 0L;\n    if (state == State.RUNNING\n        || (stateUpdaterEnabled && isRunning())) {\n            \n        do {\n            log.debug(\"Processing tasks with {} iterations.\", numIterations);\n            final int processed = taskManager.process(numIterations, time);\n            final long processLatency = advanceNowAndComputeLatency();\n            totalProcessLatency += processLatency;\n            if (processed > 0) {\n                    \n                    \n                processRateSensor.record(processed, now);\n\n                    \n                    \n                    \n                    \n                processLatencySensor.record(processLatency / (double) processed, now);\n\n                totalProcessed += processed;\n                totalRecordsProcessedSinceLastSummary += processed;\n            }\n\n            log.debug(\"Processed {} records with {} iterations; invoking punctuators if necessary\",\n                      processed,\n                      numIterations);\n\n            final int punctuated = taskManager.punctuate();\n            totalPunctuatorsSinceLastSummary += punctuated;\n            final long punctuateLatency = advanceNowAndComputeLatency();\n            totalPunctuateLatency += punctuateLatency;\n            if (punctuated > 0) {\n                punctuateSensor.record(punctuateLatency / (double) punctuated, now);\n            }\n\n            log.debug(\"{} punctuators ran.\", punctuated);\n\n            final long beforeCommitMs = now;\n            final int committed = maybeCommit();\n            final long commitLatency = Math.max(now - beforeCommitMs, 0);\n            totalCommitLatency += commitLatency;\n            if (committed > 0) {\n                totalCommittedSinceLastSummary += committed;\n                commitSensor.record(commitLatency / (double) committed, now);\n\n                if (log.isDebugEnabled()) {\n                    log.debug(\"Committed all active tasks {} and standby tasks {} in {}ms\",\n                        taskManager.activeTaskIds(), taskManager.standbyTaskIds(), commitLatency);\n                }\n            }\n\n            if (processed == 0) {\n                    \n                break;\n            } else if (Math.max(now - lastPollMs, 0) > maxPollTimeMs / 2) {\n                numIterations = numIterations > 1 ? numIterations / 2 : numIterations;\n                break;\n            } else if (punctuated > 0 || committed > 0) {\n                numIterations = numIterations > 1 ? numIterations / 2 : numIterations;\n            } else {\n                numIterations++;\n            }\n        } while (true);\n\n            \n            \n        taskManager.recordTaskProcessRatio(totalProcessLatency, now);\n    }\n\n    now = time.milliseconds();\n    final long runOnceLatency = now - startMs;\n    processRecordsSensor.record(totalProcessed, now);\n    processRatioSensor.record((double) totalProcessLatency / runOnceLatency, now);\n    punctuateRatioSensor.record((double) totalPunctuateLatency / runOnceLatency, now);\n    pollRatioSensor.record((double) pollLatency / runOnceLatency, now);\n    commitRatioSensor.record((double) totalCommitLatency / runOnceLatency, now);\n\n    final boolean logProcessingSummary = now - lastLogSummaryMs > LOG_SUMMARY_INTERVAL_MS;\n    if (logProcessingSummary) {\n        log.info(\"Processed {} total records, ran {} punctuators, and committed {} total tasks since the last update\",\n             totalRecordsProcessedSinceLastSummary, totalPunctuatorsSinceLastSummary, totalCommittedSinceLastSummary);\n\n        totalRecordsProcessedSinceLastSummary = 0L;\n        totalPunctuatorsSinceLastSummary = 0L;\n        totalCommittedSinceLastSummary = 0L;\n        lastLogSummaryMs = now;\n    }\n}",
        "summary_tokens": [
            "one",
            "iteration",
            "of",
            "a",
            "thread",
            "includes",
            "the",
            "following",
            "steps"
        ]
    },
    {
        "id": 2826,
        "code": "private ConsumerRecords<byte[], byte[]> pollRequests(final Duration pollTime) {\n    ConsumerRecords<byte[], byte[]> records = ConsumerRecords.empty();\n\n    lastPollMs = now;\n\n    try {\n        records = mainConsumer.poll(pollTime);\n    } catch (final InvalidOffsetException e) {\n        resetOffsets(e.partitions(), e);\n    }\n\n    return records;\n}",
        "summary_tokens": [
            "get",
            "the",
            "next",
            "batch",
            "of",
            "records",
            "by",
            "polling"
        ]
    },
    {
        "id": 2827,
        "code": "int maybeCommit() {\n    final int committed;\n    if (now - lastCommitMs > commitTimeMs) {\n        if (log.isDebugEnabled()) {\n            log.debug(\"Committing all active tasks {} and standby tasks {} since {}ms has elapsed (commit interval is {}ms)\",\n                      taskManager.activeTaskIds(), taskManager.standbyTaskIds(), now - lastCommitMs, commitTimeMs);\n        }\n\n        committed = taskManager.commit(\n            taskManager.allTasks()\n                .values()\n                .stream()\n                .filter(t -> t.state() == Task.State.RUNNING || t.state() == Task.State.RESTORING)\n                .collect(Collectors.toSet())\n        );\n\n        if (committed > 0 && (now - lastPurgeMs) > purgeTimeMs) {\n                \n            taskManager.maybePurgeCommittedRecords();\n            lastPurgeMs = now;\n        }\n\n        if (committed == -1) {\n            log.debug(\"Unable to commit as we are in the middle of a rebalance, will try again when it completes.\");\n        } else {\n            now = time.milliseconds();\n            lastCommitMs = now;\n        }\n    } else {\n        committed = taskManager.maybeCommitActiveTasksPerUserRequested();\n    }\n\n    return committed;\n}",
        "summary_tokens": [
            "try",
            "to",
            "commit",
            "all",
            "active",
            "tasks",
            "owned",
            "by",
            "this",
            "thread"
        ]
    },
    {
        "id": 2828,
        "code": "private long advanceNowAndComputeLatency() {\n    final long previous = now;\n    now = time.milliseconds();\n\n    return Math.max(now - previous, 0);\n}",
        "summary_tokens": [
            "compute",
            "the",
            "latency",
            "based",
            "on",
            "the",
            "current",
            "marked",
            "timestamp",
            "and",
            "update",
            "the",
            "marked",
            "timestamp",
            "with",
            "the",
            "current",
            "system",
            "timestamp"
        ]
    },
    {
        "id": 2829,
        "code": "public void shutdown() {\n    log.info(\"Informed to shut down\");\n    final State oldState = setState(State.PENDING_SHUTDOWN);\n    if (oldState == State.CREATED) {\n            \n        completeShutdown(true);\n    }\n}",
        "summary_tokens": [
            "shutdown",
            "this",
            "stream",
            "thread"
        ]
    },
    {
        "id": 2830,
        "code": "public final ThreadMetadata threadMetadata() {\n    return threadMetadata;\n}",
        "summary_tokens": [
            "return",
            "information",
            "about",
            "the",
            "current",
            "stream",
            "thread"
        ]
    },
    {
        "id": 2831,
        "code": "public String toString(final String indent) {\n    return indent + \"\\tStreamsThread threadId: \" + getName() + \"\\n\" + taskManager.toString(indent);\n}",
        "summary_tokens": [
            "produces",
            "a",
            "string",
            "representation",
            "containing",
            "useful",
            "information",
            "about",
            "a",
            "stream",
            "thread",
            "starting",
            "with",
            "the",
            "given",
            "indent"
        ]
    },
    {
        "id": 2832,
        "code": "public StreamsMetadata getLocalMetadata() {\n    return localMetadata.get();\n}",
        "summary_tokens": [
            "get",
            "the",
            "streams",
            "metadata",
            "s",
            "for",
            "the",
            "local",
            "instance",
            "in",
            "a",
            "kafka",
            "streams",
            "application"
        ]
    },
    {
        "id": 2833,
        "code": "public Collection<StreamsMetadata> getAllMetadata() {\n    return Collections.unmodifiableList(allMetadata);\n}",
        "summary_tokens": [
            "find",
            "all",
            "of",
            "the",
            "streams",
            "metadata",
            "s",
            "in",
            "a",
            "kafka",
            "streams",
            "application"
        ]
    },
    {
        "id": 2834,
        "code": "public synchronized Collection<StreamsMetadata> getAllMetadataForStore(final String storeName, final String topologyName) {\n    Objects.requireNonNull(storeName, \"storeName cannot be null\");\n    Objects.requireNonNull(topologyName, \"topologyName cannot be null\");\n\n    if (!isInitialized()) {\n        return Collections.emptyList();\n    }\n\n    final Collection<String> sourceTopics = topologyMetadata.sourceTopicsForStore(storeName, topologyName);\n    if (sourceTopics.isEmpty()) {\n        return Collections.emptyList();\n    }\n\n    final ArrayList<StreamsMetadata> results = new ArrayList<>();\n    for (final StreamsMetadata metadata : allMetadata) {\n        final String metadataTopologyName = ((StreamsMetadataImpl) metadata).topologyName();\n        if (metadataTopologyName != null && metadataTopologyName.equals(topologyName)\n            && metadata.stateStoreNames().contains(storeName) || metadata.standbyStateStoreNames().contains(storeName)) {\n            results.add(metadata);\n        }\n    }\n    return results;\n}",
        "summary_tokens": [
            "find",
            "all",
            "of",
            "the",
            "streams",
            "metadata",
            "s",
            "for",
            "a",
            "given",
            "store",
            "name",
            "in",
            "the",
            "given",
            "topology"
        ]
    },
    {
        "id": 2835,
        "code": "public synchronized <K> KeyQueryMetadata getKeyQueryMetadataForKey(final String storeName,\n                                                                   final K key,\n                                                                   final StreamPartitioner<? super K, ?> partitioner,\n                                                                   final String topologyName) {\n    Objects.requireNonNull(storeName, \"storeName can't be null\");\n    Objects.requireNonNull(key, \"key can't be null\");\n    Objects.requireNonNull(partitioner, \"partitioner can't be null\");\n    Objects.requireNonNull(topologyName, \"topologyName can't be null\");\n\n\n    if (!isInitialized()) {\n        return KeyQueryMetadata.NOT_AVAILABLE;\n    }\n\n    final SourceTopicsInfo sourceTopicsInfo = getSourceTopicsInfo(storeName, topologyName);\n    if (sourceTopicsInfo == null) {\n        return null;\n    }\n    return getKeyQueryMetadataForKey(storeName, key, partitioner, sourceTopicsInfo, topologyName);\n}",
        "summary_tokens": [
            "see",
            "streams",
            "metadata",
            "state",
            "get",
            "key",
            "query",
            "metadata",
            "for",
            "key",
            "string",
            "object",
            "stream",
            "partitioner"
        ]
    },
    {
        "id": 2836,
        "code": "synchronized void onChange(final Map<HostInfo, Set<TopicPartition>> activePartitionHostMap,\n                           final Map<HostInfo, Set<TopicPartition>> standbyPartitionHostMap,\n                           final Cluster clusterMetadata) {\n    this.clusterMetadata = clusterMetadata;\n    rebuildMetadata(activePartitionHostMap, standbyPartitionHostMap);\n}",
        "summary_tokens": [
            "respond",
            "to",
            "changes",
            "to",
            "the",
            "host",
            "info",
            "topic",
            "partition",
            "mapping"
        ]
    },
    {
        "id": 2837,
        "code": "public void configure(final Map<String, ?> configs) {\n    final AssignorConfiguration assignorConfiguration = new AssignorConfiguration(configs);\n\n    logPrefix = assignorConfiguration.logPrefix();\n    log = new LogContext(logPrefix).logger(getClass());\n    usedSubscriptionMetadataVersion = assignorConfiguration.configuredMetadataVersion(usedSubscriptionMetadataVersion);\n\n    final ReferenceContainer referenceContainer = assignorConfiguration.referenceContainer();\n    mainConsumerSupplier = () -> Objects.requireNonNull(referenceContainer.mainConsumer, \"Main consumer was not specified\");\n    adminClient = Objects.requireNonNull(referenceContainer.adminClient, \"Admin client was not specified\");\n    taskManager = Objects.requireNonNull(referenceContainer.taskManager, \"TaskManager was not specified\");\n    streamsMetadataState = Objects.requireNonNull(referenceContainer.streamsMetadataState, \"StreamsMetadataState was not specified\");\n    assignmentErrorCode = referenceContainer.assignmentErrorCode;\n    nextScheduledRebalanceMs = referenceContainer.nextScheduledRebalanceMs;\n    nonFatalExceptionsToHandle = referenceContainer.nonFatalExceptionsToHandle;\n    time = Objects.requireNonNull(referenceContainer.time, \"Time was not specified\");\n    assignmentConfigs = assignorConfiguration.assignmentConfigs();\n    partitionGrouper = new PartitionGrouper();\n    userEndPoint = assignorConfiguration.userEndPoint();\n    internalTopicManager = assignorConfiguration.internalTopicManager();\n    copartitionedTopicsEnforcer = assignorConfiguration.copartitionedTopicsEnforcer();\n    rebalanceProtocol = assignorConfiguration.rebalanceProtocol();\n    taskAssignorSupplier = assignorConfiguration::taskAssignor;\n    assignmentListener = assignorConfiguration.assignmentListener();\n    uniqueField = 0;\n    clientTags = referenceContainer.clientTags;\n}",
        "summary_tokens": [
            "we",
            "need",
            "to",
            "have",
            "the",
            "partition",
            "assignor",
            "and",
            "its",
            "stream",
            "thread",
            "to",
            "be",
            "mutually",
            "accessible",
            "since",
            "the",
            "former",
            "needs",
            "latter",
            "s",
            "cached",
            "metadata",
            "while",
            "sending",
            "subscriptions",
            "and",
            "the",
            "latter",
            "needs",
            "former",
            "s",
            "returned",
            "assignment",
            "when",
            "adding",
            "tasks"
        ]
    },
    {
        "id": 2838,
        "code": "private boolean checkMetadataVersions(final int minReceivedMetadataVersion,\n                                      final int minSupportedMetadataVersion,\n                                      final int futureMetadataVersion) {\n    final boolean versionProbing;\n\n    if (futureMetadataVersion == UNKNOWN) {\n        versionProbing = false;\n    } else if (minReceivedMetadataVersion >= EARLIEST_PROBEABLE_VERSION) {\n        versionProbing = true;\n        log.info(\"Received a future (version probing) subscription (version: {}).\"\n                     + \" Sending assignment back (with supported version {}).\",\n            futureMetadataVersion,\n            minSupportedMetadataVersion);\n\n    } else {\n        throw new TaskAssignmentException(\n            \"Received a future (version probing) subscription (version: \" + futureMetadataVersion\n                + \") and an incompatible pre Kafka 2.0 subscription (version: \" + minReceivedMetadataVersion\n                + \") at the same time.\"\n        );\n    }\n\n    if (minReceivedMetadataVersion < LATEST_SUPPORTED_VERSION) {\n        log.info(\"Downgrade metadata to version {}. Latest supported version is {}.\",\n            minReceivedMetadataVersion,\n            LATEST_SUPPORTED_VERSION);\n    }\n    if (minSupportedMetadataVersion < LATEST_SUPPORTED_VERSION) {\n        log.info(\"Downgrade latest supported metadata to version {}. Latest supported version is {}.\",\n            minSupportedMetadataVersion,\n            LATEST_SUPPORTED_VERSION);\n    }\n    return versionProbing;\n}",
        "summary_tokens": [
            "verify",
            "the",
            "subscription",
            "versions",
            "are",
            "within",
            "the",
            "expected",
            "bounds",
            "and",
            "check",
            "for",
            "version",
            "probing"
        ]
    },
    {
        "id": 2839,
        "code": "private RepartitionTopics prepareRepartitionTopics(final Cluster metadata) {\n    final RepartitionTopics repartitionTopics = new RepartitionTopics(\n        taskManager.topologyMetadata(),\n        internalTopicManager,\n        copartitionedTopicsEnforcer,\n        metadata,\n        logPrefix\n    );\n    repartitionTopics.setup();\n    final boolean isMissingInputTopics = !repartitionTopics.missingSourceTopicExceptions().isEmpty();\n    if (isMissingInputTopics) {\n        if (!taskManager.topologyMetadata().hasNamedTopologies()) {\n            throw new MissingSourceTopicException(\"Missing source topics.\");\n        } else {\n            nonFatalExceptionsToHandle.addAll(repartitionTopics.missingSourceTopicExceptions());\n        }\n    }\n    return repartitionTopics;\n}",
        "summary_tokens": [
            "computes",
            "and",
            "assembles",
            "all",
            "repartition",
            "topic",
            "metadata",
            "then",
            "creates",
            "the",
            "topics",
            "if",
            "necessary"
        ]
    },
    {
        "id": 2840,
        "code": "private void populateTasksForMaps(final Map<TopicPartition, TaskId> taskForPartition,\n                                  final Map<Subtopology, Set<TaskId>> tasksForTopicGroup,\n                                  final Set<String> allSourceTopics,\n                                  final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                  final Cluster fullMetadata) {\n        \n    final Set<TopicPartition> allAssignedPartitions = new HashSet<>();\n    for (final Map.Entry<TaskId, Set<TopicPartition>> entry : partitionsForTask.entrySet()) {\n        final TaskId id = entry.getKey();\n        final Set<TopicPartition> partitions = entry.getValue();\n\n        for (final TopicPartition partition : partitions) {\n            taskForPartition.put(partition, id);\n            if (allAssignedPartitions.contains(partition)) {\n                log.warn(\"Partition {} is assigned to more than one tasks: {}\", partition, partitionsForTask);\n            }\n        }\n        allAssignedPartitions.addAll(partitions);\n\n        tasksForTopicGroup.computeIfAbsent(new Subtopology(id.subtopology(), id.topologyName()), k -> new HashSet<>()).add(id);\n    }\n\n    checkAllPartitions(allSourceTopics, partitionsForTask, allAssignedPartitions, fullMetadata);\n}",
        "summary_tokens": [
            "populates",
            "the",
            "task",
            "for",
            "partition",
            "and",
            "tasks",
            "for",
            "topic",
            "group",
            "maps",
            "and",
            "checks",
            "that",
            "partitions",
            "are",
            "assigned",
            "to",
            "exactly",
            "one",
            "task"
        ]
    },
    {
        "id": 2841,
        "code": "private boolean assignTasksToClients(final Cluster fullMetadata,\n                                     final Set<String> allSourceTopics,\n                                     final Map<Subtopology, TopicsInfo> topicGroups,\n                                     final Map<UUID, ClientMetadata> clientMetadataMap,\n                                     final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                     final Set<TaskId> statefulTasks) {\n    if (!statefulTasks.isEmpty()) {\n        throw new TaskAssignmentException(\"The stateful tasks should not be populated before assigning tasks to clients\");\n    }\n\n    final Map<TopicPartition, TaskId> taskForPartition = new HashMap<>();\n    final Map<Subtopology, Set<TaskId>> tasksForTopicGroup = new HashMap<>();\n    populateTasksForMaps(taskForPartition, tasksForTopicGroup, allSourceTopics, partitionsForTask, fullMetadata);\n\n    final ChangelogTopics changelogTopics = new ChangelogTopics(\n        internalTopicManager,\n        topicGroups,\n        tasksForTopicGroup,\n        logPrefix\n    );\n    changelogTopics.setup();\n\n    final Map<UUID, ClientState> clientStates = new HashMap<>();\n    final boolean lagComputationSuccessful =\n        populateClientStatesMap(clientStates, clientMetadataMap, taskForPartition, changelogTopics);\n\n    log.info(\"All members participating in this rebalance: \\n{}.\",\n             clientStates.entrySet().stream()\n                 .map(entry -> entry.getKey() + \": \" + entry.getValue().consumers())\n                 .collect(Collectors.joining(Utils.NL)));\n\n    final Set<TaskId> allTasks = partitionsForTask.keySet();\n    statefulTasks.addAll(changelogTopics.statefulTaskIds());\n\n    log.debug(\"Assigning tasks {} including stateful {} to clients {} with number of replicas {}\",\n        allTasks, statefulTasks, clientStates, numStandbyReplicas());\n\n    final TaskAssignor taskAssignor = createTaskAssignor(lagComputationSuccessful);\n\n    final boolean probingRebalanceNeeded = taskAssignor.assign(clientStates,\n                                                               allTasks,\n                                                               statefulTasks,\n                                                               assignmentConfigs);\n\n    log.info(\"Assigned tasks {} including stateful {} to clients as: \\n{}.\",\n            allTasks, statefulTasks, clientStates.entrySet().stream()\n                    .map(entry -> entry.getKey() + \"=\" + entry.getValue().currentAssignment())\n                    .collect(Collectors.joining(Utils.NL)));\n\n    return probingRebalanceNeeded;\n}",
        "summary_tokens": [
            "assigns",
            "a",
            "set",
            "of",
            "tasks",
            "to",
            "each",
            "client",
            "streams",
            "instance",
            "using",
            "the",
            "configured",
            "task",
            "assignor",
            "and",
            "also",
            "populate",
            "the",
            "stateful",
            "tasks",
            "that",
            "have",
            "been",
            "assigned",
            "to",
            "the",
            "clients",
            "true",
            "if",
            "a",
            "probing",
            "rebalance",
            "should",
            "be",
            "triggered"
        ]
    },
    {
        "id": 2842,
        "code": "private boolean populateClientStatesMap(final Map<UUID, ClientState> clientStates,\n                                        final Map<UUID, ClientMetadata> clientMetadataMap,\n                                        final Map<TopicPartition, TaskId> taskForPartition,\n                                        final ChangelogTopics changelogTopics) {\n    boolean fetchEndOffsetsSuccessful;\n    Map<TaskId, Long> allTaskEndOffsetSums;\n    try {\n            \n            \n        final KafkaFuture<Map<TopicPartition, ListOffsetsResultInfo>> endOffsetsFuture =\n            fetchEndOffsetsFuture(changelogTopics.preExistingNonSourceTopicBasedPartitions(), adminClient);\n\n        final Map<TopicPartition, Long> sourceChangelogEndOffsets =\n            fetchCommittedOffsets(changelogTopics.preExistingSourceTopicBasedPartitions(), mainConsumerSupplier.get());\n\n        final Map<TopicPartition, ListOffsetsResultInfo> endOffsets = ClientUtils.getEndOffsets(endOffsetsFuture);\n\n        allTaskEndOffsetSums = computeEndOffsetSumsByTask(\n            endOffsets,\n            sourceChangelogEndOffsets,\n            changelogTopics\n        );\n        fetchEndOffsetsSuccessful = true;\n    } catch (final StreamsException | TimeoutException e) {\n        allTaskEndOffsetSums = changelogTopics.statefulTaskIds().stream().collect(Collectors.toMap(t -> t, t -> UNKNOWN_OFFSET_SUM));\n        fetchEndOffsetsSuccessful = false;\n    }\n\n    for (final Map.Entry<UUID, ClientMetadata> entry : clientMetadataMap.entrySet()) {\n        final UUID uuid = entry.getKey();\n        final ClientState state = entry.getValue().state;\n        state.initializePrevTasks(taskForPartition, taskManager.topologyMetadata().hasNamedTopologies());\n\n        state.computeTaskLags(uuid, allTaskEndOffsetSums);\n        clientStates.put(uuid, state);\n    }\n\n    return fetchEndOffsetsSuccessful;\n}",
        "summary_tokens": [
            "builds",
            "a",
            "map",
            "from",
            "client",
            "to",
            "state",
            "and",
            "readies",
            "each",
            "client",
            "state",
            "for",
            "assignment",
            "by",
            "adding",
            "any",
            "missing",
            "prev",
            "tasks",
            "and",
            "computing",
            "the",
            "per",
            "task",
            "overall",
            "lag",
            "based",
            "on",
            "the",
            "fetched",
            "end",
            "offsets",
            "for",
            "each",
            "changelog"
        ]
    },
    {
        "id": 2843,
        "code": "private Map<TaskId, Long> computeEndOffsetSumsByTask(final Map<TopicPartition, ListOffsetsResultInfo> endOffsets,\n                                                     final Map<TopicPartition, Long> sourceChangelogEndOffsets,\n                                                     final ChangelogTopics changelogTopics) {\n\n    final Map<TaskId, Long> taskEndOffsetSums = new HashMap<>();\n    for (final TaskId taskId : changelogTopics.statefulTaskIds()) {\n        taskEndOffsetSums.put(taskId, 0L);\n        for (final TopicPartition changelogPartition : changelogTopics.preExistingPartitionsFor(taskId)) {\n            final long changelogPartitionEndOffset;\n            if (sourceChangelogEndOffsets.containsKey(changelogPartition)) {\n                changelogPartitionEndOffset = sourceChangelogEndOffsets.get(changelogPartition);\n            } else if (endOffsets.containsKey(changelogPartition)) {\n                changelogPartitionEndOffset = endOffsets.get(changelogPartition).offset();\n            } else {\n                log.debug(\"Fetched offsets did not contain the changelog {} of task {}\", changelogPartition, taskId);\n                throw new IllegalStateException(\"Could not get end offset for \" + changelogPartition);\n            }\n            final long newEndOffsetSum = taskEndOffsetSums.get(taskId) + changelogPartitionEndOffset;\n            if (newEndOffsetSum < 0) {\n                taskEndOffsetSums.put(taskId, Long.MAX_VALUE);\n                break;\n            } else {\n                taskEndOffsetSums.put(taskId, newEndOffsetSum);\n            }\n        }\n    }\n    return taskEndOffsetSums;\n}",
        "summary_tokens": [
            "end",
            "offsets",
            "the",
            "list",
            "offsets",
            "result",
            "from",
            "the",
            "admin",
            "client",
            "source",
            "changelog",
            "end",
            "offsets",
            "the",
            "end",
            "committed",
            "offsets",
            "of",
            "optimized",
            "source",
            "changelogs",
            "changelog",
            "topics",
            "object",
            "that",
            "manages",
            "changelog",
            "topics"
        ]
    },
    {
        "id": 2844,
        "code": "private void populatePartitionsByHostMaps(final Map<HostInfo, Set<TopicPartition>> partitionsByHost,\n                                          final Map<HostInfo, Set<TopicPartition>> standbyPartitionsByHost,\n                                          final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                          final Map<UUID, ClientMetadata> clientMetadataMap) {\n    for (final Map.Entry<UUID, ClientMetadata> entry : clientMetadataMap.entrySet()) {\n        final HostInfo hostInfo = entry.getValue().hostInfo;\n\n            \n        if (hostInfo != null) {\n            final Set<TopicPartition> topicPartitions = new HashSet<>();\n            final Set<TopicPartition> standbyPartitions = new HashSet<>();\n            final ClientState state = entry.getValue().state;\n\n            for (final TaskId id : state.activeTasks()) {\n                topicPartitions.addAll(partitionsForTask.get(id));\n            }\n\n            for (final TaskId id : state.standbyTasks()) {\n                standbyPartitions.addAll(partitionsForTask.get(id));\n            }\n\n            partitionsByHost.put(hostInfo, topicPartitions);\n            standbyPartitionsByHost.put(hostInfo, standbyPartitions);\n        }\n    }\n}",
        "summary_tokens": [
            "populates",
            "the",
            "global",
            "partitions",
            "by",
            "host",
            "and",
            "standby",
            "partitions",
            "by",
            "host",
            "maps",
            "that",
            "are",
            "sent",
            "to",
            "each",
            "member"
        ]
    },
    {
        "id": 2845,
        "code": "private Map<String, Assignment> computeNewAssignment(final Set<TaskId> statefulTasks,\n                                                     final Map<UUID, ClientMetadata> clientsMetadata,\n                                                     final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                                     final Map<HostInfo, Set<TopicPartition>> partitionsByHostState,\n                                                     final Map<HostInfo, Set<TopicPartition>> standbyPartitionsByHost,\n                                                     final Set<TopicPartition> allOwnedPartitions,\n                                                     final int minUserMetadataVersion,\n                                                     final int minSupportedMetadataVersion,\n                                                     final boolean versionProbing,\n                                                     final boolean shouldTriggerProbingRebalance) {\n    boolean rebalanceRequired = shouldTriggerProbingRebalance || versionProbing;\n    final Map<String, Assignment> assignment = new HashMap<>();\n\n        \n    for (final Map.Entry<UUID, ClientMetadata> clientEntry : clientsMetadata.entrySet()) {\n        final UUID clientId = clientEntry.getKey();\n        final ClientMetadata clientMetadata = clientEntry.getValue();\n        final ClientState state = clientMetadata.state;\n        final SortedSet<String> consumers = clientMetadata.consumers;\n        final Map<String, Integer> threadTaskCounts = new HashMap<>();\n\n        final Map<String, List<TaskId>> activeTaskStatefulAssignment = assignTasksToThreads(\n            state.statefulActiveTasks(),\n            true,\n            consumers,\n            state,\n            threadTaskCounts\n        );\n\n        final Map<String, List<TaskId>> standbyTaskAssignment = assignTasksToThreads(\n            state.standbyTasks(),\n            true,\n            consumers,\n            state,\n            threadTaskCounts\n        );\n\n        final Map<String, List<TaskId>> activeTaskStatelessAssignment = assignTasksToThreads(\n            state.statelessActiveTasks(),\n            false,\n            consumers,\n            state,\n            threadTaskCounts\n        );\n\n            \n            \n        final Map<String, List<TaskId>> activeTaskAssignment = activeTaskStatefulAssignment;\n        for (final Map.Entry<String, List<TaskId>> threadEntry : activeTaskStatelessAssignment.entrySet()) {\n            activeTaskAssignment.get(threadEntry.getKey()).addAll(threadEntry.getValue());\n        }\n\n            \n            \n            \n        final boolean encodeNextProbingRebalanceTime = shouldTriggerProbingRebalance && clientId.equals(taskManager.processId());\n\n        final boolean tasksRevoked = addClientAssignments(\n            statefulTasks,\n            assignment,\n            clientMetadata,\n            partitionsForTask,\n            partitionsByHostState,\n            standbyPartitionsByHost,\n            allOwnedPartitions,\n            activeTaskAssignment,\n            standbyTaskAssignment,\n            minUserMetadataVersion,\n            minSupportedMetadataVersion,\n            encodeNextProbingRebalanceTime\n        );\n\n        if (tasksRevoked || encodeNextProbingRebalanceTime) {\n            rebalanceRequired = true;\n            log.debug(\"Requested client {} to schedule a followup rebalance\", clientId);\n        }\n\n        log.info(\"Client {} per-consumer assignment:\\n\" +\n            \"\\tprev owned active {}\\n\" +\n            \"\\tprev owned standby {}\\n\" +\n            \"\\tassigned active {}\\n\" +\n            \"\\trevoking active {}\\n\" +\n            \"\\tassigned standby {}\\n\",\n            clientId,\n            clientMetadata.state.prevOwnedActiveTasksByConsumer(),\n            clientMetadata.state.prevOwnedStandbyByConsumer(),\n            clientMetadata.state.assignedActiveTasksByConsumer(),\n            clientMetadata.state.revokingActiveTasksByConsumer(),\n            clientMetadata.state.assignedStandbyTasksByConsumer());\n    }\n\n    if (rebalanceRequired) {\n        assignmentListener.onAssignmentComplete(false);\n        log.info(\"Finished unstable assignment of tasks, a followup rebalance will be scheduled.\");\n    } else {\n        assignmentListener.onAssignmentComplete(true);\n        log.info(\"Finished stable assignment of tasks, no followup rebalances required.\");\n    }\n\n    return assignment;\n}",
        "summary_tokens": [
            "computes",
            "the",
            "assignment",
            "of",
            "tasks",
            "to",
            "threads",
            "within",
            "each",
            "client",
            "and",
            "assembles",
            "the",
            "final",
            "assignment",
            "to",
            "send",
            "out"
        ]
    },
    {
        "id": 2846,
        "code": "private boolean addClientAssignments(final Set<TaskId> statefulTasks,\n                                     final Map<String, Assignment> assignment,\n                                     final ClientMetadata clientMetadata,\n                                     final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                     final Map<HostInfo, Set<TopicPartition>> partitionsByHostState,\n                                     final Map<HostInfo, Set<TopicPartition>> standbyPartitionsByHost,\n                                     final Set<TopicPartition> allOwnedPartitions,\n                                     final Map<String, List<TaskId>> activeTaskAssignments,\n                                     final Map<String, List<TaskId>> standbyTaskAssignments,\n                                     final int minUserMetadataVersion,\n                                     final int minSupportedMetadataVersion,\n                                     final boolean probingRebalanceNeeded) {\n    boolean followupRebalanceRequiredForRevokedTasks = false;\n\n        \n    boolean shouldEncodeProbingRebalance = probingRebalanceNeeded;\n\n        \n    for (final String consumer : clientMetadata.consumers) {\n        final List<TaskId> activeTasksForConsumer = activeTaskAssignments.get(consumer);\n\n            \n        final List<TopicPartition> activePartitionsList = new ArrayList<>();\n        final List<TaskId> assignedActiveList = new ArrayList<>();\n\n        final Set<TaskId> activeTasksRemovedPendingRevokation = populateActiveTaskAndPartitionsLists(\n            activePartitionsList,\n            assignedActiveList,\n            consumer,\n            clientMetadata.state,\n            activeTasksForConsumer,\n            partitionsForTask,\n            allOwnedPartitions\n        );\n\n        final Map<TaskId, Set<TopicPartition>> standbyTaskMap = buildStandbyTaskMap(\n                consumer,\n                standbyTaskAssignments.get(consumer),\n                activeTasksRemovedPendingRevokation,\n                statefulTasks,\n                partitionsForTask,\n                clientMetadata.state\n            );\n\n        final AssignmentInfo info = new AssignmentInfo(\n            minUserMetadataVersion,\n            minSupportedMetadataVersion,\n            assignedActiveList,\n            standbyTaskMap,\n            partitionsByHostState,\n            standbyPartitionsByHost,\n            AssignorError.NONE.code()\n        );\n\n        if (!activeTasksRemovedPendingRevokation.isEmpty()) {\n                \n            log.info(\"Requesting followup rebalance be scheduled immediately by {} due to tasks changing ownership.\", consumer);\n            info.setNextRebalanceTime(0L);\n            followupRebalanceRequiredForRevokedTasks = true;\n                \n            shouldEncodeProbingRebalance = false;\n        } else if (shouldEncodeProbingRebalance) {\n            final long nextRebalanceTimeMs = time.milliseconds() + probingRebalanceIntervalMs();\n            log.info(\"Requesting followup rebalance be scheduled by {} for {} ms to probe for caught-up replica tasks.\",\n                    consumer, nextRebalanceTimeMs);\n            info.setNextRebalanceTime(nextRebalanceTimeMs);\n            shouldEncodeProbingRebalance = false;\n        }\n\n        assignment.put(\n            consumer,\n            new Assignment(\n                activePartitionsList,\n                info.encode()\n            )\n        );\n    }\n    return followupRebalanceRequiredForRevokedTasks;\n}",
        "summary_tokens": [
            "adds",
            "the",
            "encoded",
            "assignment",
            "for",
            "each",
            "stream",
            "thread",
            "consumer",
            "in",
            "the",
            "client",
            "to",
            "the",
            "overall",
            "assignment",
            "map",
            "true",
            "if",
            "a",
            "followup",
            "rebalance",
            "will",
            "be",
            "required",
            "due",
            "to",
            "revoked",
            "tasks"
        ]
    },
    {
        "id": 2847,
        "code": "private Set<TaskId> populateActiveTaskAndPartitionsLists(final List<TopicPartition> activePartitionsList,\n                                                         final List<TaskId> assignedActiveList,\n                                                         final String consumer,\n                                                         final ClientState clientState,\n                                                         final List<TaskId> activeTasksForConsumer,\n                                                         final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                                         final Set<TopicPartition> allOwnedPartitions) {\n    final List<AssignedPartition> assignedPartitions = new ArrayList<>();\n    final Set<TaskId> removedActiveTasks = new TreeSet<>();\n\n    for (final TaskId taskId : activeTasksForConsumer) {\n            \n            \n        clientState.assignActiveToConsumer(taskId, consumer);\n\n        final List<AssignedPartition> assignedPartitionsForTask = new ArrayList<>();\n        for (final TopicPartition partition : partitionsForTask.get(taskId)) {\n            final String oldOwner = clientState.previousOwnerForPartition(partition);\n            final boolean newPartitionForConsumer = oldOwner == null || !oldOwner.equals(consumer);\n\n                \n                \n            if (newPartitionForConsumer && allOwnedPartitions.contains(partition)) {\n                log.info(\n                    \"Removing task {} from {} active assignment until it is safely revoked in followup rebalance\",\n                    taskId,\n                    consumer\n                );\n                removedActiveTasks.add(taskId);\n\n                clientState.revokeActiveFromConsumer(taskId, consumer);\n\n                    \n                    \n                assignedPartitionsForTask.clear();\n\n                    \n                    \n                clientState.unassignActive(taskId);\n                break;\n            } else {\n                assignedPartitionsForTask.add(new AssignedPartition(taskId, partition));\n            }\n        }\n            \n        assignedPartitions.addAll(assignedPartitionsForTask);\n    }\n\n        \n    Collections.sort(assignedPartitions);\n    for (final AssignedPartition partition : assignedPartitions) {\n        assignedActiveList.add(partition.taskId);\n        activePartitionsList.add(partition.partition);\n    }\n    return removedActiveTasks;\n}",
        "summary_tokens": [
            "populates",
            "the",
            "lists",
            "of",
            "active",
            "tasks",
            "and",
            "active",
            "task",
            "partitions",
            "for",
            "the",
            "consumer",
            "with",
            "a",
            "0",
            "0",
            "mapping",
            "between",
            "them",
            "such",
            "that",
            "the",
            "nth",
            "task",
            "corresponds",
            "to",
            "the",
            "nth",
            "partition",
            "in",
            "the",
            "list"
        ]
    },
    {
        "id": 2848,
        "code": "private Map<TaskId, Set<TopicPartition>> buildStandbyTaskMap(final String consumer,\n                                                             final Iterable<TaskId> standbyTasks,\n                                                             final Iterable<TaskId> revokedTasks,\n                                                             final Set<TaskId> allStatefulTasks,\n                                                             final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                                             final ClientState clientState) {\n    final Map<TaskId, Set<TopicPartition>> standbyTaskMap = new HashMap<>();\n\n    for (final TaskId task : standbyTasks) {\n        clientState.assignStandbyToConsumer(task, consumer);\n        standbyTaskMap.put(task, partitionsForTask.get(task));\n    }\n\n    for (final TaskId task : revokedTasks) {\n        if (allStatefulTasks.contains(task)) {\n            log.info(\"Adding removed stateful active task {} as a standby for {} before it is revoked in followup rebalance\",\n                    task, consumer);\n\n                \n                \n            clientState.assignStandbyToConsumer(task, consumer);\n            clientState.assignStandby(task);\n\n            standbyTaskMap.put(task, partitionsForTask.get(task));\n        }\n    }\n    return standbyTaskMap;\n}",
        "summary_tokens": [
            "map",
            "from",
            "task",
            "id",
            "to",
            "its",
            "assigned",
            "partitions",
            "for",
            "all",
            "standby",
            "tasks"
        ]
    },
    {
        "id": 2849,
        "code": "static Map<String, List<TaskId>> assignTasksToThreads(final Collection<TaskId> tasksToAssign,\n                                                      final boolean isStateful,\n                                                      final SortedSet<String> consumers,\n                                                      final ClientState state,\n                                                      final Map<String, Integer> threadLoad) {\n    final Map<String, List<TaskId>> assignment = new HashMap<>();\n    for (final String consumer : consumers) {\n        assignment.put(consumer, new ArrayList<>());\n    }\n\n    final int totalTasks = threadLoad.values().stream().reduce(tasksToAssign.size(), Integer::sum);\n\n    final int minTasksPerThread = (int) Math.floor(((double) totalTasks) / consumers.size());\n    final PriorityQueue<TaskId> unassignedTasks = new PriorityQueue<>(tasksToAssign);\n\n    final Queue<String> consumersToFill = new LinkedList<>();\n        \n        \n    final Map<TaskId, String> unassignedTaskToPreviousOwner = new TreeMap<>();\n\n    if (!unassignedTasks.isEmpty()) {\n            \n        for (final String consumer : consumers) {\n            final List<TaskId> threadAssignment = assignment.get(consumer);\n                \n            final int tasksTargetCount = minTasksPerThread - threadLoad.getOrDefault(consumer, 0);\n\n            if (isStateful) {\n                for (final TaskId task : state.prevTasksByLag(consumer)) {\n                    if (unassignedTasks.contains(task)) {\n                        if (threadAssignment.size() < tasksTargetCount) {\n                            threadAssignment.add(task);\n                            unassignedTasks.remove(task);\n                        } else {\n                            unassignedTaskToPreviousOwner.put(task, consumer);\n                        }\n                    }\n                }\n            }\n\n            if (threadAssignment.size() < tasksTargetCount) {\n                consumersToFill.offer(consumer);\n            }\n        }\n\n            \n        while (!consumersToFill.isEmpty()) {\n            final TaskId task = unassignedTasks.poll();\n            if (task != null) {\n                final String consumer = consumersToFill.poll();\n                final List<TaskId> threadAssignment = assignment.get(consumer);\n                threadAssignment.add(task);\n                final int threadTaskCount = threadAssignment.size() + threadLoad.getOrDefault(consumer, 0);\n                if (threadTaskCount < minTasksPerThread) {\n                    consumersToFill.offer(consumer);\n                }\n            } else {\n                throw new TaskAssignmentException(\"Ran out of unassigned stateful tasks but some members were not at capacity\");\n            }\n        }\n\n            \n            \n            \n            \n        if (!unassignedTasks.isEmpty()) {\n            for (final String consumer : consumers) {\n                final int taskCount = assignment.get(consumer).size() + threadLoad.getOrDefault(consumer, 0);\n                if (taskCount == minTasksPerThread) {\n                    consumersToFill.add(consumer);\n                }\n            }\n\n                \n            for (final Map.Entry<TaskId, String> taskEntry : unassignedTaskToPreviousOwner.entrySet()) {\n                final TaskId task = taskEntry.getKey();\n                final String consumer = taskEntry.getValue();\n                if (consumersToFill.contains(consumer) && unassignedTasks.contains(task)) {\n                    assignment.get(consumer).add(task);\n                    unassignedTasks.remove(task);\n                        \n                    consumersToFill.remove(consumer);\n                }\n            }\n\n                \n            for (final TaskId task : unassignedTasks) {\n                final String consumer = consumersToFill.poll();\n                final List<TaskId> threadAssignment = assignment.get(consumer);\n                threadAssignment.add(task);\n            }\n        }\n    }\n        \n    for (final Map.Entry<String, List<TaskId>> taskEntry : assignment.entrySet()) {\n        final String consumer = taskEntry.getKey();\n        final int totalCount = threadLoad.getOrDefault(consumer, 0) + taskEntry.getValue().size();\n        threadLoad.put(consumer, totalCount);\n    }\n\n    return assignment;\n}",
        "summary_tokens": [
            "generate",
            "an",
            "assignment",
            "that",
            "tries",
            "to",
            "preserve",
            "thread",
            "level",
            "stickiness",
            "for",
            "stateful",
            "tasks",
            "without",
            "violating",
            "balance"
        ]
    },
    {
        "id": 2850,
        "code": "private boolean verifyHostInfo(final Set<HostInfo> groupHostInfo) {\n    if (userEndPoint != null && !groupHostInfo.isEmpty()) {\n        final HostInfo myHostInfo = HostInfo.buildFromEndpoint(userEndPoint);\n\n        return groupHostInfo.contains(myHostInfo);\n    } else {\n        return true;\n    }\n}",
        "summary_tokens": [
            "verify",
            "that",
            "this",
            "client",
            "s",
            "host",
            "info",
            "was",
            "included",
            "in",
            "the",
            "map",
            "returned",
            "in",
            "the",
            "assignment",
            "and",
            "trigger",
            "a",
            "rebalance",
            "if",
            "not"
        ]
    },
    {
        "id": 2851,
        "code": "void initTransaction() {\n    if (!eosEnabled()) {\n        throw new IllegalStateException(formatException(\"Exactly-once is not enabled\"));\n    }\n    if (!transactionInitialized) {\n            \n            \n        try {\n            producer.initTransactions();\n            transactionInitialized = true;\n        } catch (final TimeoutException timeoutException) {\n            log.warn(\n                \"Timeout exception caught trying to initialize transactions. \" +\n                    \"The broker is either slow or in bad state (like not having enough replicas) in \" +\n                    \"responding to the request, or the connection to broker was interrupted sending \" +\n                    \"the request or receiving the response. \" +\n                    \"Will retry initializing the task in the next loop. \" +\n                    \"Consider overwriting {} to a larger value to avoid timeout errors\",\n                ProducerConfig.MAX_BLOCK_MS_CONFIG\n            );\n\n                \n            throw timeoutException;\n        } catch (final KafkaException exception) {\n            throw new StreamsException(\n                formatException(\"Error encountered trying to initialize transactions\"),\n                exception\n            );\n        }\n    }\n}",
        "summary_tokens": [
            "illegal",
            "state",
            "exception",
            "if",
            "eos",
            "is",
            "disabled"
        ]
    },
    {
        "id": 2852,
        "code": "protected void commitTransaction(final Map<TopicPartition, OffsetAndMetadata> offsets,\n                                 final ConsumerGroupMetadata consumerGroupMetadata) {\n    if (!eosEnabled()) {\n        throw new IllegalStateException(formatException(\"Exactly-once is not enabled\"));\n    }\n    maybeBeginTransaction();\n    try {\n            \n            \n        final ConsumerGroupMetadata maybeDowngradedGroupMetadata = processingMode == EXACTLY_ONCE_V2 ? consumerGroupMetadata : new ConsumerGroupMetadata(consumerGroupMetadata.groupId());\n        producer.sendOffsetsToTransaction(offsets, maybeDowngradedGroupMetadata);\n        producer.commitTransaction();\n        transactionInFlight = false;\n    } catch (final ProducerFencedException | InvalidProducerEpochException | CommitFailedException error) {\n        throw new TaskMigratedException(\n            formatException(\"Producer got fenced trying to commit a transaction\"),\n            error\n        );\n    } catch (final TimeoutException timeoutException) {\n            \n        throw timeoutException;\n    } catch (final KafkaException error) {\n        throw new StreamsException(\n            formatException(\"Error encountered trying to commit a transaction\"),\n            error\n        );\n    }\n}",
        "summary_tokens": [
            "illegal",
            "state",
            "exception",
            "if",
            "eos",
            "is",
            "disabled",
            "task",
            "migrated",
            "exception"
        ]
    },
    {
        "id": 2853,
        "code": "void abortTransaction() {\n    if (!eosEnabled()) {\n        throw new IllegalStateException(formatException(\"Exactly-once is not enabled\"));\n    }\n    if (transactionInFlight) {\n        try {\n            producer.abortTransaction();\n        } catch (final TimeoutException logAndSwallow) {\n                \n                \n            log.warn(\n                \"Aborting transaction failed due to timeout.\" +\n                    \" Will rely on broker to eventually abort the transaction after the transaction timeout passed.\",\n                logAndSwallow\n            );\n        } catch (final ProducerFencedException | InvalidProducerEpochException error) {\n                \n                \n                \n                \n                \n                \n                \n                \n            log.debug(\"Encountered {} while aborting the transaction; this is expected and hence swallowed\", error.getMessage());\n        } catch (final KafkaException error) {\n            throw new StreamsException(\n                formatException(\"Error encounter trying to abort a transaction\"),\n                error\n            );\n        }\n        transactionInFlight = false;\n    }\n}",
        "summary_tokens": [
            "illegal",
            "state",
            "exception",
            "if",
            "eos",
            "is",
            "disabled"
        ]
    },
    {
        "id": 2854,
        "code": "List<PartitionInfo> partitionsFor(final String topic) {\n    return producer.partitionsFor(topic);\n}",
        "summary_tokens": [
            "cf",
            "kafka",
            "producer",
            "partitions",
            "for",
            "string"
        ]
    },
    {
        "id": 2855,
        "code": "int process(final int maxNumRecords, final Time time) {\n    int totalProcessed = 0;\n    Task lastProcessed = null;\n\n    for (final Task task : tasks.activeTasks()) {\n        final long now = time.milliseconds();\n        try {\n            if (executionMetadata.canProcessTask(task, now)) {\n                lastProcessed = task;\n                totalProcessed += processTask(task, maxNumRecords, now, time);\n            }\n        } catch (final Throwable t) {\n            executionMetadata.registerTaskError(task, t, now);\n            executionMetadata.removeTaskFromSuccessfullyProcessedBeforeClosing(lastProcessed);\n            commitSuccessfullyProcessedTasks();\n            throw t;\n        }\n    }\n\n    return totalProcessed;\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "only",
            "streams",
            "exception",
            "if",
            "any",
            "task",
            "threw",
            "an",
            "exception",
            "while",
            "processing"
        ]
    },
    {
        "id": 2856,
        "code": "int commitTasksAndMaybeUpdateCommittableOffsets(final Collection<Task> tasksToCommit,\n                                                final Map<Task, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadata) {\n    int committed = 0;\n    for (final Task task : tasksToCommit) {\n            \n        if (task.commitNeeded()) {\n            final Map<TopicPartition, OffsetAndMetadata> offsetAndMetadata = task.prepareCommit();\n            if (!offsetAndMetadata.isEmpty()) {\n                consumedOffsetsAndMetadata.put(task, offsetAndMetadata);\n            }\n        }\n    }\n\n    commitOffsetsOrTransaction(consumedOffsetsAndMetadata);\n\n    for (final Task task : tasksToCommit) {\n        if (task.commitNeeded()) {\n            task.clearTaskTimeout();\n            ++committed;\n            task.postCommit(false);\n        }\n    }\n\n    return committed;\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "committing",
            "offsets",
            "failed",
            "non",
            "eos",
            "or",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "timeout",
            "exception",
            "if",
            "committing",
            "offsets",
            "failed",
            "due",
            "to",
            "timeout",
            "exception",
            "non",
            "eos",
            "task",
            "corrupted",
            "exception",
            "if",
            "committing",
            "offsets",
            "failed",
            "due",
            "to",
            "timeout",
            "exception",
            "eos",
            "consumed",
            "offsets",
            "and",
            "metadata",
            "an",
            "empty",
            "map",
            "that",
            "will",
            "be",
            "filled",
            "in",
            "with",
            "the",
            "prepared",
            "offsets",
            "number",
            "of",
            "committed",
            "offsets",
            "or",
            "0",
            "if",
            "we",
            "are",
            "in",
            "the",
            "middle",
            "of",
            "a",
            "rebalance",
            "and",
            "cannot",
            "commit"
        ]
    },
    {
        "id": 2857,
        "code": "void commitOffsetsOrTransaction(final Map<Task, Map<TopicPartition, OffsetAndMetadata>> offsetsPerTask) {\n    log.debug(\"Committing task offsets {}\", offsetsPerTask.entrySet().stream().collect(Collectors.toMap(t -> t.getKey().id(), Entry::getValue))); \n\n    final Set<TaskId> corruptedTasks = new HashSet<>();\n\n    if (!offsetsPerTask.isEmpty()) {\n        if (executionMetadata.processingMode() == EXACTLY_ONCE_ALPHA) {\n            for (final Map.Entry<Task, Map<TopicPartition, OffsetAndMetadata>> taskToCommit : offsetsPerTask.entrySet()) {\n                final Task task = taskToCommit.getKey();\n                try {\n                    taskManager.streamsProducerForTask(task.id())\n                        .commitTransaction(taskToCommit.getValue(), taskManager.mainConsumer().groupMetadata());\n                    updateTaskCommitMetadata(taskToCommit.getValue());\n                } catch (final TimeoutException timeoutException) {\n                    log.error(\n                        String.format(\"Committing task %s failed.\", task.id()),\n                        timeoutException\n                    );\n                    corruptedTasks.add(task.id());\n                }\n            }\n        } else {\n            final Map<TopicPartition, OffsetAndMetadata> allOffsets = offsetsPerTask.values().stream()\n                .flatMap(e -> e.entrySet().stream()).collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n            if (executionMetadata.processingMode() == EXACTLY_ONCE_V2) {\n                try {\n                    taskManager.threadProducer().commitTransaction(allOffsets, taskManager.mainConsumer().groupMetadata());\n                    updateTaskCommitMetadata(allOffsets);\n                } catch (final TimeoutException timeoutException) {\n                    log.error(\n                        String.format(\"Committing task(s) %s failed.\",\n                            offsetsPerTask\n                                .keySet()\n                                .stream()\n                                .map(t -> t.id().toString())\n                                .collect(Collectors.joining(\", \"))),\n                        timeoutException\n                    );\n                    offsetsPerTask\n                        .keySet()\n                        .forEach(task -> corruptedTasks.add(task.id()));\n                }\n            } else {\n                try {\n                    taskManager.mainConsumer().commitSync(allOffsets);\n                    updateTaskCommitMetadata(allOffsets);\n                } catch (final CommitFailedException error) {\n                    throw new TaskMigratedException(\"Consumer committing offsets failed, \" +\n                        \"indicating the corresponding thread is no longer part of the group\", error);\n                } catch (final TimeoutException timeoutException) {\n                    log.error(\n                        String.format(\"Committing task(s) %s failed.\",\n                            offsetsPerTask\n                                .keySet()\n                                .stream()\n                                .map(t -> t.id().toString())\n                                .collect(Collectors.joining(\", \"))),\n                        timeoutException\n                    );\n                    throw timeoutException;\n                } catch (final KafkaException error) {\n                    throw new StreamsException(\"Error encountered committing offsets via consumer\", error);\n                }\n            }\n        }\n\n        if (!corruptedTasks.isEmpty()) {\n            throw new TaskCorruptedException(corruptedTasks);\n        }\n    }\n}",
        "summary_tokens": [
            "caution",
            "do",
            "not",
            "invoke",
            "this",
            "directly",
            "if",
            "it",
            "s",
            "possible",
            "a",
            "rebalance",
            "is",
            "occurring",
            "as",
            "the",
            "commit",
            "will",
            "fail"
        ]
    },
    {
        "id": 2858,
        "code": "int punctuate() {\n    int punctuated = 0;\n\n    for (final Task task : tasks.activeTasks()) {\n        try {\n            if (executionMetadata.canPunctuateTask(task)) {\n                if (task.maybePunctuateStreamTime()) {\n                    punctuated++;\n                }\n                if (task.maybePunctuateSystemTime()) {\n                    punctuated++;\n                }\n            }\n        } catch (final TaskMigratedException e) {\n            log.info(\"Failed to punctuate stream task {} since it got migrated to another thread already. \" +\n                \"Will trigger a new rebalance and close all tasks as zombies together.\", task.id());\n            throw e;\n        } catch (final StreamsException e) {\n            log.error(\"Failed to punctuate stream task {} due to the following error:\", task.id(), e);\n            e.setTaskId(task.id());\n            throw e;\n        } catch (final KafkaException e) {\n            log.error(\"Failed to punctuate stream task {} due to the following error:\", task.id(), e);\n            throw new StreamsException(e, task.id());\n        }\n    }\n\n    return punctuated;\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "only"
        ]
    },
    {
        "id": 2859,
        "code": "public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                             final Map<TaskId, Set<TopicPartition>> standbyTasks) {\n    log.info(\"Handle new assignment with:\\n\" +\n                 \"\\tNew active tasks: {}\\n\" +\n                 \"\\tNew standby tasks: {}\\n\" +\n                 \"\\tExisting active tasks: {}\\n\" +\n                 \"\\tExisting standby tasks: {}\",\n             activeTasks.keySet(), standbyTasks.keySet(), activeTaskIds(), standbyTaskIds());\n\n    topologyMetadata.addSubscribedTopicsFromAssignment(\n        activeTasks.values().stream().flatMap(Collection::stream).collect(Collectors.toList()),\n        logPrefix\n    );\n\n    final Map<TaskId, Set<TopicPartition>> activeTasksToCreate = new HashMap<>(activeTasks);\n    final Map<TaskId, Set<TopicPartition>> standbyTasksToCreate = new HashMap<>(standbyTasks);\n    final Map<Task, Set<TopicPartition>> tasksToRecycle = new HashMap<>();\n    final Set<Task> tasksToCloseClean = new TreeSet<>(Comparator.comparing(Task::id));\n\n        \n    tasks.clearPendingTasksToCreate();\n    tasks.addPendingActiveTasksToCreate(pendingTasksToCreate(activeTasksToCreate));\n    tasks.addPendingStandbyTasksToCreate(pendingTasksToCreate(standbyTasksToCreate));\n        \n        \n        \n        \n        \n    if (stateUpdater == null) {\n        classifyTasksWithoutStateUpdater(activeTasksToCreate, standbyTasksToCreate, tasksToRecycle, tasksToCloseClean);\n    } else {\n        classifyTasksWithStateUpdater(activeTasksToCreate, standbyTasksToCreate, tasksToRecycle, tasksToCloseClean);\n    }\n\n    final Map<TaskId, RuntimeException> taskCloseExceptions = closeAndRecycleTasks(tasksToRecycle, tasksToCloseClean);\n\n    maybeThrowTaskExceptions(taskCloseExceptions);\n\n    createNewTasks(activeTasksToCreate, standbyTasksToCreate);\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "only",
            "streams",
            "exception",
            "fatal",
            "error",
            "while",
            "creating",
            "initializing",
            "the",
            "task"
        ]
    },
    {
        "id": 2860,
        "code": "boolean tryToCompleteRestoration(final long now,\n                                 final java.util.function.Consumer<Set<TopicPartition>> offsetResetter) {\n    boolean allRunning = true;\n\n        \n    changelogReader.enforceRestoreActive();\n\n    final List<Task> activeTasks = new LinkedList<>();\n    for (final Task task : tasks.allTasks()) {\n        try {\n            task.initializeIfNeeded();\n            task.clearTaskTimeout();\n        } catch (final LockException lockException) {\n                \n                \n                \n            log.debug(\"Could not initialize task {} since: {}; will retry\", task.id(), lockException.getMessage());\n            allRunning = false;\n        } catch (final TimeoutException timeoutException) {\n            task.maybeInitTaskTimeoutOrThrow(now, timeoutException);\n            allRunning = false;\n        }\n\n        if (task.isActive()) {\n            activeTasks.add(task);\n        }\n    }\n\n    if (allRunning && !activeTasks.isEmpty()) {\n\n        final Set<TopicPartition> restored = changelogReader.completedChangelogs();\n\n        for (final Task task : activeTasks) {\n            if (restored.containsAll(task.changelogPartitions())) {\n                try {\n                    task.completeRestoration(offsetResetter);\n                    task.clearTaskTimeout();\n                } catch (final TimeoutException timeoutException) {\n                    task.maybeInitTaskTimeoutOrThrow(now, timeoutException);\n                    log.debug(\n                        String.format(\n                            \"Could not complete restoration for %s due to the following exception; will retry\",\n                            task.id()),\n                        timeoutException\n                    );\n\n                    allRunning = false;\n                }\n            } else {\n                    \n                    \n                allRunning = false;\n            }\n        }\n    }\n    if (allRunning) {\n            \n        mainConsumer.resume(mainConsumer.assignment());\n        changelogReader.transitToUpdateStandby();\n    }\n\n    return allRunning;\n}",
        "summary_tokens": [
            "tries",
            "to",
            "initialize",
            "any",
            "new",
            "or",
            "still",
            "uninitialized",
            "tasks",
            "then",
            "checks",
            "if",
            "they",
            "can",
            "have",
            "completed",
            "restoration"
        ]
    },
    {
        "id": 2861,
        "code": "void handleRevocation(final Collection<TopicPartition> revokedPartitions) {\n    final Set<TopicPartition> remainingRevokedPartitions = new HashSet<>(revokedPartitions);\n\n    final Set<Task> revokedActiveTasks = new HashSet<>();\n    final Set<Task> commitNeededActiveTasks = new HashSet<>();\n    final Map<Task, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsPerTask = new HashMap<>();\n    final AtomicReference<RuntimeException> firstException = new AtomicReference<>(null);\n\n    for (final Task task : activeTaskIterable()) {\n        if (remainingRevokedPartitions.containsAll(task.inputPartitions())) {\n                \n                \n            revokedActiveTasks.add(task);\n            remainingRevokedPartitions.removeAll(task.inputPartitions());\n        } else if (task.commitNeeded()) {\n            commitNeededActiveTasks.add(task);\n        }\n    }\n\n    removeRevokedTasksFromStateUpdater(remainingRevokedPartitions);\n\n    if (!remainingRevokedPartitions.isEmpty()) {\n        log.debug(\"The following revoked partitions {} are missing from the current task partitions. It could \"\n                      + \"potentially be due to race condition of consumer detecting the heartbeat failure, or the tasks \" +\n                     \"have been cleaned up by the handleAssignment callback.\", remainingRevokedPartitions);\n    }\n\n    prepareCommitAndAddOffsetsToMap(revokedActiveTasks, consumedOffsetsPerTask);\n\n        \n    final boolean shouldCommitAdditionalTasks = !consumedOffsetsPerTask.isEmpty();\n    if (shouldCommitAdditionalTasks) {\n        prepareCommitAndAddOffsetsToMap(commitNeededActiveTasks, consumedOffsetsPerTask);\n    }\n\n        \n        \n        \n    final Set<Task> dirtyTasks = new HashSet<>();\n    try {\n            \n            \n            \n        taskExecutor.commitOffsetsOrTransaction(consumedOffsetsPerTask);\n    } catch (final TaskCorruptedException e) {\n        log.warn(\"Some tasks were corrupted when trying to commit offsets, these will be cleaned and revived: {}\",\n                 e.corruptedTasks());\n\n            \n        dirtyTasks.addAll(tasks.tasks(e.corruptedTasks()));\n        closeDirtyAndRevive(dirtyTasks, true);\n    } catch (final TimeoutException e) {\n        log.warn(\"Timed out while trying to commit all tasks during revocation, these will be cleaned and revived\");\n\n            \n        dirtyTasks.addAll(consumedOffsetsPerTask.keySet());\n        closeDirtyAndRevive(dirtyTasks, false);\n    } catch (final RuntimeException e) {\n        log.error(\"Exception caught while committing those revoked tasks \" + revokedActiveTasks, e);\n        firstException.compareAndSet(null, e);\n        dirtyTasks.addAll(consumedOffsetsPerTask.keySet());\n    }\n\n        \n        \n    for (final Task task : revokedActiveTasks) {\n        if (!dirtyTasks.contains(task)) {\n            try {\n                task.postCommit(true);\n            } catch (final RuntimeException e) {\n                log.error(\"Exception caught while post-committing task \" + task.id(), e);\n                maybeSetFirstException(false, maybeWrapTaskException(e, task.id()), firstException);\n            }\n        }\n    }\n\n    if (shouldCommitAdditionalTasks) {\n        for (final Task task : commitNeededActiveTasks) {\n            if (!dirtyTasks.contains(task)) {\n                try {\n                        \n                        \n                        \n                    task.postCommit(false);\n                } catch (final RuntimeException e) {\n                    log.error(\"Exception caught while post-committing task \" + task.id(), e);\n                    maybeSetFirstException(false, maybeWrapTaskException(e, task.id()), firstException);\n                }\n            }\n        }\n    }\n\n    for (final Task task : revokedActiveTasks) {\n        try {\n            task.suspend();\n        } catch (final RuntimeException e) {\n            log.error(\"Caught the following exception while trying to suspend revoked task \" + task.id(), e);\n            maybeSetFirstException(false, maybeWrapTaskException(e, task.id()), firstException);\n        }\n    }\n\n    if (firstException.get() != null) {\n        throw firstException.get();\n    }\n}",
        "summary_tokens": [
            "handle",
            "the",
            "revoked",
            "partitions",
            "and",
            "prepare",
            "for",
            "closing",
            "the",
            "associated",
            "tasks",
            "in",
            "handle",
            "assignment",
            "map",
            "map",
            "we",
            "should",
            "commit",
            "the",
            "revoking",
            "tasks",
            "first",
            "before",
            "suspending",
            "them",
            "as",
            "we",
            "will",
            "not",
            "officially",
            "own",
            "them",
            "anymore",
            "when",
            "handle",
            "assignment",
            "map",
            "map",
            "is",
            "called"
        ]
    },
    {
        "id": 2862,
        "code": "void handleLostAll() {\n    log.debug(\"Closing lost active tasks as zombies.\");\n\n    closeRunningTasksDirty();\n    removeLostActiveTasksFromStateUpdater();\n\n    if (processingMode == EXACTLY_ONCE_V2) {\n        activeTaskCreator.reInitializeThreadProducer();\n    }\n}",
        "summary_tokens": [
            "closes",
            "active",
            "tasks",
            "as",
            "zombies",
            "as",
            "these",
            "partitions",
            "have",
            "been",
            "lost",
            "and",
            "are",
            "no",
            "longer",
            "owned"
        ]
    },
    {
        "id": 2863,
        "code": "public Map<TaskId, Long> getTaskOffsetSums() {\n    final Map<TaskId, Long> taskOffsetSums = new HashMap<>();\n\n        \n        \n        \n    for (final TaskId id : union(HashSet::new, lockedTaskDirectories, tasks.allTaskIds())) {\n        final Task task = tasks.contains(id) ? tasks.task(id) : null;\n            \n        if (task != null && task.state() != State.CREATED && task.state() != State.CLOSED) {\n            final Map<TopicPartition, Long> changelogOffsets = task.changelogOffsets();\n            if (changelogOffsets.isEmpty()) {\n                log.debug(\"Skipping to encode apparently stateless (or non-logged) offset sum for task {}\", id);\n            } else {\n                taskOffsetSums.put(id, sumOfChangelogOffsets(id, changelogOffsets));\n            }\n        } else {\n            final File checkpointFile = stateDirectory.checkpointFileFor(id);\n            try {\n                if (checkpointFile.exists()) {\n                    taskOffsetSums.put(id, sumOfChangelogOffsets(id, new OffsetCheckpoint(checkpointFile).read()));\n                }\n            } catch (final IOException e) {\n                log.warn(String.format(\"Exception caught while trying to read checkpoint for task %s:\", id), e);\n            }\n        }\n    }\n\n    return taskOffsetSums;\n}",
        "summary_tokens": [
            "compute",
            "the",
            "offset",
            "total",
            "summed",
            "across",
            "all",
            "stores",
            "in",
            "a",
            "task"
        ]
    },
    {
        "id": 2864,
        "code": "private void tryToLockAllNonEmptyTaskDirectories() {\n        \n        \n    lockedTaskDirectories.clear();\n\n    for (final TaskDirectory taskDir : stateDirectory.listNonEmptyTaskDirectories()) {\n        final File dir = taskDir.file();\n        final String namedTopology = taskDir.namedTopology();\n        try {\n            final TaskId id = parseTaskDirectoryName(dir.getName(), namedTopology);\n            if (stateDirectory.lock(id)) {\n                lockedTaskDirectories.add(id);\n                if (!tasks.contains(id)) {\n                    log.debug(\"Temporarily locked unassigned task {} for the upcoming rebalance\", id);\n                }\n            }\n        } catch (final TaskIdFormatException e) {\n                \n        }\n    }\n}",
        "summary_tokens": [
            "makes",
            "a",
            "weak",
            "attempt",
            "to",
            "lock",
            "all",
            "non",
            "empty",
            "task",
            "directories",
            "in",
            "the",
            "state",
            "dir"
        ]
    },
    {
        "id": 2865,
        "code": "private void releaseLockedDirectoriesForTasks(final Set<TaskId> tasksToUnlock) {\n    final Iterator<TaskId> taskIdIterator = lockedTaskDirectories.iterator();\n    while (taskIdIterator.hasNext()) {\n        final TaskId id = taskIdIterator.next();\n        if (tasksToUnlock.contains(id)) {\n            stateDirectory.unlock(id);\n            taskIdIterator.remove();\n        }\n    }\n}",
        "summary_tokens": [
            "clean",
            "up",
            "after",
            "closed",
            "or",
            "removed",
            "tasks",
            "by",
            "making",
            "sure",
            "to",
            "unlock",
            "any",
            "remaining",
            "locked",
            "directories",
            "for",
            "them",
            "for",
            "example",
            "unassigned",
            "tasks",
            "or",
            "those",
            "in",
            "the",
            "created",
            "state",
            "when",
            "closed",
            "since",
            "task",
            "close",
            "will",
            "not",
            "unlock",
            "them"
        ]
    },
    {
        "id": 2866,
        "code": "private void releaseLockedUnassignedTaskDirectories() {\n    final Iterator<TaskId> taskIdIterator = lockedTaskDirectories.iterator();\n    while (taskIdIterator.hasNext()) {\n        final TaskId id = taskIdIterator.next();\n        if (!tasks.contains(id)) {\n            stateDirectory.unlock(id);\n            taskIdIterator.remove();\n        }\n    }\n}",
        "summary_tokens": [
            "we",
            "must",
            "release",
            "the",
            "lock",
            "for",
            "any",
            "unassigned",
            "tasks",
            "that",
            "we",
            "temporarily",
            "locked",
            "in",
            "preparation",
            "for",
            "a",
            "rebalance",
            "in",
            "try",
            "to",
            "lock",
            "all",
            "non",
            "empty",
            "task",
            "directories"
        ]
    },
    {
        "id": 2867,
        "code": "void closeAndCleanUpTasks(final Collection<Task> activeTasks, final Collection<Task> standbyTasks, final boolean clean) {\n    final AtomicReference<RuntimeException> firstException = new AtomicReference<>(null);\n\n    final Set<Task> tasksToCloseDirty = new HashSet<>();\n    tasksToCloseDirty.addAll(tryCloseCleanActiveTasks(activeTasks, clean, firstException));\n    tasksToCloseDirty.addAll(tryCloseCleanStandbyTasks(standbyTasks, clean, firstException));\n\n    for (final Task task : tasksToCloseDirty) {\n        closeTaskDirty(task, true);\n    }\n\n    final RuntimeException exception = firstException.get();\n    if (exception != null) {\n        throw exception;\n    }\n}",
        "summary_tokens": [
            "closes",
            "and",
            "cleans",
            "up",
            "after",
            "the",
            "provided",
            "tasks",
            "including",
            "closing",
            "their",
            "corresponding",
            "task",
            "producers"
        ]
    },
    {
        "id": 2868,
        "code": "void addRecordsToTasks(final ConsumerRecords<byte[], byte[]> records) {\n    for (final TopicPartition partition : records.partitions()) {\n        final Task activeTask = tasks.activeTasksForInputPartition(partition);\n\n        if (activeTask == null) {\n            log.error(\"Unable to locate active task for received-record partition {}. Current tasks: {}\",\n                partition, toString(\">\"));\n            throw new NullPointerException(\"Task was unexpectedly missing for partition \" + partition);\n        }\n\n        activeTask.addRecords(partition, records.records(partition));\n    }\n}",
        "summary_tokens": [
            "take",
            "records",
            "and",
            "add",
            "them",
            "to",
            "each",
            "respective",
            "task"
        ]
    },
    {
        "id": 2869,
        "code": "int commit(final Collection<Task> tasksToCommit) {\n    int committed = 0;\n\n    final Map<Task, Map<TopicPartition, OffsetAndMetadata>> consumedOffsetsAndMetadataPerTask = new HashMap<>();\n    try {\n        committed = commitTasksAndMaybeUpdateCommittableOffsets(tasksToCommit, consumedOffsetsAndMetadataPerTask);\n    } catch (final TimeoutException timeoutException) {\n        consumedOffsetsAndMetadataPerTask\n            .keySet()\n            .forEach(t -> t.maybeInitTaskTimeoutOrThrow(time.milliseconds(), timeoutException));\n    }\n\n    return committed;\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "committing",
            "offsets",
            "failed",
            "non",
            "eos",
            "or",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "timeout",
            "exception",
            "if",
            "task"
        ]
    },
    {
        "id": 2870,
        "code": "int maybeCommitActiveTasksPerUserRequested() {\n    if (rebalanceInProgress) {\n        return -1;\n    } else {\n        for (final Task task : activeTaskIterable()) {\n            if (task.commitRequested() && task.commitNeeded()) {\n                return commit(activeTaskIterable());\n            }\n        }\n        return 0;\n    }\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "committing",
            "offsets",
            "failed",
            "non",
            "eos",
            "or",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos"
        ]
    },
    {
        "id": 2871,
        "code": "void handleTopologyUpdates() {\n    topologyMetadata.executeTopologyUpdatesAndBumpThreadVersion(\n        this::createPendingTasks,\n        this::maybeCloseTasksFromRemovedTopologies\n    );\n\n    if (topologyMetadata.isEmpty()) {\n        log.info(\"Proactively unsubscribing from all topics due to empty topology\");\n        mainConsumer.unsubscribe();\n    }\n\n    topologyMetadata.maybeNotifyTopologyVersionListeners();\n}",
        "summary_tokens": [
            "handle",
            "any",
            "added",
            "or",
            "removed",
            "named",
            "topologies"
        ]
    },
    {
        "id": 2872,
        "code": "int process(final int maxNumRecords, final Time time) {\n    return taskExecutor.process(maxNumRecords, time);\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "only",
            "streams",
            "exception",
            "if",
            "any",
            "task",
            "threw",
            "an",
            "exception",
            "while",
            "processing"
        ]
    },
    {
        "id": 2873,
        "code": "int punctuate() {\n    return  taskExecutor.punctuate();\n}",
        "summary_tokens": [
            "task",
            "migrated",
            "exception",
            "if",
            "the",
            "task",
            "producer",
            "got",
            "fenced",
            "eos",
            "only"
        ]
    },
    {
        "id": 2874,
        "code": "public String toString() {\n    return toString(\"\");\n}",
        "summary_tokens": [
            "produces",
            "a",
            "string",
            "representation",
            "containing",
            "useful",
            "information",
            "about",
            "the",
            "task",
            "manager"
        ]
    },
    {
        "id": 2875,
        "code": "public Set<Task> allTasks() {\n    return union(HashSet::new, new HashSet<>(activeTasksPerId.values()), new HashSet<>(standbyTasksPerId.values()));\n}",
        "summary_tokens": [
            "all",
            "tasks",
            "returned",
            "by",
            "any",
            "of",
            "the",
            "getters",
            "are",
            "read",
            "only",
            "and",
            "should",
            "not",
            "be",
            "modified",
            "and",
            "the",
            "returned",
            "task",
            "could",
            "be",
            "modified",
            "by",
            "other",
            "threads",
            "concurrently"
        ]
    },
    {
        "id": 2876,
        "code": "public void registerAndBuildNewTopology(final KafkaFutureImpl<Void> future, final InternalTopologyBuilder newTopologyBuilder) {\n    try {\n        lock();\n        buildAndVerifyTopology(newTopologyBuilder);\n        log.info(\"New NamedTopology {} passed validation and will be added, old topology version is {}\", newTopologyBuilder.topologyName(), version.topologyVersion.get());\n        version.topologyVersion.incrementAndGet();\n        version.activeTopologyUpdateListeners.add(new TopologyVersionListener(topologyVersion(), future));\n        builders.put(newTopologyBuilder.topologyName(), newTopologyBuilder);\n        wakeupThreads();\n        log.info(\"Added NamedTopology {} and updated topology version to {}\", newTopologyBuilder.topologyName(), version.topologyVersion.get());\n    } catch (final Throwable throwable) {\n        log.error(\"Failed to add NamedTopology {}, please retry the operation.\", newTopologyBuilder.topologyName());\n        future.completeExceptionally(throwable);\n    } finally {\n        unlock();\n    }\n}",
        "summary_tokens": [
            "adds",
            "the",
            "topology",
            "and",
            "registers",
            "a",
            "future",
            "that",
            "listens",
            "for",
            "all",
            "threads",
            "on",
            "the",
            "older",
            "version",
            "to",
            "see",
            "the",
            "update"
        ]
    },
    {
        "id": 2877,
        "code": "public void pauseTopology(final String topologyName) {\n    pausedTopologies.add(topologyName);\n}",
        "summary_tokens": [
            "pauses",
            "a",
            "topology",
            "by",
            "name",
            "topology",
            "name",
            "name",
            "of",
            "the",
            "topology",
            "to",
            "pause"
        ]
    },
    {
        "id": 2878,
        "code": "public boolean isPaused(final String topologyName) {\n    if (topologyName == null) {\n        return pausedTopologies.contains(UNNAMED_TOPOLOGY);\n    } else {\n        return pausedTopologies.contains(topologyName);\n    }\n}",
        "summary_tokens": [
            "checks",
            "if",
            "a",
            "given",
            "topology",
            "is",
            "paused"
        ]
    },
    {
        "id": 2879,
        "code": "public void resumeTopology(final String topologyName) {\n    pausedTopologies.remove(topologyName);\n}",
        "summary_tokens": [
            "resumes",
            "a",
            "topology",
            "by",
            "name",
            "topology",
            "name",
            "name",
            "of",
            "the",
            "topology",
            "to",
            "resume"
        ]
    },
    {
        "id": 2880,
        "code": "public KafkaFuture<Void> unregisterTopology(final KafkaFutureImpl<Void> removeTopologyFuture,\n                                            final String topologyName) {\n    try {\n        lock();\n        log.info(\"Beginning removal of NamedTopology {}, old topology version is {}\", topologyName, version.topologyVersion.get());\n        version.topologyVersion.incrementAndGet();\n        version.activeTopologyUpdateListeners.add(new TopologyVersionListener(topologyVersion(), removeTopologyFuture));\n        final InternalTopologyBuilder removedBuilder = builders.remove(topologyName);\n        removedBuilder.fullSourceTopicNames().forEach(allInputTopics::remove);\n        removedBuilder.allSourcePatternStrings().forEach(allInputTopics::remove);\n        log.info(\"Finished removing NamedTopology {}, topology version was updated to {}\", topologyName, version.topologyVersion.get());\n    } catch (final Throwable throwable) {\n        log.error(\"Failed to remove NamedTopology {}, please retry.\", topologyName);\n        removeTopologyFuture.completeExceptionally(throwable);\n    } finally {\n        unlock();\n    }\n    return removeTopologyFuture;\n}",
        "summary_tokens": [
            "removes",
            "the",
            "topology",
            "and",
            "registers",
            "a",
            "future",
            "that",
            "listens",
            "for",
            "all",
            "threads",
            "on",
            "the",
            "older",
            "version",
            "to",
            "see",
            "the",
            "update"
        ]
    },
    {
        "id": 2881,
        "code": "public boolean hasNamedTopologies() {\n    return !builders.containsKey(UNNAMED_TOPOLOGY);\n}",
        "summary_tokens": [
            "true",
            "iff",
            "the",
            "app",
            "is",
            "using",
            "named",
            "topologies",
            "or",
            "was",
            "started",
            "up",
            "with",
            "no",
            "topology",
            "at",
            "all"
        ]
    },
    {
        "id": 2882,
        "code": "public boolean hasGlobalTopology() {\n    return evaluateConditionIsTrueForAnyBuilders(InternalTopologyBuilder::hasGlobalStores);\n}",
        "summary_tokens": [
            "true",
            "iff",
            "any",
            "of",
            "the",
            "topologies",
            "have",
            "a",
            "global",
            "topology"
        ]
    },
    {
        "id": 2883,
        "code": "public boolean hasNoLocalTopology() {\n    return evaluateConditionIsTrueForAnyBuilders(InternalTopologyBuilder::hasNoLocalTopology);\n}",
        "summary_tokens": [
            "true",
            "iff",
            "any",
            "of",
            "the",
            "topologies",
            "have",
            "no",
            "local",
            "aka",
            "non",
            "global",
            "topology"
        ]
    },
    {
        "id": 2884,
        "code": "public ProcessorTopology buildSubtopology(final TaskId task) {\n    final InternalTopologyBuilder builder = lookupBuilderForTask(task);\n    return builder.buildSubtopology(task.subtopology());\n}",
        "summary_tokens": [
            "the",
            "processor",
            "topology",
            "subtopology",
            "built",
            "for",
            "this",
            "task",
            "guaranteed",
            "to",
            "be",
            "non",
            "null"
        ]
    },
    {
        "id": 2885,
        "code": "public Collection<String> sourceTopicsForStore(final String storeName, final String topologyName) {\n    return lookupBuilderForNamedTopology(topologyName).sourceTopicsForStore(storeName);\n}",
        "summary_tokens": [
            "store",
            "name",
            "the",
            "name",
            "of",
            "the",
            "state",
            "store",
            "topology",
            "name",
            "the",
            "name",
            "of",
            "the",
            "topology",
            "to",
            "search",
            "for",
            "stores",
            "within",
            "topics",
            "subscribed",
            "from",
            "source",
            "processors",
            "that",
            "are",
            "connected",
            "to",
            "these",
            "state",
            "stores"
        ]
    },
    {
        "id": 2886,
        "code": "public Map<Subtopology, TopicsInfo> subtopologyTopicsInfoMapExcluding(final Set<String> topologiesToExclude) {\n    final Map<Subtopology, TopicsInfo> subtopologyTopicsInfo = new HashMap<>();\n    applyToEachBuilder(b -> {\n        if (!topologiesToExclude.contains(b.topologyName())) {\n            subtopologyTopicsInfo.putAll(b.subtopologyToTopicsInfo());\n        }\n    });\n    return subtopologyTopicsInfo;\n}",
        "summary_tokens": [
            "topologies",
            "to",
            "exclude",
            "the",
            "names",
            "of",
            "any",
            "topologies",
            "to",
            "exclude",
            "from",
            "the",
            "returned",
            "topic",
            "groups",
            "eg",
            "because",
            "they",
            "have",
            "missing",
            "source",
            "topics",
            "and",
            "can",
            "t",
            "be",
            "processed",
            "yet"
        ]
    },
    {
        "id": 2887,
        "code": "public Map<String, Map<Subtopology, TopicsInfo>> topologyToSubtopologyTopicsInfoMap() {\n    final Map<String, Map<Subtopology, TopicsInfo>> topologyToSubtopologyTopicsInfoMap = new HashMap<>();\n    applyToEachBuilder(b -> topologyToSubtopologyTopicsInfoMap.put(b.topologyName(), b.subtopologyToTopicsInfo()));\n    return  topologyToSubtopologyTopicsInfoMap;\n}",
        "summary_tokens": [
            "map",
            "from",
            "topology",
            "to",
            "its",
            "subtopologies",
            "and",
            "their",
            "topics",
            "info"
        ]
    },
    {
        "id": 2888,
        "code": "private InternalTopologyBuilder lookupBuilderForTask(final TaskId task) {\n    final InternalTopologyBuilder builder = task.topologyName() == null ?\n        builders.get(UNNAMED_TOPOLOGY) :\n        builders.get(task.topologyName());\n    if (builder == null) {\n        throw new UnknownTopologyException(\"Unable to locate topology builder\", task.topologyName());\n    } else {\n        return builder;\n    }\n}",
        "summary_tokens": [
            "the",
            "internal",
            "topology",
            "builder",
            "for",
            "this",
            "task",
            "s",
            "topology",
            "guaranteed",
            "to",
            "be",
            "non",
            "null"
        ]
    },
    {
        "id": 2889,
        "code": "public InternalTopologyBuilder lookupBuilderForNamedTopology(final String topologyName) {\n    if (topologyName == null) {\n        return builders.get(UNNAMED_TOPOLOGY);\n    } else {\n        return builders.get(topologyName);\n    }\n}",
        "summary_tokens": [
            "the",
            "internal",
            "topology",
            "builder",
            "for",
            "the",
            "named",
            "topology",
            "with",
            "the",
            "given",
            "topology",
            "name",
            "or",
            "the",
            "builder",
            "for",
            "a",
            "regular",
            "topology",
            "if",
            "topology",
            "name",
            "is",
            "null",
            "else",
            "returns",
            "null",
            "if",
            "topology",
            "name",
            "is",
            "non",
            "null",
            "but",
            "no",
            "such",
            "named",
            "topology",
            "exists"
        ]
    },
    {
        "id": 2890,
        "code": "public Map<String, String> getProperties(final Map<String, String> defaultProperties, final long additionalRetentionMs) {\n        \n    final Map<String, String> topicConfig = new HashMap<>(UNWINDOWED_STORE_CHANGELOG_TOPIC_DEFAULT_OVERRIDES);\n\n    topicConfig.putAll(defaultProperties);\n\n    topicConfig.putAll(topicConfigs);\n\n    return topicConfig;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configured",
            "properties",
            "for",
            "this",
            "topic"
        ]
    },
    {
        "id": 2891,
        "code": "public Map<String, String> getProperties(final Map<String, String> defaultProperties, final long additionalRetentionMs) {\n        \n    final Map<String, String> topicConfig = new HashMap<>(WINDOWED_STORE_CHANGELOG_TOPIC_DEFAULT_OVERRIDES);\n\n    topicConfig.putAll(defaultProperties);\n\n    topicConfig.putAll(topicConfigs);\n\n    if (retentionMs != null) {\n        long retentionValue;\n        try {\n            retentionValue = Math.addExact(retentionMs, additionalRetentionMs);\n        } catch (final ArithmeticException swallow) {\n            retentionValue = Long.MAX_VALUE;\n        }\n        topicConfig.put(TopicConfig.RETENTION_MS_CONFIG, String.valueOf(retentionValue));\n    }\n\n    return topicConfig;\n}",
        "summary_tokens": [
            "get",
            "the",
            "configured",
            "properties",
            "for",
            "this",
            "topic"
        ]
    },
    {
        "id": 2892,
        "code": "public ByteBuffer encode() {\n    final ByteArrayOutputStream baos = new ByteArrayOutputStream();\n\n    try (final DataOutputStream out = new DataOutputStream(baos)) {\n        switch (usedVersion) {\n            case 1:\n                out.writeInt(usedVersion); \n                encodeActiveAndStandbyTaskAssignment(out);\n                break;\n            case 2:\n                out.writeInt(usedVersion); \n                encodeActiveAndStandbyTaskAssignment(out);\n                encodePartitionsByHost(out);\n                break;\n            case 3:\n                out.writeInt(usedVersion);\n                out.writeInt(commonlySupportedVersion);\n                encodeActiveAndStandbyTaskAssignment(out);\n                encodePartitionsByHost(out);\n                break;\n            case 4:\n                out.writeInt(usedVersion);\n                out.writeInt(commonlySupportedVersion);\n                encodeActiveAndStandbyTaskAssignment(out);\n                encodePartitionsByHost(out);\n                out.writeInt(errCode);\n                break;\n            case 5:\n                out.writeInt(usedVersion);\n                out.writeInt(commonlySupportedVersion);\n                encodeActiveAndStandbyTaskAssignment(out);\n                encodePartitionsByHostAsDictionary(out);\n                out.writeInt(errCode);\n                break;\n            case 6:\n                out.writeInt(usedVersion);\n                out.writeInt(commonlySupportedVersion);\n                encodeActiveAndStandbyTaskAssignment(out);\n                encodeActiveAndStandbyHostPartitions(out);\n                out.writeInt(errCode);\n                break;\n            case 7:\n            case 8:\n            case 9:\n            case 10:\n            case 11:\n                out.writeInt(usedVersion);\n                out.writeInt(commonlySupportedVersion);\n                encodeActiveAndStandbyTaskAssignment(out);\n                encodeActiveAndStandbyHostPartitions(out);\n                out.writeInt(errCode);\n                out.writeLong(nextRebalanceMs);\n                break;\n            default:\n                throw new IllegalStateException(\"Unknown metadata version: \" + usedVersion\n                        + \"; latest commonly supported version: \" + commonlySupportedVersion);\n        }\n\n        out.flush();\n        out.close();\n\n        return ByteBuffer.wrap(baos.toByteArray());\n    } catch (final IOException ex) {\n        throw new TaskAssignmentException(\"Failed to encode AssignmentInfo\", ex);\n    }\n}",
        "summary_tokens": [
            "task",
            "assignment",
            "exception",
            "if",
            "method",
            "fails",
            "to",
            "encode",
            "the",
            "data",
            "e"
        ]
    },
    {
        "id": 2893,
        "code": "public static AssignmentInfo decode(final ByteBuffer data) {\n        \n    data.rewind();\n\n    try (final DataInputStream in = new DataInputStream(new ByteBufferInputStream(data))) {\n        final AssignmentInfo assignmentInfo;\n\n        final int usedVersion = in.readInt();\n        final int commonlySupportedVersion;\n        switch (usedVersion) {\n            case 1:\n                assignmentInfo = new AssignmentInfo(usedVersion, UNKNOWN);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                assignmentInfo.partitionsByHost = new HashMap<>();\n                break;\n            case 2:\n                assignmentInfo = new AssignmentInfo(usedVersion, UNKNOWN);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHost(assignmentInfo, in);\n                break;\n            case 3:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHost(assignmentInfo, in);\n                break;\n            case 4:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHost(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                break;\n            case 5:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHostUsingDictionary(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                break;\n            case 6:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodeActiveAndStandbyHostPartitions(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                break;\n            case 7:\n            case 8:\n            case 9:\n            case 10:\n            case 11:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodeActiveAndStandbyHostPartitions(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                assignmentInfo.nextRebalanceMs = in.readLong();\n                break;\n            default:\n                final TaskAssignmentException fatalException = new TaskAssignmentException(\"Unable to decode assignment data: \" +\n                    \"used version: \" + usedVersion + \"; latest supported version: \" + LATEST_SUPPORTED_VERSION);\n                log.error(fatalException.getMessage(), fatalException);\n                throw fatalException;\n        }\n\n        return assignmentInfo;\n    } catch (final IOException ex) {\n        throw new TaskAssignmentException(\"Failed to decode AssignmentInfo\", ex);\n    }\n}",
        "summary_tokens": [
            "task",
            "assignment",
            "exception",
            "if",
            "method",
            "fails",
            "to",
            "decode",
            "the",
            "data",
            "or",
            "if",
            "the",
            "data",
            "version",
            "is",
            "unknown"
        ]
    },
    {
        "id": 2894,
        "code": "public void computeTaskLags(final UUID uuid, final Map<TaskId, Long> allTaskEndOffsetSums) {\n    if (!taskLagTotals.isEmpty()) {\n        throw new IllegalStateException(\"Already computed task lags for this client.\");\n    }\n\n    for (final Map.Entry<TaskId, Long> taskEntry : allTaskEndOffsetSums.entrySet()) {\n        final TaskId task = taskEntry.getKey();\n        final Long endOffsetSum = taskEntry.getValue();\n        final Long offsetSum = taskOffsetSums.getOrDefault(task, 0L);\n\n        if (offsetSum == Task.LATEST_OFFSET) {\n            taskLagTotals.put(task, Task.LATEST_OFFSET);\n        } else if (offsetSum == UNKNOWN_OFFSET_SUM) {\n            taskLagTotals.put(task, UNKNOWN_OFFSET_SUM);\n        } else if (endOffsetSum < offsetSum) {\n            LOG.warn(\"Task \" + task + \" had endOffsetSum=\" + endOffsetSum + \" smaller than offsetSum=\" +\n                         offsetSum + \" on member \" + uuid + \". This probably means the task is corrupted,\" +\n                         \" which in turn indicates that it will need to restore from scratch if it gets assigned.\" +\n                         \" The assignor will de-prioritize returning this task to this member in the hopes that\" +\n                         \" some other member may be able to re-use its state.\");\n            taskLagTotals.put(task, endOffsetSum);\n        } else {\n            taskLagTotals.put(task, endOffsetSum - offsetSum);\n        }\n    }\n}",
        "summary_tokens": [
            "compute",
            "the",
            "lag",
            "for",
            "each",
            "stateful",
            "task",
            "including",
            "tasks",
            "this",
            "client",
            "did",
            "not",
            "previously",
            "have"
        ]
    },
    {
        "id": 2895,
        "code": "public long lagFor(final TaskId task) {\n    final Long totalLag = taskLagTotals.get(task);\n    if (totalLag == null) {\n        throw new IllegalStateException(\"Tried to lookup lag for unknown task \" + task);\n    }\n    return totalLag;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "total",
            "lag",
            "across",
            "all",
            "logged",
            "stores",
            "in",
            "the",
            "task"
        ]
    },
    {
        "id": 2896,
        "code": "public SortedSet<TaskId> prevTasksByLag(final String consumer) {\n    final SortedSet<TaskId> prevTasksByLag = new TreeSet<>(comparingLong(this::lagFor).thenComparing(TaskId::compareTo));\n    for (final TaskId task : prevOwnedStatefulTasksByConsumer(consumer)) {\n        if (taskLagTotals.containsKey(task)) {\n            prevTasksByLag.add(task);\n        } else {\n            LOG.debug(\"Skipping previous task {} since it's not part of the current assignment\", task);\n        }\n    }\n    return prevTasksByLag;\n}",
        "summary_tokens": [
            "the",
            "previous",
            "tasks",
            "assigned",
            "to",
            "this",
            "consumer",
            "ordered",
            "by",
            "lag",
            "filtered",
            "for",
            "any",
            "tasks",
            "that",
            "don",
            "t",
            "exist",
            "in",
            "this",
            "assignment"
        ]
    },
    {
        "id": 2897,
        "code": "public boolean assign(final Map<UUID, ClientState> clients,\n                      final Set<TaskId> allTaskIds,\n                      final Set<TaskId> statefulTaskIds,\n                      final AssignorConfiguration.AssignmentConfigs configs) {\n    final int numStandbyReplicas = configs.numStandbyReplicas;\n    final Set<String> rackAwareAssignmentTags = new HashSet<>(configs.rackAwareAssignmentTags);\n\n    final Map<TaskId, Integer> tasksToRemainingStandbys = computeTasksToRemainingStandbys(\n        numStandbyReplicas,\n        statefulTaskIds\n    );\n\n    final Map<String, Set<String>> tagKeyToValues = new HashMap<>();\n    final Map<TagEntry, Set<UUID>> tagEntryToClients = new HashMap<>();\n\n    fillClientsTagStatistics(clients, tagEntryToClients, tagKeyToValues);\n\n    final ConstrainedPrioritySet standbyTaskClientsByTaskLoad = createLeastLoadedPrioritySetConstrainedByAssignedTask(clients);\n\n    final Map<TaskId, UUID> pendingStandbyTasksToClientId = new HashMap<>();\n\n    for (final TaskId statefulTaskId : statefulTaskIds) {\n        for (final Map.Entry<UUID, ClientState> entry : clients.entrySet()) {\n            final UUID clientId = entry.getKey();\n            final ClientState clientState = entry.getValue();\n\n            if (clientState.activeTasks().contains(statefulTaskId)) {\n                assignStandbyTasksToClientsWithDifferentTags(\n                    numStandbyReplicas,\n                    standbyTaskClientsByTaskLoad,\n                    statefulTaskId,\n                    clientId,\n                    rackAwareAssignmentTags,\n                    clients,\n                    tasksToRemainingStandbys,\n                    tagKeyToValues,\n                    tagEntryToClients,\n                    pendingStandbyTasksToClientId\n                );\n            }\n        }\n    }\n\n    if (!tasksToRemainingStandbys.isEmpty()) {\n        assignPendingStandbyTasksToLeastLoadedClients(clients,\n                                                      numStandbyReplicas,\n                                                      standbyTaskClientsByTaskLoad,\n                                                      tasksToRemainingStandbys);\n    }\n\n        \n    return false;\n}",
        "summary_tokens": [
            "the",
            "algorithm",
            "distributes",
            "standby",
            "tasks",
            "for",
            "the",
            "stateful",
            "task",
            "ids",
            "over",
            "different",
            "tag",
            "dimensions"
        ]
    },
    {
        "id": 2898,
        "code": "UUID poll(final TaskId task) {\n    return poll(task, client -> true);\n}",
        "summary_tokens": [
            "the",
            "next",
            "least",
            "loaded",
            "client",
            "that",
            "satisfies",
            "the",
            "given",
            "criteria",
            "or",
            "null",
            "if",
            "none",
            "do"
        ]
    },
    {
        "id": 2899,
        "code": "public static void writeTaskIdTo(final TaskId taskId, final DataOutputStream out, final int version) throws IOException {\n    out.writeInt(taskId.subtopology());\n    out.writeInt(taskId.partition());\n    if (version >= MIN_NAMED_TOPOLOGY_VERSION) {\n        if (taskId.topologyName() != null) {\n            out.writeInt(taskId.topologyName().length());\n            out.writeChars(taskId.topologyName());\n        } else {\n            out.writeInt(0);\n        }\n    } else if (taskId.topologyName() != null) {\n        throw new TaskAssignmentException(\"Named topologies are not compatible with protocol version \" + version);\n    }\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "cannot",
            "write",
            "to",
            "output",
            "stream"
        ]
    },
    {
        "id": 2900,
        "code": "public static TaskId readTaskIdFrom(final DataInputStream in, final int version) throws IOException {\n    final int subtopology = in.readInt();\n    final int partition = in.readInt();\n    final String namedTopology;\n    if (version >= MIN_NAMED_TOPOLOGY_VERSION) {\n        final int numNamedTopologyChars = in.readInt();\n        final StringBuilder namedTopologyBuilder = new StringBuilder();\n        for (int i = 0; i < numNamedTopologyChars; ++i) {\n            namedTopologyBuilder.append(in.readChar());\n        }\n        namedTopology = namedTopologyBuilder.toString();\n    } else {\n        namedTopology = null;\n    }\n    return new TaskId(subtopology, partition, getNamedTopologyOrElseNull(namedTopology));\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "cannot",
            "read",
            "from",
            "input",
            "stream"
        ]
    },
    {
        "id": 2901,
        "code": "private static String getNamedTopologyOrElseNull(final String namedTopology) {\n    return (namedTopology == null || namedTopology.length() == 0) ?\n            null :\n            namedTopology;\n}",
        "summary_tokens": [
            "the",
            "named",
            "topology",
            "name",
            "or",
            "null",
            "if",
            "the",
            "passed",
            "in",
            "named",
            "topology",
            "is",
            "null",
            "or",
            "the",
            "empty",
            "string"
        ]
    },
    {
        "id": 2902,
        "code": "public ByteBuffer encode() {\n    if (data.version() > LATEST_SUPPORTED_VERSION) {\n        throw new IllegalStateException(\n            \"Should never try to encode a SubscriptionInfo with version [\" +\n                data.version() + \"] > LATEST_SUPPORTED_VERSION [\" + LATEST_SUPPORTED_VERSION + \"]\"\n        );\n    } else return MessageUtil.toByteBuffer(data, (short) data.version());\n}",
        "summary_tokens": [
            "task",
            "assignment",
            "exception",
            "if",
            "method",
            "fails",
            "to",
            "encode",
            "the",
            "data"
        ]
    },
    {
        "id": 2903,
        "code": "public static SubscriptionInfo decode(final ByteBuffer data) {\n    data.rewind();\n    final int version = data.getInt();\n\n    if (version > LATEST_SUPPORTED_VERSION) {\n            \n            \n        final int latestSupportedVersion = data.getInt();\n        final SubscriptionInfoData subscriptionInfoData = new SubscriptionInfoData();\n        subscriptionInfoData.setVersion(version);\n        subscriptionInfoData.setLatestSupportedVersion(latestSupportedVersion);\n        LOG.info(\"Unable to decode subscription data: used version: {}; latest supported version: {}\",\n            version,\n            latestSupportedVersion\n        );\n        return new SubscriptionInfo(subscriptionInfoData);\n    } else {\n        data.rewind();\n        final ByteBufferAccessor accessor = new ByteBufferAccessor(data);\n        final SubscriptionInfoData subscriptionInfoData = new SubscriptionInfoData(accessor, (short) version);\n        return new SubscriptionInfo(subscriptionInfoData);\n    }\n}",
        "summary_tokens": [
            "task",
            "assignment",
            "exception",
            "if",
            "method",
            "fails",
            "to",
            "decode",
            "the",
            "data"
        ]
    },
    {
        "id": 2904,
        "code": "public void removeSensor(final Sensor sensor) {\n    Objects.requireNonNull(sensor, \"Sensor is null\");\n    metrics.removeSensor(sensor.name());\n\n    final Sensor parent = parentSensors.remove(sensor);\n    if (parent != null) {\n        metrics.removeSensor(parent.name());\n    }\n}",
        "summary_tokens": [
            "deletes",
            "a",
            "sensor",
            "and",
            "its",
            "parents",
            "if",
            "any"
        ]
    },
    {
        "id": 2905,
        "code": "public KafkaFuture<Void> all() {\n    return addTopologyFuture;\n}",
        "summary_tokens": [
            "a",
            "kafka",
            "future",
            "that",
            "completes",
            "successfully",
            "when",
            "all",
            "threads",
            "on",
            "this",
            "client",
            "have",
            "picked",
            "up",
            "the",
            "new",
            "named",
            "topology"
        ]
    },
    {
        "id": 2906,
        "code": "public StreamsException exceptionNow() {\n    try {\n        addTopologyFuture.getNow(null);\n        return null;\n    } catch (final ExecutionException e) {\n        if (e.getCause() instanceof StreamsException) {\n            return (StreamsException) e.getCause();\n        } else {\n            return new StreamsException(e.getCause());\n        }\n    } catch (final InterruptedException e) {\n        return null;\n    }\n}",
        "summary_tokens": [
            "boiler",
            "plate",
            "to",
            "get",
            "the",
            "root",
            "cause",
            "as",
            "a",
            "streams",
            "exception",
            "if",
            "completed",
            "exceptionally",
            "otherwise",
            "returns",
            "null"
        ]
    },
    {
        "id": 2907,
        "code": "public synchronized void start(final Collection<NamedTopology> initialTopologies) {\n    log.info(\"Starting Streams with topologies: {}\", initialTopologies);\n    for (final NamedTopology topology : initialTopologies) {\n        final AddNamedTopologyResult addNamedTopologyResult = addNamedTopology(topology);\n        if (addNamedTopologyResult.all().isCompletedExceptionally()) {\n            final StreamsException e = addNamedTopologyResult.exceptionNow();\n            log.error(\"Failed to start Streams when adding topology \" + topology.name() + \" due to\", e);\n            throw e;\n        }\n    }\n    super.start();\n}",
        "summary_tokens": [
            "start",
            "up",
            "streams",
            "with",
            "a",
            "collection",
            "of",
            "initial",
            "named",
            "topologies",
            "may",
            "be",
            "empty"
        ]
    },
    {
        "id": 2908,
        "code": "public NamedTopologyBuilder newNamedTopologyBuilder(final String topologyName) {\n    return newNamedTopologyBuilder(topologyName, new Properties());\n}",
        "summary_tokens": [
            "provides",
            "a",
            "high",
            "level",
            "dsl",
            "for",
            "specifying",
            "the",
            "processing",
            "logic",
            "of",
            "your",
            "application",
            "and",
            "building",
            "it",
            "into",
            "an",
            "independent",
            "topology",
            "that",
            "can",
            "be",
            "executed",
            "by",
            "this",
            "kafka",
            "streams"
        ]
    },
    {
        "id": 2909,
        "code": "public synchronized Optional<NamedTopology> getTopologyByName(final String name) {\n    return Optional.ofNullable(topologyMetadata.lookupBuilderForNamedTopology(name)).map(InternalTopologyBuilder::namedTopology);\n}",
        "summary_tokens": [
            "the",
            "named",
            "topology",
            "for",
            "the",
            "specific",
            "name",
            "or",
            "optional"
        ]
    },
    {
        "id": 2910,
        "code": "public AddNamedTopologyResult addNamedTopology(final NamedTopology newTopology) {\n    log.info(\"Adding new NamedTopology: {}\", newTopology.name());\n    final KafkaFutureImpl<Void> future = new KafkaFutureImpl<>();\n\n    if (hasStartedOrFinishedShuttingDown()) {\n        future.completeExceptionally(\n            new IllegalStateException(\"Cannot add a NamedTopology while the state is \" + super.state)\n        );\n    } else if (getTopologyByName(newTopology.name()).isPresent()) {\n        future.completeExceptionally(\n            new IllegalArgumentException(\"Unable to add the new NamedTopology \" + newTopology.name() +\n                                               \" as another of the same name already exists\")\n        );\n    } else {\n        topologyMetadata.registerAndBuildNewTopology(future, newTopology.internalTopologyBuilder());\n        maybeCompleteFutureIfStillInCREATED(future, \"adding topology \" + newTopology.name());\n    }\n\n    return new AddNamedTopologyResult(future);\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "named",
            "topology",
            "to",
            "a",
            "running",
            "kafka",
            "streams",
            "app"
        ]
    },
    {
        "id": 2911,
        "code": "public RemoveNamedTopologyResult removeNamedTopology(final String topologyToRemove) {\n    return removeNamedTopology(topologyToRemove, false);\n}",
        "summary_tokens": [
            "remove",
            "an",
            "existing",
            "named",
            "topology",
            "from",
            "a",
            "running",
            "kafka",
            "streams",
            "app"
        ]
    },
    {
        "id": 2912,
        "code": "public void pauseNamedTopology(final String topologyName) {\n    topologyMetadata.pauseTopology(topologyName);\n}",
        "summary_tokens": [
            "pauses",
            "a",
            "topology",
            "by",
            "name",
            "topology",
            "name",
            "name",
            "of",
            "the",
            "topology",
            "to",
            "pause"
        ]
    },
    {
        "id": 2913,
        "code": "public boolean isNamedTopologyPaused(final String topologyName) {\n    return topologyMetadata.isPaused(topologyName);\n}",
        "summary_tokens": [
            "checks",
            "if",
            "a",
            "given",
            "topology",
            "is",
            "paused"
        ]
    },
    {
        "id": 2914,
        "code": "public void resumeNamedTopology(final String topologyName) {\n    topologyMetadata.resumeTopology(topologyName);\n}",
        "summary_tokens": [
            "resumes",
            "a",
            "topology",
            "by",
            "name",
            "topology",
            "name",
            "name",
            "of",
            "the",
            "topology",
            "to",
            "resume"
        ]
    },
    {
        "id": 2915,
        "code": "private boolean maybeCompleteFutureIfStillInCREATED(final KafkaFutureImpl<Void> updateTopologyFuture,\n                                                    final String operation) {\n    if (state == State.CREATED && !updateTopologyFuture.isDone()) {\n        updateTopologyFuture.complete(null);\n        log.info(\"Completed {} since application has not been started\", operation);\n        return true;\n    } else {\n        return false;\n    }\n}",
        "summary_tokens": [
            "true",
            "iff",
            "the",
            "application",
            "is",
            "still",
            "in",
            "created",
            "and",
            "the",
            "future",
            "was",
            "completed"
        ]
    },
    {
        "id": 2916,
        "code": "public void cleanUpNamedTopology(final String name) {\n    if (getTopologyByName(name).isPresent()) {\n        throw new IllegalStateException(\"Can't clean up local state for an active NamedTopology: \" + name);\n    }\n    stateDirectory.clearLocalStateForNamedTopology(name);\n}",
        "summary_tokens": [
            "do",
            "a",
            "clean",
            "up",
            "of",
            "the",
            "local",
            "state",
            "directory",
            "for",
            "this",
            "named",
            "topology",
            "by",
            "deleting",
            "all",
            "data",
            "with",
            "regard",
            "to",
            "the",
            "streams",
            "config",
            "application",
            "id",
            "config",
            "application",
            "id",
            "in",
            "the",
            "streams",
            "config",
            "state",
            "dir",
            "config",
            "p",
            "may",
            "be",
            "called",
            "while",
            "the",
            "streams",
            "is",
            "in",
            "any",
            "state",
            "but",
            "only",
            "on",
            "a",
            "named",
            "topology",
            "that",
            "has",
            "already",
            "been",
            "removed",
            "via",
            "remove",
            "named",
            "topology",
            "string"
        ]
    },
    {
        "id": 2917,
        "code": "public <T> T store(final NamedTopologyStoreQueryParameters<T> storeQueryParameters) {\n    final String topologyName = storeQueryParameters.topologyName;\n    final String storeName = storeQueryParameters.storeName();\n    verifyTopologyStateStore(topologyName, storeName);\n    return super.store(storeQueryParameters);\n}",
        "summary_tokens": [
            "see",
            "kafka",
            "streams",
            "store",
            "store",
            "query",
            "parameters"
        ]
    },
    {
        "id": 2918,
        "code": "public Collection<StreamsMetadata> streamsMetadataForStore(final String storeName, final String topologyName) {\n    verifyTopologyStateStore(topologyName, storeName);\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadataForStore(storeName, topologyName);\n}",
        "summary_tokens": [
            "see",
            "kafka",
            "streams",
            "streams",
            "metadata",
            "for",
            "store",
            "string"
        ]
    },
    {
        "id": 2919,
        "code": "public Collection<StreamsMetadata> allStreamsClientsMetadataForTopology(final String topologyName) {\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadataForTopology(topologyName);\n}",
        "summary_tokens": [
            "see",
            "kafka",
            "streams",
            "metadata",
            "for",
            "all",
            "streams",
            "clients"
        ]
    },
    {
        "id": 2920,
        "code": "public <K> KeyQueryMetadata queryMetadataForKey(final String storeName,\n                                                final K key,\n                                                final Serializer<K> keySerializer,\n                                                final String topologyName) {\n    verifyTopologyStateStore(topologyName, storeName);\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getKeyQueryMetadataForKey(storeName, key, keySerializer, topologyName);\n}",
        "summary_tokens": [
            "see",
            "kafka",
            "streams",
            "query",
            "metadata",
            "for",
            "key",
            "string",
            "object",
            "serializer"
        ]
    },
    {
        "id": 2921,
        "code": "public Map<String, Map<Integer, LagInfo>> allLocalStorePartitionLagsForTopology(final String topologyName) {\n    if (!getTopologyByName(topologyName).isPresent()) {\n        log.error(\"Can't get local store partition lags since topology {} does not exist in this application\",\n                  topologyName);\n        throw new UnknownTopologyException(\"Can't get local store partition lags\", topologyName);\n    }\n    final List<Task> allTopologyTasks = new ArrayList<>();\n    processStreamThread(thread -> allTopologyTasks.addAll(\n        thread.allTasks().values().stream()\n            .filter(t -> topologyName.equals(t.id().topologyName()))\n            .collect(Collectors.toList())));\n    return allLocalStorePartitionLags(allTopologyTasks);\n}",
        "summary_tokens": [
            "see",
            "kafka",
            "streams",
            "all",
            "local",
            "store",
            "partition",
            "lags"
        ]
    },
    {
        "id": 2922,
        "code": "public String name() {\n    return internalTopologyBuilder.topologyName();\n}",
        "summary_tokens": [
            "the",
            "name",
            "of",
            "this",
            "topology"
        ]
    },
    {
        "id": 2923,
        "code": "public List<String> sourceTopics() {\n    return super.internalTopologyBuilder.fullSourceTopicNames();\n}",
        "summary_tokens": [
            "the",
            "list",
            "of",
            "all",
            "source",
            "topics",
            "this",
            "topology",
            "is",
            "subscribed",
            "to"
        ]
    },
    {
        "id": 2924,
        "code": "public NamedTopologyStoreQueryParameters<T> withPartition(final Integer partition) {\n    return new NamedTopologyStoreQueryParameters<>(this.topologyName(), this.storeName(), this.queryableStoreType(), partition, this.staleStoresEnabled());\n}",
        "summary_tokens": [
            "see",
            "store",
            "query",
            "parameters",
            "with",
            "partition",
            "integer"
        ]
    },
    {
        "id": 2925,
        "code": "public NamedTopologyStoreQueryParameters<T> enableStaleStores() {\n    return new NamedTopologyStoreQueryParameters<>(this.topologyName(), this.storeName(), this.queryableStoreType(), this.partition(), true);\n}",
        "summary_tokens": [
            "see",
            "store",
            "query",
            "parameters",
            "enable",
            "stale",
            "stores"
        ]
    },
    {
        "id": 2926,
        "code": "public final KafkaFuture<Void> all() {\n    if (resetOffsetsFuture == null) {\n        return removeTopologyFuture;\n    } else {\n        return resetOffsetsFuture;\n    }\n}",
        "summary_tokens": [
            "a",
            "kafka",
            "future",
            "that",
            "completes",
            "successfully",
            "when",
            "all",
            "threads",
            "on",
            "this",
            "client",
            "have",
            "removed",
            "the",
            "corresponding",
            "named",
            "topology",
            "and",
            "all",
            "source",
            "topic",
            "offsets",
            "have",
            "been",
            "deleted",
            "if",
            "applicable"
        ]
    },
    {
        "id": 2927,
        "code": "public static <K, V> KeyQuery<K, V> withKey(final K key) {\n    return new KeyQuery<>(key, false);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "query",
            "that",
            "will",
            "retrieve",
            "the",
            "record",
            "identified",
            "by",
            "key",
            "if",
            "it",
            "exists",
            "or",
            "null",
            "otherwise"
        ]
    },
    {
        "id": 2928,
        "code": "public KeyQuery<K, V> skipCache() {\n    return new KeyQuery<>(key, true);\n}",
        "summary_tokens": [
            "specifies",
            "that",
            "the",
            "cache",
            "should",
            "be",
            "skipped",
            "during",
            "query",
            "evaluation"
        ]
    },
    {
        "id": 2929,
        "code": "public K getKey() {\n    return key;\n}",
        "summary_tokens": [
            "the",
            "key",
            "that",
            "was",
            "specified",
            "for",
            "this",
            "query"
        ]
    },
    {
        "id": 2930,
        "code": "public boolean isSkipCache() {\n    return skipCache;\n}",
        "summary_tokens": [
            "the",
            "flag",
            "whether",
            "to",
            "skip",
            "the",
            "cache",
            "or",
            "not",
            "during",
            "query",
            "evaluation"
        ]
    },
    {
        "id": 2931,
        "code": "public static Position emptyPosition() {\n    return new Position(new ConcurrentHashMap<>());\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "empty",
            "position"
        ]
    },
    {
        "id": 2932,
        "code": "public static Position fromMap(final Map<String, ? extends Map<Integer, Long>> map) {\n    return new Position(deepCopy(map));\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "position",
            "and",
            "populate",
            "it",
            "with",
            "a",
            "mapping",
            "of",
            "topic",
            "partition",
            "offset"
        ]
    },
    {
        "id": 2933,
        "code": "public Position withComponent(final String topic, final int partition, final long offset) {\n    position\n        .computeIfAbsent(topic, k -> new ConcurrentHashMap<>())\n        .compute(\n            partition,\n            (integer, prior) -> prior == null || offset > prior ? offset : prior\n        );\n    return this;\n}",
        "summary_tokens": [
            "augment",
            "an",
            "existing",
            "position",
            "by",
            "setting",
            "a",
            "new",
            "offset",
            "for",
            "a",
            "topic",
            "and",
            "partition"
        ]
    },
    {
        "id": 2934,
        "code": "public Position copy() {\n    return new Position(deepCopy(position));\n}",
        "summary_tokens": [
            "create",
            "a",
            "deep",
            "copy",
            "of",
            "the",
            "position"
        ]
    },
    {
        "id": 2935,
        "code": "public Position merge(final Position other) {\n    if (other == null) {\n        return this;\n    } else {\n        for (final Entry<String, ConcurrentHashMap<Integer, Long>> entry : other.position.entrySet()) {\n            final String topic = entry.getKey();\n            final Map<Integer, Long> partitionMap =\n                position.computeIfAbsent(topic, k -> new ConcurrentHashMap<>());\n            for (final Entry<Integer, Long> partitionOffset : entry.getValue().entrySet()) {\n                final Integer partition = partitionOffset.getKey();\n                final Long offset = partitionOffset.getValue();\n                if (!partitionMap.containsKey(partition)\n                    || partitionMap.get(partition) < offset) {\n                    partitionMap.put(partition, offset);\n                }\n            }\n        }\n        return this;\n    }\n}",
        "summary_tokens": [
            "merges",
            "the",
            "provided",
            "position",
            "into",
            "the",
            "current",
            "instance"
        ]
    },
    {
        "id": 2936,
        "code": "public Set<String> getTopics() {\n    return Collections.unmodifiableSet(position.keySet());\n}",
        "summary_tokens": [
            "return",
            "the",
            "topics",
            "that",
            "are",
            "represented",
            "in",
            "this",
            "position"
        ]
    },
    {
        "id": 2937,
        "code": "public Map<Integer, Long> getPartitionPositions(final String topic) {\n    final ConcurrentHashMap<Integer, Long> bound = position.get(topic);\n    return bound == null ? Collections.emptyMap() : Collections.unmodifiableMap(bound);\n}",
        "summary_tokens": [
            "return",
            "the",
            "partition",
            "offset",
            "mapping",
            "for",
            "a",
            "specific",
            "topic"
        ]
    },
    {
        "id": 2938,
        "code": "public static PositionBound unbounded() {\n    return new PositionBound(Position.emptyPosition());\n}",
        "summary_tokens": [
            "creates",
            "a",
            "new",
            "position",
            "bound",
            "representing",
            "no",
            "bound"
        ]
    },
    {
        "id": 2939,
        "code": "public static PositionBound at(final Position position) {\n    return new PositionBound(position);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "new",
            "position",
            "bound",
            "representing",
            "a",
            "specific",
            "position"
        ]
    },
    {
        "id": 2940,
        "code": "public boolean isUnbounded() {\n    return position.isEmpty();\n}",
        "summary_tokens": [
            "returns",
            "true",
            "iff",
            "this",
            "object",
            "specifies",
            "that",
            "there",
            "is",
            "no",
            "position",
            "bound"
        ]
    },
    {
        "id": 2941,
        "code": "public Position position() {\n    return position;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "specific",
            "position",
            "of",
            "this",
            "bound"
        ]
    },
    {
        "id": 2942,
        "code": "static <R> QueryResult<R> forResult(final R result) {\n    return new SucceededQueryResult<>(result);\n}",
        "summary_tokens": [
            "static",
            "factory",
            "method",
            "to",
            "create",
            "a",
            "result",
            "object",
            "for",
            "a",
            "successful",
            "query"
        ]
    },
    {
        "id": 2943,
        "code": "static <R> QueryResult<R> forFailure(\n    final FailureReason failureReason,\n    final String failureMessage) {\n\n    return new FailedQueryResult<>(failureReason, failureMessage);\n}",
        "summary_tokens": [
            "static",
            "factory",
            "method",
            "to",
            "create",
            "a",
            "result",
            "object",
            "for",
            "a",
            "failed",
            "query"
        ]
    },
    {
        "id": 2944,
        "code": "static <R> QueryResult<R> forUnknownQueryType(\n    final Query<R> query,\n    final StateStore store) {\n\n    return forFailure(\n        FailureReason.UNKNOWN_QUERY_TYPE,\n        \"This store (\" + store.getClass() + \") doesn't know how to execute \"\n            + \"the given query (\" + query + \").\" +\n            \" Contact the store maintainer if you need support for a new query type.\");\n}",
        "summary_tokens": [
            "static",
            "factory",
            "method",
            "to",
            "create",
            "a",
            "failed",
            "query",
            "result",
            "object",
            "to",
            "indicate",
            "that",
            "the",
            "store",
            "does",
            "not",
            "know",
            "how",
            "to",
            "handle",
            "the",
            "query"
        ]
    },
    {
        "id": 2945,
        "code": "static <R> QueryResult<R> notUpToBound(\n    final Position currentPosition,\n    final PositionBound positionBound,\n    final Integer partition) {\n\n    if (partition == null) {\n        return new FailedQueryResult<>(\n            FailureReason.NOT_UP_TO_BOUND,\n            \"The store is not initialized yet, so it is not yet up to the bound \"\n                + positionBound\n        );\n    } else {\n        return new FailedQueryResult<>(\n            FailureReason.NOT_UP_TO_BOUND,\n            \"For store partition \" + partition + \", the current position \"\n                + currentPosition + \" is not yet up to the bound \"\n                + positionBound\n        );\n    }\n}",
        "summary_tokens": [
            "static",
            "factory",
            "method",
            "to",
            "create",
            "a",
            "failed",
            "query",
            "result",
            "object",
            "to",
            "indicate",
            "that",
            "the",
            "store",
            "has",
            "not",
            "yet",
            "caught",
            "up",
            "to",
            "the",
            "requested",
            "position",
            "bound"
        ]
    },
    {
        "id": 2946,
        "code": "public static <K, V> RangeQuery<K, V> withRange(final K lower, final K upper) {\n    return new RangeQuery<>(Optional.of(lower), Optional.of(upper));\n}",
        "summary_tokens": [
            "interactive",
            "range",
            "query",
            "using",
            "a",
            "lower",
            "and",
            "upper",
            "bound",
            "to",
            "filter",
            "the",
            "keys",
            "returned"
        ]
    },
    {
        "id": 2947,
        "code": "public static <K, V> RangeQuery<K, V> withUpperBound(final K upper) {\n    return new RangeQuery<>(Optional.empty(), Optional.of(upper));\n}",
        "summary_tokens": [
            "interactive",
            "range",
            "query",
            "using",
            "an",
            "upper",
            "bound",
            "to",
            "filter",
            "the",
            "keys",
            "returned"
        ]
    },
    {
        "id": 2948,
        "code": "public static <K, V> RangeQuery<K, V> withLowerBound(final K lower) {\n    return new RangeQuery<>(Optional.of(lower), Optional.empty());\n}",
        "summary_tokens": [
            "interactive",
            "range",
            "query",
            "using",
            "a",
            "lower",
            "bound",
            "to",
            "filter",
            "the",
            "keys",
            "returned"
        ]
    },
    {
        "id": 2949,
        "code": "public static <K, V> RangeQuery<K, V> withNoBounds() {\n    return new RangeQuery<>(Optional.empty(), Optional.empty());\n}",
        "summary_tokens": [
            "interactive",
            "scan",
            "query",
            "that",
            "returns",
            "all",
            "records",
            "in",
            "the",
            "store"
        ]
    },
    {
        "id": 2950,
        "code": "public Optional<K> getLowerBound() {\n    return lower;\n}",
        "summary_tokens": [
            "the",
            "lower",
            "bound",
            "of",
            "the",
            "query",
            "if",
            "specified"
        ]
    },
    {
        "id": 2951,
        "code": "public Optional<K> getUpperBound() {\n    return upper;\n}",
        "summary_tokens": [
            "the",
            "upper",
            "bound",
            "of",
            "the",
            "query",
            "if",
            "specified"
        ]
    },
    {
        "id": 2952,
        "code": "public static InStore inStore(final String name) {\n    return new InStore(name);\n}",
        "summary_tokens": [
            "specifies",
            "the",
            "name",
            "of",
            "the",
            "store",
            "to",
            "query"
        ]
    },
    {
        "id": 2953,
        "code": "public StateQueryRequest<R> withPositionBound(final PositionBound positionBound) {\n    return new StateQueryRequest<>(\n        storeName,\n        positionBound,\n        partitions,\n        query,\n        executionInfoEnabled,\n        requireActive\n    );\n}",
        "summary_tokens": [
            "bounds",
            "the",
            "position",
            "of",
            "the",
            "state",
            "store",
            "against",
            "its",
            "input",
            "topics"
        ]
    },
    {
        "id": 2954,
        "code": "public StateQueryRequest<R> withAllPartitions() {\n    return new StateQueryRequest<>(\n        storeName,\n        position,\n        Optional.empty(),\n        query,\n        executionInfoEnabled,\n        requireActive\n    );\n}",
        "summary_tokens": [
            "specifies",
            "that",
            "the",
            "query",
            "will",
            "run",
            "against",
            "all",
            "locally",
            "available",
            "partitions"
        ]
    },
    {
        "id": 2955,
        "code": "public StateQueryRequest<R> withPartitions(final Set<Integer> partitions) {\n    return new StateQueryRequest<>(\n        storeName,\n        position,\n        Optional.of(Collections.unmodifiableSet(new HashSet<>(partitions))),\n        query,\n        executionInfoEnabled,\n        requireActive\n    );\n}",
        "summary_tokens": [
            "specifies",
            "a",
            "set",
            "of",
            "partitions",
            "to",
            "run",
            "against"
        ]
    },
    {
        "id": 2956,
        "code": "public StateQueryRequest<R> enableExecutionInfo() {\n    return new StateQueryRequest<>(\n        storeName,\n        position,\n        partitions,\n        query,\n        true,\n        requireActive\n    );\n}",
        "summary_tokens": [
            "requests",
            "for",
            "stores",
            "and",
            "the",
            "streams",
            "runtime",
            "to",
            "record",
            "any",
            "useful",
            "details",
            "about",
            "how",
            "the",
            "query",
            "was",
            "executed"
        ]
    },
    {
        "id": 2957,
        "code": "public StateQueryRequest<R> requireActive() {\n    return new StateQueryRequest<>(\n        storeName,\n        position,\n        partitions,\n        query,\n        executionInfoEnabled,\n        true\n    );\n}",
        "summary_tokens": [
            "specifies",
            "that",
            "this",
            "query",
            "should",
            "only",
            "run",
            "on",
            "partitions",
            "for",
            "which",
            "this",
            "instance",
            "is",
            "the",
            "leader",
            "aka",
            "active"
        ]
    },
    {
        "id": 2958,
        "code": "public String getStoreName() {\n    return storeName;\n}",
        "summary_tokens": [
            "the",
            "name",
            "of",
            "the",
            "store",
            "this",
            "request",
            "is",
            "for"
        ]
    },
    {
        "id": 2959,
        "code": "public PositionBound getPositionBound() {\n    return position;\n}",
        "summary_tokens": [
            "the",
            "bound",
            "that",
            "this",
            "request",
            "places",
            "on",
            "its",
            "query",
            "in",
            "terms",
            "of",
            "the",
            "partitions",
            "positions",
            "against",
            "its",
            "inputs"
        ]
    },
    {
        "id": 2960,
        "code": "public Query<R> getQuery() {\n    return query;\n}",
        "summary_tokens": [
            "the",
            "query",
            "this",
            "request",
            "is",
            "meant",
            "to",
            "run"
        ]
    },
    {
        "id": 2961,
        "code": "public boolean isAllPartitions() {\n    return !partitions.isPresent();\n}",
        "summary_tokens": [
            "whether",
            "this",
            "request",
            "should",
            "fetch",
            "from",
            "all",
            "locally",
            "available",
            "partitions"
        ]
    },
    {
        "id": 2962,
        "code": "public Set<Integer> getPartitions() {\n    if (!partitions.isPresent()) {\n        throw new IllegalStateException(\n            \"Cannot list partitions of an 'all partitions' request\");\n    } else {\n        return partitions.get();\n    }\n}",
        "summary_tokens": [
            "if",
            "the",
            "request",
            "is",
            "for",
            "specific",
            "partitions",
            "return",
            "the",
            "set",
            "of",
            "partitions",
            "to",
            "query"
        ]
    },
    {
        "id": 2963,
        "code": "public boolean executionInfoEnabled() {\n    return executionInfoEnabled;\n}",
        "summary_tokens": [
            "whether",
            "the",
            "request",
            "includes",
            "detailed",
            "execution",
            "information"
        ]
    },
    {
        "id": 2964,
        "code": "public boolean isRequireActive() {\n    return requireActive;\n}",
        "summary_tokens": [
            "whether",
            "this",
            "request",
            "requires",
            "the",
            "query",
            "to",
            "execute",
            "only",
            "on",
            "active",
            "partitions"
        ]
    },
    {
        "id": 2965,
        "code": "public void setGlobalResult(final QueryResult<R> r) {\n    this.globalResult = r;\n}",
        "summary_tokens": [
            "set",
            "the",
            "result",
            "for",
            "a",
            "global",
            "store",
            "query"
        ]
    },
    {
        "id": 2966,
        "code": "public void addResult(final int partition, final QueryResult<R> r) {\n    partitionResults.put(partition, r);\n}",
        "summary_tokens": [
            "set",
            "the",
            "result",
            "for",
            "a",
            "partitioned",
            "store",
            "query"
        ]
    },
    {
        "id": 2967,
        "code": "public Map<Integer, QueryResult<R>> getPartitionResults() {\n    return partitionResults;\n}",
        "summary_tokens": [
            "the",
            "query",
            "s",
            "result",
            "for",
            "each",
            "partition",
            "that",
            "executed",
            "the",
            "query"
        ]
    },
    {
        "id": 2968,
        "code": "public QueryResult<R> getOnlyPartitionResult() {\n    final List<QueryResult<R>> nonempty =\n        partitionResults\n            .values()\n            .stream()\n            .filter(r -> r.getResult() != null)\n            .collect(Collectors.toList());\n\n    if (nonempty.size() != 1) {\n        throw new IllegalArgumentException(\n            \"The query did not return exactly one partition result: \" + partitionResults\n        );\n    } else {\n        return nonempty.get(0);\n    }\n}",
        "summary_tokens": [
            "for",
            "queries",
            "that",
            "are",
            "expected",
            "to",
            "match",
            "records",
            "in",
            "only",
            "one",
            "partition",
            "returns",
            "the",
            "result"
        ]
    },
    {
        "id": 2969,
        "code": "public QueryResult<R> getGlobalResult() {\n    return globalResult;\n}",
        "summary_tokens": [
            "the",
            "query",
            "s",
            "result",
            "for",
            "global",
            "store",
            "queries"
        ]
    },
    {
        "id": 2970,
        "code": "public Position getPosition() {\n    if (globalResult != null) {\n        return globalResult.getPosition();\n    } else {\n        final Position position = Position.emptyPosition();\n        for (final QueryResult<R> r : partitionResults.values()) {\n            position.merge(r.getPosition());\n        }\n        return position;\n    }\n}",
        "summary_tokens": [
            "the",
            "position",
            "of",
            "the",
            "state",
            "store",
            "at",
            "the",
            "moment",
            "it",
            "executed",
            "the",
            "query"
        ]
    },
    {
        "id": 2971,
        "code": "public void addExecutionInfo(final String message) {\n    executionInfo.add(message);\n}",
        "summary_tokens": [
            "used",
            "by",
            "stores",
            "to",
            "add",
            "detailed",
            "execution",
            "information",
            "if",
            "requested",
            "during",
            "query",
            "execution"
        ]
    },
    {
        "id": 2972,
        "code": "public void setPosition(final Position position) {\n    this.position = position;\n}",
        "summary_tokens": [
            "used",
            "by",
            "stores",
            "to",
            "report",
            "what",
            "exact",
            "position",
            "in",
            "the",
            "store",
            "s",
            "history",
            "it",
            "was",
            "at",
            "when",
            "it",
            "executed",
            "the",
            "query"
        ]
    },
    {
        "id": 2973,
        "code": "public List<String> getExecutionInfo() {\n    return executionInfo;\n}",
        "summary_tokens": [
            "if",
            "detailed",
            "execution",
            "information",
            "was",
            "requested",
            "in",
            "state",
            "query",
            "request",
            "enable",
            "execution",
            "info",
            "this",
            "method",
            "returned",
            "the",
            "execution",
            "details",
            "for",
            "this",
            "partition",
            "s",
            "result"
        ]
    },
    {
        "id": 2974,
        "code": "public Position getPosition() {\n    return position;\n}",
        "summary_tokens": [
            "this",
            "state",
            "partition",
            "s",
            "exact",
            "position",
            "in",
            "its",
            "history",
            "when",
            "this",
            "query",
            "was",
            "executed"
        ]
    },
    {
        "id": 2975,
        "code": "public boolean isSuccess() {\n    return false;\n}",
        "summary_tokens": [
            "true",
            "iff",
            "the",
            "query",
            "was",
            "successfully",
            "executed"
        ]
    },
    {
        "id": 2976,
        "code": "public boolean isFailure() {\n    return true;\n}",
        "summary_tokens": [
            "true",
            "iff",
            "the",
            "query",
            "execution",
            "failed"
        ]
    },
    {
        "id": 2977,
        "code": "public FailureReason getFailureReason() {\n    return failureReason;\n}",
        "summary_tokens": [
            "if",
            "this",
            "partition",
            "failed",
            "to",
            "execute",
            "the",
            "query",
            "returns",
            "the",
            "reason"
        ]
    },
    {
        "id": 2978,
        "code": "public String getFailureMessage() {\n    return failure;\n}",
        "summary_tokens": [
            "if",
            "this",
            "partition",
            "failed",
            "to",
            "execute",
            "the",
            "query",
            "returns",
            "the",
            "failure",
            "message"
        ]
    },
    {
        "id": 2979,
        "code": "public R getResult() {\n    throw new IllegalArgumentException(\n        \"Cannot get result for failed query. Failure is \" + failureReason.name() + \": \"\n            + failure);\n}",
        "summary_tokens": [
            "returns",
            "the",
            "result",
            "of",
            "executing",
            "the",
            "query",
            "on",
            "one",
            "partition"
        ]
    },
    {
        "id": 2980,
        "code": "public static <R> QueryResult<R> copyAndSubstituteDeserializedResult(\n    final QueryResult<?> rawResult,\n    final R deserializedResult) {\n\n    if (rawResult.isFailure()) {\n        throw new IllegalArgumentException(\n            \"Callers must avoid calling this method on a failed result.\"\n        );\n    } else {\n        return new SucceededQueryResult<>(\n            deserializedResult,\n            rawResult.getExecutionInfo(),\n            rawResult.getPosition()\n        );\n    }\n}",
        "summary_tokens": [
            "creates",
            "a",
            "new",
            "query",
            "result",
            "preserving",
            "the",
            "execution",
            "info",
            "and",
            "position",
            "of",
            "the",
            "provided",
            "result"
        ]
    },
    {
        "id": 2981,
        "code": "public boolean isSuccess() {\n    return true;\n}",
        "summary_tokens": [
            "true",
            "iff",
            "the",
            "query",
            "was",
            "successfully",
            "executed"
        ]
    },
    {
        "id": 2982,
        "code": "public boolean isFailure() {\n    return false;\n}",
        "summary_tokens": [
            "true",
            "iff",
            "the",
            "query",
            "execution",
            "failed"
        ]
    },
    {
        "id": 2983,
        "code": "public FailureReason getFailureReason() {\n    throw new IllegalArgumentException(\n        \"Cannot get failure reason because this query did not fail.\"\n    );\n}",
        "summary_tokens": [
            "if",
            "this",
            "partition",
            "failed",
            "to",
            "execute",
            "the",
            "query",
            "returns",
            "the",
            "reason"
        ]
    },
    {
        "id": 2984,
        "code": "public String getFailureMessage() {\n    throw new IllegalArgumentException(\n        \"Cannot get failure message because this query did not fail.\"\n    );\n}",
        "summary_tokens": [
            "if",
            "this",
            "partition",
            "failed",
            "to",
            "execute",
            "the",
            "query",
            "returns",
            "the",
            "failure",
            "message"
        ]
    },
    {
        "id": 2985,
        "code": "public R getResult() {\n    return result;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "result",
            "of",
            "executing",
            "the",
            "query",
            "on",
            "one",
            "partition"
        ]
    },
    {
        "id": 2986,
        "code": "public static HostInfo buildFromEndpoint(final String endPoint) {\n    if (Utils.isBlank(endPoint)) {\n        return null;\n    }\n\n    final String host = getHost(endPoint);\n    final Integer port = getPort(endPoint);\n\n    if (host == null || port == null) {\n        throw new ConfigException(\n            String.format(\"Error parsing host address %s. Expected format host:port.\", endPoint)\n        );\n    }\n    return new HostInfo(host, port);\n}",
        "summary_tokens": [
            "config",
            "exception",
            "if",
            "the",
            "host",
            "or",
            "port",
            "cannot",
            "be",
            "parsed",
            "from",
            "the",
            "given",
            "endpoint",
            "string",
            "a",
            "new",
            "host",
            "info",
            "or",
            "null",
            "if",
            "end",
            "point",
            "is",
            "null",
            "or",
            "has",
            "no",
            "characters"
        ]
    },
    {
        "id": 2987,
        "code": "public static HostInfo unavailable() {\n    return new HostInfo(\"unavailable\", -1);\n}",
        "summary_tokens": [
            "a",
            "sentinel",
            "for",
            "cases",
            "where",
            "the",
            "host",
            "metadata",
            "is",
            "currently",
            "unavailable",
            "eg",
            "during",
            "rebalance",
            "operations"
        ]
    },
    {
        "id": 2988,
        "code": "public static <K, V> QueryableStoreType<ReadOnlyKeyValueStore<K, V>> keyValueStore() {\n    return new KeyValueStoreType<>();\n}",
        "summary_tokens": [
            "a",
            "queryable",
            "store",
            "type",
            "that",
            "accepts",
            "read",
            "only",
            "key",
            "value",
            "store"
        ]
    },
    {
        "id": 2989,
        "code": "public static <K, V> QueryableStoreType<ReadOnlyKeyValueStore<K, ValueAndTimestamp<V>>> timestampedKeyValueStore() {\n    return new TimestampedKeyValueStoreType<>();\n}",
        "summary_tokens": [
            "a",
            "queryable",
            "store",
            "type",
            "that",
            "accepts",
            "read",
            "only",
            "key",
            "value",
            "store",
            "read",
            "only",
            "key",
            "value",
            "store",
            "k",
            "value",
            "and",
            "timestamp",
            "v"
        ]
    },
    {
        "id": 2990,
        "code": "public static <K, V> QueryableStoreType<ReadOnlyWindowStore<K, V>> windowStore() {\n    return new WindowStoreType<>();\n}",
        "summary_tokens": [
            "a",
            "queryable",
            "store",
            "type",
            "that",
            "accepts",
            "read",
            "only",
            "window",
            "store"
        ]
    },
    {
        "id": 2991,
        "code": "public static <K, V> QueryableStoreType<ReadOnlyWindowStore<K, ValueAndTimestamp<V>>> timestampedWindowStore() {\n    return new TimestampedWindowStoreType<>();\n}",
        "summary_tokens": [
            "a",
            "queryable",
            "store",
            "type",
            "that",
            "accepts",
            "read",
            "only",
            "window",
            "store",
            "read",
            "only",
            "window",
            "store",
            "k",
            "value",
            "and",
            "timestamp",
            "v"
        ]
    },
    {
        "id": 2992,
        "code": "public static <K, V> QueryableStoreType<ReadOnlySessionStore<K, V>> sessionStore() {\n    return new SessionStoreType<>();\n}",
        "summary_tokens": [
            "a",
            "queryable",
            "store",
            "type",
            "that",
            "accepts",
            "read",
            "only",
            "session",
            "store"
        ]
    },
    {
        "id": 2993,
        "code": "default KeyValueIterator<K, V> reverseRange(K from, K to) {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "get",
            "a",
            "reverse",
            "iterator",
            "over",
            "a",
            "given",
            "range",
            "of",
            "keys"
        ]
    },
    {
        "id": 2994,
        "code": "default KeyValueIterator<K, V> reverseAll() {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "return",
            "a",
            "reverse",
            "iterator",
            "over",
            "all",
            "keys",
            "in",
            "this",
            "store"
        ]
    },
    {
        "id": 2995,
        "code": "default <PS extends Serializer<P>, P> KeyValueIterator<K, V> prefixScan(P prefix, PS prefixKeySerializer) {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "return",
            "an",
            "iterator",
            "over",
            "all",
            "keys",
            "with",
            "the",
            "specified",
            "prefix"
        ]
    },
    {
        "id": 2996,
        "code": "default KeyValueIterator<Windowed<K>, AGG> findSessions(final K keyFrom,\n                                                        final K keyTo,\n                                                        final Instant earliestSessionEndTime,\n                                                        final Instant latestSessionStartTime) {\n    throw new UnsupportedOperationException(\n        \"This API is not supported by this implementation of ReadOnlySessionStore.\");\n}",
        "summary_tokens": [
            "fetch",
            "any",
            "sessions",
            "in",
            "the",
            "given",
            "range",
            "of",
            "keys",
            "and",
            "the",
            "sessions",
            "end",
            "is",
            "ge",
            "earliest",
            "session",
            "end",
            "time",
            "and",
            "the",
            "sessions",
            "start",
            "is",
            "le",
            "latest",
            "session",
            "start",
            "time",
            "iterating",
            "from",
            "earliest",
            "to",
            "latest"
        ]
    },
    {
        "id": 2997,
        "code": "default KeyValueIterator<Windowed<K>, AGG> backwardFindSessions(final K keyFrom,\n                                                                final K keyTo,\n                                                                final Instant earliestSessionEndTime,\n                                                                final Instant latestSessionStartTime) {\n    throw new UnsupportedOperationException(\n        \"This API is not supported by this implementation of ReadOnlySessionStore.\");\n}",
        "summary_tokens": [
            "fetch",
            "any",
            "sessions",
            "in",
            "the",
            "given",
            "range",
            "of",
            "keys",
            "and",
            "the",
            "sessions",
            "end",
            "is",
            "ge",
            "earliest",
            "session",
            "end",
            "time",
            "and",
            "the",
            "sessions",
            "start",
            "is",
            "le",
            "latest",
            "session",
            "start",
            "time",
            "iterating",
            "from",
            "latest",
            "to",
            "earliest"
        ]
    },
    {
        "id": 2998,
        "code": "default AGG fetchSession(final K key,\n                         final Instant sessionStartTime,\n                         final Instant sessionEndTime) {\n    throw new UnsupportedOperationException(\n        \"This API is not supported by this implementation of ReadOnlySessionStore.\");\n}",
        "summary_tokens": [
            "get",
            "the",
            "value",
            "of",
            "key",
            "from",
            "a",
            "single",
            "session"
        ]
    },
    {
        "id": 2999,
        "code": "default KeyValueIterator<Windowed<K>, AGG> backwardFetch(final K keyFrom, final K keyTo) {\n    throw new UnsupportedOperationException(\n        \"This API is not supported by this implementation of ReadOnlySessionStore.\");\n}",
        "summary_tokens": [
            "retrieve",
            "all",
            "aggregated",
            "sessions",
            "for",
            "the",
            "given",
            "range",
            "of",
            "keys"
        ]
    },
    {
        "id": 3000,
        "code": "default KeyValueIterator<Windowed<K>, V> backwardFetch(K keyFrom, K keyTo, Instant timeFrom, Instant timeTo)\n    throws IllegalArgumentException  {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "get",
            "all",
            "the",
            "key",
            "value",
            "pairs",
            "in",
            "the",
            "given",
            "key",
            "range",
            "and",
            "time",
            "range",
            "from",
            "all",
            "the",
            "existing",
            "windows",
            "in",
            "backward",
            "order",
            "with",
            "respect",
            "to",
            "time",
            "from",
            "end",
            "to",
            "beginning",
            "of",
            "time"
        ]
    },
    {
        "id": 3001,
        "code": "default KeyValueIterator<Windowed<K>, V> backwardAll() {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "gets",
            "all",
            "the",
            "key",
            "value",
            "pairs",
            "in",
            "the",
            "existing",
            "windows",
            "in",
            "backward",
            "order",
            "with",
            "respect",
            "to",
            "time",
            "from",
            "end",
            "to",
            "beginning",
            "of",
            "time"
        ]
    },
    {
        "id": 3002,
        "code": "default KeyValueIterator<Windowed<K>, V> backwardFetchAll(Instant timeFrom, Instant timeTo) throws IllegalArgumentException  {\n    throw new UnsupportedOperationException();\n}",
        "summary_tokens": [
            "gets",
            "all",
            "the",
            "key",
            "value",
            "pairs",
            "that",
            "belong",
            "to",
            "the",
            "windows",
            "within",
            "in",
            "the",
            "given",
            "time",
            "range",
            "in",
            "backward",
            "order",
            "with",
            "respect",
            "to",
            "time",
            "from",
            "end",
            "to",
            "beginning",
            "of",
            "time"
        ]
    },
    {
        "id": 3003,
        "code": "default KeyValueIterator<Windowed<K>, AGG> findSessions(final long earliestSessionEndTime,\n                                                        final long latestSessionEndTime) {\n    throw new UnsupportedOperationException(\n            \"This API is not supported by this implementation of SessionStore.\");\n}",
        "summary_tokens": [
            "return",
            "all",
            "the",
            "session",
            "window",
            "entries",
            "that",
            "ends",
            "between",
            "the",
            "specified",
            "range",
            "both",
            "ends",
            "are",
            "inclusive"
        ]
    },
    {
        "id": 3004,
        "code": "public static <K, V> StateSerdes<K, V> withBuiltinTypes(\n    final String topic,\n    final Class<K> keyClass,\n    final Class<V> valueClass) {\n    return new StateSerdes<>(topic, Serdes.serdeFrom(keyClass), Serdes.serdeFrom(valueClass));\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "instance",
            "of",
            "state",
            "serdes",
            "for",
            "the",
            "given",
            "state",
            "name",
            "and",
            "key",
            "value",
            "type",
            "classes"
        ]
    },
    {
        "id": 3005,
        "code": "public Serde<K> keySerde() {\n    return keySerde;\n}",
        "summary_tokens": [
            "return",
            "the",
            "key",
            "serde"
        ]
    },
    {
        "id": 3006,
        "code": "public Serde<V> valueSerde() {\n    return valueSerde;\n}",
        "summary_tokens": [
            "return",
            "the",
            "value",
            "serde"
        ]
    },
    {
        "id": 3007,
        "code": "public Deserializer<K> keyDeserializer() {\n    return keySerde.deserializer();\n}",
        "summary_tokens": [
            "return",
            "the",
            "key",
            "deserializer"
        ]
    },
    {
        "id": 3008,
        "code": "public Serializer<K> keySerializer() {\n    return keySerde.serializer();\n}",
        "summary_tokens": [
            "return",
            "the",
            "key",
            "serializer"
        ]
    },
    {
        "id": 3009,
        "code": "public Deserializer<V> valueDeserializer() {\n    return valueSerde.deserializer();\n}",
        "summary_tokens": [
            "return",
            "the",
            "value",
            "deserializer"
        ]
    },
    {
        "id": 3010,
        "code": "public Serializer<V> valueSerializer() {\n    return valueSerde.serializer();\n}",
        "summary_tokens": [
            "return",
            "the",
            "value",
            "serializer"
        ]
    },
    {
        "id": 3011,
        "code": "public K keyFrom(final byte[] rawKey) {\n    return keySerde.deserializer().deserialize(topic, rawKey);\n}",
        "summary_tokens": [
            "deserialize",
            "the",
            "key",
            "from",
            "raw",
            "bytes"
        ]
    },
    {
        "id": 3012,
        "code": "public V valueFrom(final byte[] rawValue) {\n    return valueSerde.deserializer().deserialize(topic, rawValue);\n}",
        "summary_tokens": [
            "deserialize",
            "the",
            "value",
            "from",
            "raw",
            "bytes"
        ]
    },
    {
        "id": 3013,
        "code": "public byte[] rawKey(final K key) {\n    try {\n        return keySerde.serializer().serialize(topic, key);\n    } catch (final ClassCastException e) {\n        final String keyClass = key == null ? \"unknown because key is null\" : key.getClass().getName();\n        throw new StreamsException(\n                String.format(\"A serializer (%s) is not compatible to the actual key type \" +\n                                \"(key type: %s). Change the default Serdes in StreamConfig or \" +\n                                \"provide correct Serdes via method parameters.\",\n                        keySerializer().getClass().getName(),\n                        keyClass),\n                e);\n    }\n}",
        "summary_tokens": [
            "serialize",
            "the",
            "given",
            "key"
        ]
    },
    {
        "id": 3014,
        "code": "public byte[] rawValue(final V value) {\n    try {\n        return valueSerde.serializer().serialize(topic, value);\n    } catch (final ClassCastException e) {\n        final String valueClass;\n        final Class<? extends Serializer> serializerClass;\n        if (valueSerializer() instanceof ValueAndTimestampSerializer) {\n            serializerClass = ((ValueAndTimestampSerializer) valueSerializer()).valueSerializer.getClass();\n            valueClass = value == null ? \"unknown because value is null\" : ((ValueAndTimestamp) value).value().getClass().getName();\n        } else {\n            serializerClass = valueSerializer().getClass();\n            valueClass = value == null ? \"unknown because value is null\" : value.getClass().getName();\n        }\n        throw new StreamsException(\n                String.format(\"A serializer (%s) is not compatible to the actual value type \" +\n                                \"(value type: %s). Change the default Serdes in StreamConfig or \" +\n                                \"provide correct Serdes via method parameters.\",\n                        serializerClass.getName(),\n                        valueClass),\n                e);\n    }\n}",
        "summary_tokens": [
            "serialize",
            "the",
            "given",
            "value"
        ]
    },
    {
        "id": 3015,
        "code": "public static KeyValueBytesStoreSupplier persistentKeyValueStore(final String name) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    return new RocksDbKeyValueBytesStoreSupplier(name, false);\n}",
        "summary_tokens": [
            "create",
            "a",
            "persistent",
            "key",
            "value",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3016,
        "code": "public static KeyValueBytesStoreSupplier persistentTimestampedKeyValueStore(final String name) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    return new RocksDbKeyValueBytesStoreSupplier(name, true);\n}",
        "summary_tokens": [
            "create",
            "a",
            "persistent",
            "key",
            "value",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3017,
        "code": "public static KeyValueBytesStoreSupplier inMemoryKeyValueStore(final String name) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    return new InMemoryKeyValueBytesStoreSupplier(name);\n}",
        "summary_tokens": [
            "create",
            "an",
            "in",
            "memory",
            "key",
            "value",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3018,
        "code": "public static KeyValueBytesStoreSupplier lruMap(final String name, final int maxCacheSize) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    if (maxCacheSize < 0) {\n        throw new IllegalArgumentException(\"maxCacheSize cannot be negative\");\n    }\n    return new KeyValueBytesStoreSupplier() {\n        @Override\n        public String name() {\n            return name;\n        }\n\n        @Override\n        public KeyValueStore<Bytes, byte[]> get() {\n            return new MemoryNavigableLRUCache(name, maxCacheSize);\n        }\n\n        @Override\n        public String metricsScope() {\n            return \"in-memory-lru\";\n        }\n    };\n}",
        "summary_tokens": [
            "create",
            "a",
            "lru",
            "map",
            "key",
            "value",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3019,
        "code": "public static WindowBytesStoreSupplier persistentWindowStore(final String name,\n                                                             final Duration retentionPeriod,\n                                                             final Duration windowSize,\n                                                             final boolean retainDuplicates) throws IllegalArgumentException {\n    return persistentWindowStore(name, retentionPeriod, windowSize, retainDuplicates, false);\n}",
        "summary_tokens": [
            "create",
            "a",
            "persistent",
            "window",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3020,
        "code": "public static WindowBytesStoreSupplier persistentTimestampedWindowStore(final String name,\n                                                                        final Duration retentionPeriod,\n                                                                        final Duration windowSize,\n                                                                        final boolean retainDuplicates) throws IllegalArgumentException {\n    return persistentWindowStore(name, retentionPeriod, windowSize, retainDuplicates, true);\n}",
        "summary_tokens": [
            "create",
            "a",
            "persistent",
            "window",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3021,
        "code": "public static WindowBytesStoreSupplier inMemoryWindowStore(final String name,\n                                                           final Duration retentionPeriod,\n                                                           final Duration windowSize,\n                                                           final boolean retainDuplicates) throws IllegalArgumentException {\n    Objects.requireNonNull(name, \"name cannot be null\");\n\n    final String repartitionPeriodErrorMessagePrefix = prepareMillisCheckFailMsgPrefix(retentionPeriod, \"retentionPeriod\");\n    final long retentionMs = validateMillisecondDuration(retentionPeriod, repartitionPeriodErrorMessagePrefix);\n    if (retentionMs < 0L) {\n        throw new IllegalArgumentException(\"retentionPeriod cannot be negative\");\n    }\n\n    final String windowSizeErrorMessagePrefix = prepareMillisCheckFailMsgPrefix(windowSize, \"windowSize\");\n    final long windowSizeMs = validateMillisecondDuration(windowSize, windowSizeErrorMessagePrefix);\n    if (windowSizeMs < 0L) {\n        throw new IllegalArgumentException(\"windowSize cannot be negative\");\n    }\n\n    if (windowSizeMs > retentionMs) {\n        throw new IllegalArgumentException(\"The retention period of the window store \"\n            + name + \" must be no smaller than its window size. Got size=[\"\n            + windowSize + \"], retention=[\" + retentionPeriod + \"]\");\n    }\n\n    return new InMemoryWindowBytesStoreSupplier(name, retentionMs, windowSizeMs, retainDuplicates);\n}",
        "summary_tokens": [
            "create",
            "an",
            "in",
            "memory",
            "window",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3022,
        "code": "public static SessionBytesStoreSupplier persistentSessionStore(final String name,\n                                                               final Duration retentionPeriod) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(retentionPeriod, \"retentionPeriod\");\n    final long retentionPeriodMs = validateMillisecondDuration(retentionPeriod, msgPrefix);\n    if (retentionPeriodMs < 0) {\n        throw new IllegalArgumentException(\"retentionPeriod cannot be negative\");\n    }\n    return new RocksDbSessionBytesStoreSupplier(name, retentionPeriodMs);\n}",
        "summary_tokens": [
            "create",
            "a",
            "persistent",
            "session",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3023,
        "code": "public static SessionBytesStoreSupplier inMemorySessionStore(final String name, final Duration retentionPeriod) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(retentionPeriod, \"retentionPeriod\");\n    final long retentionPeriodMs = validateMillisecondDuration(retentionPeriod, msgPrefix);\n    if (retentionPeriodMs < 0) {\n        throw new IllegalArgumentException(\"retentionPeriod cannot be negative\");\n    }\n    return new InMemorySessionBytesStoreSupplier(name, retentionPeriodMs);\n}",
        "summary_tokens": [
            "create",
            "an",
            "in",
            "memory",
            "session",
            "bytes",
            "store",
            "supplier"
        ]
    },
    {
        "id": 3024,
        "code": "public static <K, V> StoreBuilder<KeyValueStore<K, V>> keyValueStoreBuilder(final KeyValueBytesStoreSupplier supplier,\n                                                                            final Serde<K> keySerde,\n                                                                            final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new KeyValueStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "store",
            "builder",
            "that",
            "can",
            "be",
            "used",
            "to",
            "build",
            "a",
            "key",
            "value",
            "store"
        ]
    },
    {
        "id": 3025,
        "code": "public static <K, V> StoreBuilder<TimestampedKeyValueStore<K, V>> timestampedKeyValueStoreBuilder(final KeyValueBytesStoreSupplier supplier,\n                                                                                                  final Serde<K> keySerde,\n                                                                                                  final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new TimestampedKeyValueStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "store",
            "builder",
            "that",
            "can",
            "be",
            "used",
            "to",
            "build",
            "a",
            "timestamped",
            "key",
            "value",
            "store"
        ]
    },
    {
        "id": 3026,
        "code": "public static <K, V> StoreBuilder<WindowStore<K, V>> windowStoreBuilder(final WindowBytesStoreSupplier supplier,\n                                                                        final Serde<K> keySerde,\n                                                                        final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new WindowStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "store",
            "builder",
            "that",
            "can",
            "be",
            "used",
            "to",
            "build",
            "a",
            "window",
            "store"
        ]
    },
    {
        "id": 3027,
        "code": "public static <K, V> StoreBuilder<TimestampedWindowStore<K, V>> timestampedWindowStoreBuilder(final WindowBytesStoreSupplier supplier,\n                                                                                              final Serde<K> keySerde,\n                                                                                              final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new TimestampedWindowStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "store",
            "builder",
            "that",
            "can",
            "be",
            "used",
            "to",
            "build",
            "a",
            "timestamped",
            "window",
            "store"
        ]
    },
    {
        "id": 3028,
        "code": "public static <K, V> StoreBuilder<SessionStore<K, V>> sessionStoreBuilder(final SessionBytesStoreSupplier supplier,\n                                                                          final Serde<K> keySerde,\n                                                                          final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new SessionStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "store",
            "builder",
            "that",
            "can",
            "be",
            "used",
            "to",
            "build",
            "a",
            "session",
            "store"
        ]
    },
    {
        "id": 3029,
        "code": "public HostInfo hostInfo() {\n    return hostInfo;\n}",
        "summary_tokens": [
            "the",
            "value",
            "of",
            "org"
        ]
    },
    {
        "id": 3030,
        "code": "public Set<String> stateStoreNames() {\n    return Collections.unmodifiableSet(stateStoreNames);\n}",
        "summary_tokens": [
            "state",
            "stores",
            "owned",
            "by",
            "the",
            "instance",
            "as",
            "an",
            "active",
            "replica"
        ]
    },
    {
        "id": 3031,
        "code": "public Set<TopicPartition> topicPartitions() {\n    return Collections.unmodifiableSet(topicPartitions);\n}",
        "summary_tokens": [
            "topic",
            "partitions",
            "consumed",
            "by",
            "the",
            "instance",
            "as",
            "an",
            "active",
            "replica"
        ]
    },
    {
        "id": 3032,
        "code": "public Set<TopicPartition> standbyTopicPartitions() {\n    return Collections.unmodifiableSet(standbyTopicPartitions);\n}",
        "summary_tokens": [
            "source",
            "topic",
            "partitions",
            "for",
            "which",
            "the",
            "instance",
            "acts",
            "as",
            "standby"
        ]
    },
    {
        "id": 3033,
        "code": "public Set<String> standbyStateStoreNames() {\n    return Collections.unmodifiableSet(standbyStateStoreNames);\n}",
        "summary_tokens": [
            "state",
            "stores",
            "owned",
            "by",
            "the",
            "instance",
            "as",
            "a",
            "standby",
            "replica"
        ]
    },
    {
        "id": 3034,
        "code": "public static <V> ValueAndTimestamp<V> make(final V value,\n                                            final long timestamp) {\n    return value == null ? null : new ValueAndTimestamp<>(value, timestamp);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "value",
            "and",
            "timestamp",
            "instance",
            "if",
            "the",
            "provided",
            "value",
            "is",
            "not",
            "null"
        ]
    },
    {
        "id": 3035,
        "code": "public static <V> V getValueOrNull(final ValueAndTimestamp<V> valueAndTimestamp) {\n    return valueAndTimestamp == null ? null : valueAndTimestamp.value();\n}",
        "summary_tokens": [
            "return",
            "the",
            "wrapped",
            "value",
            "of",
            "the",
            "given",
            "value",
            "and",
            "timestamp",
            "parameter",
            "if",
            "the",
            "parameter",
            "is",
            "not",
            "null"
        ]
    },
    {
        "id": 3036,
        "code": "public static <V1, V2> LeftOrRightValue<V1, V2> makeLeftValue(final V1 leftValue) {\n    return new LeftOrRightValue<>(leftValue, null);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "left",
            "or",
            "right",
            "value",
            "instance",
            "with",
            "the",
            "v",
            "0",
            "value",
            "as",
            "left",
            "value",
            "and",
            "v",
            "0",
            "value",
            "as",
            "null"
        ]
    },
    {
        "id": 3037,
        "code": "public static <V1, V2> LeftOrRightValue<V1, V2> makeRightValue(final V2 rightValue) {\n    return new LeftOrRightValue<>(null, rightValue);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "left",
            "or",
            "right",
            "value",
            "instance",
            "with",
            "the",
            "v",
            "0",
            "value",
            "as",
            "right",
            "value",
            "and",
            "v",
            "0",
            "value",
            "as",
            "null"
        ]
    },
    {
        "id": 3038,
        "code": "public static <V> LeftOrRightValue make(final boolean isLeftSide, final V value) {\n    Objects.requireNonNull(value, \"value is null\");\n    return isLeftSide\n        ? LeftOrRightValue.makeLeftValue(value)\n        : LeftOrRightValue.makeRightValue(value);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "left",
            "or",
            "right",
            "value",
            "instance",
            "with",
            "the",
            "v",
            "value",
            "as",
            "left",
            "value",
            "if",
            "is",
            "left",
            "side",
            "is",
            "true",
            "otherwise",
            "right",
            "value",
            "if",
            "is",
            "left",
            "side",
            "is",
            "false"
        ]
    },
    {
        "id": 3039,
        "code": "public KeyValueIterator<Bytes, byte[]> range(final Bytes from, final Bytes to) {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support range() function.\");\n}",
        "summary_tokens": [
            "unsupported",
            "operation",
            "exception",
            "at",
            "every",
            "invocation"
        ]
    },
    {
        "id": 3040,
        "code": "public KeyValueIterator<Bytes, byte[]> reverseRange(final Bytes from, final Bytes to) {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support reverseRange() function.\");\n}",
        "summary_tokens": [
            "unsupported",
            "operation",
            "exception",
            "at",
            "every",
            "invocation"
        ]
    },
    {
        "id": 3041,
        "code": "public KeyValueIterator<Bytes, byte[]> all() {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support all() function.\");\n}",
        "summary_tokens": [
            "unsupported",
            "operation",
            "exception",
            "at",
            "every",
            "invocation"
        ]
    },
    {
        "id": 3042,
        "code": "public KeyValueIterator<Bytes, byte[]> reverseAll() {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support reverseAll() function.\");\n}",
        "summary_tokens": [
            "unsupported",
            "operation",
            "exception",
            "at",
            "every",
            "invocation"
        ]
    },
    {
        "id": 3043,
        "code": "public <PS extends Serializer<P>, P> KeyValueIterator<Bytes, byte[]> prefixScan(final P prefix,\n                                                                                final PS prefixKeySerializer) {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support prefixScan() function.\");\n}",
        "summary_tokens": [
            "unsupported",
            "operation",
            "exception",
            "at",
            "every",
            "invocation"
        ]
    },
    {
        "id": 3044,
        "code": "public static int hash32(byte[] data, int offset, int length, int seed) {\n    int hash = seed;\n    final int nblocks = length >> 2;\n\n        \n    for (int i = 0; i < nblocks; i++) {\n        int i_4 = i << 2;\n        int k = (data[offset + i_4] & 0xff)\n                | ((data[offset + i_4 + 1] & 0xff) << 8)\n                | ((data[offset + i_4 + 2] & 0xff) << 16)\n                | ((data[offset + i_4 + 3] & 0xff) << 24);\n\n        hash = mix32(k, hash);\n    }\n\n        \n    int idx = nblocks << 2;\n    int k1 = 0;\n    switch (length - idx) {\n        case 3:\n            k1 ^= data[offset + idx + 2] << 16;\n        case 2:\n            k1 ^= data[offset + idx + 1] << 8;\n        case 1:\n            k1 ^= data[offset + idx];\n\n                \n            k1 *= C1_32;\n            k1 = Integer.rotateLeft(k1, R1_32);\n            k1 *= C2_32;\n            hash ^= k1;\n    }\n\n    return fmix32(length, hash);\n}",
        "summary_tokens": [
            "murmur",
            "0",
            "0",
            "bit",
            "variant"
        ]
    },
    {
        "id": 3045,
        "code": "public static long hash64(byte[] data, int offset, int length, int seed) {\n    long hash = seed;\n    final int nblocks = length >> 3;\n\n        \n    for (int i = 0; i < nblocks; i++) {\n        final int i8 = i << 3;\n        long k = ((long) data[offset + i8] & 0xff)\n                | (((long) data[offset + i8 + 1] & 0xff) << 8)\n                | (((long) data[offset + i8 + 2] & 0xff) << 16)\n                | (((long) data[offset + i8 + 3] & 0xff) << 24)\n                | (((long) data[offset + i8 + 4] & 0xff) << 32)\n                | (((long) data[offset + i8 + 5] & 0xff) << 40)\n                | (((long) data[offset + i8 + 6] & 0xff) << 48)\n                | (((long) data[offset + i8 + 7] & 0xff) << 56);\n\n            \n        k *= C1;\n        k = Long.rotateLeft(k, R1);\n        k *= C2;\n        hash ^= k;\n        hash = Long.rotateLeft(hash, R2) * M + N1;\n    }\n\n        \n    long k1 = 0;\n    int tailStart = nblocks << 3;\n    switch (length - tailStart) {\n        case 7:\n            k1 ^= ((long) data[offset + tailStart + 6] & 0xff) << 48;\n        case 6:\n            k1 ^= ((long) data[offset + tailStart + 5] & 0xff) << 40;\n        case 5:\n            k1 ^= ((long) data[offset + tailStart + 4] & 0xff) << 32;\n        case 4:\n            k1 ^= ((long) data[offset + tailStart + 3] & 0xff) << 24;\n        case 3:\n            k1 ^= ((long) data[offset + tailStart + 2] & 0xff) << 16;\n        case 2:\n            k1 ^= ((long) data[offset + tailStart + 1] & 0xff) << 8;\n        case 1:\n            k1 ^= ((long) data[offset + tailStart] & 0xff);\n            k1 *= C1;\n            k1 = Long.rotateLeft(k1, R1);\n            k1 *= C2;\n            hash ^= k1;\n    }\n\n        \n    hash ^= length;\n    hash = fmix64(hash);\n\n    return hash;\n}",
        "summary_tokens": [
            "murmur",
            "0",
            "0",
            "bit",
            "variant"
        ]
    },
    {
        "id": 3046,
        "code": "public static long[] hash128(byte[] data, int offset, int length, int seed) {\n    long h1 = seed;\n    long h2 = seed;\n    final int nblocks = length >> 4;\n\n        \n    for (int i = 0; i < nblocks; i++) {\n        final int i16 = i << 4;\n        long k1 = ((long) data[offset + i16] & 0xff)\n                | (((long) data[offset + i16 + 1] & 0xff) << 8)\n                | (((long) data[offset + i16 + 2] & 0xff) << 16)\n                | (((long) data[offset + i16 + 3] & 0xff) << 24)\n                | (((long) data[offset + i16 + 4] & 0xff) << 32)\n                | (((long) data[offset + i16 + 5] & 0xff) << 40)\n                | (((long) data[offset + i16 + 6] & 0xff) << 48)\n                | (((long) data[offset + i16 + 7] & 0xff) << 56);\n\n        long k2 = ((long) data[offset + i16 + 8] & 0xff)\n                | (((long) data[offset + i16 + 9] & 0xff) << 8)\n                | (((long) data[offset + i16 + 10] & 0xff) << 16)\n                | (((long) data[offset + i16 + 11] & 0xff) << 24)\n                | (((long) data[offset + i16 + 12] & 0xff) << 32)\n                | (((long) data[offset + i16 + 13] & 0xff) << 40)\n                | (((long) data[offset + i16 + 14] & 0xff) << 48)\n                | (((long) data[offset + i16 + 15] & 0xff) << 56);\n\n            \n        k1 *= C1;\n        k1 = Long.rotateLeft(k1, R1);\n        k1 *= C2;\n        h1 ^= k1;\n        h1 = Long.rotateLeft(h1, R2);\n        h1 += h2;\n        h1 = h1 * M + N1;\n\n            \n        k2 *= C2;\n        k2 = Long.rotateLeft(k2, R3);\n        k2 *= C1;\n        h2 ^= k2;\n        h2 = Long.rotateLeft(h2, R1);\n        h2 += h1;\n        h2 = h2 * M + N2;\n    }\n\n        \n    long k1 = 0;\n    long k2 = 0;\n    int tailStart = nblocks << 4;\n    switch (length - tailStart) {\n        case 15:\n            k2 ^= (long) (data[offset + tailStart + 14] & 0xff) << 48;\n        case 14:\n            k2 ^= (long) (data[offset + tailStart + 13] & 0xff) << 40;\n        case 13:\n            k2 ^= (long) (data[offset + tailStart + 12] & 0xff) << 32;\n        case 12:\n            k2 ^= (long) (data[offset + tailStart + 11] & 0xff) << 24;\n        case 11:\n            k2 ^= (long) (data[offset + tailStart + 10] & 0xff) << 16;\n        case 10:\n            k2 ^= (long) (data[offset + tailStart + 9] & 0xff) << 8;\n        case 9:\n            k2 ^= (long) (data[offset + tailStart + 8] & 0xff);\n            k2 *= C2;\n            k2 = Long.rotateLeft(k2, R3);\n            k2 *= C1;\n            h2 ^= k2;\n\n        case 8:\n            k1 ^= (long) (data[offset + tailStart + 7] & 0xff) << 56;\n        case 7:\n            k1 ^= (long) (data[offset + tailStart + 6] & 0xff) << 48;\n        case 6:\n            k1 ^= (long) (data[offset + tailStart + 5] & 0xff) << 40;\n        case 5:\n            k1 ^= (long) (data[offset + tailStart + 4] & 0xff) << 32;\n        case 4:\n            k1 ^= (long) (data[offset + tailStart + 3] & 0xff) << 24;\n        case 3:\n            k1 ^= (long) (data[offset + tailStart + 2] & 0xff) << 16;\n        case 2:\n            k1 ^= (long) (data[offset + tailStart + 1] & 0xff) << 8;\n        case 1:\n            k1 ^= (long) (data[offset + tailStart] & 0xff);\n            k1 *= C1;\n            k1 = Long.rotateLeft(k1, R1);\n            k1 *= C2;\n            h1 ^= k1;\n    }\n\n        \n    h1 ^= length;\n    h2 ^= length;\n\n    h1 += h2;\n    h2 += h1;\n\n    h1 = fmix64(h1);\n    h2 = fmix64(h2);\n\n    h1 += h2;\n    h2 += h1;\n\n    return new long[]{h1, h2};\n}",
        "summary_tokens": [
            "murmur",
            "0",
            "0",
            "bit",
            "variant"
        ]
    },
    {
        "id": 3047,
        "code": "public void write(final Map<TopicPartition, Long> offsets) throws IOException {\n        \n        \n    if (offsets.isEmpty()) {\n        Utils.delete(file);\n        return;\n    }\n\n    synchronized (lock) {\n            \n        final File temp = new File(file.getAbsolutePath() + \".tmp\");\n        LOG.trace(\"Writing tmp checkpoint file {}\", temp.getAbsolutePath());\n\n        final FileOutputStream fileOutputStream = new FileOutputStream(temp);\n        try (final BufferedWriter writer = new BufferedWriter(\n                new OutputStreamWriter(fileOutputStream, StandardCharsets.UTF_8))) {\n            writeIntLine(writer, VERSION);\n            writeIntLine(writer, offsets.size());\n\n            for (final Map.Entry<TopicPartition, Long> entry : offsets.entrySet()) {\n                final TopicPartition tp = entry.getKey();\n                final Long offset = entry.getValue();\n                if (isValid(offset)) {\n                    writeEntry(writer, tp, offset);\n                } else {\n                    LOG.error(\"Received offset={} to write to checkpoint file for {}\", offset, tp);\n                    throw new IllegalStateException(\"Attempted to write a negative offset to the checkpoint file\");\n                }\n            }\n\n            writer.flush();\n            fileOutputStream.getFD().sync();\n        }\n\n        LOG.trace(\"Swapping tmp checkpoint file {} {}\", temp.toPath(), file.toPath());\n        Utils.atomicMoveWithFallback(temp.toPath(), file.toPath());\n    }\n}",
        "summary_tokens": [
            "write",
            "the",
            "given",
            "offsets",
            "to",
            "the",
            "checkpoint",
            "file"
        ]
    },
    {
        "id": 3048,
        "code": "static void writeIntLine(final BufferedWriter writer,\n                         final int number) throws IOException {\n    writer.write(Integer.toString(number));\n    writer.newLine();\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "file",
            "write",
            "operations",
            "failed",
            "with",
            "any",
            "io",
            "exception"
        ]
    },
    {
        "id": 3049,
        "code": "static void writeEntry(final BufferedWriter writer,\n                       final TopicPartition part,\n                       final long offset) throws IOException {\n    writer.write(part.topic());\n    writer.write(' ');\n    writer.write(Integer.toString(part.partition()));\n    writer.write(' ');\n    writer.write(Long.toString(offset));\n    writer.newLine();\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "file",
            "write",
            "operations",
            "failed",
            "with",
            "any",
            "io",
            "exception"
        ]
    },
    {
        "id": 3050,
        "code": "public Map<TopicPartition, Long> read() throws IOException {\n    synchronized (lock) {\n        try (final BufferedReader reader = Files.newBufferedReader(file.toPath())) {\n            final int version = readInt(reader);\n            switch (version) {\n                case 0:\n                    int expectedSize = readInt(reader);\n                    final Map<TopicPartition, Long> offsets = new HashMap<>();\n                    String line = reader.readLine();\n                    while (line != null) {\n                        final String[] pieces = WHITESPACE_MINIMUM_ONCE.split(line);\n                        if (pieces.length != 3) {\n                            throw new IOException(\n                                String.format(\"Malformed line in offset checkpoint file: '%s'.\", line));\n                        }\n\n                        final String topic = pieces[0];\n                        final int partition = Integer.parseInt(pieces[1]);\n                        final TopicPartition tp = new TopicPartition(topic, partition);\n                        final long offset = Long.parseLong(pieces[2]);\n                        if (isValid(offset)) {\n                            offsets.put(tp, offset);\n                        } else {\n                            LOG.warn(\"Read offset={} from checkpoint file for {}\", offset, tp);\n                            --expectedSize;\n                        }\n\n                        line = reader.readLine();\n                    }\n                    if (offsets.size() != expectedSize) {\n                        throw new IOException(\n                            String.format(\"Expected %d entries but found only %d\", expectedSize, offsets.size()));\n                    }\n                    return offsets;\n\n                default:\n                    throw new IllegalArgumentException(\"Unknown offset checkpoint version: \" + version);\n            }\n        } catch (final NoSuchFileException e) {\n            return Collections.emptyMap();\n        }\n    }\n}",
        "summary_tokens": [
            "reads",
            "the",
            "offsets",
            "from",
            "the",
            "local",
            "checkpoint",
            "file",
            "skipping",
            "any",
            "negative",
            "offsets",
            "it",
            "finds"
        ]
    },
    {
        "id": 3051,
        "code": "private int readInt(final BufferedReader reader) throws IOException {\n    final String line = reader.readLine();\n    if (line == null) {\n        throw new EOFException(\"File ended prematurely.\");\n    }\n    return Integer.parseInt(line);\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "file",
            "read",
            "ended",
            "prematurely"
        ]
    },
    {
        "id": 3052,
        "code": "public void delete() throws IOException {\n    Files.deleteIfExists(file.toPath());\n}",
        "summary_tokens": [
            "ioexception",
            "if",
            "there",
            "is",
            "any",
            "io",
            "exception",
            "during",
            "delete"
        ]
    },
    {
        "id": 3053,
        "code": "static Bytes upperRange(final Bytes key, final byte[] maxSuffix) {\n    final byte[] bytes = key.get();\n    final ByteBuffer rangeEnd = ByteBuffer.allocate(bytes.length + maxSuffix.length);\n    final int firstTimestampByte = maxSuffix[0] & 0xFF;\n\n        \n        \n    if (firstTimestampByte == 0) {\n        return Bytes.wrap(\n            rangeEnd\n                .put(bytes)\n                .put(maxSuffix)\n                .array()\n        );\n    } else {\n        int i = 0;\n        while (i < bytes.length && (\n            i < MIN_KEY_LENGTH \n            || (bytes[i] & 0xFF) >= firstTimestampByte\n            )) {\n            rangeEnd.put(bytes[i++]);\n        }\n\n        rangeEnd.put(maxSuffix);\n        rangeEnd.flip();\n\n        final byte[] res = new byte[rangeEnd.remaining()];\n        ByteBuffer.wrap(res).put(rangeEnd);\n        return Bytes.wrap(res);\n    }\n}",
        "summary_tokens": [
            "returns",
            "the",
            "upper",
            "byte",
            "range",
            "for",
            "a",
            "key",
            "with",
            "a",
            "given",
            "fixed",
            "size",
            "maximum",
            "suffix"
        ]
    },
    {
        "id": 3054,
        "code": "public <T> T getStore(final StoreQueryParameters<T> storeQueryParameters) {\n    final String storeName = storeQueryParameters.storeName();\n    final QueryableStoreType<T> queryableStoreType = storeQueryParameters.queryableStoreType();\n    final List<T> globalStore = globalStoreProvider.stores(storeName, queryableStoreType);\n    if (!globalStore.isEmpty()) {\n        return queryableStoreType.create(globalStoreProvider, storeName);\n    }\n    return queryableStoreType.create(\n        new WrappingStoreProvider(storeProviders.values(), storeQueryParameters),\n        storeName\n    );\n}",
        "summary_tokens": [
            "get",
            "a",
            "composite",
            "object",
            "wrapping",
            "the",
            "instances",
            "of",
            "the",
            "state",
            "store",
            "with",
            "the",
            "provided",
            "store",
            "name",
            "and",
            "queryable",
            "store",
            "type"
        ]
    },
    {
        "id": 3055,
        "code": "public long approximateNumEntries() {\n    validateStoreOpen();\n    final long numEntries;\n    try {\n        numEntries = dbAccessor.approximateNumEntries();\n    } catch (final RocksDBException e) {\n        throw new ProcessorStateException(\"Error fetching property from store \" + name, e);\n    }\n    if (isOverflowing(numEntries)) {\n        return Long.MAX_VALUE;\n    }\n    return numEntries;\n}",
        "summary_tokens": [
            "return",
            "an",
            "approximate",
            "count",
            "of",
            "key",
            "value",
            "mappings",
            "in",
            "this",
            "store"
        ]
    },
    {
        "id": 3056,
        "code": "public HostInfo hostInfo() {\n    return hostInfo;\n}",
        "summary_tokens": [
            "the",
            "value",
            "of",
            "org"
        ]
    },
    {
        "id": 3057,
        "code": "public Set<String> stateStoreNames() {\n    return stateStoreNames;\n}",
        "summary_tokens": [
            "state",
            "stores",
            "owned",
            "by",
            "the",
            "instance",
            "as",
            "an",
            "active",
            "replica"
        ]
    },
    {
        "id": 3058,
        "code": "public Set<TopicPartition> topicPartitions() {\n    return topicPartitions;\n}",
        "summary_tokens": [
            "topic",
            "partitions",
            "consumed",
            "by",
            "the",
            "instance",
            "as",
            "an",
            "active",
            "replica"
        ]
    },
    {
        "id": 3059,
        "code": "public Set<TopicPartition> standbyTopicPartitions() {\n    return standbyTopicPartitions;\n}",
        "summary_tokens": [
            "source",
            "topic",
            "partitions",
            "for",
            "which",
            "the",
            "instance",
            "acts",
            "as",
            "standby"
        ]
    },
    {
        "id": 3060,
        "code": "public Set<String> standbyStateStoreNames() {\n    return standbyStateStoreNames;\n}",
        "summary_tokens": [
            "state",
            "stores",
            "owned",
            "by",
            "the",
            "instance",
            "as",
            "a",
            "standby",
            "replica"
        ]
    },
    {
        "id": 3061,
        "code": "public static String nameSpaceFromTaskIdAndStore(final String taskIDString, final String underlyingStoreName) {\n    return taskIDString + \"-\" + underlyingStoreName;\n}",
        "summary_tokens": [
            "the",
            "thread",
            "cache",
            "maintains",
            "a",
            "set",
            "of",
            "named",
            "cache",
            "s",
            "whose",
            "names",
            "are",
            "a",
            "concatenation",
            "of",
            "the",
            "task",
            "id",
            "and",
            "the",
            "underlying",
            "store",
            "name"
        ]
    },
    {
        "id": 3062,
        "code": "public static String taskIDfromCacheName(final String cacheName) {\n    final String[] tokens = cacheName.split(\"-\", 2);\n    return tokens[0];\n}",
        "summary_tokens": [
            "given",
            "a",
            "cache",
            "name",
            "of",
            "the",
            "form",
            "taskid",
            "storename",
            "return",
            "the",
            "task",
            "id"
        ]
    },
    {
        "id": 3063,
        "code": "public static String underlyingStoreNamefromCacheName(final String cacheName) {\n    final String[] tokens = cacheName.split(\"-\", 2);\n    return tokens[1];\n}",
        "summary_tokens": [
            "given",
            "a",
            "cache",
            "name",
            "of",
            "the",
            "form",
            "taskid",
            "storename",
            "return",
            "the",
            "store",
            "name"
        ]
    },
    {
        "id": 3064,
        "code": "public void addDirtyEntryFlushListener(final String namespace, final DirtyEntryFlushListener listener) {\n    final NamedCache cache = getOrCreateCache(namespace);\n    cache.setListener(listener);\n}",
        "summary_tokens": [
            "add",
            "a",
            "listener",
            "that",
            "is",
            "called",
            "each",
            "time",
            "an",
            "entry",
            "is",
            "evicted",
            "from",
            "the",
            "cache",
            "or",
            "an",
            "explicit",
            "flush",
            "is",
            "called"
        ]
    },
    {
        "id": 3065,
        "code": "public static <K> TimestampedKeyAndJoinSide<K> make(final boolean leftSide, final K key, final long timestamp) {\n    return new TimestampedKeyAndJoinSide<>(leftSide, key, timestamp);\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "timestamped",
            "key",
            "and",
            "join",
            "side",
            "instance",
            "if",
            "the",
            "provide",
            "key",
            "is",
            "not",
            "null"
        ]
    },
    {
        "id": 3066,
        "code": "static TimeWindow timeWindowForSize(final long startMs,\n                                    final long windowSize) {\n    long endMs = startMs + windowSize;\n\n    if (endMs < 0) {\n        LOG.warn(\"Warning: window end time was truncated to Long.MAX\");\n        endMs = Long.MAX_VALUE;\n    }\n    return new TimeWindow(startMs, endMs);\n}",
        "summary_tokens": [
            "safely",
            "construct",
            "a",
            "time",
            "window",
            "of",
            "the",
            "given",
            "size",
            "taking",
            "care",
            "of",
            "bounding",
            "end",
            "ms",
            "to",
            "long"
        ]
    },
    {
        "id": 3067,
        "code": "public void init(final StreamsMetricsImpl streamsMetrics,\n                 final TaskId taskId) {\n    Objects.requireNonNull(streamsMetrics, \"Streams metrics must not be null\");\n    Objects.requireNonNull(streamsMetrics, \"task ID must not be null\");\n    if (this.taskId != null && !this.taskId.equals(taskId)) {\n        throw new IllegalStateException(\"Metrics recorder is re-initialised with different task: previous task is \" +\n            this.taskId + \" whereas current task is \" + taskId + \". This is a bug in Kafka Streams. \" +\n            \"Please open a bug report under https://issues.apache.org/jira/projects/KAFKA/issues\");\n    }\n    if (this.streamsMetrics != null && this.streamsMetrics != streamsMetrics) {\n        throw new IllegalStateException(\"Metrics recorder is re-initialised with different Streams metrics. \"\n            + \"This is a bug in Kafka Streams. \" +\n            \"Please open a bug report under https://issues.apache.org/jira/projects/KAFKA/issues\");\n    }\n    final RocksDBMetricContext metricContext = new RocksDBMetricContext(taskId.toString(), metricsScope, storeName);\n    initSensors(streamsMetrics, metricContext);\n    initGauges(streamsMetrics, metricContext);\n    this.taskId = taskId;\n    this.streamsMetrics = streamsMetrics;\n}",
        "summary_tokens": [
            "the",
            "initialisation",
            "of",
            "the",
            "metrics",
            "recorder",
            "is",
            "idempotent"
        ]
    },
    {
        "id": 3068,
        "code": "public void setStreamThreadStateListener(final StreamThread.StateListener listener) {\n    if (state == State.CREATED) {\n        for (final StreamThread thread : threads) {\n            thread.setStateListener(listener);\n        }\n    } else {\n        throw new IllegalStateException(\"Can only set StateListener in CREATED state. \" +\n            \"Current state is: \" + state);\n    }\n}",
        "summary_tokens": [
            "an",
            "app",
            "can",
            "set",
            "a",
            "single",
            "stream",
            "thread"
        ]
    },
    {
        "id": 3069,
        "code": "public <K, V> ProcessorContext<K, V> setCurrentNodeForProcessorContext(final String processorName) {\n    final ProcessorContext<K, V> context = task.processorContext();\n    ((ProcessorContextImpl) context).setCurrentNode(getProcessor(processorName));\n    return context;\n}",
        "summary_tokens": [
            "get",
            "the",
            "processor",
            "context",
            "setting",
            "the",
            "processor",
            "whose",
            "name",
            "is",
            "given",
            "as",
            "current",
            "node"
        ]
    },
    {
        "id": 3070,
        "code": "public ProcessorNode<?, ?, ?, ?> getProcessor(final String name) {\n    for (final ProcessorNode<?, ?, ?, ?> node : processorTopology.processors()) {\n        if (node.name().equals(name)) {\n            return node;\n        }\n    }\n    for (final ProcessorNode<?, ?, ?, ?> node : globalTopology.processors()) {\n        if (node.name().equals(name)) {\n            return node;\n        }\n    }\n    throw new StreamsException(\"Could not find a processor named '\" + name + \"'\");\n}",
        "summary_tokens": [
            "get",
            "a",
            "processor",
            "by",
            "name"
        ]
    },
    {
        "id": 3071,
        "code": "private void verifyMetadataForTopology(final String topologyName,\n                                       final Collection<StreamsMetadata> left,\n                                       final Collection<StreamsMetadata> right) {\n    assertThat(left.size(), equalTo(right.size()));\n    final Iterator<StreamsMetadata> leftIter = left.iterator();\n    final Iterator<StreamsMetadata> rightIter = right.iterator();\n\n    while (leftIter.hasNext()) {\n        final StreamsMetadataImpl leftMetadata = (StreamsMetadataImpl) leftIter.next();\n        final StreamsMetadataImpl rightMetadata = (StreamsMetadataImpl) rightIter.next();\n\n        verifyPartitionsAndStoresForTopology(topologyName, leftMetadata);\n        verifyPartitionsAndStoresForTopology(topologyName, rightMetadata);\n\n        assertThat(verifyEquivalentMetadataForHost(leftMetadata, rightMetadata), is(true));\n    }\n}",
        "summary_tokens": [
            "validates",
            "that",
            "each",
            "metadata",
            "object",
            "has",
            "only",
            "partitions",
            "state",
            "stores",
            "for",
            "its",
            "specific",
            "topology",
            "name",
            "and",
            "asserts",
            "that",
            "left",
            "and",
            "right",
            "differ",
            "only",
            "by",
            "streams",
            "metadata",
            "host",
            "info"
        ]
    },
    {
        "id": 3072,
        "code": "private static boolean verifyEquivalentMetadataForHost(final StreamsMetadataImpl left, final StreamsMetadataImpl right) {\n    return left.hostInfo().equals(right.hostInfo())\n        && left.stateStoreNames().equals(right.stateStoreNames())\n        && left.topicPartitions().equals(right.topicPartitions())\n        && left.standbyStateStoreNames().equals(right.standbyStateStoreNames())\n        && left.standbyTopicPartitions().equals(right.standbyTopicPartitions());\n}",
        "summary_tokens": [
            "true",
            "iff",
            "all",
            "fields",
            "other",
            "than",
            "streams",
            "metadata",
            "impl",
            "topology",
            "name",
            "match",
            "between",
            "the",
            "two",
            "streams",
            "metadata",
            "objects"
        ]
    },
    {
        "id": 3073,
        "code": "private List<String> getInputValues() {\n    List<String> input = new ArrayList<>();\n    final ClassLoader classLoader = getClass().getClassLoader();\n    final String fileName = \"QueryableStateIntegrationTest\" + File.separator + \"inputValues.txt\";\n    try (final BufferedReader reader = new BufferedReader(\n        new FileReader(Objects.requireNonNull(classLoader.getResource(fileName)).getFile()))) {\n\n        for (String line = reader.readLine(); line != null; line = reader.readLine()) {\n            input.add(line);\n        }\n    } catch (final Exception e) {\n        log.warn(\"Unable to read '{}{}{}'. Using default inputValues list\", \"resources\", File.separator, fileName);\n        input = Arrays.asList(\n                    \"hello world\",\n                    \"all streams lead to kafka\",\n                    \"streams\",\n                    \"kafka streams\",\n                    \"the cat in the hat\",\n                    \"green eggs and ham\",\n                    \"that Sam i am\",\n                    \"up the creek without a paddle\",\n                    \"run forest run\",\n                    \"a tank full of gas\",\n                    \"eat sleep rave repeat\",\n                    \"one jolly sailor\",\n                    \"king of the world\");\n\n    }\n    return input;\n}",
        "summary_tokens": [
            "try",
            "to",
            "read",
            "input",
            "values",
            "from",
            "resources",
            "queryable",
            "state",
            "integration",
            "test",
            "input",
            "values"
        ]
    },
    {
        "id": 3074,
        "code": "private KafkaStreams createCountStream(final String inputTopic,\n                                       final String outputTopic,\n                                       final String windowOutputTopic,\n                                       final String storeName,\n                                       final String windowStoreName,\n                                       final Properties streamsConfiguration) {\n    final StreamsBuilder builder = new StreamsBuilder();\n    final Serde<String> stringSerde = Serdes.String();\n    final KStream<String, String> textLines = builder.stream(inputTopic, Consumed.with(stringSerde, stringSerde));\n\n    final KGroupedStream<String, String> groupedByWord = textLines\n        .flatMapValues((ValueMapper<String, Iterable<String>>) value -> Arrays.asList(value.split(\"\\\\W+\")))\n        .groupBy(MockMapper.selectValueMapper());\n\n        \n    groupedByWord\n        .count(Materialized.as(storeName + \"-\" + inputTopic))\n        .toStream()\n        .to(outputTopic, Produced.with(Serdes.String(), Serdes.Long()));\n\n        \n    groupedByWord\n        .windowedBy(TimeWindows.of(ofMillis(WINDOW_SIZE)))\n        .count(Materialized.as(windowStoreName + \"-\" + inputTopic))\n        .toStream((key, value) -> key.key())\n        .to(windowOutputTopic, Produced.with(Serdes.String(), Serdes.Long()));\n\n    return new KafkaStreams(builder.build(), streamsConfiguration);\n}",
        "summary_tokens": [
            "creates",
            "a",
            "typical",
            "word",
            "count",
            "topology"
        ]
    },
    {
        "id": 3075,
        "code": "private long scaledTime(final long unscaledTime) {\n    return COMMIT_INTERVAL * 2 * unscaledTime;\n}",
        "summary_tokens": [
            "scaling",
            "to",
            "ensure",
            "that",
            "there",
            "are",
            "commits",
            "in",
            "between",
            "the",
            "various",
            "test",
            "events",
            "just",
            "to",
            "exercise",
            "that",
            "everything",
            "works",
            "properly",
            "in",
            "the",
            "presence",
            "of",
            "commits"
        ]
    },
    {
        "id": 3076,
        "code": "private static long scaledTime(final long unscaledTime) {\n    return COMMIT_INTERVAL * 2 * unscaledTime;\n}",
        "summary_tokens": [
            "scaling",
            "to",
            "ensure",
            "that",
            "there",
            "are",
            "commits",
            "in",
            "between",
            "the",
            "various",
            "test",
            "events",
            "just",
            "to",
            "exercise",
            "that",
            "everything",
            "works",
            "properly",
            "in",
            "the",
            "presence",
            "of",
            "commits"
        ]
    },
    {
        "id": 3077,
        "code": "public void start() throws IOException {\n    log.debug(\"Initiating embedded Kafka cluster startup\");\n    log.debug(\"Starting a ZooKeeper instance\");\n    zookeeper = new EmbeddedZookeeper();\n    log.debug(\"ZooKeeper instance is running at {}\", zKConnectString());\n\n    brokerConfig.put(KafkaConfig.ZkConnectProp(), zKConnectString());\n    putIfAbsent(brokerConfig, KafkaConfig.ListenersProp(), \"PLAINTEXT://localhost:\" + DEFAULT_BROKER_PORT);\n    putIfAbsent(brokerConfig, KafkaConfig.DeleteTopicEnableProp(), true);\n    putIfAbsent(brokerConfig, KafkaConfig.LogCleanerDedupeBufferSizeProp(), 2 * 1024 * 1024L);\n    putIfAbsent(brokerConfig, KafkaConfig.GroupMinSessionTimeoutMsProp(), 0);\n    putIfAbsent(brokerConfig, KafkaConfig.GroupInitialRebalanceDelayMsProp(), 0);\n    putIfAbsent(brokerConfig, KafkaConfig.OffsetsTopicReplicationFactorProp(), (short) 1);\n    putIfAbsent(brokerConfig, KafkaConfig.OffsetsTopicPartitionsProp(), 5);\n    putIfAbsent(brokerConfig, KafkaConfig.TransactionsTopicPartitionsProp(), 5);\n    putIfAbsent(brokerConfig, KafkaConfig.AutoCreateTopicsEnableProp(), true);\n\n    for (int i = 0; i < brokers.length; i++) {\n        brokerConfig.put(KafkaConfig.BrokerIdProp(), i);\n        log.debug(\"Starting a Kafka instance on {} ...\", brokerConfig.get(KafkaConfig.ListenersProp()));\n        brokers[i] = new KafkaEmbedded(brokerConfig, time);\n\n        log.debug(\"Kafka instance is running at {}, connected to ZooKeeper at {}\",\n            brokers[i].brokerList(), brokers[i].zookeeperConnect());\n    }\n}",
        "summary_tokens": [
            "creates",
            "and",
            "starts",
            "a",
            "kafka",
            "cluster"
        ]
    },
    {
        "id": 3078,
        "code": "public void stop() {\n    if (brokers.length > 1) {\n            \n        final Set<String> topics = getAllTopicsInCluster();\n        if (!topics.isEmpty()) {\n            try (final Admin adminClient = brokers[0].createAdminClient()) {\n                adminClient.deleteTopics(topics).all().get();\n            } catch (final InterruptedException e) {\n                log.warn(\"Got interrupted while deleting topics in preparation for stopping embedded brokers\", e);\n                throw new RuntimeException(e);\n            } catch (final ExecutionException | RuntimeException e) {\n                log.warn(\"Couldn't delete all topics before stopping brokers\", e);\n            }\n        }\n    }\n    for (final KafkaEmbedded broker : brokers) {\n        broker.stopAsync();\n    }\n    for (final KafkaEmbedded broker : brokers) {\n        broker.awaitStoppedAndPurge();\n    }\n    zookeeper.shutdown();\n}",
        "summary_tokens": [
            "stop",
            "the",
            "kafka",
            "cluster"
        ]
    },
    {
        "id": 3079,
        "code": "public String zKConnectString() {\n    return \"127.0.0.1:\" + zookeeper.port();\n}",
        "summary_tokens": [
            "the",
            "zoo",
            "keeper",
            "connection",
            "string",
            "aka",
            "zookeeper"
        ]
    },
    {
        "id": 3080,
        "code": "public String bootstrapServers() {\n    return brokers[0].brokerList();\n}",
        "summary_tokens": [
            "this",
            "cluster",
            "s",
            "bootstrap"
        ]
    },
    {
        "id": 3081,
        "code": "public void createTopics(final String... topics) throws InterruptedException {\n    for (final String topic : topics) {\n        createTopic(topic, 1, 1, Collections.emptyMap());\n    }\n}",
        "summary_tokens": [
            "create",
            "multiple",
            "kafka",
            "topics",
            "each",
            "with",
            "0",
            "partition",
            "and",
            "a",
            "replication",
            "factor",
            "of",
            "0"
        ]
    },
    {
        "id": 3082,
        "code": "public void createTopic(final String topic,\n                        final int partitions,\n                        final int replication,\n                        final Map<String, String> topicConfig) throws InterruptedException {\n    brokers[0].createTopic(topic, partitions, replication, topicConfig);\n    final List<TopicPartition> topicPartitions = new ArrayList<>();\n    for (int partition = 0; partition < partitions; partition++) {\n        topicPartitions.add(new TopicPartition(topic, partition));\n    }\n    IntegrationTestUtils.waitForTopicPartitions(brokers(), topicPartitions, TOPIC_CREATION_TIMEOUT);\n}",
        "summary_tokens": [
            "create",
            "a",
            "kafka",
            "topic",
            "with",
            "the",
            "given",
            "parameters"
        ]
    },
    {
        "id": 3083,
        "code": "public void deleteTopic(final String topic) throws InterruptedException {\n    deleteTopicsAndWait(-1L, topic);\n}",
        "summary_tokens": [
            "deletes",
            "a",
            "topic",
            "returns",
            "immediately"
        ]
    },
    {
        "id": 3084,
        "code": "public void deleteTopicAndWait(final String topic) throws InterruptedException {\n    deleteTopicsAndWait(TOPIC_DELETION_TIMEOUT, topic);\n}",
        "summary_tokens": [
            "deletes",
            "a",
            "topic",
            "and",
            "blocks",
            "for",
            "max",
            "0",
            "sec",
            "until",
            "the",
            "topic",
            "got",
            "deleted"
        ]
    },
    {
        "id": 3085,
        "code": "public void deleteTopics(final String... topics) throws InterruptedException {\n    deleteTopicsAndWait(-1, topics);\n}",
        "summary_tokens": [
            "deletes",
            "multiple",
            "topics",
            "returns",
            "immediately"
        ]
    },
    {
        "id": 3086,
        "code": "public void deleteTopicsAndWait(final long timeoutMs, final String... topics) throws InterruptedException {\n    for (final String topic : topics) {\n        try {\n            brokers[0].deleteTopic(topic);\n        } catch (final UnknownTopicOrPartitionException ignored) { }\n    }\n\n    if (timeoutMs > 0) {\n        TestUtils.waitForCondition(new TopicsDeletedCondition(topics), timeoutMs, \"Topics not deleted after \" + timeoutMs + \" milli seconds.\");\n    }\n}",
        "summary_tokens": [
            "deletes",
            "multiple",
            "topics",
            "and",
            "blocks",
            "until",
            "all",
            "topics",
            "got",
            "deleted"
        ]
    },
    {
        "id": 3087,
        "code": "public void deleteAllTopicsAndWait(final long timeoutMs) throws InterruptedException {\n    final Set<String> topics = getAllTopicsInCluster();\n    for (final String topic : topics) {\n        try {\n            brokers[0].deleteTopic(topic);\n        } catch (final UnknownTopicOrPartitionException ignored) { }\n    }\n\n    if (timeoutMs > 0) {\n        TestUtils.waitForCondition(new TopicsDeletedCondition(topics), timeoutMs, \"Topics not deleted after \" + timeoutMs + \" milli seconds.\");\n    }\n}",
        "summary_tokens": [
            "deletes",
            "all",
            "topics",
            "and",
            "blocks",
            "until",
            "all",
            "topics",
            "got",
            "deleted"
        ]
    },
    {
        "id": 3088,
        "code": "public static <R> StateQueryResult<R> iqv2WaitForPartitions(\n    final KafkaStreams kafkaStreams,\n    final StateQueryRequest<R> request,\n    final Set<Integer> partitions) {\n\n    final long start = System.currentTimeMillis();\n    final long deadline = start + DEFAULT_TIMEOUT;\n\n    do {\n        if (Thread.currentThread().isInterrupted()) {\n            fail(\"Test was interrupted.\");\n        }\n        final StateQueryResult<R> result = kafkaStreams.query(request);\n        if (result.getPartitionResults().keySet().containsAll(partitions)) {\n            return result;\n        } else {\n            sleep(100L);\n        }\n    } while (System.currentTimeMillis() < deadline);\n\n    throw new TimeoutException(\"The query never returned the desired partitions\");\n}",
        "summary_tokens": [
            "repeatedly",
            "runs",
            "the",
            "query",
            "until",
            "the",
            "response",
            "is",
            "valid",
            "and",
            "then",
            "return",
            "the",
            "response"
        ]
    },
    {
        "id": 3089,
        "code": "public static <R> StateQueryResult<R> iqv2WaitForResult(\n    final KafkaStreams kafkaStreams,\n    final StateQueryRequest<R> request) {\n\n    final long start = System.currentTimeMillis();\n    final long deadline = start + DEFAULT_TIMEOUT;\n\n    StateQueryResult<R> result;\n    do {\n        if (Thread.currentThread().isInterrupted()) {\n            fail(\"Test was interrupted.\");\n        }\n\n        result = kafkaStreams.query(request);\n        final LinkedList<QueryResult<R>> allResults = getAllResults(result);\n\n        if (allResults.isEmpty()) {\n            sleep(100L);\n        } else {\n            final boolean needToWait = allResults\n                .stream()\n                .anyMatch(IntegrationTestUtils::needToWait);\n            if (needToWait) {\n                sleep(100L);\n            } else {\n                return result;\n            }\n        }\n    } while (System.currentTimeMillis() < deadline);\n\n    throw new TimeoutException(\n        \"The query never returned within the bound. Last result: \"\n        + result\n    );\n}",
        "summary_tokens": [
            "repeatedly",
            "runs",
            "the",
            "query",
            "until",
            "the",
            "response",
            "is",
            "valid",
            "and",
            "then",
            "return",
            "the",
            "response"
        ]
    },
    {
        "id": 3090,
        "code": "public static String safeUniqueTestName(final Class<?> testClass, final TestName testName) {\n    return safeUniqueTestName(testClass, testName.getMethodName());\n}",
        "summary_tokens": [
            "gives",
            "a",
            "test",
            "name",
            "that",
            "is",
            "safe",
            "to",
            "be",
            "used",
            "in",
            "application",
            "ids",
            "topic",
            "names",
            "etc"
        ]
    },
    {
        "id": 3091,
        "code": "public static void purgeLocalStreamsState(final Collection<Properties> streamsConfigurations) throws IOException {\n    for (final Properties streamsConfig : streamsConfigurations) {\n        purgeLocalStreamsState(streamsConfig);\n    }\n}",
        "summary_tokens": [
            "removes",
            "local",
            "state",
            "stores"
        ]
    },
    {
        "id": 3092,
        "code": "public static <K, V> void produceKeyValuesSynchronously(final String topic,\n                                                        final Collection<KeyValue<K, V>> records,\n                                                        final Properties producerConfig,\n                                                        final Headers headers,\n                                                        final Time time,\n                                                        final boolean enableTransactions) {\n    try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {\n        if (enableTransactions) {\n            producer.initTransactions();\n            producer.beginTransaction();\n        }\n        for (final KeyValue<K, V> record : records) {\n            producer.send(new ProducerRecord<>(topic, null, time.milliseconds(), record.key, record.value, headers));\n            time.sleep(1L);\n        }\n        if (enableTransactions) {\n            producer.commitTransaction();\n        } else {\n            producer.flush();\n        }\n    }\n}",
        "summary_tokens": [
            "topic",
            "kafka",
            "topic",
            "to",
            "write",
            "the",
            "data",
            "records",
            "to",
            "records",
            "data",
            "records",
            "to",
            "write",
            "to",
            "kafka",
            "producer",
            "config",
            "kafka",
            "producer",
            "configuration",
            "headers",
            "headers",
            "of",
            "the",
            "data",
            "records",
            "time",
            "timestamp",
            "provider",
            "enable",
            "transactions",
            "send",
            "messages",
            "in",
            "a",
            "transaction",
            "k",
            "key",
            "type",
            "of",
            "the",
            "data",
            "records",
            "v",
            "value",
            "type",
            "of",
            "the",
            "data",
            "records"
        ]
    },
    {
        "id": 3093,
        "code": "public static <K, V> void produceKeyValuesSynchronouslyWithTimestamp(final String topic,\n                                                                     final Collection<KeyValue<K, V>> records,\n                                                                     final Properties producerConfig,\n                                                                     final Headers headers,\n                                                                     final Long timestamp,\n                                                                     final boolean enableTransactions) {\n    try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {\n        if (enableTransactions) {\n            producer.initTransactions();\n            producer.beginTransaction();\n        }\n        for (final KeyValue<K, V> record : records) {\n            producer.send(new ProducerRecord<>(topic, null, timestamp, record.key, record.value, headers));\n        }\n        if (enableTransactions) {\n            producer.commitTransaction();\n        }\n    }\n}",
        "summary_tokens": [
            "topic",
            "kafka",
            "topic",
            "to",
            "write",
            "the",
            "data",
            "records",
            "to",
            "records",
            "data",
            "records",
            "to",
            "write",
            "to",
            "kafka",
            "producer",
            "config",
            "kafka",
            "producer",
            "configuration",
            "headers",
            "headers",
            "of",
            "the",
            "data",
            "records",
            "timestamp",
            "timestamp",
            "of",
            "the",
            "record",
            "enable",
            "transactions",
            "send",
            "messages",
            "in",
            "a",
            "transaction",
            "k",
            "key",
            "type",
            "of",
            "the",
            "data",
            "records",
            "v",
            "value",
            "type",
            "of",
            "the",
            "data",
            "records"
        ]
    },
    {
        "id": 3094,
        "code": "public static <K, V> void produceAbortedKeyValuesSynchronouslyWithTimestamp(final String topic,\n                                                                            final Collection<KeyValue<K, V>> records,\n                                                                            final Properties producerConfig,\n                                                                            final Long timestamp) throws Exception {\n    try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {\n        producer.initTransactions();\n        for (final KeyValue<K, V> record : records) {\n            producer.beginTransaction();\n            final Future<RecordMetadata> f = producer\n                    .send(new ProducerRecord<>(topic, null, timestamp, record.key, record.value));\n            f.get();\n            producer.abortTransaction();\n        }\n    }\n}",
        "summary_tokens": [
            "produce",
            "data",
            "records",
            "and",
            "send",
            "them",
            "synchronously",
            "in",
            "an",
            "aborted",
            "transaction",
            "that",
            "is",
            "a",
            "transaction",
            "is",
            "started",
            "for",
            "each",
            "data",
            "record",
            "but",
            "not",
            "committed"
        ]
    },
    {
        "id": 3095,
        "code": "public static <V> void produceValuesSynchronously(final String topic,\n                                                  final Collection<V> records,\n                                                  final Properties producerConfig,\n                                                  final Time time,\n                                                  final boolean enableTransactions) {\n    final Collection<KeyValue<Object, V>> keyedRecords = new ArrayList<>();\n    for (final V value : records) {\n        final KeyValue<Object, V> kv = new KeyValue<>(null, value);\n        keyedRecords.add(kv);\n    }\n    produceKeyValuesSynchronously(topic, keyedRecords, producerConfig, time, enableTransactions);\n}",
        "summary_tokens": [
            "topic",
            "kafka",
            "topic",
            "to",
            "write",
            "the",
            "data",
            "records",
            "to",
            "records",
            "data",
            "records",
            "to",
            "write",
            "to",
            "kafka",
            "producer",
            "config",
            "kafka",
            "producer",
            "configuration",
            "time",
            "timestamp",
            "provider",
            "enable",
            "transactions",
            "send",
            "messages",
            "in",
            "a",
            "transaction",
            "v",
            "value",
            "type",
            "of",
            "the",
            "data",
            "records"
        ]
    },
    {
        "id": 3096,
        "code": "public static void waitForCompletion(final KafkaStreams streams,\n                                     final int expectedPartitions,\n                                     final long timeoutMilliseconds) {\n    final long start = System.currentTimeMillis();\n    while (true) {\n        int lagMetrics = 0;\n        double totalLag = 0.0;\n        for (final Metric metric : streams.metrics().values()) {\n            if (metric.metricName().name().equals(\"records-lag\")) {\n                if (!metric.metricName().tags().get(\"client-id\").endsWith(\"restore-consumer\")) {\n                    lagMetrics++;\n                    totalLag += ((Number) metric.metricValue()).doubleValue();\n                }\n            }\n        }\n        if (lagMetrics >= expectedPartitions && totalLag == 0.0) {\n            return;\n        }\n        if (System.currentTimeMillis() - start >= timeoutMilliseconds) {\n            throw new RuntimeException(String.format(\n                \"Timed out waiting for completion. lagMetrics=[%s/%s] totalLag=[%s]\",\n                lagMetrics, expectedPartitions, totalLag\n            ));\n        }\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "streams",
            "to",
            "finish",
            "based",
            "on",
            "the",
            "consumer",
            "lag",
            "metric"
        ]
    },
    {
        "id": 3097,
        "code": "public static void waitForStandbyCompletion(final KafkaStreams streams,\n                                            final int expectedPartitions,\n                                            final long timeoutMilliseconds) {\n    final long start = System.currentTimeMillis();\n    while (true) {\n        int lagMetrics = 0;\n        double totalLag = 0.0;\n        for (final Metric metric : streams.metrics().values()) {\n            if (metric.metricName().name().equals(\"records-lag\")) {\n                if (metric.metricName().tags().get(\"client-id\").endsWith(\"restore-consumer\")) {\n                    lagMetrics++;\n                    totalLag += ((Number) metric.metricValue()).doubleValue();\n                }\n            }\n        }\n        if (lagMetrics >= expectedPartitions && totalLag == 0.0) {\n            return;\n        }\n        if (System.currentTimeMillis() - start >= timeoutMilliseconds) {\n            throw new RuntimeException(String.format(\n                \"Timed out waiting for completion. lagMetrics=[%s/%s] totalLag=[%s]\",\n                lagMetrics, expectedPartitions, totalLag\n            ));\n        }\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "streams",
            "to",
            "finish",
            "processing",
            "standbys",
            "based",
            "on",
            "the",
            "restore",
            "consumer",
            "lag",
            "metric"
        ]
    },
    {
        "id": 3098,
        "code": "public static <K, V> List<ConsumerRecord<K, V>> waitUntilMinRecordsReceived(final Properties consumerConfig,\n                                                                            final String topic,\n                                                                            final int expectedNumRecords,\n                                                                            final long waitTime) throws Exception {\n    final List<ConsumerRecord<K, V>> accumData = new ArrayList<>();\n    final String reason = String.format(\n        \"Did not receive all %d records from topic %s within %d ms\",\n        expectedNumRecords,\n        topic,\n        waitTime\n    );\n    try (final Consumer<K, V> consumer = createConsumer(consumerConfig)) {\n        retryOnExceptionWithTimeout(waitTime, () -> {\n            final List<ConsumerRecord<K, V>> readData =\n                readRecords(topic, consumer, waitTime, expectedNumRecords);\n            accumData.addAll(readData);\n            assertThat(reason, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n        });\n    }\n    return accumData;\n}",
        "summary_tokens": [
            "wait",
            "until",
            "enough",
            "data",
            "consumer",
            "records",
            "has",
            "been",
            "consumed"
        ]
    },
    {
        "id": 3099,
        "code": "public static <K, V> List<KeyValue<K, V>> waitUntilMinKeyValueRecordsReceived(final Properties consumerConfig,\n                                                                              final String topic,\n                                                                              final int expectedNumRecords,\n                                                                              final long waitTime) throws Exception {\n    final List<KeyValue<K, V>> accumData = new ArrayList<>();\n    final String reason = String.format(\n        \"Did not receive all %d records from topic %s within %d ms\",\n        expectedNumRecords,\n        topic,\n        waitTime\n    );\n    try (final Consumer<K, V> consumer = createConsumer(consumerConfig)) {\n        retryOnExceptionWithTimeout(waitTime, () -> {\n            final List<KeyValue<K, V>> readData =\n                readKeyValues(topic, consumer, waitTime, expectedNumRecords);\n            accumData.addAll(readData);\n            assertThat(reason + \",  currently accumulated data is \" + accumData, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n        });\n    }\n    return accumData;\n}",
        "summary_tokens": [
            "wait",
            "until",
            "enough",
            "data",
            "key",
            "value",
            "records",
            "has",
            "been",
            "consumed"
        ]
    },
    {
        "id": 3100,
        "code": "public static <K, V> List<KeyValueTimestamp<K, V>> waitUntilMinKeyValueWithTimestampRecordsReceived(final Properties consumerConfig,\n                                                                                                    final String topic,\n                                                                                                    final int expectedNumRecords,\n                                                                                                    final long waitTime) throws Exception {\n    final List<KeyValueTimestamp<K, V>> accumData = new ArrayList<>();\n    final String reason = String.format(\n        \"Did not receive all %d records from topic %s within %d ms\",\n        expectedNumRecords,\n        topic,\n        waitTime\n    );\n    try (final Consumer<K, V> consumer = createConsumer(consumerConfig)) {\n        retryOnExceptionWithTimeout(waitTime, () -> {\n            final List<KeyValueTimestamp<K, V>> readData =\n                readKeyValuesWithTimestamp(topic, consumer, waitTime, expectedNumRecords);\n            accumData.addAll(readData);\n            assertThat(reason, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n        });\n    }\n    return accumData;\n}",
        "summary_tokens": [
            "wait",
            "until",
            "enough",
            "data",
            "timestamped",
            "key",
            "value",
            "records",
            "has",
            "been",
            "consumed"
        ]
    },
    {
        "id": 3101,
        "code": "public static <K, V> List<KeyValue<K, V>> waitUntilFinalKeyValueRecordsReceived(final Properties consumerConfig,\n                                                                                final String topic,\n                                                                                final List<KeyValue<K, V>> expectedRecords,\n                                                                                final long waitTime) throws Exception {\n    return waitUntilFinalKeyValueRecordsReceived(consumerConfig, topic, expectedRecords, waitTime, false);\n}",
        "summary_tokens": [
            "wait",
            "until",
            "final",
            "key",
            "value",
            "mappings",
            "have",
            "been",
            "consumed"
        ]
    },
    {
        "id": 3102,
        "code": "public static <K, V> List<KeyValueTimestamp<K, V>> waitUntilFinalKeyValueTimestampRecordsReceived(final Properties consumerConfig,\n                                                                                                  final String topic,\n                                                                                                  final List<KeyValueTimestamp<K, V>> expectedRecords) throws Exception {\n    return waitUntilFinalKeyValueRecordsReceived(consumerConfig, topic, expectedRecords, DEFAULT_TIMEOUT, true);\n}",
        "summary_tokens": [
            "wait",
            "until",
            "final",
            "key",
            "value",
            "mappings",
            "have",
            "been",
            "consumed"
        ]
    },
    {
        "id": 3103,
        "code": "public static <V> List<V> waitUntilMinValuesRecordsReceived(final Properties consumerConfig,\n                                                            final String topic,\n                                                            final int expectedNumRecords,\n                                                            final long waitTime) throws Exception {\n    final List<V> accumData = new ArrayList<>();\n    final String reason = String.format(\n        \"Did not receive all %d records from topic %s within %d ms\",\n        expectedNumRecords,\n        topic,\n        waitTime\n    );\n    try (final Consumer<Object, V> consumer = createConsumer(consumerConfig)) {\n        retryOnExceptionWithTimeout(waitTime, () -> {\n            final List<V> readData =\n                readValues(topic, consumer, waitTime, expectedNumRecords);\n            accumData.addAll(readData);\n            assertThat(reason, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n        });\n    }\n    return accumData;\n}",
        "summary_tokens": [
            "wait",
            "until",
            "enough",
            "data",
            "value",
            "records",
            "has",
            "been",
            "consumed"
        ]
    },
    {
        "id": 3104,
        "code": "public static void startApplicationAndWaitUntilRunning(final List<KafkaStreams> streamsList,\n                                                       final Duration timeout) throws Exception {\n    final Lock stateLock = new ReentrantLock();\n    final Condition stateUpdate = stateLock.newCondition();\n    final Map<KafkaStreams, State> stateMap = new HashMap<>();\n    for (final KafkaStreams streams : streamsList) {\n        stateMap.put(streams, streams.state());\n        final StateListener prevStateListener = getStateListener(streams);\n        final StateListener newStateListener = (newState, oldState) -> {\n            stateLock.lock();\n            try {\n                stateMap.put(streams, newState);\n                if (newState == State.RUNNING) {\n                    if (stateMap.values().stream().allMatch(state -> state == State.RUNNING)) {\n                        stateUpdate.signalAll();\n                    }\n                }\n            } finally {\n                stateLock.unlock();\n            }\n        };\n\n        streams.setStateListener(prevStateListener != null\n            ? new CompositeStateListener(prevStateListener, newStateListener)\n            : newStateListener);\n    }\n\n    for (final KafkaStreams streams : streamsList) {\n        streams.start();\n    }\n\n    final long expectedEnd = System.currentTimeMillis() + timeout.toMillis();\n    stateLock.lock();\n    try {\n            \n            \n        while (true) {\n            final Map<KafkaStreams, State> nonRunningStreams = new HashMap<>();\n            for (final Entry<KafkaStreams, State> entry : stateMap.entrySet()) {\n                if (entry.getValue() != State.RUNNING) {\n                    nonRunningStreams.put(entry.getKey(), entry.getValue());\n                }\n            }\n\n            if (nonRunningStreams.isEmpty()) {\n                return;\n            }\n\n            final long millisRemaining = expectedEnd - System.currentTimeMillis();\n            if (millisRemaining <= 0) {\n                fail(\n                    \"Application did not reach a RUNNING state for all streams instances. \" +\n                        \"Non-running instances: \" + nonRunningStreams\n                );\n            }\n\n            stateUpdate.await(millisRemaining, TimeUnit.MILLISECONDS);\n        }\n    } finally {\n        stateLock.unlock();\n    }\n}",
        "summary_tokens": [
            "starts",
            "the",
            "given",
            "kafka",
            "streams",
            "instances",
            "and",
            "waits",
            "for",
            "all",
            "of",
            "them",
            "to",
            "reach",
            "the",
            "state",
            "running",
            "state",
            "at",
            "the",
            "same",
            "time"
        ]
    },
    {
        "id": 3105,
        "code": "public static void waitForApplicationState(final List<KafkaStreams> streamsList,\n                                           final State state,\n                                           final Duration timeout) throws InterruptedException {\n    retryOnExceptionWithTimeout(timeout.toMillis(), () -> {\n        final Map<KafkaStreams, State> streamsToStates = streamsList\n            .stream()\n            .collect(Collectors.toMap(stream -> stream, KafkaStreams::state));\n\n        final Map<KafkaStreams, State> wrongStateMap = streamsToStates.entrySet()\n            .stream()\n            .filter(entry -> entry.getValue() != state)\n            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n        final String reason = String.format(\n            \"Expected all streams instances in %s to be %s within %d ms, but the following were not: %s\",\n            streamsList,\n            state,\n            timeout.toMillis(),\n            wrongStateMap\n        );\n        assertThat(reason, wrongStateMap.isEmpty());\n    });\n}",
        "summary_tokens": [
            "waits",
            "for",
            "the",
            "given",
            "kafka",
            "streams",
            "instances",
            "to",
            "all",
            "be",
            "in",
            "a",
            "specific",
            "state"
        ]
    },
    {
        "id": 3106,
        "code": "private static <V> List<V> readValues(final String topic,\n                                      final Consumer<Object, V> consumer,\n                                      final long waitTime,\n                                      final int maxMessages) {\n    final List<V> returnList = new ArrayList<>();\n    final List<KeyValue<Object, V>> kvs = readKeyValues(topic, consumer, waitTime, maxMessages);\n    for (final KeyValue<?, V> kv : kvs) {\n        returnList.add(kv.value);\n    }\n    return returnList;\n}",
        "summary_tokens": [
            "returns",
            "up",
            "to",
            "max",
            "messages",
            "message",
            "values",
            "from",
            "the",
            "topic"
        ]
    },
    {
        "id": 3107,
        "code": "private static <K, V> List<KeyValue<K, V>> readKeyValues(final String topic,\n                                                         final Consumer<K, V> consumer,\n                                                         final long waitTime,\n                                                         final int maxMessages) {\n    final List<KeyValue<K, V>> consumedValues = new ArrayList<>();\n    final List<ConsumerRecord<K, V>> records = readRecords(topic, consumer, waitTime, maxMessages);\n    for (final ConsumerRecord<K, V> record : records) {\n        consumedValues.add(new KeyValue<>(record.key(), record.value()));\n    }\n    return consumedValues;\n}",
        "summary_tokens": [
            "returns",
            "up",
            "to",
            "max",
            "messages",
            "by",
            "reading",
            "via",
            "the",
            "provided",
            "consumer",
            "the",
            "topic",
            "s",
            "to",
            "read",
            "from",
            "are",
            "already",
            "configured",
            "in",
            "the",
            "consumer"
        ]
    },
    {
        "id": 3108,
        "code": "private static <K, V> List<KeyValueTimestamp<K, V>> readKeyValuesWithTimestamp(final String topic,\n                                                                               final Consumer<K, V> consumer,\n                                                                               final long waitTime,\n                                                                               final int maxMessages) {\n    final List<KeyValueTimestamp<K, V>> consumedValues = new ArrayList<>();\n    final List<ConsumerRecord<K, V>> records = readRecords(topic, consumer, waitTime, maxMessages);\n    for (final ConsumerRecord<K, V> record : records) {\n        consumedValues.add(new KeyValueTimestamp<>(record.key(), record.value(), record.timestamp()));\n    }\n    return consumedValues;\n}",
        "summary_tokens": [
            "returns",
            "up",
            "to",
            "max",
            "messages",
            "by",
            "reading",
            "via",
            "the",
            "provided",
            "consumer",
            "the",
            "topic",
            "s",
            "to",
            "read",
            "from",
            "are",
            "already",
            "configured",
            "in",
            "the",
            "consumer"
        ]
    },
    {
        "id": 3109,
        "code": "private static <K, V> KafkaConsumer<K, V> createConsumer(final Properties consumerConfig) {\n    final Properties filtered = new Properties();\n    filtered.putAll(consumerConfig);\n    filtered.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n    filtered.setProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n    return new KafkaConsumer<>(filtered);\n}",
        "summary_tokens": [
            "sets",
            "up",
            "a",
            "kafka",
            "consumer",
            "from",
            "a",
            "copy",
            "of",
            "the",
            "given",
            "configuration",
            "that",
            "has",
            "consumer",
            "config",
            "auto",
            "offset",
            "reset",
            "config",
            "set",
            "to",
            "earliest",
            "and",
            "consumer",
            "config",
            "enable",
            "auto",
            "commit",
            "config",
            "set",
            "to",
            "true",
            "to",
            "prevent",
            "missing",
            "events",
            "as",
            "well",
            "as",
            "repeat",
            "consumption"
        ]
    },
    {
        "id": 3110,
        "code": "private Properties effectiveConfigFrom(final Properties initialConfig) {\n    final Properties effectiveConfig = new Properties();\n    effectiveConfig.put(KafkaConfig.BrokerIdProp(), 0);\n    effectiveConfig.put(KafkaConfig.NumPartitionsProp(), 1);\n    effectiveConfig.put(KafkaConfig.AutoCreateTopicsEnableProp(), true);\n    effectiveConfig.put(KafkaConfig.MessageMaxBytesProp(), 1000000);\n    effectiveConfig.put(KafkaConfig.ControlledShutdownEnableProp(), true);\n    effectiveConfig.put(KafkaConfig.ZkSessionTimeoutMsProp(), 10000);\n\n    effectiveConfig.putAll(initialConfig);\n    effectiveConfig.setProperty(KafkaConfig.LogDirProp(), logDir.getAbsolutePath());\n    return effectiveConfig;\n}",
        "summary_tokens": [
            "creates",
            "the",
            "configuration",
            "for",
            "starting",
            "the",
            "kafka",
            "broker",
            "by",
            "merging",
            "default",
            "values",
            "with",
            "overwrites"
        ]
    },
    {
        "id": 3111,
        "code": "public String brokerList() {\n    final EndPoint endPoint = kafka.advertisedListeners().head();\n    return endPoint.host() + \":\" + endPoint.port();\n}",
        "summary_tokens": [
            "this",
            "broker",
            "s",
            "metadata"
        ]
    },
    {
        "id": 3112,
        "code": "public String zookeeperConnect() {\n    return effectiveConfig.getProperty(\"zookeeper.connect\", DEFAULT_ZK_CONNECT);\n}",
        "summary_tokens": [
            "the",
            "zoo",
            "keeper",
            "connection",
            "string",
            "aka",
            "zookeeper"
        ]
    },
    {
        "id": 3113,
        "code": "public void createTopic(final String topic,\n                        final int partitions,\n                        final int replication,\n                        final Map<String, String> topicConfig) {\n    log.debug(\"Creating topic { name: {}, partitions: {}, replication: {}, config: {} }\",\n        topic, partitions, replication, topicConfig);\n    final NewTopic newTopic = new NewTopic(topic, partitions, (short) replication);\n    newTopic.configs(topicConfig);\n\n    try (final Admin adminClient = createAdminClient()) {\n        adminClient.createTopics(Collections.singletonList(newTopic)).all().get();\n    } catch (final InterruptedException | ExecutionException e) {\n        throw new RuntimeException(e);\n    }\n}",
        "summary_tokens": [
            "create",
            "a",
            "kafka",
            "topic",
            "with",
            "the",
            "given",
            "parameters"
        ]
    },
    {
        "id": 3114,
        "code": "private static byte[] mergeChangeArraysIntoSingleLegacyFormattedArray(final Change<byte[]> serialChange) {\n    if (serialChange == null) {\n        return null;\n    }\n\n    final int oldSize = serialChange.oldValue == null ? -1 : serialChange.oldValue.length;\n    final int newSize = serialChange.newValue == null ? -1 : serialChange.newValue.length;\n\n    final ByteBuffer buffer = ByteBuffer.allocate(Integer.BYTES * 2 + Math.max(0, oldSize) + Math.max(0, newSize));\n\n\n    buffer.putInt(oldSize);\n    if (serialChange.oldValue != null) {\n        buffer.put(serialChange.oldValue);\n    }\n\n    buffer.putInt(newSize);\n    if (serialChange.newValue != null) {\n        buffer.put(serialChange.newValue);\n    }\n    return buffer.array();\n}",
        "summary_tokens": [
            "we",
            "used",
            "to",
            "serialize",
            "a",
            "change",
            "into",
            "a",
            "single",
            "byte"
        ]
    },
    {
        "id": 3115,
        "code": "public void shouldForwardCurrentHeaders() {\n    final StreamsBuilder builder = new StreamsBuilder();\n\n    final KStream<Integer, String> stream1;\n    final KStream<Integer, String> stream2;\n    final KStream<Integer, String> joined;\n    final MockApiProcessorSupplier<Integer, String, Void, Void> supplier = new MockApiProcessorSupplier<>();\n    stream1 = builder.stream(topic1, consumed);\n    stream2 = builder.stream(topic2, consumed);\n\n    joined = stream1.outerJoin(\n        stream2,\n        MockValueJoiner.TOSTRING_JOINER,\n        JoinWindows.ofTimeDifferenceAndGrace(ofMillis(100L), ofMillis(10L)),\n        StreamJoined.with(Serdes.Integer(), Serdes.String(), Serdes.String())\n    );\n    joined.process(supplier);\n\n    try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), PROPS)) {\n        final TestInputTopic<Integer, String> inputTopic1 =\n            driver.createInputTopic(topic1, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n        final TestInputTopic<Integer, String> inputTopic2 =\n            driver.createInputTopic(topic2, new IntegerSerializer(), new StringSerializer(), Instant.ofEpochMilli(0L), Duration.ZERO);\n        final MockApiProcessor<Integer, String, Void, Void> processor = supplier.theCapturedProcessor();\n\n        inputTopic1.pipeInput(new TestRecord<>(\n            0,\n            \"A0\",\n            new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x1})}),\n            0L\n        ));\n        inputTopic2.pipeInput(new TestRecord<>(\n            1,\n            \"a0\",\n            new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x2})}),\n            0L\n        ));\n            \n        inputTopic2.pipeInput(new TestRecord<>(\n            3,\n            \"dummy\",\n            new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x3})}),\n            (long) 211\n        ));\n\n            \n            \n        processor.checkAndClearProcessedRecords(\n            new Record<>(\n                1,\n                \"null+a0\",\n                0L,\n                new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x3})})\n            ),\n            new Record<>(\n                0,\n                \"A0+null\",\n                0L,\n                new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x3})})\n            )\n        );\n\n            \n        inputTopic1.pipeInput(new TestRecord<>(\n            2,\n            \"A2\",\n            new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x4})}),\n            200L\n        ));\n        inputTopic2.pipeInput(new TestRecord<>(\n            2,\n            \"a2\",\n            new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x5})}),\n            200L\n        ));\n\n        processor.checkAndClearProcessedRecords(\n            new Record<>(\n                2,\n                \"A2+a2\",\n                200L,\n                new RecordHeaders(new Header[]{new RecordHeader(\"h\", new byte[]{0x5})})\n            )\n        );\n    }\n}",
        "summary_tokens": [
            "note",
            "header",
            "forwarding",
            "is",
            "undefined",
            "behavior",
            "but",
            "we",
            "still",
            "want",
            "to",
            "understand",
            "the",
            "behavior",
            "so",
            "that",
            "we",
            "can",
            "make",
            "decisions",
            "about",
            "defining",
            "it",
            "in",
            "the",
            "future"
        ]
    },
    {
        "id": 3116,
        "code": "public void shouldNotThrowIllegalStateExceptionWhenMultiCacheEvictions() {\n    final String agg = \"agg\";\n    final String tableOne = \"tableOne\";\n    final String tableTwo = \"tableTwo\";\n    final String tableThree = \"tableThree\";\n    final String tableFour = \"tableFour\";\n    final String tableFive = \"tableFive\";\n    final String tableSix = \"tableSix\";\n    final String[] inputs = {agg, tableOne, tableTwo, tableThree, tableFour, tableFive, tableSix};\n\n    final StreamsBuilder builder = new StreamsBuilder();\n    final Consumed<Long, String> consumed = Consumed.with(Serdes.Long(), Serdes.String());\n    final KTable<Long, String> aggTable = builder\n        .table(agg, consumed, Materialized.as(Stores.inMemoryKeyValueStore(\"agg-base-store\")))\n        .groupBy(KeyValue::new, Grouped.with(Serdes.Long(), Serdes.String()))\n        .reduce(\n            MockReducer.STRING_ADDER,\n            MockReducer.STRING_ADDER,\n            Materialized.as(Stores.inMemoryKeyValueStore(\"agg-store\")));\n\n    final KTable<Long, String> one = builder.table(\n        tableOne,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableOne-base-store\")));\n    final KTable<Long, String> two = builder.table(\n        tableTwo,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableTwo-base-store\")));\n    final KTable<Long, String> three = builder.table(\n        tableThree,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableThree-base-store\")));\n    final KTable<Long, String> four = builder.table(\n        tableFour,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableFour-base-store\")));\n    final KTable<Long, String> five = builder.table(\n        tableFive,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableFive-base-store\")));\n    final KTable<Long, String> six = builder.table(\n        tableSix,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableSix-base-store\")));\n\n    final ValueMapper<String, String> mapper = value -> value.toUpperCase(Locale.ROOT);\n\n    final KTable<Long, String> seven = one.mapValues(mapper);\n\n    final KTable<Long, String> eight = six.leftJoin(seven, MockValueJoiner.TOSTRING_JOINER);\n\n    aggTable\n        .leftJoin(one, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(two, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(three, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(four, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(five, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(eight, MockValueJoiner.TOSTRING_JOINER)\n        .mapValues(mapper);\n\n    try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n        final String[] values = {\n            \"a\", \"AA\", \"BBB\", \"CCCC\", \"DD\", \"EEEEEEEE\", \"F\", \"GGGGGGGGGGGGGGG\", \"HHH\", \"IIIIIIIIII\",\n            \"J\", \"KK\", \"LLLL\", \"MMMMMMMMMMMMMMMMMMMMMM\", \"NNNNN\", \"O\", \"P\", \"QQQQQ\", \"R\", \"SSSS\",\n            \"T\", \"UU\", \"VVVVVVVVVVVVVVVVVVV\"\n        };\n\n        TestInputTopic<Long, String> inputTopic;\n        final Random random = new Random();\n        for (int i = 0; i < 1000; i++) {\n            for (final String input : inputs) {\n                final Long key = (long) random.nextInt(1000);\n                final String value = values[random.nextInt(values.length)];\n                inputTopic = driver.createInputTopic(input, Serdes.Long().serializer(), Serdes.String().serializer());\n                inputTopic.pipeInput(key, value);\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "this",
            "test",
            "was",
            "written",
            "to",
            "reproduce",
            "https",
            "issues"
        ]
    },
    {
        "id": 3117,
        "code": "public void finalResultsWithZeroGraceShouldStillBufferUntilTheWindowEnd() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(finalResults(ofMillis(0L)), timeWindowedSerdeFrom(String.class, 100L), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n        \n        \n    final long timestamp = 5L;\n    final long windowEnd = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final Windowed<String> key = new Windowed<>(\"hey\", new TimeWindow(0, windowEnd));\n    final Change<Long> value = ARBITRARY_CHANGE;\n    harness.processor.process(new Record<>(key, value, timestamp));\n    assertThat(context.forwarded(), hasSize(0));\n\n    context.setRecordMetadata(\"\", 0, 1L);\n    context.setTimestamp(windowEnd);\n    harness.processor.process(new Record<>(new Windowed<>(\"dummyKey\", new TimeWindow(windowEnd, windowEnd + 100L)), ARBITRARY_CHANGE, windowEnd));\n\n    assertThat(context.forwarded(), hasSize(1));\n    final MockProcessorContext.CapturedForward capturedForward = context.forwarded().get(0);\n    assertThat(capturedForward.record(), is(new Record<>(key, value, timestamp)));\n}",
        "summary_tokens": [
            "testing",
            "a",
            "special",
            "case",
            "of",
            "final",
            "results",
            "that",
            "even",
            "with",
            "a",
            "grace",
            "period",
            "of",
            "0",
            "it",
            "will",
            "still",
            "buffer",
            "events",
            "and",
            "emit",
            "only",
            "after",
            "the",
            "end",
            "of",
            "the",
            "window"
        ]
    },
    {
        "id": 3118,
        "code": "public void finalResultsShouldDropTombstonesForTimeWindows() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(finalResults(ofMillis(0L)), timeWindowedSerdeFrom(String.class, 100L), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final Windowed<String> key = new Windowed<>(\"hey\", new TimeWindow(0, 100L));\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(0));\n}",
        "summary_tokens": [
            "it",
            "s",
            "desirable",
            "to",
            "drop",
            "tombstones",
            "for",
            "final",
            "results",
            "windowed",
            "streams",
            "since",
            "as",
            "described",
            "in",
            "the",
            "suppressed",
            "internal",
            "javadoc",
            "they",
            "are",
            "unnecessary",
            "to",
            "emit"
        ]
    },
    {
        "id": 3119,
        "code": "public void finalResultsShouldDropTombstonesForSessionWindows() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(finalResults(ofMillis(0L)), sessionWindowedSerdeFrom(String.class), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final Windowed<String> key = new Windowed<>(\"hey\", new SessionWindow(0L, 0L));\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(0));\n}",
        "summary_tokens": [
            "it",
            "s",
            "desirable",
            "to",
            "drop",
            "tombstones",
            "for",
            "final",
            "results",
            "windowed",
            "streams",
            "since",
            "as",
            "described",
            "in",
            "the",
            "suppressed",
            "internal",
            "javadoc",
            "they",
            "are",
            "unnecessary",
            "to",
            "emit"
        ]
    },
    {
        "id": 3120,
        "code": "public void suppressShouldNotDropTombstonesForTimeWindows() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(untilTimeLimit(ofMillis(0), maxRecords(0)), timeWindowedSerdeFrom(String.class, 100L), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    final Headers headers = new RecordHeaders().add(\"k\", \"v\".getBytes(StandardCharsets.UTF_8));\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    context.setHeaders(headers);\n    final Windowed<String> key = new Windowed<>(\"hey\", new TimeWindow(0L, 100L));\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(1));\n    final MockProcessorContext.CapturedForward capturedForward = context.forwarded().get(0);\n    assertThat(capturedForward.record(), is(new Record<>(key, value, timestamp, headers)));\n}",
        "summary_tokens": [
            "it",
            "s",
            "not",
            "ok",
            "to",
            "drop",
            "tombstones",
            "for",
            "non",
            "final",
            "results",
            "windowed",
            "streams",
            "since",
            "we",
            "may",
            "have",
            "emitted",
            "some",
            "results",
            "for",
            "the",
            "window",
            "before",
            "getting",
            "the",
            "tombstone",
            "see",
            "the",
            "suppressed",
            "internal",
            "javadoc"
        ]
    },
    {
        "id": 3121,
        "code": "public void suppressShouldNotDropTombstonesForSessionWindows() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(untilTimeLimit(ofMillis(0), maxRecords(0)), sessionWindowedSerdeFrom(String.class), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final Windowed<String> key = new Windowed<>(\"hey\", new SessionWindow(0L, 0L));\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(1));\n    final MockProcessorContext.CapturedForward capturedForward = context.forwarded().get(0);\n    assertThat(capturedForward.record(), is(new Record<>(key, value, timestamp)));\n}",
        "summary_tokens": [
            "it",
            "s",
            "not",
            "ok",
            "to",
            "drop",
            "tombstones",
            "for",
            "non",
            "final",
            "results",
            "windowed",
            "streams",
            "since",
            "we",
            "may",
            "have",
            "emitted",
            "some",
            "results",
            "for",
            "the",
            "window",
            "before",
            "getting",
            "the",
            "tombstone",
            "see",
            "the",
            "suppressed",
            "internal",
            "javadoc"
        ]
    },
    {
        "id": 3122,
        "code": "public void suppressShouldNotDropTombstonesForKTable() {\n    final Harness<String, Long> harness =\n        new Harness<>(untilTimeLimit(ofMillis(0), maxRecords(0)), String(), Long());\n    final MockInternalNewProcessorContext<String, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final String key = \"hey\";\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(1));\n    final MockProcessorContext.CapturedForward capturedForward = context.forwarded().get(0);\n    assertThat(capturedForward.record(), is(new Record<>(key, value, timestamp)));\n}",
        "summary_tokens": [
            "it",
            "s",
            "super",
            "not",
            "ok",
            "to",
            "drop",
            "tombstones",
            "for",
            "non",
            "windowed",
            "streams",
            "since",
            "we",
            "may",
            "have",
            "emitted",
            "some",
            "results",
            "for",
            "the",
            "key",
            "before",
            "getting",
            "the",
            "tombstone",
            "see",
            "the",
            "suppressed",
            "internal",
            "javadoc"
        ]
    },
    {
        "id": 3123,
        "code": "private static Map<TopicPartition, Long> getTopicPartitionOffsetsMap(final List<String> changelogTopics,\n                                                                     final List<Integer> topicsNumPartitions) {\n    if (changelogTopics.size() != topicsNumPartitions.size()) {\n        throw new IllegalStateException(\"Passed in \" + changelogTopics.size() + \" changelog topic names, but \" +\n                                            topicsNumPartitions.size() + \" different numPartitions for the topics\");\n    }\n    final Map<TopicPartition, Long> changelogEndOffsets = new HashMap<>();\n    for (int i = 0; i < changelogTopics.size(); ++i) {\n        final String topic = changelogTopics.get(i);\n        final int numPartitions = topicsNumPartitions.get(i);\n        for (int partition = 0; partition < numPartitions; ++partition) {\n            changelogEndOffsets.put(new TopicPartition(topic, partition), Long.MAX_VALUE);\n        }\n    }\n    return changelogEndOffsets;\n}",
        "summary_tokens": [
            "helper",
            "for",
            "building",
            "the",
            "input",
            "to",
            "create",
            "mock",
            "admin",
            "client",
            "in",
            "cases",
            "where",
            "we",
            "don",
            "t",
            "care",
            "about",
            "the",
            "actual",
            "offsets",
            "changelog",
            "topics",
            "the",
            "names",
            "of",
            "all",
            "changelog",
            "topics",
            "in",
            "the",
            "topology",
            "topics",
            "num",
            "partitions",
            "the",
            "number",
            "of",
            "partitions",
            "for",
            "the",
            "corresponding",
            "changelog",
            "topic",
            "such",
            "that",
            "the",
            "number",
            "of",
            "partitions",
            "of",
            "the",
            "ith",
            "topic",
            "in",
            "changelog",
            "topics",
            "is",
            "given",
            "by",
            "the",
            "ith",
            "element",
            "of",
            "topics",
            "num",
            "partitions"
        ]
    },
    {
        "id": 3124,
        "code": "private static Map<TopicPartition, Long> getTopicPartitionOffsetsMap(final List<String> changelogTopics,\n                                                                     final List<Integer> topicsNumPartitions) {\n    if (changelogTopics.size() != topicsNumPartitions.size()) {\n        throw new IllegalStateException(\"Passed in \" + changelogTopics.size() + \" changelog topic names, but \" +\n                topicsNumPartitions.size() + \" different numPartitions for the topics\");\n    }\n    final Map<TopicPartition, Long> changelogEndOffsets = new HashMap<>();\n    for (int i = 0; i < changelogTopics.size(); ++i) {\n        final String topic = changelogTopics.get(i);\n        final int numPartitions = topicsNumPartitions.get(i);\n        for (int partition = 0; partition < numPartitions; ++partition) {\n            changelogEndOffsets.put(new TopicPartition(topic, partition), Long.MAX_VALUE);\n        }\n    }\n    return changelogEndOffsets;\n}",
        "summary_tokens": [
            "helper",
            "for",
            "building",
            "the",
            "input",
            "to",
            "create",
            "mock",
            "admin",
            "client",
            "in",
            "cases",
            "where",
            "we",
            "don",
            "t",
            "care",
            "about",
            "the",
            "actual",
            "offsets",
            "changelog",
            "topics",
            "the",
            "names",
            "of",
            "all",
            "changelog",
            "topics",
            "in",
            "the",
            "topology",
            "topics",
            "num",
            "partitions",
            "the",
            "number",
            "of",
            "partitions",
            "for",
            "the",
            "corresponding",
            "changelog",
            "topic",
            "such",
            "that",
            "the",
            "number",
            "of",
            "partitions",
            "of",
            "the",
            "ith",
            "topic",
            "in",
            "changelog",
            "topics",
            "is",
            "given",
            "by",
            "the",
            "ith",
            "element",
            "of",
            "topics",
            "num",
            "partitions"
        ]
    },
    {
        "id": 3125,
        "code": "public void testHighAvailabilityTaskAssignorLargePartitionCount() {\n    completeLargeAssignment(6_000, 2, 1, 1, HighAvailabilityTaskAssignor.class);\n}",
        "summary_tokens": [
            "high",
            "availability",
            "task",
            "assignor",
            "tests"
        ]
    },
    {
        "id": 3126,
        "code": "public void testStickyTaskAssignorLargePartitionCount() {\n    completeLargeAssignment(2_000, 2, 1, 1, StickyTaskAssignor.class);\n}",
        "summary_tokens": [
            "sticky",
            "task",
            "assignor",
            "tests"
        ]
    },
    {
        "id": 3127,
        "code": "public void testFallbackPriorTaskAssignorLargePartitionCount() {\n    completeLargeAssignment(2_000, 2, 1, 1, FallbackPriorTaskAssignor.class);\n}",
        "summary_tokens": [
            "fallback",
            "prior",
            "task",
            "assignor",
            "tests"
        ]
    },
    {
        "id": 3128,
        "code": "private static Map<TopicPartition, Long> getTopicPartitionOffsetsMap(final List<String> changelogTopics,\n                                                                     final List<Integer> topicsNumPartitions) {\n    if (changelogTopics.size() != topicsNumPartitions.size()) {\n        throw new IllegalStateException(\"Passed in \" + changelogTopics.size() + \" changelog topic names, but \" +\n                                           topicsNumPartitions.size() + \" different numPartitions for the topics\");\n    }\n    final Map<TopicPartition, Long> changelogEndOffsets = new HashMap<>();\n    for (int i = 0; i < changelogTopics.size(); ++i) {\n        final String topic = changelogTopics.get(i);\n        final int numPartitions = topicsNumPartitions.get(i);\n        for (int partition = 0; partition < numPartitions; ++partition) {\n            changelogEndOffsets.put(new TopicPartition(topic, partition), Long.MAX_VALUE);\n        }\n    }\n    return changelogEndOffsets;\n}",
        "summary_tokens": [
            "helper",
            "for",
            "building",
            "the",
            "input",
            "to",
            "create",
            "mock",
            "admin",
            "client",
            "in",
            "cases",
            "where",
            "we",
            "don",
            "t",
            "care",
            "about",
            "the",
            "actual",
            "offsets",
            "changelog",
            "topics",
            "the",
            "names",
            "of",
            "all",
            "changelog",
            "topics",
            "in",
            "the",
            "topology",
            "topics",
            "num",
            "partitions",
            "the",
            "number",
            "of",
            "partitions",
            "for",
            "the",
            "corresponding",
            "changelog",
            "topic",
            "such",
            "that",
            "the",
            "number",
            "of",
            "partitions",
            "of",
            "the",
            "ith",
            "topic",
            "in",
            "changelog",
            "topics",
            "is",
            "given",
            "by",
            "the",
            "ith",
            "element",
            "of",
            "topics",
            "num",
            "partitions"
        ]
    },
    {
        "id": 3129,
        "code": "public static UUID uuidForInt(final int n) {\n    return new UUID(0, n);\n}",
        "summary_tokens": [
            "builds",
            "a",
            "uuid",
            "by",
            "repeating",
            "the",
            "given",
            "number",
            "n"
        ]
    },
    {
        "id": 3130,
        "code": "public ByteBuffer encode() {\n    if (usedVersion == 3 || usedVersion == 4 || usedVersion == 5 || usedVersion == 6) {\n        final byte[] endPointBytes = prepareUserEndPoint(this.userEndPoint);\n\n        final ByteBuffer buf = ByteBuffer.allocate(\n            4 + \n                4 + \n                16 + \n                4 + prevTasks.size() * 8 + \n                4 + standbyTasks.size() * 8 + \n                4 + endPointBytes.length\n        );\n\n        buf.putInt(usedVersion); \n        buf.putInt(LATEST_SUPPORTED_VERSION); \n        encodeClientUUID(buf, processId());\n        encodeTasks(buf, prevTasks, usedVersion);\n        encodeTasks(buf, standbyTasks, usedVersion);\n        encodeUserEndPoint(buf, endPointBytes);\n\n        buf.rewind();\n\n        return buf;\n    } else if (usedVersion == 2) {\n        final byte[] endPointBytes = prepareUserEndPoint(this.userEndPoint);\n\n        final ByteBuffer buf = ByteBuffer.allocate(\n            4 + \n                16 + \n                4 + prevTasks.size() * 8 + \n                4 + standbyTasks.size() * 8 + \n                4 + endPointBytes.length\n        );\n\n        buf.putInt(2); \n        encodeClientUUID(buf, processId());\n        encodeTasks(buf, prevTasks, usedVersion);\n        encodeTasks(buf, standbyTasks, usedVersion);\n        encodeUserEndPoint(buf, endPointBytes);\n\n        buf.rewind();\n\n        return buf;\n    } else if (usedVersion == 1) {\n        final ByteBuffer buf1 = ByteBuffer.allocate(\n            4 + \n                16 + \n                4 + prevTasks.size() * 8 + \n                4 + standbyTasks.size() * 8\n        );\n\n        buf1.putInt(1); \n        encodeClientUUID(buf1, processId());\n        encodeTasks(buf1, prevTasks, usedVersion);\n        encodeTasks(buf1, standbyTasks, usedVersion);\n        buf1.rewind();\n        return buf1;\n    } else {\n        throw new IllegalStateException(\"Unknown metadata version: \" + usedVersion\n                                            + \"; latest supported version: \" + LATEST_SUPPORTED_VERSION);\n    }\n}",
        "summary_tokens": [
            "task",
            "assignment",
            "exception",
            "if",
            "method",
            "fails",
            "to",
            "encode",
            "the",
            "data"
        ]
    },
    {
        "id": 3131,
        "code": "public static LegacySubscriptionInfoSerde decode(final ByteBuffer data) {\n\n        \n    data.rewind();\n\n    final int usedVersion = data.getInt();\n    if (usedVersion > 2 && usedVersion < 7) {\n        final int latestSupportedVersion = data.getInt();\n        final UUID processId = decodeProcessId(data);\n        final Set<TaskId> prevTasks = decodeTasks(data, usedVersion);\n        final Set<TaskId> standbyTasks = decodeTasks(data, usedVersion);\n        final String userEndPoint = decodeUserEndpoint(data);\n        return new LegacySubscriptionInfoSerde(usedVersion, latestSupportedVersion, processId, prevTasks, standbyTasks, userEndPoint);\n    } else if (usedVersion == 2) {\n        final UUID processId = decodeProcessId(data);\n        final Set<TaskId> prevTasks = decodeTasks(data, usedVersion);\n        final Set<TaskId> standbyTasks = decodeTasks(data, usedVersion);\n        final String userEndPoint = decodeUserEndpoint(data);\n        return new LegacySubscriptionInfoSerde(2, UNKNOWN, processId, prevTasks, standbyTasks, userEndPoint);\n    } else if (usedVersion == 1) {\n        final UUID processId = decodeProcessId(data);\n        final Set<TaskId> prevTasks = decodeTasks(data, usedVersion);\n        final Set<TaskId> standbyTasks = decodeTasks(data, usedVersion);\n        return new LegacySubscriptionInfoSerde(1, UNKNOWN, processId, prevTasks, standbyTasks, null);\n    } else {\n        final int latestSupportedVersion = data.getInt();\n        log.info(\"Unable to decode subscription data: used version: {}; latest supported version: {}\", usedVersion, LATEST_SUPPORTED_VERSION);\n        return new LegacySubscriptionInfoSerde(usedVersion, latestSupportedVersion, null, null, null, null);\n    }\n}",
        "summary_tokens": [
            "task",
            "assignment",
            "exception",
            "if",
            "method",
            "fails",
            "to",
            "decode",
            "the",
            "data"
        ]
    },
    {
        "id": 3132,
        "code": "private static SortedSet<UUID> mkOrderedSet(final UUID... clients) {\n    final List<UUID> clientList = asList(clients);\n    final SortedSet<UUID> set = new TreeSet<>(Comparator.comparing(clientList::indexOf));\n    set.addAll(clientList);\n    return set;\n}",
        "summary_tokens": [
            "creates",
            "a",
            "sorted",
            "set",
            "with",
            "the",
            "sort",
            "order",
            "being",
            "the",
            "order",
            "of",
            "elements",
            "in",
            "the",
            "parameter",
            "list"
        ]
    },
    {
        "id": 3133,
        "code": "public static <K, V> KeyValueStoreTestDriver<K, V> create(final Serializer<K> keySerializer,\n                                                          final Deserializer<K> keyDeserializer,\n                                                          final Serializer<V> valueSerializer,\n                                                          final Deserializer<V> valueDeserializer) {\n    final StateSerdes<K, V> serdes = new StateSerdes<>(\n        \"unexpected\",\n        Serdes.serdeFrom(keySerializer, keyDeserializer),\n        Serdes.serdeFrom(valueSerializer, valueDeserializer));\n    return new KeyValueStoreTestDriver<>(serdes);\n}",
        "summary_tokens": [
            "create",
            "a",
            "driver",
            "object",
            "that",
            "will",
            "have",
            "a",
            "context",
            "that",
            "records",
            "messages",
            "processor",
            "context",
            "forward",
            "object",
            "object",
            "forwarded",
            "by",
            "the",
            "store",
            "and",
            "that",
            "provides",
            "the",
            "specified",
            "serializers",
            "and",
            "deserializers"
        ]
    },
    {
        "id": 3134,
        "code": "public Iterable<KeyValue<byte[], byte[]>> restoredEntries() {\n    return restorableEntries;\n}",
        "summary_tokens": [
            "get",
            "the",
            "entries",
            "that",
            "are",
            "restored",
            "to",
            "a",
            "key",
            "value",
            "store",
            "when",
            "it",
            "is",
            "constructed",
            "with",
            "this",
            "driver",
            "s",
            "context",
            "processor",
            "context"
        ]
    },
    {
        "id": 3135,
        "code": "public void addEntryToRestoreLog(final K key, final V value) {\n    restorableEntries.add(new KeyValue<>(stateSerdes.rawKey(key), stateSerdes.rawValue(value)));\n}",
        "summary_tokens": [
            "this",
            "method",
            "adds",
            "an",
            "entry",
            "to",
            "the",
            "restore",
            "log",
            "for",
            "the",
            "key",
            "value",
            "store",
            "and",
            "is",
            "used",
            "em",
            "only",
            "em",
            "when",
            "testing",
            "the",
            "restore",
            "functionality",
            "of",
            "a",
            "key",
            "value",
            "store",
            "implementation"
        ]
    },
    {
        "id": 3136,
        "code": "public StateStoreContext context() {\n    return context;\n}",
        "summary_tokens": [
            "get",
            "the",
            "context",
            "that",
            "should",
            "be",
            "supplied",
            "to",
            "a",
            "key",
            "value",
            "store",
            "s",
            "constructor"
        ]
    },
    {
        "id": 3137,
        "code": "public int checkForRestoredEntries(final KeyValueStore<K, V> store) {\n    int missing = 0;\n    for (final KeyValue<byte[], byte[]> kv : restorableEntries) {\n        if (kv != null) {\n            final V value = store.get(stateSerdes.keyFrom(kv.key));\n            if (!Objects.equals(value, stateSerdes.valueFrom(kv.value))) {\n                ++missing;\n            }\n        }\n    }\n    return missing;\n}",
        "summary_tokens": [
            "utility",
            "method",
            "that",
            "will",
            "count",
            "the",
            "number",
            "of",
            "add",
            "entry",
            "to",
            "restore",
            "log",
            "object",
            "object",
            "restore",
            "entries",
            "missing",
            "from",
            "the",
            "supplied",
            "store"
        ]
    },
    {
        "id": 3138,
        "code": "public int sizeOf(final KeyValueStore<K, V> store) {\n    int size = 0;\n    try (final KeyValueIterator<K, V> iterator = store.all()) {\n        while (iterator.hasNext()) {\n            iterator.next();\n            ++size;\n        }\n    }\n    return size;\n}",
        "summary_tokens": [
            "utility",
            "method",
            "to",
            "compute",
            "the",
            "number",
            "of",
            "entries",
            "within",
            "the",
            "store"
        ]
    },
    {
        "id": 3139,
        "code": "public V flushedEntryStored(final K key) {\n    return flushedEntries.get(key);\n}",
        "summary_tokens": [
            "retrieve",
            "the",
            "value",
            "that",
            "the",
            "store",
            "key",
            "value",
            "store",
            "flush",
            "flushed",
            "with",
            "the",
            "given",
            "key"
        ]
    },
    {
        "id": 3140,
        "code": "public boolean flushedEntryRemoved(final K key) {\n    return flushedRemovals.contains(key);\n}",
        "summary_tokens": [
            "determine",
            "whether",
            "the",
            "store",
            "key",
            "value",
            "store",
            "flush",
            "flushed",
            "the",
            "removal",
            "of",
            "the",
            "given",
            "key"
        ]
    },
    {
        "id": 3141,
        "code": "public int numFlushedEntryStored() {\n    return flushedEntries.size();\n}",
        "summary_tokens": [
            "return",
            "number",
            "of",
            "removed",
            "entry"
        ]
    },
    {
        "id": 3142,
        "code": "public int numFlushedEntryRemoved() {\n    return flushedRemovals.size();\n}",
        "summary_tokens": [
            "return",
            "number",
            "of",
            "removed",
            "entry"
        ]
    },
    {
        "id": 3143,
        "code": "public void clear() {\n    restorableEntries.clear();\n    flushedEntries.clear();\n    flushedRemovals.clear();\n}",
        "summary_tokens": [
            "remove",
            "all",
            "flushed",
            "entry",
            "stored",
            "object",
            "flushed",
            "entries",
            "flushed",
            "entry",
            "removed",
            "object",
            "flushed",
            "removals"
        ]
    },
    {
        "id": 3144,
        "code": "static void writeVersion0(final Map<TopicPartition, Long> offsets, final File file) throws IOException {\n    final FileOutputStream fileOutputStream = new FileOutputStream(file);\n    try (final BufferedWriter writer = new BufferedWriter(\n        new OutputStreamWriter(fileOutputStream, StandardCharsets.UTF_8))) {\n        writeIntLine(writer, 0);\n        writeIntLine(writer, offsets.size());\n\n        for (final Map.Entry<TopicPartition, Long> entry : offsets.entrySet()) {\n            final TopicPartition tp = entry.getKey();\n            final Long offset = entry.getValue();\n            writeEntry(writer, tp, offset);\n        }\n\n        writer.flush();\n        fileOutputStream.getFD().sync();\n    }\n}",
        "summary_tokens": [
            "write",
            "all",
            "the",
            "offsets",
            "following",
            "the",
            "version",
            "0",
            "format",
            "without",
            "any",
            "verification",
            "eg",
            "enforcing",
            "offsets",
            "0"
        ]
    },
    {
        "id": 3145,
        "code": "private static Map<String, String> updatedConfigs(final String formattedConfigs) {\n    final String[] parts = formattedConfigs.split(\",\");\n    final Map<String, String> updatedConfigs = new HashMap<>();\n    for (final String part : parts) {\n        final String[] keyValue = part.split(\"=\");\n        updatedConfigs.put(keyValue[KEY], keyValue[VALUE]);\n    }\n    return updatedConfigs;\n}",
        "summary_tokens": [
            "takes",
            "a",
            "string",
            "with",
            "keys",
            "and",
            "values",
            "separated",
            "by",
            "and",
            "each",
            "key",
            "value",
            "pair",
            "separated",
            "by",
            "for",
            "example",
            "max"
        ]
    },
    {
        "id": 3146,
        "code": "public static void main(final String[] args) throws IOException {\n    if (args.length < 2) {\n        System.err.println(\"StreamsEosTest are expecting two parameters: propFile, command; but only see \" + args.length + \" parameter\");\n        Exit.exit(1);\n    }\n\n    final String propFileName = args[0];\n    final String command = args[1];\n\n    final Properties streamsProperties = Utils.loadProps(propFileName);\n    final String kafka = streamsProperties.getProperty(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG);\n    final String processingGuarantee = streamsProperties.getProperty(StreamsConfig.PROCESSING_GUARANTEE_CONFIG);\n\n    if (kafka == null) {\n        System.err.println(\"No bootstrap kafka servers specified in \" + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG);\n        Exit.exit(1);\n    }\n\n    if (\"process\".equals(command) || \"process-complex\".equals(command)) {\n        if (!StreamsConfig.EXACTLY_ONCE.equals(processingGuarantee) &&\n            !StreamsConfig.EXACTLY_ONCE_BETA.equals(processingGuarantee) &&\n            !StreamsConfig.EXACTLY_ONCE_V2.equals(processingGuarantee)) {\n\n            System.err.println(\"processingGuarantee must be either \" + StreamsConfig.EXACTLY_ONCE + \" or \" +\n                                   StreamsConfig.EXACTLY_ONCE_BETA + \" or \" + StreamsConfig.EXACTLY_ONCE_V2);\n            Exit.exit(1);\n        }\n    }\n\n    System.out.println(\"StreamsTest instance started\");\n    System.out.println(\"kafka=\" + kafka);\n    System.out.println(\"props=\" + streamsProperties);\n    System.out.println(\"command=\" + command);\n    System.out.flush();\n\n    if (command == null || propFileName == null) {\n        Exit.exit(-1);\n    }\n\n    switch (command) {\n        case \"run\":\n            EosTestDriver.generate(kafka);\n            break;\n        case \"process\":\n            new EosTestClient(streamsProperties, false).start();\n            break;\n        case \"process-complex\":\n            new EosTestClient(streamsProperties, true).start();\n            break;\n        case \"verify\":\n            EosTestDriver.verify(kafka, false);\n            break;\n        case \"verify-complex\":\n            EosTestDriver.verify(kafka, true);\n            break;\n        default:\n            System.out.println(\"unknown command: \" + command);\n            System.out.flush();\n            Exit.exit(-1);\n    }\n}",
        "summary_tokens": [
            "args",
            "kafka",
            "prop",
            "file",
            "name",
            "command",
            "command",
            "run",
            "process",
            "verify"
        ]
    },
    {
        "id": 3147,
        "code": "public static void main(final String[] args) throws IOException {\n    if (args.length < 2) {\n        System.err.println(\"StreamsSmokeTest are expecting two parameters: propFile, command; but only see \" + args.length + \" parameter\");\n        Exit.exit(1);\n    }\n\n    final String propFileName = args[0];\n    final String command = args[1];\n    final boolean disableAutoTerminate = args.length > 2;\n\n    final Properties streamsProperties = Utils.loadProps(propFileName);\n    final String kafka = streamsProperties.getProperty(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG);\n    final String processingGuarantee = streamsProperties.getProperty(StreamsConfig.PROCESSING_GUARANTEE_CONFIG);\n\n    if (kafka == null) {\n        System.err.println(\"No bootstrap kafka servers specified in \" + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG);\n        Exit.exit(1);\n    }\n\n    if (\"process\".equals(command)) {\n        if (!StreamsConfig.AT_LEAST_ONCE.equals(processingGuarantee) &&\n            !StreamsConfig.EXACTLY_ONCE_V2.equals(processingGuarantee)) {\n\n            System.err.println(\"processingGuarantee must be either \" + StreamsConfig.AT_LEAST_ONCE + \" or \" +\n                StreamsConfig.EXACTLY_ONCE_V2);\n\n            Exit.exit(1);\n        }\n    }\n\n    System.out.println(\"StreamsTest instance started (StreamsSmokeTest)\");\n    System.out.println(\"command=\" + command);\n    System.out.println(\"props=\" + streamsProperties);\n    System.out.println(\"disableAutoTerminate=\" + disableAutoTerminate);\n\n    switch (command) {\n        case \"run\":\n                \n            final int numKeys = 10;\n            final int maxRecordsPerKey = 500;\n            if (disableAutoTerminate) {\n                generatePerpetually(kafka, numKeys, maxRecordsPerKey);\n            } else {\n                    \n                    \n                final Map<String, Set<Integer>> allData =\n                    generate(kafka, numKeys, maxRecordsPerKey, Duration.ofSeconds(30));\n                SmokeTestDriver.verify(kafka, allData, maxRecordsPerKey);\n            }\n            break;\n        case \"process\":\n                \n            new SmokeTestClient(UUID.randomUUID().toString()).start(streamsProperties);\n            break;\n        default:\n            System.out.println(\"unknown command: \" + command);\n    }\n}",
        "summary_tokens": [
            "args",
            "kafka",
            "prop",
            "file",
            "name",
            "command",
            "disable",
            "auto",
            "terminate",
            "command",
            "run",
            "process"
        ]
    },
    {
        "id": 3148,
        "code": "public static Map<String, String> parseConfigs(final String formattedConfigs) {\n    Objects.requireNonNull(formattedConfigs, \"Formatted config String can't be null\");\n\n    if (formattedConfigs.indexOf('=') == -1) {\n        throw new IllegalStateException(String.format(\"Provided string [ %s ] does not have expected key-value separator of '='\", formattedConfigs));\n    }\n\n    final String[] parts = formattedConfigs.split(\",\");\n    final Map<String, String> configs = new HashMap<>();\n    for (final String part : parts) {\n        final String[] keyValue = part.split(\"=\");\n        if (keyValue.length > 2) {\n            throw new IllegalStateException(\n                String.format(\"Provided string [ %s ] does not have expected key-value pair separator of ','\", formattedConfigs));\n        }\n        configs.put(keyValue[KEY], keyValue[VALUE]);\n    }\n    return configs;\n}",
        "summary_tokens": [
            "takes",
            "a",
            "string",
            "with",
            "keys",
            "and",
            "values",
            "separated",
            "by",
            "and",
            "each",
            "key",
            "value",
            "pair",
            "separated",
            "by",
            "for",
            "example",
            "max"
        ]
    },
    {
        "id": 3149,
        "code": "public static boolean isCheckSupplierCall() {\n    return Arrays.stream(Thread.currentThread().getStackTrace())\n            .anyMatch(caller -> \"org.apache.kafka.streams.internals.ApiUtils\".equals(caller.getClassName()) && \"checkSupplier\".equals(caller.getMethodName()));\n}",
        "summary_tokens": [
            "used",
            "to",
            "keep",
            "tests",
            "simple",
            "and",
            "ignore",
            "calls",
            "from",
            "org"
        ]
    },
    {
        "id": 3150,
        "code": "public void advanceTime(final Duration advance) {\n    if (advance.isNegative()) {\n        throw new IllegalArgumentException(\"advance must be positive\");\n    }\n    currentTime = currentTime.plus(advance);\n}",
        "summary_tokens": [
            "advances",
            "the",
            "internally",
            "tracked",
            "event",
            "time",
            "of",
            "this",
            "input",
            "topic"
        ]
    },
    {
        "id": 3151,
        "code": "public void pipeInput(final K key,\n                      final V value,\n                      final Instant timestamp) {\n    pipeInput(new TestRecord<>(key, value, timestamp));\n}",
        "summary_tokens": [
            "send",
            "an",
            "input",
            "record",
            "with",
            "the",
            "given",
            "key",
            "value",
            "and",
            "timestamp",
            "on",
            "the",
            "topic",
            "and",
            "then",
            "commit",
            "the",
            "records"
        ]
    },
    {
        "id": 3152,
        "code": "public void pipeRecordList(final List<? extends TestRecord<K, V>> records) {\n    for (final TestRecord<K, V> record : records) {\n        pipeInput(record);\n    }\n}",
        "summary_tokens": [
            "send",
            "input",
            "records",
            "with",
            "the",
            "given",
            "key",
            "value",
            "list",
            "on",
            "the",
            "topic",
            "then",
            "commit",
            "each",
            "record",
            "individually"
        ]
    },
    {
        "id": 3153,
        "code": "public void pipeKeyValueList(final List<KeyValue<K, V>> keyValues,\n                             final Instant startTimestamp,\n                             final Duration advance) {\n    Instant recordTime = startTimestamp;\n    for (final KeyValue<K, V> keyValue : keyValues) {\n        pipeInput(keyValue.key, keyValue.value, recordTime);\n        recordTime = recordTime.plus(advance);\n    }\n}",
        "summary_tokens": [
            "send",
            "input",
            "records",
            "with",
            "the",
            "given",
            "key",
            "value",
            "list",
            "on",
            "the",
            "topic",
            "then",
            "commit",
            "each",
            "record",
            "individually"
        ]
    },
    {
        "id": 3154,
        "code": "public void pipeValueList(final List<V> values,\n                          final Instant startTimestamp,\n                          final Duration advance) {\n    Instant recordTime = startTimestamp;\n    for (final V value : values) {\n        pipeInput(value, recordTime);\n        recordTime = recordTime.plus(advance);\n    }\n}",
        "summary_tokens": [
            "send",
            "input",
            "records",
            "with",
            "the",
            "given",
            "value",
            "list",
            "on",
            "the",
            "topic",
            "then",
            "commit",
            "each",
            "record",
            "individually"
        ]
    },
    {
        "id": 3155,
        "code": "public V readValue() {\n    final TestRecord<K, V> record = readRecord();\n    return record.value();\n}",
        "summary_tokens": [
            "read",
            "one",
            "record",
            "from",
            "the",
            "output",
            "topic",
            "and",
            "return",
            "record",
            "s",
            "value"
        ]
    },
    {
        "id": 3156,
        "code": "public KeyValue<K, V> readKeyValue() {\n    final TestRecord<K, V> record = readRecord();\n    return new KeyValue<>(record.key(), record.value());\n}",
        "summary_tokens": [
            "read",
            "one",
            "record",
            "from",
            "the",
            "output",
            "topic",
            "and",
            "return",
            "its",
            "key",
            "and",
            "value",
            "as",
            "pair"
        ]
    },
    {
        "id": 3157,
        "code": "public TestRecord<K, V> readRecord() {\n    return driver.readRecord(topic, keyDeserializer, valueDeserializer);\n}",
        "summary_tokens": [
            "read",
            "one",
            "record",
            "from",
            "output",
            "topic"
        ]
    },
    {
        "id": 3158,
        "code": "public List<TestRecord<K, V>> readRecordsToList() {\n    final List<TestRecord<K, V>> output = new LinkedList<>();\n    while (!isEmpty()) {\n        output.add(readRecord());\n    }\n    return output;\n}",
        "summary_tokens": [
            "read",
            "output",
            "to",
            "list"
        ]
    },
    {
        "id": 3159,
        "code": "public Map<K, V> readKeyValuesToMap() {\n    final Map<K, V> output = new HashMap<>();\n    TestRecord<K, V> outputRow;\n    while (!isEmpty()) {\n        outputRow = readRecord();\n        if (outputRow.key() == null) {\n            throw new IllegalStateException(\"Null keys not allowed with readKeyValuesToMap method\");\n        }\n        output.put(outputRow.key(), outputRow.value());\n    }\n    return output;\n}",
        "summary_tokens": [
            "read",
            "output",
            "to",
            "map"
        ]
    },
    {
        "id": 3160,
        "code": "public List<KeyValue<K, V>> readKeyValuesToList() {\n    final List<KeyValue<K, V>> output = new LinkedList<>();\n    KeyValue<K, V> outputRow;\n    while (!isEmpty()) {\n        outputRow = readKeyValue();\n        output.add(outputRow);\n    }\n    return output;\n}",
        "summary_tokens": [
            "read",
            "all",
            "key",
            "values",
            "from",
            "topic",
            "to",
            "list"
        ]
    },
    {
        "id": 3161,
        "code": "public List<V> readValuesToList() {\n    final List<V> output = new LinkedList<>();\n    V outputValue;\n    while (!isEmpty()) {\n        outputValue = readValue();\n        output.add(outputValue);\n    }\n    return output;\n}",
        "summary_tokens": [
            "read",
            "all",
            "values",
            "from",
            "topic",
            "to",
            "list"
        ]
    },
    {
        "id": 3162,
        "code": "public final long getQueueSize() {\n    return driver.getQueueSize(topic);\n}",
        "summary_tokens": [
            "get",
            "size",
            "of",
            "unread",
            "record",
            "in",
            "the",
            "topic",
            "queue"
        ]
    },
    {
        "id": 3163,
        "code": "public final boolean isEmpty() {\n    return driver.isEmpty(topic);\n}",
        "summary_tokens": [
            "verify",
            "if",
            "the",
            "topic",
            "queue",
            "is",
            "empty"
        ]
    },
    {
        "id": 3164,
        "code": "public Map<MetricName, ? extends Metric> metrics() {\n    return Collections.unmodifiableMap(metrics.metrics());\n}",
        "summary_tokens": [
            "get",
            "read",
            "only",
            "handle",
            "on",
            "global",
            "metrics",
            "registry"
        ]
    },
    {
        "id": 3165,
        "code": "public void advanceWallClockTime(final Duration advance) {\n    Objects.requireNonNull(advance, \"advance cannot be null\");\n    mockWallClockTime.sleep(advance.toMillis());\n    if (task != null) {\n        task.maybePunctuateSystemTime();\n        commit(task.prepareCommit());\n        task.postCommit(true);\n    }\n    completeAllProcessableWork();\n}",
        "summary_tokens": [
            "advances",
            "the",
            "internally",
            "mocked",
            "wall",
            "clock",
            "time"
        ]
    },
    {
        "id": 3166,
        "code": "public final <K, V> TestInputTopic<K, V> createInputTopic(final String topicName,\n                                                          final Serializer<K> keySerializer,\n                                                          final Serializer<V> valueSerializer,\n                                                          final Instant startTimestamp,\n                                                          final Duration autoAdvance) {\n    return new TestInputTopic<>(this, topicName, keySerializer, valueSerializer, startTimestamp, autoAdvance);\n}",
        "summary_tokens": [
            "create",
            "test",
            "input",
            "topic",
            "to",
            "be",
            "used",
            "for",
            "piping",
            "records",
            "to",
            "topic",
            "uses",
            "provided",
            "start",
            "timestamp",
            "and",
            "auto",
            "advance",
            "parameter",
            "for",
            "records"
        ]
    },
    {
        "id": 3167,
        "code": "public final <K, V> TestOutputTopic<K, V> createOutputTopic(final String topicName,\n                                                            final Deserializer<K> keyDeserializer,\n                                                            final Deserializer<V> valueDeserializer) {\n    return new TestOutputTopic<>(this, topicName, keyDeserializer, valueDeserializer);\n}",
        "summary_tokens": [
            "create",
            "test",
            "output",
            "topic",
            "to",
            "be",
            "used",
            "for",
            "reading",
            "records",
            "from",
            "topic"
        ]
    },
    {
        "id": 3168,
        "code": "public final Set<String> producedTopicNames() {\n    return Collections.unmodifiableSet(outputRecordsByTopic.keySet());\n}",
        "summary_tokens": [
            "get",
            "all",
            "the",
            "names",
            "of",
            "all",
            "the",
            "topics",
            "to",
            "which",
            "records",
            "have",
            "been",
            "produced",
            "during",
            "the",
            "test",
            "run"
        ]
    },
    {
        "id": 3169,
        "code": "public Map<String, StateStore> getAllStateStores() {\n    final Map<String, StateStore> allStores = new HashMap<>();\n    for (final String storeName : internalTopologyBuilder.allStateStoreNames()) {\n        allStores.put(storeName, getStateStore(storeName, false));\n    }\n    return allStores;\n}",
        "summary_tokens": [
            "get",
            "all",
            "state",
            "store",
            "state",
            "stores",
            "from",
            "the",
            "topology"
        ]
    },
    {
        "id": 3170,
        "code": "public StateStore getStateStore(final String name) throws IllegalArgumentException {\n    return getStateStore(name, true);\n}",
        "summary_tokens": [
            "get",
            "the",
            "state",
            "store",
            "with",
            "the",
            "given",
            "name"
        ]
    },
    {
        "id": 3171,
        "code": "public <K, V> KeyValueStore<K, V> getKeyValueStore(final String name) {\n    final StateStore store = getStateStore(name, false);\n    if (store instanceof TimestampedKeyValueStore) {\n        log.info(\"Method #getTimestampedKeyValueStore() should be used to access a TimestampedKeyValueStore.\");\n        return new KeyValueStoreFacade<>((TimestampedKeyValueStore<K, V>) store);\n    }\n    return store instanceof KeyValueStore ? (KeyValueStore<K, V>) store : null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "key",
            "value",
            "store",
            "or",
            "timestamped",
            "key",
            "value",
            "store",
            "with",
            "the",
            "given",
            "name"
        ]
    },
    {
        "id": 3172,
        "code": "public <K, V> KeyValueStore<K, ValueAndTimestamp<V>> getTimestampedKeyValueStore(final String name) {\n    final StateStore store = getStateStore(name, false);\n    return store instanceof TimestampedKeyValueStore ? (TimestampedKeyValueStore<K, V>) store : null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "timestamped",
            "key",
            "value",
            "store",
            "with",
            "the",
            "given",
            "name"
        ]
    },
    {
        "id": 3173,
        "code": "public <K, V> WindowStore<K, V> getWindowStore(final String name) {\n    final StateStore store = getStateStore(name, false);\n    if (store instanceof TimestampedWindowStore) {\n        log.info(\"Method #getTimestampedWindowStore() should be used to access a TimestampedWindowStore.\");\n        return new WindowStoreFacade<>((TimestampedWindowStore<K, V>) store);\n    }\n    return store instanceof WindowStore ? (WindowStore<K, V>) store : null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "window",
            "store",
            "or",
            "timestamped",
            "window",
            "store",
            "with",
            "the",
            "given",
            "name"
        ]
    },
    {
        "id": 3174,
        "code": "public <K, V> WindowStore<K, ValueAndTimestamp<V>> getTimestampedWindowStore(final String name) {\n    final StateStore store = getStateStore(name, false);\n    return store instanceof TimestampedWindowStore ? (TimestampedWindowStore<K, V>) store : null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "timestamped",
            "window",
            "store",
            "with",
            "the",
            "given",
            "name"
        ]
    },
    {
        "id": 3175,
        "code": "public <K, V> SessionStore<K, V> getSessionStore(final String name) {\n    final StateStore store = getStateStore(name, false);\n    return store instanceof SessionStore ? (SessionStore<K, V>) store : null;\n}",
        "summary_tokens": [
            "get",
            "the",
            "session",
            "store",
            "with",
            "the",
            "given",
            "name"
        ]
    },
    {
        "id": 3176,
        "code": "public void close() {\n    if (task != null) {\n        task.suspend();\n        task.prepareCommit();\n        task.postCommit(true);\n        task.closeClean();\n    }\n    if (globalStateTask != null) {\n        try {\n            globalStateTask.close(false);\n        } catch (final IOException e) {\n                \n        }\n    }\n    completeAllProcessableWork();\n    if (task != null && task.hasRecordsQueued()) {\n        log.warn(\"Found some records that cannot be processed due to the\" +\n                     \" {} configuration during TopologyTestDriver#close().\",\n                 StreamsConfig.MAX_TASK_IDLE_MS_CONFIG);\n    }\n    if (processingMode == AT_LEAST_ONCE) {\n        producer.close();\n    }\n    stateDirectory.clean();\n}",
        "summary_tokens": [
            "close",
            "the",
            "driver",
            "its",
            "topology",
            "and",
            "all",
            "processors"
        ]
    },
    {
        "id": 3177,
        "code": "public void setRecordMetadata(final String topic,\n                              final int partition,\n                              final long offset,\n                              final Headers headers,\n                              final long timestamp) {\n    this.topic = topic;\n    this.partition = partition;\n    this.offset = offset;\n    this.headers = headers;\n    this.recordTimestamp = timestamp;\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "these",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3178,
        "code": "public void setTopic(final String topic) {\n    this.topic = topic;\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "this",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3179,
        "code": "public void setPartition(final int partition) {\n    this.partition = partition;\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "this",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3180,
        "code": "public void setOffset(final long offset) {\n    this.offset = offset;\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "this",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3181,
        "code": "public void setHeaders(final Headers headers) {\n    this.headers = headers;\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "this",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3182,
        "code": "public void setTimestamp(final long timestamp) {\n    this.recordTimestamp = timestamp;\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "this",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3183,
        "code": "public void setRecordTimestamp(final long recordTimestamp) {\n    this.recordTimestamp = recordTimestamp;\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "this",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3184,
        "code": "public Headers headers() {\n    return headers;\n}",
        "summary_tokens": [
            "returns",
            "the",
            "headers",
            "of",
            "the",
            "current",
            "input",
            "record",
            "could",
            "be",
            "null",
            "if",
            "it",
            "is",
            "not",
            "available"
        ]
    },
    {
        "id": 3185,
        "code": "public List<CapturedPunctuator> scheduledPunctuators() {\n    return new LinkedList<>(punctuators);\n}",
        "summary_tokens": [
            "get",
            "the",
            "punctuators",
            "scheduled",
            "so",
            "far"
        ]
    },
    {
        "id": 3186,
        "code": "public List<CapturedForward> forwarded(final String childName) {\n    final LinkedList<CapturedForward> result = new LinkedList<>();\n    for (final CapturedForward capture : capturedForwards) {\n        if (capture.childName() == null || capture.childName().equals(childName)) {\n            result.add(capture);\n        }\n    }\n    return result;\n}",
        "summary_tokens": [
            "get",
            "all",
            "the",
            "forwarded",
            "data",
            "this",
            "context",
            "has",
            "observed",
            "for",
            "a",
            "specific",
            "child",
            "by",
            "name"
        ]
    },
    {
        "id": 3187,
        "code": "public void resetForwards() {\n    capturedForwards.clear();\n}",
        "summary_tokens": [
            "clear",
            "the",
            "captured",
            "forwarded",
            "data"
        ]
    },
    {
        "id": 3188,
        "code": "public boolean committed() {\n    return committed;\n}",
        "summary_tokens": [
            "whether",
            "processor",
            "context",
            "commit",
            "has",
            "been",
            "called",
            "in",
            "this",
            "context"
        ]
    },
    {
        "id": 3189,
        "code": "public void resetCommit() {\n    committed = false;\n}",
        "summary_tokens": [
            "reset",
            "the",
            "commit",
            "capture",
            "to",
            "false",
            "whether",
            "or",
            "not",
            "it",
            "was",
            "previously",
            "true"
        ]
    },
    {
        "id": 3190,
        "code": "public void setRecordMetadata(final String topic,\n                              final int partition,\n                              final long offset) {\n    recordMetadata = new MockRecordMetadata(topic, partition, offset);\n}",
        "summary_tokens": [
            "the",
            "context",
            "exposes",
            "these",
            "metadata",
            "for",
            "use",
            "in",
            "the",
            "processor"
        ]
    },
    {
        "id": 3191,
        "code": "public List<CapturedPunctuator> scheduledPunctuators() {\n    return new LinkedList<>(punctuators);\n}",
        "summary_tokens": [
            "get",
            "the",
            "punctuators",
            "scheduled",
            "so",
            "far"
        ]
    },
    {
        "id": 3192,
        "code": "public List<CapturedForward<? extends KForward, ? extends VForward>> forwarded(final String childName) {\n    final LinkedList<CapturedForward<? extends KForward, ? extends VForward>> result = new LinkedList<>();\n    for (final CapturedForward<? extends KForward, ? extends VForward> capture : capturedForwards) {\n        if (!capture.childName().isPresent() || capture.childName().equals(Optional.of(childName))) {\n            result.add(capture);\n        }\n    }\n    return result;\n}",
        "summary_tokens": [
            "get",
            "all",
            "the",
            "forwarded",
            "data",
            "this",
            "context",
            "has",
            "observed",
            "for",
            "a",
            "specific",
            "child",
            "by",
            "name"
        ]
    },
    {
        "id": 3193,
        "code": "public void resetForwards() {\n    capturedForwards.clear();\n}",
        "summary_tokens": [
            "clear",
            "the",
            "captured",
            "forwarded",
            "data"
        ]
    },
    {
        "id": 3194,
        "code": "public boolean committed() {\n    return committed;\n}",
        "summary_tokens": [
            "whether",
            "processor",
            "context",
            "commit",
            "has",
            "been",
            "called",
            "in",
            "this",
            "context"
        ]
    },
    {
        "id": 3195,
        "code": "public void resetCommit() {\n    committed = false;\n}",
        "summary_tokens": [
            "reset",
            "the",
            "commit",
            "capture",
            "to",
            "false",
            "whether",
            "or",
            "not",
            "it",
            "was",
            "previously",
            "true"
        ]
    },
    {
        "id": 3196,
        "code": "public StateStoreContext getStateStoreContext() {\n    return new StateStoreContext() {\n        @Override\n        public String applicationId() {\n            return MockProcessorContext.this.applicationId();\n        }\n\n        @Override\n        public TaskId taskId() {\n            return MockProcessorContext.this.taskId();\n        }\n\n        @Override\n        public Optional<RecordMetadata> recordMetadata() {\n            return MockProcessorContext.this.recordMetadata();\n        }\n\n        @Override\n        public Serde<?> keySerde() {\n            return MockProcessorContext.this.keySerde();\n        }\n\n        @Override\n        public Serde<?> valueSerde() {\n            return MockProcessorContext.this.valueSerde();\n        }\n\n        @Override\n        public File stateDir() {\n            return MockProcessorContext.this.stateDir();\n        }\n\n        @Override\n        public StreamsMetrics metrics() {\n            return MockProcessorContext.this.metrics();\n        }\n\n        @Override\n        public void register(final StateStore store,\n                             final StateRestoreCallback stateRestoreCallback) {\n            register(store, stateRestoreCallback, () -> { });\n        }\n\n        @Override\n        public void register(final StateStore store,\n                             final StateRestoreCallback stateRestoreCallback,\n                             final CommitCallback checkpoint) {\n            stateStores.put(store.name(), store);\n        }\n\n        @Override\n        public Map<String, Object> appConfigs() {\n            return MockProcessorContext.this.appConfigs();\n        }\n\n        @Override\n        public Map<String, Object> appConfigsWithPrefix(final String prefix) {\n            return MockProcessorContext.this.appConfigsWithPrefix(prefix);\n        }\n    };\n}",
        "summary_tokens": [
            "used",
            "to",
            "get",
            "a",
            "state",
            "store",
            "context",
            "for",
            "use",
            "with",
            "state",
            "store",
            "init",
            "state",
            "store",
            "context",
            "state",
            "store",
            "if",
            "you",
            "need",
            "to",
            "initialize",
            "a",
            "store",
            "for",
            "your",
            "tests"
        ]
    },
    {
        "id": 3197,
        "code": "public K key() {\n    return key;\n}",
        "summary_tokens": [
            "the",
            "key",
            "or",
            "null",
            "if",
            "no",
            "key",
            "is",
            "specified"
        ]
    },
    {
        "id": 3198,
        "code": "public Long timestamp() {\n    return this.recordTime == null ? null : this.recordTime.toEpochMilli();\n}",
        "summary_tokens": [
            "the",
            "timestamp",
            "which",
            "is",
            "in",
            "milliseconds",
            "since",
            "epoch"
        ]
    },
    {
        "id": 3199,
        "code": "public K getKey() {\n    return key;\n}",
        "summary_tokens": [
            "the",
            "key",
            "or",
            "null",
            "if",
            "no",
            "key",
            "is",
            "specified"
        ]
    },
    {
        "id": 3200,
        "code": "public static void main(final String[] args) throws Exception {\n    if (args.length < 2) {\n        System.err.println(\"StreamsUpgradeTest requires two arguments (zookeeper-url, properties-file) but only \" + args.length + \" provided: \"\n            + (args.length > 0 ? args[0] + \" \" : \"\"));\n    }\n    final String zookeeper = args[0];\n    final String propFileName = args[1];\n\n    final Properties streamsProperties = Utils.loadProps(propFileName);\n\n    System.out.println(\"StreamsTest instance started (StreamsUpgradeTest v0.10.1)\");\n    System.out.println(\"zookeeper=\" + zookeeper);\n    System.out.println(\"props=\" + streamsProperties);\n\n    final KStreamBuilder builder = new KStreamBuilder();\n    final KStream dataStream = builder.stream(\"data\");\n    dataStream.process(printProcessorSupplier());\n    dataStream.to(\"echo\");\n\n    final Properties config = new Properties();\n    config.setProperty(StreamsConfig.APPLICATION_ID_CONFIG, \"StreamsUpgradeTest\");\n    config.setProperty(StreamsConfig.ZOOKEEPER_CONNECT_CONFIG, zookeeper);\n    config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000L);\n    config.putAll(streamsProperties);\n\n    final KafkaStreams streams = new KafkaStreams(builder, config);\n    streams.start();\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        @Override\n        public void run() {\n            System.out.println(\"closing Kafka Streams instance\");\n            System.out.flush();\n            streams.close();\n            System.out.println(\"UPGRADE-TEST-CLIENT-CLOSED\");\n            System.out.flush();\n        }\n    });\n}",
        "summary_tokens": [
            "this",
            "test",
            "cannot",
            "be",
            "executed",
            "as",
            "long",
            "as",
            "kafka",
            "0"
        ]
    },
    {
        "id": 3201,
        "code": "static ArgumentParser argParser() {\n    ArgumentParser parser = ArgumentParsers\n            .newArgumentParser(\"producer-performance\")\n            .defaultHelp(true)\n            .description(\"This tool is used to verify the producer performance.\");\n\n    MutuallyExclusiveGroup payloadOptions = parser\n            .addMutuallyExclusiveGroup()\n            .required(true)\n            .description(\"either --record-size or --payload-file must be specified but not both.\");\n\n    parser.addArgument(\"--topic\")\n            .action(store())\n            .required(true)\n            .type(String.class)\n            .metavar(\"TOPIC\")\n            .help(\"produce messages to this topic\");\n\n    parser.addArgument(\"--num-records\")\n            .action(store())\n            .required(true)\n            .type(Long.class)\n            .metavar(\"NUM-RECORDS\")\n            .dest(\"numRecords\")\n            .help(\"number of messages to produce\");\n\n    payloadOptions.addArgument(\"--record-size\")\n            .action(store())\n            .required(false)\n            .type(Integer.class)\n            .metavar(\"RECORD-SIZE\")\n            .dest(\"recordSize\")\n            .help(\"message size in bytes. Note that you must provide exactly one of --record-size or --payload-file.\");\n\n    payloadOptions.addArgument(\"--payload-file\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"PAYLOAD-FILE\")\n            .dest(\"payloadFile\")\n            .help(\"file to read the message payloads from. This works only for UTF-8 encoded text files. \" +\n                    \"Payloads will be read from this file and a payload will be randomly selected when sending messages. \" +\n                    \"Note that you must provide exactly one of --record-size or --payload-file.\");\n\n    parser.addArgument(\"--payload-delimiter\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"PAYLOAD-DELIMITER\")\n            .dest(\"payloadDelimiter\")\n            .setDefault(\"\\\\n\")\n            .help(\"provides delimiter to be used when --payload-file is provided. \" +\n                    \"Defaults to new line. \" +\n                    \"Note that this parameter will be ignored if --payload-file is not provided.\");\n\n    parser.addArgument(\"--throughput\")\n            .action(store())\n            .required(true)\n            .type(Integer.class)\n            .metavar(\"THROUGHPUT\")\n            .help(\"throttle maximum message throughput to *approximately* THROUGHPUT messages/sec. Set this to -1 to disable throttling.\");\n\n    parser.addArgument(\"--producer-props\")\n             .nargs(\"+\")\n             .required(false)\n             .metavar(\"PROP-NAME=PROP-VALUE\")\n             .type(String.class)\n             .dest(\"producerConfig\")\n             .help(\"kafka producer related configuration properties like bootstrap.servers,client.id etc. \" +\n                     \"These configs take precedence over those passed via --producer.config.\");\n\n    parser.addArgument(\"--producer.config\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"CONFIG-FILE\")\n            .dest(\"producerConfigFile\")\n            .help(\"producer config properties file.\");\n\n    parser.addArgument(\"--print-metrics\")\n            .action(storeTrue())\n            .type(Boolean.class)\n            .metavar(\"PRINT-METRICS\")\n            .dest(\"printMetrics\")\n            .help(\"print out metrics at the end of the test.\");\n\n    parser.addArgument(\"--transactional-id\")\n           .action(store())\n           .required(false)\n           .type(String.class)\n           .metavar(\"TRANSACTIONAL-ID\")\n           .dest(\"transactionalId\")\n           .setDefault(\"performance-producer-default-transactional-id\")\n           .help(\"The transactionalId to use if transaction-duration-ms is > 0. Useful when testing the performance of concurrent transactions.\");\n\n    parser.addArgument(\"--transaction-duration-ms\")\n           .action(store())\n           .required(false)\n           .type(Long.class)\n           .metavar(\"TRANSACTION-DURATION\")\n           .dest(\"transactionDurationMs\")\n           .setDefault(0L)\n           .help(\"The max age of each transaction. The commitTransaction will be called after this time has elapsed. Transactions are only enabled if this value is positive.\");\n\n\n    return parser;\n}",
        "summary_tokens": [
            "get",
            "the",
            "command",
            "line",
            "argument",
            "parser"
        ]
    },
    {
        "id": 3202,
        "code": "public boolean shouldThrottle(long amountSoFar, long sendStartMs) {\n    if (this.targetThroughput < 0) {\n            \n        return false;\n    }\n\n    float elapsedSec = (sendStartMs - startMs) / 1000.f;\n    return elapsedSec > 0 && (amountSoFar / elapsedSec) > this.targetThroughput;\n}",
        "summary_tokens": [
            "amount",
            "so",
            "far",
            "bytes",
            "produced",
            "so",
            "far",
            "if",
            "you",
            "want",
            "to",
            "throttle",
            "data",
            "throughput",
            "or",
            "messages",
            "produced",
            "so",
            "far",
            "if",
            "you",
            "want",
            "to",
            "throttle",
            "message",
            "throughput"
        ]
    },
    {
        "id": 3203,
        "code": "public void throttle() {\n    if (targetThroughput == 0) {\n        try {\n            synchronized (this) {\n                while (!wakeup) {\n                    this.wait();\n                }\n            }\n        } catch (InterruptedException e) {\n                \n        }\n        return;\n    }\n\n        \n        \n    sleepDeficitNs += sleepTimeNs;\n\n        \n    if (sleepDeficitNs >= MIN_SLEEP_NS) {\n        long sleepStartNs = System.nanoTime();\n        try {\n            synchronized (this) {\n                long remaining = sleepDeficitNs;\n                while (!wakeup && remaining > 0) {\n                    long sleepMs = remaining / 1000000;\n                    long sleepNs = remaining - sleepMs * 1000000;\n                    this.wait(sleepMs, (int) sleepNs);\n                    long elapsed = System.nanoTime() - sleepStartNs;\n                    remaining = sleepDeficitNs - elapsed;\n                }\n                wakeup = false;\n            }\n            sleepDeficitNs = 0;\n        } catch (InterruptedException e) {\n                \n                \n            long sleepElapsedNs = System.nanoTime() - sleepStartNs;\n            if (sleepElapsedNs <= sleepDeficitNs) {\n                sleepDeficitNs -= sleepElapsedNs;\n            }\n        }\n    }\n}",
        "summary_tokens": [
            "occasionally",
            "blocks",
            "for",
            "small",
            "amounts",
            "of",
            "time",
            "to",
            "achieve",
            "target",
            "throughput"
        ]
    },
    {
        "id": 3204,
        "code": "public void wakeup() {\n    synchronized (this) {\n        wakeup = true;\n        this.notifyAll();\n    }\n}",
        "summary_tokens": [
            "wakeup",
            "the",
            "throttler",
            "if",
            "its",
            "sleeping"
        ]
    },
    {
        "id": 3205,
        "code": "private static ArgumentParser argParser() {\n    ArgumentParser parser = ArgumentParsers\n            .newArgumentParser(\"transactional-message-copier\")\n            .defaultHelp(true)\n            .description(\"This tool copies messages transactionally from an input partition to an output topic, \" +\n                    \"committing the consumed offsets along with the output messages\");\n\n    parser.addArgument(\"--input-topic\")\n            .action(store())\n            .required(true)\n            .type(String.class)\n            .metavar(\"INPUT-TOPIC\")\n            .dest(\"inputTopic\")\n            .help(\"Consume messages from this topic\");\n\n    parser.addArgument(\"--input-partition\")\n            .action(store())\n            .required(true)\n            .type(Integer.class)\n            .metavar(\"INPUT-PARTITION\")\n            .dest(\"inputPartition\")\n            .help(\"Consume messages from this partition of the input topic.\");\n\n    parser.addArgument(\"--output-topic\")\n            .action(store())\n            .required(true)\n            .type(String.class)\n            .metavar(\"OUTPUT-TOPIC\")\n            .dest(\"outputTopic\")\n            .help(\"Produce messages to this topic\");\n\n    parser.addArgument(\"--broker-list\")\n            .action(store())\n            .required(true)\n            .type(String.class)\n            .metavar(\"HOST1:PORT1[,HOST2:PORT2[...]]\")\n            .dest(\"brokerList\")\n            .help(\"Comma-separated list of Kafka brokers in the form HOST1:PORT1,HOST2:PORT2,...\");\n\n    parser.addArgument(\"--max-messages\")\n            .action(store())\n            .required(false)\n            .setDefault(-1)\n            .type(Integer.class)\n            .metavar(\"MAX-MESSAGES\")\n            .dest(\"maxMessages\")\n            .help(\"Process these many messages upto the end offset at the time this program was launched. If set to -1 \" +\n                    \"we will just read to the end offset of the input partition (as of the time the program was launched).\");\n\n    parser.addArgument(\"--consumer-group\")\n            .action(store())\n            .required(false)\n            .setDefault(-1)\n            .type(String.class)\n            .metavar(\"CONSUMER-GROUP\")\n            .dest(\"consumerGroup\")\n            .help(\"The consumer group id to use for storing the consumer offsets.\");\n\n    parser.addArgument(\"--transaction-size\")\n            .action(store())\n            .required(false)\n            .setDefault(200)\n            .type(Integer.class)\n            .metavar(\"TRANSACTION-SIZE\")\n            .dest(\"messagesPerTransaction\")\n            .help(\"The number of messages to put in each transaction. Default is 200.\");\n\n    parser.addArgument(\"--transaction-timeout\")\n            .action(store())\n            .required(false)\n            .setDefault(60000)\n            .type(Integer.class)\n            .metavar(\"TRANSACTION-TIMEOUT\")\n            .dest(\"transactionTimeout\")\n            .help(\"The transaction timeout in milliseconds. Default is 60000(1 minute).\");\n\n    parser.addArgument(\"--transactional-id\")\n            .action(store())\n            .required(true)\n            .type(String.class)\n            .metavar(\"TRANSACTIONAL-ID\")\n            .dest(\"transactionalId\")\n            .help(\"The transactionalId to assign to the producer\");\n\n    parser.addArgument(\"--enable-random-aborts\")\n            .action(storeTrue())\n            .type(Boolean.class)\n            .metavar(\"ENABLE-RANDOM-ABORTS\")\n            .dest(\"enableRandomAborts\")\n            .help(\"Whether or not to enable random transaction aborts (for system testing)\");\n\n    parser.addArgument(\"--group-mode\")\n            .action(storeTrue())\n            .type(Boolean.class)\n            .metavar(\"GROUP-MODE\")\n            .dest(\"groupMode\")\n            .help(\"Whether to let consumer subscribe to the input topic or do manual assign. If we do\" +\n                      \" subscription based consumption, the input partition shall be ignored\");\n\n    parser.addArgument(\"--use-group-metadata\")\n            .action(storeTrue())\n            .type(Boolean.class)\n            .metavar(\"USE-GROUP-METADATA\")\n            .dest(\"useGroupMetadata\")\n            .help(\"Whether to use the new transactional commit API with group metadata\");\n\n    return parser;\n}",
        "summary_tokens": [
            "get",
            "the",
            "command",
            "line",
            "argument",
            "parser"
        ]
    },
    {
        "id": 3206,
        "code": "private static ArgumentParser argParser() {\n    ArgumentParser parser = ArgumentParsers\n        .newArgumentParser(\"verifiable-log4j-appender\")\n        .defaultHelp(true)\n        .description(\"This tool produces increasing integers to the specified topic using KafkaLog4jAppender.\");\n\n    parser.addArgument(\"--topic\")\n        .action(store())\n        .required(true)\n        .type(String.class)\n        .metavar(\"TOPIC\")\n        .help(\"Produce messages to this topic.\");\n\n    parser.addArgument(\"--broker-list\")\n        .action(store())\n        .required(true)\n        .type(String.class)\n        .metavar(\"HOST1:PORT1[,HOST2:PORT2[...]]\")\n        .dest(\"brokerList\")\n        .help(\"Comma-separated list of Kafka brokers in the form HOST1:PORT1,HOST2:PORT2,...\");\n\n    parser.addArgument(\"--max-messages\")\n        .action(store())\n        .required(false)\n        .setDefault(-1)\n        .type(Integer.class)\n        .metavar(\"MAX-MESSAGES\")\n        .dest(\"maxMessages\")\n        .help(\"Produce this many messages. If -1, produce messages until the process is killed externally.\");\n\n    parser.addArgument(\"--acks\")\n        .action(store())\n        .required(false)\n        .setDefault(\"-1\")\n        .type(String.class)\n        .choices(\"0\", \"1\", \"-1\")\n        .metavar(\"ACKS\")\n        .help(\"Acks required on each produced message. See Kafka docs on request.required.acks for details.\");\n\n    parser.addArgument(\"--security-protocol\")\n        .action(store())\n        .required(false)\n        .setDefault(\"PLAINTEXT\")\n        .type(String.class)\n        .choices(\"PLAINTEXT\", \"SSL\", \"SASL_PLAINTEXT\", \"SASL_SSL\")\n        .metavar(\"SECURITY-PROTOCOL\")\n        .dest(\"securityProtocol\")\n        .help(\"Security protocol to be used while communicating with Kafka brokers.\");\n\n    parser.addArgument(\"--ssl-truststore-location\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"SSL-TRUSTSTORE-LOCATION\")\n        .dest(\"sslTruststoreLocation\")\n        .help(\"Location of SSL truststore to use.\");\n\n    parser.addArgument(\"--ssl-truststore-password\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"SSL-TRUSTSTORE-PASSWORD\")\n        .dest(\"sslTruststorePassword\")\n        .help(\"Password for SSL truststore to use.\");\n\n    parser.addArgument(\"--appender.config\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"CONFIG_FILE\")\n        .help(\"Log4jAppender config properties file.\");\n\n    parser.addArgument(\"--sasl-kerberos-service-name\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"SASL-KERBEROS-SERVICE-NAME\")\n        .dest(\"saslKerberosServiceName\")\n        .help(\"Name of sasl kerberos service.\");\n\n    parser.addArgument(\"--client-jaas-conf-path\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"CLIENT-JAAS-CONF-PATH\")\n        .dest(\"clientJaasConfPath\")\n        .help(\"Path of JAAS config file of Kafka client.\");\n\n    parser.addArgument(\"--kerb5-conf-path\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"KERB5-CONF-PATH\")\n        .dest(\"kerb5ConfPath\")\n        .help(\"Path of Kerb5 config file.\");\n\n    return parser;\n}",
        "summary_tokens": [
            "get",
            "the",
            "command",
            "line",
            "argument",
            "parser"
        ]
    },
    {
        "id": 3207,
        "code": "public static Properties loadProps(String filename) throws IOException {\n    Properties props = new Properties();\n    try (InputStream propStream = Files.newInputStream(Paths.get(filename))) {\n        props.load(propStream);\n    }\n    return props;\n}",
        "summary_tokens": [
            "read",
            "a",
            "properties",
            "file",
            "from",
            "the",
            "given",
            "path",
            "filename",
            "the",
            "path",
            "of",
            "the",
            "file",
            "to",
            "read"
        ]
    },
    {
        "id": 3208,
        "code": "public static VerifiableLog4jAppender createFromArgs(String[] args) {\n    ArgumentParser parser = argParser();\n    VerifiableLog4jAppender producer = null;\n\n    try {\n        Namespace res = parser.parseArgs(args);\n\n        int maxMessages = res.getInt(\"maxMessages\");\n        String topic = res.getString(\"topic\");\n        String configFile = res.getString(\"appender.config\");\n\n        Properties props = new Properties();\n        props.setProperty(\"log4j.rootLogger\", \"INFO, KAFKA\");\n        props.setProperty(\"log4j.appender.KAFKA\", \"org.apache.kafka.log4jappender.KafkaLog4jAppender\");\n        props.setProperty(\"log4j.appender.KAFKA.layout\", \"org.apache.log4j.PatternLayout\");\n        props.setProperty(\"log4j.appender.KAFKA.layout.ConversionPattern\", \"%-5p: %c - %m%n\");\n        props.setProperty(\"log4j.appender.KAFKA.BrokerList\", res.getString(\"brokerList\"));\n        props.setProperty(\"log4j.appender.KAFKA.Topic\", topic);\n        props.setProperty(\"log4j.appender.KAFKA.RequiredNumAcks\", res.getString(\"acks\"));\n        props.setProperty(\"log4j.appender.KAFKA.SyncSend\", \"true\");\n        final String securityProtocol = res.getString(\"securityProtocol\");\n        if (securityProtocol != null && !securityProtocol.equals(SecurityProtocol.PLAINTEXT.toString())) {\n            props.setProperty(\"log4j.appender.KAFKA.SecurityProtocol\", securityProtocol);\n        }\n        if (securityProtocol != null && securityProtocol.contains(\"SSL\")) {\n            props.setProperty(\"log4j.appender.KAFKA.SslTruststoreLocation\", res.getString(\"sslTruststoreLocation\"));\n            props.setProperty(\"log4j.appender.KAFKA.SslTruststorePassword\", res.getString(\"sslTruststorePassword\"));\n        }\n        if (securityProtocol != null && securityProtocol.contains(\"SASL\")) {\n            props.setProperty(\"log4j.appender.KAFKA.SaslKerberosServiceName\", res.getString(\"saslKerberosServiceName\"));\n            props.setProperty(\"log4j.appender.KAFKA.clientJaasConfPath\", res.getString(\"clientJaasConfPath\"));\n            props.setProperty(\"log4j.appender.KAFKA.kerb5ConfPath\", res.getString(\"kerb5ConfPath\"));\n        }\n        props.setProperty(\"log4j.logger.kafka.log4j\", \"INFO, KAFKA\");\n            \n            \n        props.setProperty(\"log4j.logger.org.apache.kafka.clients.Metadata\", \"WARN, KAFKA\");\n\n        if (configFile != null) {\n            try {\n                props.putAll(loadProps(configFile));\n            } catch (IOException e) {\n                throw new ArgumentParserException(e.getMessage(), parser);\n            }\n        }\n\n        producer = new VerifiableLog4jAppender(props, maxMessages);\n    } catch (ArgumentParserException e) {\n        if (args.length == 0) {\n            parser.printHelp();\n            Exit.exit(0);\n        } else {\n            parser.handleError(e);\n            Exit.exit(1);\n        }\n    }\n\n    return producer;\n}",
        "summary_tokens": [
            "construct",
            "a",
            "verifiable",
            "log",
            "0",
            "j",
            "appender",
            "object",
            "from",
            "command",
            "line",
            "arguments"
        ]
    },
    {
        "id": 3209,
        "code": "private static ArgumentParser argParser() {\n    ArgumentParser parser = ArgumentParsers\n            .newArgumentParser(\"verifiable-producer\")\n            .defaultHelp(true)\n            .description(\"This tool produces increasing integers to the specified topic and prints JSON metadata to stdout on each \\\"send\\\" request, making externally visible which messages have been acked and which have not.\");\n\n    parser.addArgument(\"--topic\")\n            .action(store())\n            .required(true)\n            .type(String.class)\n            .metavar(\"TOPIC\")\n            .help(\"Produce messages to this topic.\");\n    MutuallyExclusiveGroup connectionGroup = parser.addMutuallyExclusiveGroup(\"Connection Group\")\n            .description(\"Group of arguments for connection to brokers\")\n            .required(true);\n    connectionGroup.addArgument(\"--bootstrap-server\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"HOST1:PORT1[,HOST2:PORT2[...]]\")\n            .dest(\"bootstrapServer\")\n            .help(\"REQUIRED: The server(s) to connect to. Comma-separated list of Kafka brokers in the form HOST1:PORT1,HOST2:PORT2,...\");\n\n    connectionGroup.addArgument(\"--broker-list\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"HOST1:PORT1[,HOST2:PORT2[...]]\")\n            .dest(\"brokerList\")\n            .help(\"DEPRECATED, use --bootstrap-server instead; ignored if --bootstrap-server is specified.  Comma-separated list of Kafka brokers in the form HOST1:PORT1,HOST2:PORT2,...\");\n\n    parser.addArgument(\"--max-messages\")\n            .action(store())\n            .required(false)\n            .setDefault(-1)\n            .type(Integer.class)\n            .metavar(\"MAX-MESSAGES\")\n            .dest(\"maxMessages\")\n            .help(\"Produce this many messages. If -1, produce messages until the process is killed externally.\");\n\n    parser.addArgument(\"--throughput\")\n            .action(store())\n            .required(false)\n            .setDefault(-1)\n            .type(Integer.class)\n            .metavar(\"THROUGHPUT\")\n            .help(\"If set >= 0, throttle maximum message throughput to *approximately* THROUGHPUT messages/sec.\");\n\n    parser.addArgument(\"--acks\")\n            .action(store())\n            .required(false)\n            .setDefault(-1)\n            .type(Integer.class)\n            .choices(0, 1, -1)\n            .metavar(\"ACKS\")\n            .help(\"Acks required on each produced message. See Kafka docs on acks for details.\");\n\n    parser.addArgument(\"--producer.config\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"CONFIG_FILE\")\n            .help(\"Producer config properties file.\");\n\n    parser.addArgument(\"--message-create-time\")\n            .action(store())\n            .required(false)\n            .setDefault(-1L)\n            .type(Long.class)\n            .metavar(\"CREATETIME\")\n            .dest(\"createTime\")\n            .help(\"Send messages with creation time starting at the arguments value, in milliseconds since epoch\");\n\n    parser.addArgument(\"--value-prefix\")\n        .action(store())\n        .required(false)\n        .type(Integer.class)\n        .metavar(\"VALUE-PREFIX\")\n        .dest(\"valuePrefix\")\n        .help(\"If specified, each produced value will have this prefix with a dot separator\");\n\n    parser.addArgument(\"--repeating-keys\")\n        .action(store())\n        .required(false)\n        .type(Integer.class)\n        .metavar(\"REPEATING-KEYS\")\n        .dest(\"repeatingKeys\")\n        .help(\"If specified, each produced record will have a key starting at 0 increment by 1 up to the number specified (exclusive), then the key is set to 0 again\");\n\n    return parser;\n}",
        "summary_tokens": [
            "get",
            "the",
            "command",
            "line",
            "argument",
            "parser"
        ]
    },
    {
        "id": 3210,
        "code": "public static Properties loadProps(String filename) throws IOException {\n    Properties props = new Properties();\n    try (InputStream propStream = Files.newInputStream(Paths.get(filename))) {\n        props.load(propStream);\n    }\n    return props;\n}",
        "summary_tokens": [
            "read",
            "a",
            "properties",
            "file",
            "from",
            "the",
            "given",
            "path",
            "filename",
            "the",
            "path",
            "of",
            "the",
            "file",
            "to",
            "read"
        ]
    },
    {
        "id": 3211,
        "code": "public static VerifiableProducer createFromArgs(ArgumentParser parser, String[] args) throws ArgumentParserException {\n    Namespace res = parser.parseArgs(args);\n\n    int maxMessages = res.getInt(\"maxMessages\");\n    String topic = res.getString(\"topic\");\n    int throughput = res.getInt(\"throughput\");\n    String configFile = res.getString(\"producer.config\");\n    Integer valuePrefix = res.getInt(\"valuePrefix\");\n    Long createTime = res.getLong(\"createTime\");\n    Integer repeatingKeys = res.getInt(\"repeatingKeys\");\n\n    if (createTime == -1L)\n        createTime = null;\n\n    Properties producerProps = new Properties();\n\n    if (res.get(\"bootstrapServer\") != null) {\n        producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, res.getString(\"bootstrapServer\"));\n    } else if (res.getString(\"brokerList\") != null) {\n        producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, res.getString(\"brokerList\"));\n    } else {\n        parser.printHelp();\n            \n        System.exit(0);\n    }\n\n    producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n            \"org.apache.kafka.common.serialization.StringSerializer\");\n    producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n            \"org.apache.kafka.common.serialization.StringSerializer\");\n    producerProps.put(ProducerConfig.ACKS_CONFIG, Integer.toString(res.getInt(\"acks\")));\n        \n    producerProps.put(ProducerConfig.RETRIES_CONFIG, \"0\");\n    if (configFile != null) {\n        try {\n            producerProps.putAll(loadProps(configFile));\n        } catch (IOException e) {\n            throw new ArgumentParserException(e.getMessage(), parser);\n        }\n    }\n\n    StringSerializer serializer = new StringSerializer();\n    KafkaProducer<String, String> producer = new KafkaProducer<>(producerProps, serializer, serializer);\n\n    return new VerifiableProducer(producer, topic, throughput, maxMessages, valuePrefix, createTime, repeatingKeys);\n}",
        "summary_tokens": [
            "construct",
            "a",
            "verifiable",
            "producer",
            "object",
            "from",
            "command",
            "line",
            "arguments"
        ]
    },
    {
        "id": 3212,
        "code": "public void send(String key, String value) {\n    ProducerRecord<String, String> record;\n\n        \n        \n        \n    if (createTime != null) {\n        record = new ProducerRecord<>(topic, null, createTime, key, value);\n        createTime += System.currentTimeMillis() - startTime;\n    } else {\n        record = new ProducerRecord<>(topic, key, value);\n    }\n\n    numSent++;\n    try {\n        producer.send(record, new PrintInfoCallback(key, value));\n    } catch (Exception e) {\n\n        synchronized (System.out) {\n            printJson(new FailedSend(key, value, topic, e));\n        }\n    }\n}",
        "summary_tokens": [
            "produce",
            "a",
            "message",
            "with",
            "given",
            "key",
            "and",
            "value"
        ]
    },
    {
        "id": 3213,
        "code": "public String getValue(long val) {\n    if (this.valuePrefix != null) {\n        return String.format(\"%d.%d\", this.valuePrefix, val);\n    }\n    return String.format(\"%d\", val);\n}",
        "summary_tokens": [
            "returns",
            "a",
            "string",
            "to",
            "publish",
            "ether",
            "value",
            "prefix"
        ]
    },
    {
        "id": 3214,
        "code": "public void close() {\n    producer.close();\n    printJson(new ShutdownComplete());\n}",
        "summary_tokens": [
            "close",
            "the",
            "producer",
            "to",
            "flush",
            "any",
            "remaining",
            "messages"
        ]
    },
    {
        "id": 3215,
        "code": "TaskSpec rebaseTaskSpecTime(TaskSpec spec) throws Exception {\n    ObjectNode node = JsonUtil.JSON_SERDE.valueToTree(spec);\n    node.set(\"startMs\", new LongNode(Math.max(time.milliseconds(), spec.startMs())));\n    return JsonUtil.JSON_SERDE.treeToValue(node, TaskSpec.class);\n}",
        "summary_tokens": [
            "rebase",
            "the",
            "task",
            "spec",
            "time",
            "so",
            "that",
            "it",
            "is",
            "not",
            "earlier",
            "than",
            "the",
            "current",
            "time"
        ]
    },
    {
        "id": 3216,
        "code": "boolean exec(TaskSpec spec, PrintStream out) throws Exception {\n    TaskController controller = null;\n    try {\n        controller = spec.newController(EXEC_TASK_ID);\n    } catch (Exception e) {\n        out.println(\"Unable to create the task controller.\");\n        e.printStackTrace(out);\n        return false;\n    }\n    Set<String> nodes = controller.targetNodes(platform.topology());\n    if (!nodes.contains(platform.curNode().name())) {\n        out.println(\"This task is not configured to run on this node.  It runs on node(s): \" +\n            Utils.join(nodes, \", \") + \", whereas this node is \" +\n            platform.curNode().name());\n        return false;\n    }\n    KafkaFuture<String> future = null;\n    try {\n        future = workerManager.createWorker(EXEC_WORKER_ID, EXEC_TASK_ID, spec);\n    } catch (Throwable e) {\n        out.println(\"createWorker failed\");\n        e.printStackTrace(out);\n        return false;\n    }\n    out.println(\"Waiting for completion of task:\" + JsonUtil.toPrettyJsonString(spec));\n    String error = future.get();\n    if (error == null || error.isEmpty()) {\n        out.println(\"Task succeeded with status \" +\n            JsonUtil.toPrettyJsonString(workerManager.workerStates().get(EXEC_WORKER_ID).status()));\n        return true;\n    } else {\n        out.println(\"Task failed with status \" +\n            JsonUtil.toPrettyJsonString(workerManager.workerStates().get(EXEC_WORKER_ID).status()) +\n            \" and error \" + error);\n        return false;\n    }\n}",
        "summary_tokens": [
            "start",
            "a",
            "task",
            "on",
            "the",
            "agent",
            "and",
            "block",
            "until",
            "it",
            "completes"
        ]
    },
    {
        "id": 3217,
        "code": "    static boolean openBraceComesFirst(String input) {\n        for (int i = 0; i < input.length(); i++) {\n            char c = input.charAt(i);\n            if (!Character.isWhitespace(c)) {\n                return c == '{';\n            }\n        }\n        return false;\n    }\n\n    \n    public static <T> T objectFromCommandLineArgument(String argument, Class<T> clazz) throws Exception {\n        if (openBraceComesFirst(argument)) {\n            return JSON_SERDE.readValue(argument, clazz);\n        } else {\n            return JSON_SERDE.readValue(new File(argument), clazz);\n        }\n    }\n}",
        "summary_tokens": [
            "determine",
            "if",
            "a",
            "string",
            "is",
            "a",
            "json",
            "object",
            "literal"
        ]
    },
    {
        "id": 3218,
        "code": "public static <T> T objectFromCommandLineArgument(String argument, Class<T> clazz) throws Exception {\n    if (openBraceComesFirst(argument)) {\n        return JSON_SERDE.readValue(argument, clazz);\n    } else {\n        return JSON_SERDE.readValue(new File(argument), clazz);\n    }\n}",
        "summary_tokens": [
            "read",
            "a",
            "json",
            "object",
            "from",
            "a",
            "command",
            "line",
            "argument"
        ]
    },
    {
        "id": 3219,
        "code": "public static String dateString(long timeMs, ZoneOffset zoneOffset) {\n    return new Date(timeMs).toInstant().\n        atOffset(zoneOffset).\n        format(DateTimeFormatter.ISO_OFFSET_DATE_TIME);\n}",
        "summary_tokens": [
            "pretty",
            "print",
            "a",
            "date",
            "string"
        ]
    },
    {
        "id": 3220,
        "code": "public static String durationString(long periodMs) {\n    StringBuilder bld = new StringBuilder();\n    Duration duration = Duration.ofMillis(periodMs);\n    long hours = duration.toHours();\n    if (hours > 0) {\n        bld.append(hours).append(\"h\");\n        duration = duration.minusHours(hours);\n    }\n    long minutes = duration.toMinutes();\n    if (minutes > 0) {\n        bld.append(minutes).append(\"m\");\n        duration = duration.minusMinutes(minutes);\n    }\n    long seconds = duration.getSeconds();\n    if ((seconds != 0) || bld.toString().isEmpty()) {\n        bld.append(seconds).append(\"s\");\n    }\n    return bld.toString();\n}",
        "summary_tokens": [
            "pretty",
            "print",
            "a",
            "duration"
        ]
    },
    {
        "id": 3221,
        "code": "public static String prettyPrintGrid(List<List<String>> lines) {\n    int numColumns = -1;\n    int rowIndex = 0;\n    for (List<String> col : lines) {\n        if (numColumns == -1) {\n            numColumns = col.size();\n        } else if (numColumns != col.size()) {\n            throw new RuntimeException(\"Expected \" + numColumns + \" columns in row \" +\n                rowIndex + \", but got \" + col.size());\n        }\n        rowIndex++;\n    }\n    List<Integer> widths = new ArrayList<>(numColumns);\n    for (int x = 0; x < numColumns; x++) {\n        int w = 0;\n        for (List<String> cols : lines) {\n            w = Math.max(w, cols.get(x).length() + 1);\n        }\n        widths.add(w);\n    }\n    StringBuilder bld = new StringBuilder();\n    for (int y = 0; y < lines.size(); y++) {\n        List<String> cols = lines.get(y);\n        for (int x = 0; x < cols.size(); x++) {\n            String val = cols.get(x);\n            int minWidth = widths.get(x);\n            bld.append(val);\n            for (int i = 0; i < minWidth - val.length(); i++) {\n                bld.append(\" \");\n            }\n        }\n        bld.append(String.format(\"%n\"));\n    }\n    return bld.toString();\n}",
        "summary_tokens": [
            "formats",
            "strings",
            "in",
            "a",
            "grid",
            "pattern"
        ]
    },
    {
        "id": 3222,
        "code": "public static void abort(Logger log, String what, Throwable exception,\n        KafkaFutureImpl<String> doneFuture) throws KafkaException {\n    log.warn(\"{} caught an exception\", what, exception);\n    if (exception.getMessage() == null || exception.getMessage().isEmpty()) {\n        doneFuture.complete(exception.getClass().getCanonicalName());\n    } else {\n        doneFuture.complete(exception.getMessage());\n    }\n    throw new KafkaException(exception);\n}",
        "summary_tokens": [
            "handle",
            "an",
            "exception",
            "in",
            "a",
            "task",
            "worker"
        ]
    },
    {
        "id": 3223,
        "code": "public static int perSecToPerPeriod(float perSec, long periodMs) {\n    float period = ((float) periodMs) / 1000.0f;\n    float perPeriod = perSec * period;\n    perPeriod = Math.max(1.0f, perPeriod);\n    return (int) perPeriod;\n}",
        "summary_tokens": [
            "convert",
            "a",
            "rate",
            "expressed",
            "per",
            "second",
            "to",
            "a",
            "rate",
            "expressed",
            "per",
            "the",
            "given",
            "period"
        ]
    },
    {
        "id": 3224,
        "code": "public static void addConfigsToProperties(\n    Properties props, Map<String, String> commonConf, Map<String, String> clientConf) {\n    for (Map.Entry<String, String> commonEntry : commonConf.entrySet()) {\n        props.setProperty(commonEntry.getKey(), commonEntry.getValue());\n    }\n    for (Map.Entry<String, String> entry : clientConf.entrySet()) {\n        props.setProperty(entry.getKey(), entry.getValue());\n    }\n}",
        "summary_tokens": [
            "adds",
            "all",
            "properties",
            "from",
            "common",
            "conf",
            "and",
            "then",
            "from",
            "client",
            "conf",
            "to",
            "given",
            "props",
            "in",
            "that",
            "order",
            "over",
            "writing",
            "properties",
            "with",
            "the",
            "same",
            "keys"
        ]
    },
    {
        "id": 3225,
        "code": "private static Collection<String> createTopics(Logger log, Admin adminClient,\n                                               Collection<NewTopic> topics) throws Throwable {\n    long startMs = Time.SYSTEM.milliseconds();\n    int tries = 0;\n    List<String> existingTopics = new ArrayList<>();\n\n    Map<String, NewTopic> newTopics = new HashMap<>();\n    for (NewTopic newTopic : topics) {\n        newTopics.put(newTopic.name(), newTopic);\n    }\n    List<String> topicsToCreate = new ArrayList<>(newTopics.keySet());\n    while (true) {\n        log.info(\"Attempting to create {} topics (try {})...\", topicsToCreate.size(), ++tries);\n        Map<String, Future<Void>> creations = new HashMap<>();\n        while (!topicsToCreate.isEmpty()) {\n            List<NewTopic> newTopicsBatch = new ArrayList<>();\n            for (int i = 0; (i < MAX_CREATE_TOPICS_BATCH_SIZE) &&\n                            !topicsToCreate.isEmpty(); i++) {\n                String topicName = topicsToCreate.remove(0);\n                newTopicsBatch.add(newTopics.get(topicName));\n            }\n            creations.putAll(adminClient.createTopics(newTopicsBatch).values());\n        }\n            \n            \n        for (Map.Entry<String, Future<Void>> entry : creations.entrySet()) {\n            String topicName = entry.getKey();\n            Future<Void> future = entry.getValue();\n            try {\n                future.get();\n                log.debug(\"Successfully created {}.\", topicName);\n            } catch (Exception e) {\n                if ((e.getCause() instanceof TimeoutException)\n                    || (e.getCause() instanceof NotEnoughReplicasException)) {\n                    log.warn(\"Attempt to create topic `{}` failed: {}\", topicName,\n                             e.getCause().getMessage());\n                    topicsToCreate.add(topicName);\n                } else if (e.getCause() instanceof TopicExistsException) {\n                    log.info(\"Topic {} already exists.\", topicName);\n                    existingTopics.add(topicName);\n                } else {\n                    log.warn(\"Failed to create {}\", topicName, e.getCause());\n                    throw e.getCause();\n                }\n            }\n        }\n        if (topicsToCreate.isEmpty()) {\n            break;\n        }\n        if (Time.SYSTEM.milliseconds() > startMs + CREATE_TOPICS_CALL_TIMEOUT) {\n            String str = \"Unable to create topic(s): \" +\n                         Utils.join(topicsToCreate, \", \") + \"after \" + tries + \" attempt(s)\";\n            log.warn(str);\n            throw new TimeoutException(str);\n        }\n    }\n    return existingTopics;\n}",
        "summary_tokens": [
            "creates",
            "kafka",
            "topics",
            "and",
            "returns",
            "a",
            "list",
            "of",
            "topics",
            "that",
            "already",
            "exist",
            "log",
            "the",
            "logger",
            "to",
            "use",
            "admin",
            "client",
            "admin",
            "client",
            "topics",
            "list",
            "of",
            "topics",
            "to",
            "create",
            "collection",
            "of",
            "topics",
            "names",
            "that",
            "already",
            "exist"
        ]
    },
    {
        "id": 3226,
        "code": "static void verifyTopics(\n    Logger log, Admin adminClient,\n    Collection<String> topicsToVerify, Map<String, NewTopic> topicsInfo, int retryCount, long retryBackoffMs) throws Throwable {\n\n    Map<String, TopicDescription> topicDescriptionMap = topicDescriptions(topicsToVerify, adminClient,\n            retryCount, retryBackoffMs);\n\n    for (TopicDescription desc: topicDescriptionMap.values()) {\n            \n            \n        int partitions = topicsInfo.get(desc.name()).numPartitions();\n        if (partitions != CreateTopicsRequest.NO_NUM_PARTITIONS && desc.partitions().size() != partitions) {\n            String str = \"Topic '\" + desc.name() + \"' exists, but has \"\n                         + desc.partitions().size() + \" partitions, while requested \"\n                         + \" number of partitions is \" + partitions;\n            log.warn(str);\n            throw new RuntimeException(str);\n        }\n    }\n}",
        "summary_tokens": [
            "verifies",
            "that",
            "topics",
            "in",
            "topics",
            "to",
            "verify",
            "list",
            "have",
            "the",
            "same",
            "number",
            "of",
            "partitions",
            "as",
            "described",
            "in",
            "topics",
            "info",
            "log",
            "the",
            "logger",
            "to",
            "use",
            "admin",
            "client",
            "admin",
            "client",
            "topics",
            "to",
            "verify",
            "list",
            "of",
            "topics",
            "to",
            "verify",
            "topics",
            "info",
            "map",
            "of",
            "topic",
            "name",
            "to",
            "topic",
            "description",
            "which",
            "includes",
            "topics",
            "in",
            "topics",
            "to",
            "verify",
            "list"
        ]
    },
    {
        "id": 3227,
        "code": "static Collection<TopicPartition> getMatchingTopicPartitions(\n    Admin adminClient, String topicRegex, int startPartition, int endPartition)\n    throws Throwable {\n    final Pattern topicNamePattern = Pattern.compile(topicRegex);\n\n        \n    List<String> matchedTopics = new ArrayList<>();\n    ListTopicsResult res = adminClient.listTopics(\n        new ListTopicsOptions().timeoutMs(ADMIN_REQUEST_TIMEOUT));\n    Map<String, TopicListing> topicListingMap = res.namesToListings().get();\n    for (Map.Entry<String, TopicListing> topicListingEntry: topicListingMap.entrySet()) {\n        if (!topicListingEntry.getValue().isInternal()\n            && topicNamePattern.matcher(topicListingEntry.getKey()).matches()) {\n            matchedTopics.add(topicListingEntry.getKey());\n        }\n    }\n\n        \n    List<TopicPartition> out = new ArrayList<>();\n    DescribeTopicsResult topicsResult = adminClient.describeTopics(\n        matchedTopics, new DescribeTopicsOptions().timeoutMs(ADMIN_REQUEST_TIMEOUT));\n    Map<String, TopicDescription> topicDescriptionMap = topicsResult.allTopicNames().get();\n    for (TopicDescription desc: topicDescriptionMap.values()) {\n        List<TopicPartitionInfo> partitions = desc.partitions();\n        for (TopicPartitionInfo info: partitions) {\n            if ((info.partition() >= startPartition) && (info.partition() <= endPartition)) {\n                out.add(new TopicPartition(desc.name(), info.partition()));\n            }\n        }\n    }\n    return out;\n}",
        "summary_tokens": [
            "returns",
            "list",
            "of",
            "existing",
            "not",
            "internal",
            "topics",
            "partitions",
            "that",
            "match",
            "given",
            "pattern",
            "and",
            "where",
            "partitions",
            "are",
            "in",
            "range",
            "start",
            "partition",
            "end",
            "partition",
            "admin",
            "client",
            "admin",
            "client",
            "topic",
            "regex",
            "topic",
            "regular",
            "expression",
            "to",
            "match",
            "list",
            "of",
            "topic",
            "names",
            "throwable",
            "if",
            "failed",
            "to",
            "get",
            "list",
            "of",
            "existing",
            "topics"
        ]
    },
    {
        "id": 3228,
        "code": "void rescheduleNextHeartbeat(long initialDelayMs) {\n    if (this.heartbeatFuture != null) {\n        this.heartbeatFuture.cancel(false);\n    }\n    this.heartbeatFuture = this.executor.scheduleAtFixedRate(heartbeat,\n        initialDelayMs, HEARTBEAT_DELAY_MS, TimeUnit.MILLISECONDS);\n}",
        "summary_tokens": [
            "reschedule",
            "the",
            "heartbeat",
            "runnable"
        ]
    },
    {
        "id": 3229,
        "code": "public void createWorker(long workerId, String taskId, TaskSpec spec) {\n    executor.submit(new CreateWorker(workerId, taskId, spec));\n}",
        "summary_tokens": [
            "create",
            "a",
            "new",
            "worker"
        ]
    },
    {
        "id": 3230,
        "code": "public void updateWorkerState(String nodeName, long workerId, WorkerState state) {\n    executor.submit(new UpdateWorkerState(nodeName, workerId, state));\n}",
        "summary_tokens": [
            "update",
            "the",
            "state",
            "of",
            "a",
            "particular",
            "agent",
            "s",
            "worker"
        ]
    },
    {
        "id": 3231,
        "code": "private void handleWorkerCompletion(ManagedTask task, String nodeName, WorkerDone state) {\n    if (state.error().isEmpty()) {\n        log.info(\"{}: Worker {} finished with status '{}'\",\n            nodeName, task.id, JsonUtil.toJsonString(state.status()));\n    } else {\n        log.warn(\"{}: Worker {} finished with error '{}' and status '{}'\",\n            nodeName, task.id, state.error(), JsonUtil.toJsonString(state.status()));\n        task.maybeSetError(state.error());\n    }\n    TreeMap<String, Long> activeWorkerIds = task.activeWorkerIds();\n    if (activeWorkerIds.isEmpty()) {\n        task.doneMs = time.milliseconds();\n        task.state = TaskStateType.DONE;\n        log.info(\"{}: Task {} is now complete on {} with error: {}\",\n            nodeName, task.id, Utils.join(task.workerIds.keySet(), \", \"),\n            task.error.isEmpty() ? \"(none)\" : task.error);\n    } else if ((task.state == TaskStateType.RUNNING) && (!task.error.isEmpty())) {\n        log.info(\"{}: task {} stopped with error {}.  Stopping worker(s): {}\",\n            nodeName, task.id, task.error, Utils.mkString(activeWorkerIds, \"{\", \"}\", \": \", \", \"));\n        task.state = TaskStateType.STOPPING;\n        for (Map.Entry<String, Long> entry : activeWorkerIds.entrySet()) {\n            nodeManagers.get(entry.getKey()).stopWorker(entry.getValue());\n        }\n    }\n}",
        "summary_tokens": [
            "handle",
            "a",
            "worker",
            "being",
            "completed"
        ]
    },
    {
        "id": 3232,
        "code": "public TasksResponse tasks(TasksRequest request) throws ExecutionException, InterruptedException {\n    return executor.submit(new GetTasksResponse(request)).get();\n}",
        "summary_tokens": [
            "get",
            "information",
            "about",
            "the",
            "tasks",
            "being",
            "managed"
        ]
    },
    {
        "id": 3233,
        "code": "public TaskState task(TaskRequest request) throws ExecutionException, InterruptedException {\n    return executor.submit(new GetTaskState(request)).get();\n}",
        "summary_tokens": [
            "get",
            "information",
            "about",
            "a",
            "single",
            "task",
            "being",
            "managed"
        ]
    },
    {
        "id": 3234,
        "code": "public void beginShutdown(boolean stopAgents) {\n    if (shutdown.compareAndSet(false, true)) {\n        executor.submit(new Shutdown(stopAgents));\n    }\n}",
        "summary_tokens": [
            "initiate",
            "shutdown",
            "but",
            "do",
            "not",
            "wait",
            "for",
            "it",
            "to",
            "complete"
        ]
    },
    {
        "id": 3235,
        "code": "public void waitForShutdown() throws InterruptedException {\n    while (!executor.awaitTermination(1, TimeUnit.DAYS)) { }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "shutdown",
            "to",
            "complete"
        ]
    },
    {
        "id": 3236,
        "code": "private void enableTrafficControl(Platform platform, String networkDevice, int delayMs, int rateLimitKbps) throws IOException {\n    if (delayMs > 0) {\n        int deviationMs = Math.max(1, (int) Math.sqrt(delayMs));\n        List<String> delay = new ArrayList<>();\n        rootHandler(networkDevice, delay::add);\n        netemDelay(delayMs, deviationMs, delay::add);\n        platform.runCommand(delay.toArray(new String[0]));\n\n        if (rateLimitKbps > 0) {\n            List<String> rate = new ArrayList<>();\n            childHandler(networkDevice, rate::add);\n            tbfRate(rateLimitKbps, rate::add);\n            platform.runCommand(rate.toArray(new String[0]));\n        }\n    } else if (rateLimitKbps > 0) {\n        List<String> rate = new ArrayList<>();\n        rootHandler(networkDevice, rate::add);\n        tbfRate(rateLimitKbps, rate::add);\n        platform.runCommand(rate.toArray(new String[0]));\n    } else {\n        log.warn(\"Not applying any rate limiting or latency\");\n    }\n}",
        "summary_tokens": [
            "constructs",
            "the",
            "appropriate",
            "tc",
            "commands",
            "to",
            "apply",
            "latency",
            "and",
            "rate",
            "limiting",
            "if",
            "they",
            "are",
            "non",
            "zero"
        ]
    },
    {
        "id": 3237,
        "code": "private void rootHandler(String networkDevice, Consumer<String> consumer) {\n    Stream.of(\"sudo\", \"tc\", \"qdisc\", \"add\", \"dev\", networkDevice, \"root\", \"handle\", \"1:0\").forEach(consumer);\n}",
        "summary_tokens": [
            "construct",
            "the",
            "first",
            "part",
            "of",
            "a",
            "tc",
            "command",
            "to",
            "define",
            "a",
            "qdisc",
            "root",
            "handler",
            "for",
            "the",
            "given",
            "network",
            "interface"
        ]
    },
    {
        "id": 3238,
        "code": "private void childHandler(String networkDevice, Consumer<String> consumer) {\n    Stream.of(\"sudo\", \"tc\", \"qdisc\", \"add\", \"dev\", networkDevice, \"parent\", \"1:1\", \"handle\", \"10:\").forEach(consumer);\n}",
        "summary_tokens": [
            "construct",
            "the",
            "first",
            "part",
            "of",
            "a",
            "tc",
            "command",
            "to",
            "define",
            "a",
            "qdisc",
            "child",
            "handler",
            "for",
            "the",
            "given",
            "interface"
        ]
    },
    {
        "id": 3239,
        "code": "private void netemDelay(int delayMs, int deviationMs, Consumer<String> consumer) {\n    Stream.of(\"netem\", \"delay\", String.format(\"%dms\", delayMs), String.format(\"%dms\", deviationMs),\n            \"distribution\", \"paretonormal\").forEach(consumer);\n}",
        "summary_tokens": [
            "construct",
            "the",
            "second",
            "part",
            "of",
            "a",
            "tc",
            "command",
            "that",
            "defines",
            "a",
            "netem",
            "network",
            "emulator",
            "filter",
            "that",
            "will",
            "apply",
            "some",
            "amount",
            "of",
            "latency",
            "with",
            "a",
            "small",
            "amount",
            "of",
            "deviation"
        ]
    },
    {
        "id": 3240,
        "code": "private void tbfRate(int rateLimitKbit, Consumer<String> consumer) {\n    Stream.of(\"tbf\", \"rate\", String.format(\"%dkbit\", rateLimitKbit), \"burst\", \"1mbit\", \"latency\", \"500ms\").forEach(consumer);\n}",
        "summary_tokens": [
            "construct",
            "the",
            "second",
            "part",
            "of",
            "a",
            "tc",
            "command",
            "that",
            "defines",
            "a",
            "tbf",
            "token",
            "buffer",
            "filter",
            "that",
            "will",
            "rate",
            "limit",
            "the",
            "packets",
            "going",
            "through",
            "a",
            "qdisc"
        ]
    },
    {
        "id": 3241,
        "code": "private void disableTrafficControl(Platform platform, String networkDevice) throws IOException {\n    platform.runCommand(new String[] {\n        \"sudo\", \"tc\", \"qdisc\", \"del\", \"dev\", networkDevice, \"root\"\n    });\n}",
        "summary_tokens": [
            "delete",
            "any",
            "previously",
            "defined",
            "qdisc",
            "for",
            "the",
            "given",
            "network",
            "interface"
        ]
    },
    {
        "id": 3242,
        "code": "private synchronized KiboshProcess findProcessObject(String mountPath) {\n    String path = Paths.get(mountPath).normalize().toString();\n    KiboshProcess process = processes.get(path);\n    if (process == null) {\n        process = new KiboshProcess(mountPath);\n        processes.put(path, process);\n    }\n    return process;\n}",
        "summary_tokens": [
            "get",
            "or",
            "create",
            "a",
            "kibosh",
            "process",
            "object",
            "to",
            "manage",
            "the",
            "kibosh",
            "process",
            "at",
            "a",
            "given",
            "path"
        ]
    },
    {
        "id": 3243,
        "code": "void addFault(String mountPath, KiboshFaultSpec spec) throws IOException {\n    KiboshProcess process = findProcessObject(mountPath);\n    process.addFault(spec);\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "kibosh",
            "fault"
        ]
    },
    {
        "id": 3244,
        "code": "void removeFault(String mountPath, KiboshFaultSpec spec) throws IOException {\n    KiboshProcess process = findProcessObject(mountPath);\n    process.removeFault(spec);\n}",
        "summary_tokens": [
            "remove",
            "a",
            "kibosh",
            "fault"
        ]
    },
    {
        "id": 3245,
        "code": "public void start(Object... resources) {\n    log.info(\"Starting REST server\");\n    ResourceConfig resourceConfig = new ResourceConfig();\n    resourceConfig.register(new JacksonJsonProvider(JsonUtil.JSON_SERDE));\n    for (Object resource : resources) {\n        resourceConfig.register(resource);\n        log.info(\"Registered resource {}\", resource);\n    }\n    resourceConfig.register(RestExceptionMapper.class);\n    ServletContainer servletContainer = new ServletContainer(resourceConfig);\n    ServletHolder servletHolder = new ServletHolder(servletContainer);\n    ServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS);\n    context.setContextPath(\"/\");\n    context.addServlet(servletHolder, \"/*\");\n\n    RequestLogHandler requestLogHandler = new RequestLogHandler();\n    Slf4jRequestLogWriter slf4jRequestLogWriter = new Slf4jRequestLogWriter();\n    slf4jRequestLogWriter.setLoggerName(JsonRestServer.class.getCanonicalName());\n    CustomRequestLog requestLog = new CustomRequestLog(slf4jRequestLogWriter, CustomRequestLog.EXTENDED_NCSA_FORMAT + \" %{ms}T\");\n    requestLogHandler.setRequestLog(requestLog);\n\n    HandlerCollection handlers = new HandlerCollection();\n    handlers.setHandlers(new Handler[]{context, new DefaultHandler(), requestLogHandler});\n    StatisticsHandler statsHandler = new StatisticsHandler();\n    statsHandler.setHandler(handlers);\n    jettyServer.setHandler(statsHandler);\n        \n    jettyServer.setStopTimeout(GRACEFUL_SHUTDOWN_TIMEOUT_MS);\n    jettyServer.setStopAtShutdown(true);\n\n    try {\n        jettyServer.start();\n    } catch (Exception e) {\n        throw new RuntimeException(\"Unable to start REST server\", e);\n    }\n    log.info(\"REST server listening at \" + jettyServer.getURI());\n}",
        "summary_tokens": [
            "start",
            "the",
            "json",
            "rest",
            "server"
        ]
    },
    {
        "id": 3246,
        "code": "public void beginShutdown() {\n    if (!shutdownExecutor.isShutdown()) {\n        shutdownExecutor.submit((Callable<Void>) () -> {\n            try {\n                log.info(\"Stopping REST server\");\n                jettyServer.stop();\n                jettyServer.join();\n                log.info(\"REST server stopped\");\n            } catch (Exception e) {\n                log.error(\"Unable to stop REST server\", e);\n            } finally {\n                jettyServer.destroy();\n            }\n            shutdownExecutor.shutdown();\n            return null;\n        });\n    }\n}",
        "summary_tokens": [
            "initiate",
            "shutdown",
            "but",
            "do",
            "not",
            "wait",
            "for",
            "it",
            "to",
            "complete"
        ]
    },
    {
        "id": 3247,
        "code": "public void waitForShutdown() throws InterruptedException {\n    while (!shutdownExecutor.isShutdown()) {\n        shutdownExecutor.awaitTermination(1, TimeUnit.DAYS);\n    }\n}",
        "summary_tokens": [
            "wait",
            "for",
            "shutdown",
            "to",
            "complete"
        ]
    },
    {
        "id": 3248,
        "code": "public static <T> HttpResponse<T> httpRequest(Logger logger, String url, String method,\n        Object requestBodyData, TypeReference<T> responseFormat, int maxTries)\n        throws IOException, InterruptedException {\n    IOException exc = null;\n    for (int tries = 0; tries < maxTries; tries++) {\n        if (tries > 0) {\n            Thread.sleep(tries > 1 ? 10 : 2);\n        }\n        try {\n            return httpRequest(logger, url, method, requestBodyData, responseFormat);\n        } catch (IOException e) {\n            logger.info(\"{} {}: error: {}\", method, url, e.getMessage());\n            exc = e;\n        }\n    }\n    throw exc;\n}",
        "summary_tokens": [
            "make",
            "an",
            "http",
            "request",
            "with",
            "retries"
        ]
    },
    {
        "id": 3249,
        "code": "public boolean matches(String taskId, long startMs, long endMs, TaskStateType state) {\n    if ((!taskIds.isEmpty()) && (!taskIds.contains(taskId))) {\n        return false;\n    }\n    if ((firstStartMs > 0) && (startMs < firstStartMs)) {\n        return false;\n    }\n    if ((lastStartMs > 0) && ((startMs < 0) || (startMs > lastStartMs))) {\n        return false;\n    }\n    if ((firstEndMs > 0) && (endMs < firstEndMs)) {\n        return false;\n    }\n    if ((lastEndMs > 0) && ((endMs < 0) || (endMs > lastEndMs))) {\n        return false;\n    }\n\n    if (this.state.isPresent() && !this.state.get().equals(state)) {\n        return false;\n    }\n\n    return true;\n}",
        "summary_tokens": [
            "determine",
            "if",
            "this",
            "task",
            "request",
            "should",
            "return",
            "a",
            "particular",
            "task"
        ]
    },
    {
        "id": 3250,
        "code": "public final long startMs() {\n    return startMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "target",
            "start",
            "time",
            "of",
            "this",
            "task",
            "in",
            "ms"
        ]
    },
    {
        "id": 3251,
        "code": "public final long endMs() {\n    return startMs + durationMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "deadline",
            "time",
            "of",
            "this",
            "task",
            "in",
            "ms"
        ]
    },
    {
        "id": 3252,
        "code": "public final long durationMs() {\n    return durationMs;\n}",
        "summary_tokens": [
            "get",
            "the",
            "duration",
            "of",
            "this",
            "task",
            "in",
            "ms"
        ]
    },
    {
        "id": 3253,
        "code": "Map<String, List<TopicPartition>> materializeTopics() {\n    Map<String, List<TopicPartition>> partitionsByTopics = new HashMap<>();\n\n    for (String rawTopicName : this.activeTopics) {\n        Set<String> expandedNames = expandTopicName(rawTopicName);\n        if (!expandedNames.iterator().next().matches(VALID_EXPANDED_TOPIC_NAME_PATTERN))\n            throw new IllegalArgumentException(String.format(\"Expanded topic name %s is invalid\", rawTopicName));\n\n        for (String topicName : expandedNames) {\n            TopicPartition partition = null;\n            if (topicName.contains(\":\")) {\n                String[] topicAndPartition = topicName.split(\":\");\n                topicName = topicAndPartition[0];\n                partition = new TopicPartition(topicName, Integer.parseInt(topicAndPartition[1]));\n            }\n            if (!partitionsByTopics.containsKey(topicName)) {\n                partitionsByTopics.put(topicName, new ArrayList<>());\n            }\n            if (partition != null) {\n                partitionsByTopics.get(topicName).add(partition);\n            }\n        }\n    }\n\n    return partitionsByTopics;\n}",
        "summary_tokens": [
            "materializes",
            "a",
            "list",
            "of",
            "topic",
            "names",
            "optionally",
            "with",
            "ranges",
            "into",
            "a",
            "map",
            "of",
            "the",
            "topics",
            "and",
            "their",
            "partitions"
        ]
    },
    {
        "id": 3254,
        "code": "private Set<String> expandTopicName(String topicName) {\n    Set<String> expandedNames = StringExpander.expand(topicName);\n    if (expandedNames.size() == 1) {\n        return expandedNames;\n    }\n\n    Set<String> newNames = new HashSet<>();\n    for (String name : expandedNames) {\n        newNames.addAll(expandTopicName(name));\n    }\n    return newNames;\n}",
        "summary_tokens": [
            "expands",
            "a",
            "topic",
            "name",
            "until",
            "there",
            "are",
            "no",
            "more",
            "ranges",
            "in",
            "it"
        ]
    },
    {
        "id": 3255,
        "code": "public void add(long value) {\n    if (value > Integer.MAX_VALUE) {\n        add(Integer.MAX_VALUE);\n    } else if (value < Integer.MIN_VALUE) {\n        add(Integer.MIN_VALUE);\n    } else {\n        add((int) value);\n    }\n}",
        "summary_tokens": [
            "add",
            "a",
            "new",
            "value",
            "to",
            "the",
            "histogram"
        ]
    },
    {
        "id": 3256,
        "code": "public Map<String, PartitionsSpec> materialize() {\n    HashMap<String, PartitionsSpec> all = new HashMap<>();\n    for (Map.Entry<String, PartitionsSpec> entry : map.entrySet()) {\n        String topicName = entry.getKey();\n        PartitionsSpec partitions = entry.getValue();\n        for (String expandedTopicName : StringExpander.expand(topicName))\n            all.put(expandedTopicName, partitions);\n    }\n    return all;\n}",
        "summary_tokens": [
            "enumerate",
            "the",
            "partitions",
            "inside",
            "this",
            "topics",
            "spec"
        ]
    },
    {
        "id": 3257,
        "code": "public void restartAgent(String nodeName) {\n    if (!agents.containsKey(nodeName)) {\n        throw new RuntimeException(\"There is no agent on node \" + nodeName);\n    }\n    Builder.NodeData node = nodesByAgent.get(nodeName);\n    agents.put(nodeName, new Agent(node.platform, scheduler, node.agentRestServer, node.agentRestResource));\n}",
        "summary_tokens": [
            "mimic",
            "a",
            "restart",
            "of",
            "a",
            "trogdor",
            "agent",
            "essentially",
            "cleaning",
            "out",
            "all",
            "of",
            "its",
            "active",
            "workers"
        ]
    },
    {
        "id": 3258,
        "code": "public void testAgentFailureAndTaskExpiry() throws Exception {\n    MockTime time = new MockTime(0, 0, 0);\n    Scheduler scheduler = new MockScheduler(time);\n    try (MiniTrogdorCluster cluster = new MiniTrogdorCluster.Builder().\n        addCoordinator(\"node01\").\n        addAgent(\"node02\").\n        scheduler(scheduler).\n        build()) {\n        CoordinatorClient coordinatorClient = cluster.coordinatorClient();\n\n        NoOpTaskSpec fooSpec = new NoOpTaskSpec(1, 500);\n        coordinatorClient.createTask(new CreateTaskRequest(\"foo\", fooSpec));\n        TaskState expectedState = new ExpectedTaskBuilder(\"foo\").taskState(new TaskPending(fooSpec)).build().taskState();\n\n        TaskState resp = coordinatorClient.task(new TaskRequest(\"foo\"));\n        assertEquals(expectedState, resp);\n\n\n        time.sleep(2);\n        new ExpectedTasks().\n            addTask(new ExpectedTaskBuilder(\"foo\").\n                taskState(new TaskRunning(fooSpec, 2, new TextNode(\"active\"))).\n                workerState(new WorkerRunning(\"foo\", fooSpec, 2, new TextNode(\"active\"))).\n                build()).\n            waitFor(coordinatorClient).\n            waitFor(cluster.agentClient(\"node02\"));\n\n        cluster.restartAgent(\"node02\");\n        time.sleep(550);\n            \n        new ExpectedTasks().\n            addTask(new ExpectedTaskBuilder(\"foo\").\n                taskState(new TaskDone(fooSpec, 2, 552, \"worker expired\", false, null)).\n                workerState(new WorkerDone(\"foo\", fooSpec, 552, 552, null, \"worker expired\")).\n                build()).\n            waitFor(coordinatorClient).\n            waitFor(cluster.agentClient(\"node02\"));\n\n        cluster.restartAgent(\"node02\");\n            \n        new ExpectedTasks().\n            addTask(new ExpectedTaskBuilder(\"foo\").\n                taskState(new TaskDone(fooSpec, 2, 552, \"worker expired\", false, null)).\n                    \n                build()).\n            waitFor(coordinatorClient).\n            waitFor(cluster.agentClient(\"node02\"));\n    }\n}",
        "summary_tokens": [
            "if",
            "an",
            "agent",
            "fails",
            "in",
            "the",
            "middle",
            "of",
            "a",
            "task",
            "and",
            "comes",
            "back",
            "up",
            "when",
            "the",
            "task",
            "is",
            "considered",
            "expired",
            "we",
            "want",
            "the",
            "task",
            "to",
            "be",
            "marked",
            "as",
            "done",
            "and",
            "not",
            "re",
            "sent",
            "should",
            "a",
            "second",
            "failure",
            "happen"
        ]
    },
    {
        "id": 3259,
        "code": "public void testProcessWithNormalExit() throws Exception {\n    if (OperatingSystem.IS_WINDOWS) return;\n    ExternalCommandWorker worker =\n        new ExternalCommandWorkerBuilder(\"trueTask\").command(\"true\").build();\n    KafkaFutureImpl<String> doneFuture = new KafkaFutureImpl<>();\n    worker.start(null, new AgentWorkerStatusTracker(), doneFuture);\n    assertEquals(\"\", doneFuture.get());\n    worker.stop(null);\n}",
        "summary_tokens": [
            "test",
            "running",
            "a",
            "process",
            "which",
            "exits",
            "successfully",
            "in",
            "this",
            "case",
            "bin",
            "true"
        ]
    },
    {
        "id": 3260,
        "code": "public void testProcessWithFailedExit() throws Exception {\n    if (OperatingSystem.IS_WINDOWS) return;\n    ExternalCommandWorker worker =\n        new ExternalCommandWorkerBuilder(\"falseTask\").command(\"false\").build();\n    KafkaFutureImpl<String> doneFuture = new KafkaFutureImpl<>();\n    worker.start(null, new AgentWorkerStatusTracker(), doneFuture);\n    assertEquals(\"exited with return code 1\", doneFuture.get());\n    worker.stop(null);\n}",
        "summary_tokens": [
            "test",
            "running",
            "a",
            "process",
            "which",
            "exits",
            "unsuccessfully",
            "in",
            "this",
            "case",
            "bin",
            "false"
        ]
    },
    {
        "id": 3261,
        "code": "public void testProcessNotFound() throws Exception {\n    ExternalCommandWorker worker =\n        new ExternalCommandWorkerBuilder(\"notFoundTask\").\n            command(\"/dev/null/non/existent/script/path\").build();\n    KafkaFutureImpl<String> doneFuture = new KafkaFutureImpl<>();\n    worker.start(null, new AgentWorkerStatusTracker(), doneFuture);\n    String errorString = doneFuture.get();\n    assertTrue(errorString.startsWith(\"Unable to start process\"));\n    worker.stop(null);\n}",
        "summary_tokens": [
            "test",
            "attempting",
            "to",
            "run",
            "an",
            "executable",
            "which",
            "doesn",
            "t",
            "exist"
        ]
    },
    {
        "id": 3262,
        "code": "public void testProcessStop() throws Exception {\n    if (OperatingSystem.IS_WINDOWS) return;\n    ExternalCommandWorker worker =\n        new ExternalCommandWorkerBuilder(\"testStopTask\").\n            command(\"sleep\", \"3600000\").build();\n    KafkaFutureImpl<String> doneFuture = new KafkaFutureImpl<>();\n    worker.start(null, new AgentWorkerStatusTracker(), doneFuture);\n    worker.stop(null);\n        \n        \n    assertTrue(doneFuture.get().startsWith(\"exited with return code \"));\n}",
        "summary_tokens": [
            "test",
            "running",
            "a",
            "process",
            "which",
            "times",
            "out"
        ]
    },
    {
        "id": 3263,
        "code": "public void testProcessForceKillTimeout() throws Exception {\n    if (OperatingSystem.IS_WINDOWS) return;\n    File tempFile = null;\n    try {\n        tempFile = TestUtils.tempFile();\n        try (OutputStream stream = Files.newOutputStream(tempFile.toPath())) {\n            for (String line : new String[] {\n                \"echo hello world\\n\",\n                \"# Test that the initial message is sent correctly.\\n\",\n                \"read -r line\\n\",\n                \"[[ $line == '{\\\"id\\\":\\\"testForceKillTask\\\",\\\"workload\\\":{\\\"foo\\\":\\\"value1\\\",\\\"bar\\\":123}}' ]] || exit 0\\n\",\n                \"\\n\",\n                \"# Ignore SIGTERM signals.  This ensures that we test SIGKILL delivery.\\n\",\n                \"trap 'echo SIGTERM' SIGTERM\\n\",\n                \"\\n\",\n                \"# Update the process status.  This will also unblock the junit test.\\n\",\n                \"# It is important that we do this after we disabled SIGTERM, to ensure\\n\",\n                \"# that we are testing SIGKILL.\\n\",\n                \"echo '{\\\"status\\\": \\\"green\\\", \\\"log\\\": \\\"my log message.\\\"}'\\n\",\n                \"\\n\",\n                \"# Wait for the SIGKILL.\\n\",\n                \"while true; do sleep 0.01; done\\n\"}) {\n                stream.write(line.getBytes(StandardCharsets.UTF_8));\n            }\n        }\n        CompletableFuture<String> statusFuture = new CompletableFuture<>();\n        final WorkerStatusTracker statusTracker = status -> statusFuture .complete(status.textValue());\n        ExternalCommandWorker worker = new ExternalCommandWorkerBuilder(\"testForceKillTask\").\n            shutdownGracePeriodMs(1).\n            command(\"bash\", tempFile.getAbsolutePath()).\n            build();\n        KafkaFutureImpl<String> doneFuture = new KafkaFutureImpl<>();\n        worker.start(null, statusTracker, doneFuture);\n        assertEquals(\"green\", statusFuture.get());\n        worker.stop(null);\n        assertTrue(doneFuture.get().startsWith(\"exited with return code \"));\n    } finally {\n        if (tempFile != null) {\n            Files.delete(tempFile.toPath());\n        }\n    }\n}",
        "summary_tokens": [
            "test",
            "running",
            "a",
            "process",
            "which",
            "needs",
            "to",
            "be",
            "force",
            "killed"
        ]
    }
]